{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Manual da Engenharia para Codar Um engenheiro ou cientista de dados trabalhando em um projeto da Engenharia ... Tem responsabilidades para com sua equipe \u2013 mentorar, treinar e liderar. Conhece seu manual . Segue seu manual. Corrige seu manual se ele estiver quebrado. Se encontrar um manual melhor, copia-o. Se algu\u00e9m puder usar seu manual, d\u00ea o seu. Lidera pelo exemplo. Modela os comportamentos que desejamos tanto interpessoalmente quanto tecnicamente. Esfor\u00e7a-se para entender como seu trabalho se encaixa em um contexto mais amplo e garante o resultado. Este \u00e9 o nosso manual. Todas as contribui\u00e7\u00f5es s\u00e3o bem-vindas! Sinta-se \u00e0 vontade para enviar um pull request para se envolver. Nota: Se voc\u00ea est\u00e1 lendo isso no GitHub - v\u00e1 para https://microsoft.github.io/code-with-engineering-playbook/ para uma melhor experi\u00eancia de leitura Por que ter um Manual Para aumentar a efici\u00eancia geral dos membros da equipe e da equipe como um todo. Reduzir o n\u00famero de erros e evitar armadilhas comuns. Esfor\u00e7ar-se para ser um engenheiro melhor e aprender com a experi\u00eancia compartilhada de outras pessoas. \"A\" Lista de Verifica\u00e7\u00e3o Se voc\u00ea n\u00e3o fizer mais nada, siga a Lista de Verifica\u00e7\u00e3o dos Fundamentos de Engenharia ! Ela est\u00e1 aqui para ajudar a seguir os Fundamentos de Engenharia. Estrutura de um Sprint Uma divis\u00e3o de se\u00e7\u00f5es de acordo com a estrutura de um sprint \u00e1gil. Orienta\u00e7\u00e3o Geral Mantenha o padr\u00e3o de qualidade do c\u00f3digo elevado. Valorize a qualidade e a precis\u00e3o em detrimento de 'fazer as coisas'. Trabalhe diligentemente na coisa mais importante. Como uma equipe distribu\u00edda, reserve um tempo para compartilhar o contexto via wiki, equipes e itens de backlog. Fa\u00e7a a coisa simples funcionar agora. Construa menos recursos hoje, mas garanta que eles funcionem incrivelmente bem. Depois adicione mais recursos amanh\u00e3. Evite adicionar escopo a um item de backlog, em vez disso, adicione um novo item de backlog. Nosso objetivo \u00e9 enviar valor incremental ao cliente. Mantenha os detalhes do item de backlog atualizados para comunicar o estado das coisas com o resto de sua equipe. Relate problemas de produto encontrados e forne\u00e7a feedback de engenharia claro e repet\u00edvel! Todos n\u00f3s somos propriet\u00e1rios de nosso c\u00f3digo e cada um de n\u00f3s tem a obriga\u00e7\u00e3o de tornar todas as partes da solu\u00e7\u00e3o excelentes. Links R\u00e1pidos Lista de Verifica\u00e7\u00e3o dos Fundamentos de Engenharia Estrutura de um Sprint Fundamentos de Engenharia Acessibilidade Desenvolvimento \u00c1gil Testes Automatizados Revis\u00f5es de C\u00f3digo Entrega Cont\u00ednua (CD) Integra\u00e7\u00e3o Cont\u00ednua (CI) Design Experi\u00eancia do Desenvolvedor Documenta\u00e7\u00e3o Feedback de Engenharia Observabilidade Seguran\u00e7a Privacidade Controle de Fonte Confiabilidade Fundamentos para \u00c1reas Tecnol\u00f3gicas Espec\u00edficas Fundamentos de Aprendizado de M\u00e1quina Engenharia de Interface do Usu\u00e1rio Contribuindo Veja CONTRIBUTING.md para diretrizes de contribui\u00e7\u00e3o.","title":"Manual da Engenharia para Codar"},{"location":"#manual-da-engenharia-para-codar","text":"Um engenheiro ou cientista de dados trabalhando em um projeto da Engenharia ... Tem responsabilidades para com sua equipe \u2013 mentorar, treinar e liderar. Conhece seu manual . Segue seu manual. Corrige seu manual se ele estiver quebrado. Se encontrar um manual melhor, copia-o. Se algu\u00e9m puder usar seu manual, d\u00ea o seu. Lidera pelo exemplo. Modela os comportamentos que desejamos tanto interpessoalmente quanto tecnicamente. Esfor\u00e7a-se para entender como seu trabalho se encaixa em um contexto mais amplo e garante o resultado. Este \u00e9 o nosso manual. Todas as contribui\u00e7\u00f5es s\u00e3o bem-vindas! Sinta-se \u00e0 vontade para enviar um pull request para se envolver. Nota: Se voc\u00ea est\u00e1 lendo isso no GitHub - v\u00e1 para https://microsoft.github.io/code-with-engineering-playbook/ para uma melhor experi\u00eancia de leitura","title":"Manual da Engenharia para Codar"},{"location":"#por-que-ter-um-manual","text":"Para aumentar a efici\u00eancia geral dos membros da equipe e da equipe como um todo. Reduzir o n\u00famero de erros e evitar armadilhas comuns. Esfor\u00e7ar-se para ser um engenheiro melhor e aprender com a experi\u00eancia compartilhada de outras pessoas.","title":"Por que ter um Manual"},{"location":"#a-lista-de-verificacao","text":"Se voc\u00ea n\u00e3o fizer mais nada, siga a Lista de Verifica\u00e7\u00e3o dos Fundamentos de Engenharia ! Ela est\u00e1 aqui para ajudar a seguir os Fundamentos de Engenharia.","title":"\"A\" Lista de Verifica\u00e7\u00e3o"},{"location":"#estrutura-de-um-sprint","text":"Uma divis\u00e3o de se\u00e7\u00f5es de acordo com a estrutura de um sprint \u00e1gil.","title":"Estrutura de um Sprint"},{"location":"#orientacao-geral","text":"Mantenha o padr\u00e3o de qualidade do c\u00f3digo elevado. Valorize a qualidade e a precis\u00e3o em detrimento de 'fazer as coisas'. Trabalhe diligentemente na coisa mais importante. Como uma equipe distribu\u00edda, reserve um tempo para compartilhar o contexto via wiki, equipes e itens de backlog. Fa\u00e7a a coisa simples funcionar agora. Construa menos recursos hoje, mas garanta que eles funcionem incrivelmente bem. Depois adicione mais recursos amanh\u00e3. Evite adicionar escopo a um item de backlog, em vez disso, adicione um novo item de backlog. Nosso objetivo \u00e9 enviar valor incremental ao cliente. Mantenha os detalhes do item de backlog atualizados para comunicar o estado das coisas com o resto de sua equipe. Relate problemas de produto encontrados e forne\u00e7a feedback de engenharia claro e repet\u00edvel! Todos n\u00f3s somos propriet\u00e1rios de nosso c\u00f3digo e cada um de n\u00f3s tem a obriga\u00e7\u00e3o de tornar todas as partes da solu\u00e7\u00e3o excelentes.","title":"Orienta\u00e7\u00e3o Geral"},{"location":"#links-rapidos","text":"Lista de Verifica\u00e7\u00e3o dos Fundamentos de Engenharia Estrutura de um Sprint","title":"Links R\u00e1pidos"},{"location":"#fundamentos-de-engenharia","text":"Acessibilidade Desenvolvimento \u00c1gil Testes Automatizados Revis\u00f5es de C\u00f3digo Entrega Cont\u00ednua (CD) Integra\u00e7\u00e3o Cont\u00ednua (CI) Design Experi\u00eancia do Desenvolvedor Documenta\u00e7\u00e3o Feedback de Engenharia Observabilidade Seguran\u00e7a Privacidade Controle de Fonte Confiabilidade","title":"Fundamentos de Engenharia"},{"location":"#fundamentos-para-areas-tecnologicas-especificas","text":"Fundamentos de Aprendizado de M\u00e1quina Engenharia de Interface do Usu\u00e1rio","title":"Fundamentos para \u00c1reas Tecnol\u00f3gicas Espec\u00edficas"},{"location":"#contribuindo","text":"Veja CONTRIBUTING.md para diretrizes de contribui\u00e7\u00e3o.","title":"Contribuindo"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/","text":"Lista de Verifica\u00e7\u00e3o de Fundamentos de Engenharia Esta lista de verifica\u00e7\u00e3o ajuda a garantir que nossos projetos atendam aos nossos Fundamentos de Engenharia. Controle de Fonte A branch alvo padr\u00e3o est\u00e1 bloqueada. As mesclagens s\u00e3o feitas atrav\u00e9s de PRs. PRs referenciam itens de trabalho relacionados. O hist\u00f3rico de commits \u00e9 consistente e as mensagens de commit s\u00e3o informativas (o qu\u00ea, por qu\u00ea). Conven\u00e7\u00f5es de nomenclatura de branch consistentes. Documenta\u00e7\u00e3o clara da estrutura do reposit\u00f3rio. Segredos n\u00e3o fazem parte do hist\u00f3rico de commits ou s\u00e3o tornados p\u00fablicos. (veja Verifica\u00e7\u00e3o de Credenciais ) Reposit\u00f3rios p\u00fablicos seguem as diretrizes de OSS , veja Arquivos obrigat\u00f3rios na branch padr\u00e3o para reposit\u00f3rios p\u00fablicos . Mais detalhes sobre controle de fonte Rastreamento de Item de Trabalho Todos os itens s\u00e3o rastreados no AzDevOps (ou similar). O quadro est\u00e1 organizado (faixas de nado, tags de recursos, tags de tecnologia). Mais detalhes sobre gerenciamento de backlog Testes Testes unit\u00e1rios cobrem a maioria de todos os componentes (>90% se poss\u00edvel). Testes de integra\u00e7\u00e3o s\u00e3o executados para testar a solu\u00e7\u00e3o de ponta a ponta. Mais detalhes sobre testes automatizados CI/CD O projeto executa CI com build e teste automatizados em cada PR. O projeto usa CD para gerenciar implanta\u00e7\u00f5es em um ambiente r\u00e9plica antes que os PRs sejam mesclados. A branch principal est\u00e1 sempre pronta para ser enviada. Mais detalhes sobre integra\u00e7\u00e3o cont\u00ednua e entrega cont\u00ednua Seguran\u00e7a O acesso \u00e9 concedido apenas conforme a necessidade. Segredos s\u00e3o armazenados em locais seguros e n\u00e3o s\u00e3o inclu\u00eddos no c\u00f3digo. Os dados s\u00e3o criptografados em tr\u00e2nsito (e, se necess\u00e1rio, em repouso) e as senhas s\u00e3o hashadas. O sistema est\u00e1 dividido em segmentos l\u00f3gicos com separa\u00e7\u00e3o de preocupa\u00e7\u00f5es? Isso ajuda a limitar vulnerabilidades de seguran\u00e7a. Mais detalhes sobre seguran\u00e7a Observabilidade Eventos significativos de neg\u00f3cios e funcionais s\u00e3o rastreados e m\u00e9tricas relacionadas coletadas. Falhas e erros da aplica\u00e7\u00e3o s\u00e3o registrados. A sa\u00fade do sistema \u00e9 monitorada. Os dados de observabilidade do lado do cliente e do servidor podem ser diferenciados. A configura\u00e7\u00e3o de registro pode ser modificada sem altera\u00e7\u00f5es de c\u00f3digo (por exemplo: modo verboso). Contexto de rastreamento de entrada \u00e9 propagado para permitir fins de depura\u00e7\u00e3o de problemas de produ\u00e7\u00e3o. A conformidade com o GDPR \u00e9 assegurada em rela\u00e7\u00e3o ao PII (Informa\u00e7\u00f5es Pessoalmente Identific\u00e1veis). Mais detalhes sobre observabilidade \u00c1gil/Scrum O L\u00edder de Processo (fixo/rotativo) conduz o standup di\u00e1rio. O processo \u00e1gil est\u00e1 claramente definido dentro da equipe. O L\u00edder de Desenvolvimento (+ PO/Outros) s\u00e3o respons\u00e1veis pelo gerenciamento e refinamento do backlog. Um acordo de trabalho \u00e9 estabelecido entre os membros da equipe e o cliente. Mais detalhes sobre desenvolvimento \u00e1gil Revis\u00f5es de Design O processo para realizar revis\u00f5es de design est\u00e1 inclu\u00eddo no Acordo de Trabalho . Revis\u00f5es de design para cada componente principal da solu\u00e7\u00e3o s\u00e3o realizadas e documentadas, incluindo alternativas. Hist\u00f3rias e/ou PRs est\u00e3o vinculados ao documento de design. Cada hist\u00f3ria de usu\u00e1rio inclui uma tarefa para revis\u00e3o de design por padr\u00e3o, que \u00e9 atribu\u00edda ou removida durante o planejamento do sprint. Consultores de projeto s\u00e3o convidados para revis\u00f5es de design ou solicitados a dar feedback \u00e0s decis\u00f5es de design capturadas na documenta\u00e7\u00e3o. Descubra todas as revis\u00f5es que os processos do cliente exigem e planeje para elas. Requisitos n\u00e3o funcionais claros capturados (veja Orienta\u00e7\u00e3o para Requisitos N\u00e3o Funcionais ) Mais detalhes sobre revis\u00f5es de design Revis\u00f5es de C\u00f3digo H\u00e1 um acordo claro na equipe quanto \u00e0 fun\u00e7\u00e3o das revis\u00f5es de c\u00f3digo. A equipe possui uma lista de verifica\u00e7\u00e3o de revis\u00e3o de c\u00f3digo ou processo estabelecido. Um n\u00famero m\u00ednimo de revisores (geralmente 2) para uma mesclagem de PR \u00e9 imposto por pol\u00edtica. Linters/Analisadores de C\u00f3digo, testes unit\u00e1rios e builds bem-sucedidos para mesclagens de PR est\u00e3o configurados. H\u00e1 um processo para impor uma r\u00e1pida revis\u00e3o. Mais detalhes sobre revis\u00f5es de c\u00f3digo Retrospectivas Retrospectivas s\u00e3o realizadas a cada semana/ao final de cada sprint. A equipe identifica 1-3 experimentos propostos para tentar a cada semana/sprint para melhorar o processo. Experimentos t\u00eam propriet\u00e1rios e s\u00e3o adicionados ao backlog do projeto. A equipe realiza retrospectivas mais longas para Marcos e conclus\u00e3o do projeto. Mais detalhes sobre retrospectivas Feedback de Engenharia A equipe envia feedback sobre bloqueadores de neg\u00f3cios e t\u00e9cnicos que impedem o sucesso do projeto. Sugest\u00f5es para melhorias s\u00e3o incorporadas na solu\u00e7\u00e3o. O feedback \u00e9 detalhado e repet\u00edvel. Mais detalhes sobre feedback de engenharia Experi\u00eancia do Desenvolvedor (DevEx) Desenvolvedores na equipe podem: Construir/Compilar a fonte para verificar se est\u00e1 livre de erros de sintaxe e compila. Executar todos os testes automatizados (unit\u00e1rios, e2e, etc). Iniciar/Lan\u00e7ar de ponta a ponta para simular a execu\u00e7\u00e3o em um ambiente implantado. Anexar um depurador \u00e0 solu\u00e7\u00e3o iniciada ou aos testes automatizados em execu\u00e7\u00e3o, definir pontos de interrup\u00e7\u00e3o, percorrer o c\u00f3digo e inspecionar vari\u00e1veis. Instalar automaticamente depend\u00eancias pressionando F5 (ou equivalente) em seu IDE. Usar valores de configura\u00e7\u00e3o de desenvolvimento local (ou seja, .env, appsettings.development.json). Mais detalhes sobre experi\u00eancia do desenvolvedor","title":"Lista de Verifica\u00e7\u00e3o de Fundamentos de Engenharia"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#lista-de-verificacao-de-fundamentos-de-engenharia","text":"Esta lista de verifica\u00e7\u00e3o ajuda a garantir que nossos projetos atendam aos nossos Fundamentos de Engenharia.","title":"Lista de Verifica\u00e7\u00e3o de Fundamentos de Engenharia"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#controle-de-fonte","text":"A branch alvo padr\u00e3o est\u00e1 bloqueada. As mesclagens s\u00e3o feitas atrav\u00e9s de PRs. PRs referenciam itens de trabalho relacionados. O hist\u00f3rico de commits \u00e9 consistente e as mensagens de commit s\u00e3o informativas (o qu\u00ea, por qu\u00ea). Conven\u00e7\u00f5es de nomenclatura de branch consistentes. Documenta\u00e7\u00e3o clara da estrutura do reposit\u00f3rio. Segredos n\u00e3o fazem parte do hist\u00f3rico de commits ou s\u00e3o tornados p\u00fablicos. (veja Verifica\u00e7\u00e3o de Credenciais ) Reposit\u00f3rios p\u00fablicos seguem as diretrizes de OSS , veja Arquivos obrigat\u00f3rios na branch padr\u00e3o para reposit\u00f3rios p\u00fablicos . Mais detalhes sobre controle de fonte","title":"Controle de Fonte"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#rastreamento-de-item-de-trabalho","text":"Todos os itens s\u00e3o rastreados no AzDevOps (ou similar). O quadro est\u00e1 organizado (faixas de nado, tags de recursos, tags de tecnologia). Mais detalhes sobre gerenciamento de backlog","title":"Rastreamento de Item de Trabalho"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#testes","text":"Testes unit\u00e1rios cobrem a maioria de todos os componentes (>90% se poss\u00edvel). Testes de integra\u00e7\u00e3o s\u00e3o executados para testar a solu\u00e7\u00e3o de ponta a ponta. Mais detalhes sobre testes automatizados","title":"Testes"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#cicd","text":"O projeto executa CI com build e teste automatizados em cada PR. O projeto usa CD para gerenciar implanta\u00e7\u00f5es em um ambiente r\u00e9plica antes que os PRs sejam mesclados. A branch principal est\u00e1 sempre pronta para ser enviada. Mais detalhes sobre integra\u00e7\u00e3o cont\u00ednua e entrega cont\u00ednua","title":"CI/CD"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#seguranca","text":"O acesso \u00e9 concedido apenas conforme a necessidade. Segredos s\u00e3o armazenados em locais seguros e n\u00e3o s\u00e3o inclu\u00eddos no c\u00f3digo. Os dados s\u00e3o criptografados em tr\u00e2nsito (e, se necess\u00e1rio, em repouso) e as senhas s\u00e3o hashadas. O sistema est\u00e1 dividido em segmentos l\u00f3gicos com separa\u00e7\u00e3o de preocupa\u00e7\u00f5es? Isso ajuda a limitar vulnerabilidades de seguran\u00e7a. Mais detalhes sobre seguran\u00e7a","title":"Seguran\u00e7a"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#observabilidade","text":"Eventos significativos de neg\u00f3cios e funcionais s\u00e3o rastreados e m\u00e9tricas relacionadas coletadas. Falhas e erros da aplica\u00e7\u00e3o s\u00e3o registrados. A sa\u00fade do sistema \u00e9 monitorada. Os dados de observabilidade do lado do cliente e do servidor podem ser diferenciados. A configura\u00e7\u00e3o de registro pode ser modificada sem altera\u00e7\u00f5es de c\u00f3digo (por exemplo: modo verboso). Contexto de rastreamento de entrada \u00e9 propagado para permitir fins de depura\u00e7\u00e3o de problemas de produ\u00e7\u00e3o. A conformidade com o GDPR \u00e9 assegurada em rela\u00e7\u00e3o ao PII (Informa\u00e7\u00f5es Pessoalmente Identific\u00e1veis). Mais detalhes sobre observabilidade","title":"Observabilidade"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#agilscrum","text":"O L\u00edder de Processo (fixo/rotativo) conduz o standup di\u00e1rio. O processo \u00e1gil est\u00e1 claramente definido dentro da equipe. O L\u00edder de Desenvolvimento (+ PO/Outros) s\u00e3o respons\u00e1veis pelo gerenciamento e refinamento do backlog. Um acordo de trabalho \u00e9 estabelecido entre os membros da equipe e o cliente. Mais detalhes sobre desenvolvimento \u00e1gil","title":"\u00c1gil/Scrum"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#revisoes-de-design","text":"O processo para realizar revis\u00f5es de design est\u00e1 inclu\u00eddo no Acordo de Trabalho . Revis\u00f5es de design para cada componente principal da solu\u00e7\u00e3o s\u00e3o realizadas e documentadas, incluindo alternativas. Hist\u00f3rias e/ou PRs est\u00e3o vinculados ao documento de design. Cada hist\u00f3ria de usu\u00e1rio inclui uma tarefa para revis\u00e3o de design por padr\u00e3o, que \u00e9 atribu\u00edda ou removida durante o planejamento do sprint. Consultores de projeto s\u00e3o convidados para revis\u00f5es de design ou solicitados a dar feedback \u00e0s decis\u00f5es de design capturadas na documenta\u00e7\u00e3o. Descubra todas as revis\u00f5es que os processos do cliente exigem e planeje para elas. Requisitos n\u00e3o funcionais claros capturados (veja Orienta\u00e7\u00e3o para Requisitos N\u00e3o Funcionais ) Mais detalhes sobre revis\u00f5es de design","title":"Revis\u00f5es de Design"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#revisoes-de-codigo","text":"H\u00e1 um acordo claro na equipe quanto \u00e0 fun\u00e7\u00e3o das revis\u00f5es de c\u00f3digo. A equipe possui uma lista de verifica\u00e7\u00e3o de revis\u00e3o de c\u00f3digo ou processo estabelecido. Um n\u00famero m\u00ednimo de revisores (geralmente 2) para uma mesclagem de PR \u00e9 imposto por pol\u00edtica. Linters/Analisadores de C\u00f3digo, testes unit\u00e1rios e builds bem-sucedidos para mesclagens de PR est\u00e3o configurados. H\u00e1 um processo para impor uma r\u00e1pida revis\u00e3o. Mais detalhes sobre revis\u00f5es de c\u00f3digo","title":"Revis\u00f5es de C\u00f3digo"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#retrospectivas","text":"Retrospectivas s\u00e3o realizadas a cada semana/ao final de cada sprint. A equipe identifica 1-3 experimentos propostos para tentar a cada semana/sprint para melhorar o processo. Experimentos t\u00eam propriet\u00e1rios e s\u00e3o adicionados ao backlog do projeto. A equipe realiza retrospectivas mais longas para Marcos e conclus\u00e3o do projeto. Mais detalhes sobre retrospectivas","title":"Retrospectivas"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#feedback-de-engenharia","text":"A equipe envia feedback sobre bloqueadores de neg\u00f3cios e t\u00e9cnicos que impedem o sucesso do projeto. Sugest\u00f5es para melhorias s\u00e3o incorporadas na solu\u00e7\u00e3o. O feedback \u00e9 detalhado e repet\u00edvel. Mais detalhes sobre feedback de engenharia","title":"Feedback de Engenharia"},{"location":"ENG-FUNDAMENTALS-CHECKLIST/#experiencia-do-desenvolvedor-devex","text":"Desenvolvedores na equipe podem: Construir/Compilar a fonte para verificar se est\u00e1 livre de erros de sintaxe e compila. Executar todos os testes automatizados (unit\u00e1rios, e2e, etc). Iniciar/Lan\u00e7ar de ponta a ponta para simular a execu\u00e7\u00e3o em um ambiente implantado. Anexar um depurador \u00e0 solu\u00e7\u00e3o iniciada ou aos testes automatizados em execu\u00e7\u00e3o, definir pontos de interrup\u00e7\u00e3o, percorrer o c\u00f3digo e inspecionar vari\u00e1veis. Instalar automaticamente depend\u00eancias pressionando F5 (ou equivalente) em seu IDE. Usar valores de configura\u00e7\u00e3o de desenvolvimento local (ou seja, .env, appsettings.development.json). Mais detalhes sobre experi\u00eancia do desenvolvedor","title":"Experi\u00eancia do Desenvolvedor (DevEx)"},{"location":"ISE/","text":"Quem Somos Nossa equipe, ISE (Engenharia de Solu\u00e7\u00f5es Industriais), trabalha lado a lado com os clientes para ajud\u00e1-los a enfrentar seus problemas t\u00e9cnicos mais dif\u00edceis, tanto na nuvem quanto na borda (edge). Encontramos os clientes onde eles est\u00e3o, trabalhamos nos idiomas que eles usam, com os frameworks de c\u00f3digo aberto que eles usam, nos sistemas operacionais que eles usam. Trabalhamos com empresas e startups em v\u00e1rias ind\u00fastrias, desde servi\u00e7os financeiros at\u00e9 manufatura. Nosso trabalho abrange um amplo espectro de dom\u00ednios, incluindo IoT, aprendizado de m\u00e1quina e computa\u00e7\u00e3o em alta escala. Nosso \"superpoder\" \u00e9 que trabalhamos de perto tanto com as equipes de engenharia de nossos clientes quanto com as equipes de engenharia de produtos da Microsoft, desenvolvendo expertise pr\u00e1tica que podemos usar para ajudar nossos clientes a expandir seus neg\u00f3cios e ajudar a Microsoft a melhorar nossos produtos e servi\u00e7os. Somos muito focados na comunidade em nosso trabalho, com um p\u00e9 na Microsoft e outro p\u00e9 nas comunidades de c\u00f3digo aberto que ajudamos. Fazemos pull requests em projetos de c\u00f3digo aberto para adicionar suporte para plataformas Microsoft e/ou melhorar implementa\u00e7\u00f5es existentes. Constru\u00edmos frameworks e outras ferramentas para facilitar o uso de plataformas Microsoft pelos desenvolvedores. Obtemos todas as ideias para este trabalho mantendo conex\u00f5es muito profundas com essas comunidades e os clientes e parceiros que as utilizam. Se voc\u00ea gosta de variedade, de programar em v\u00e1rios idiomas, de usar qualquer tecnologia dispon\u00edvel em nossa ind\u00fastria, de mergulhar com nossos clientes, de hack fests, de viagens ocasionais e de contar a hist\u00f3ria do que voc\u00ea fez em postagens de blog e em confer\u00eancias, ent\u00e3o venha conversar conosco. Voc\u00ea pode conferir alguns de nossos trabalhos em nosso Blog para Desenvolvedores","title":"Quem Somos"},{"location":"ISE/#quem-somos","text":"Nossa equipe, ISE (Engenharia de Solu\u00e7\u00f5es Industriais), trabalha lado a lado com os clientes para ajud\u00e1-los a enfrentar seus problemas t\u00e9cnicos mais dif\u00edceis, tanto na nuvem quanto na borda (edge). Encontramos os clientes onde eles est\u00e3o, trabalhamos nos idiomas que eles usam, com os frameworks de c\u00f3digo aberto que eles usam, nos sistemas operacionais que eles usam. Trabalhamos com empresas e startups em v\u00e1rias ind\u00fastrias, desde servi\u00e7os financeiros at\u00e9 manufatura. Nosso trabalho abrange um amplo espectro de dom\u00ednios, incluindo IoT, aprendizado de m\u00e1quina e computa\u00e7\u00e3o em alta escala. Nosso \"superpoder\" \u00e9 que trabalhamos de perto tanto com as equipes de engenharia de nossos clientes quanto com as equipes de engenharia de produtos da Microsoft, desenvolvendo expertise pr\u00e1tica que podemos usar para ajudar nossos clientes a expandir seus neg\u00f3cios e ajudar a Microsoft a melhorar nossos produtos e servi\u00e7os. Somos muito focados na comunidade em nosso trabalho, com um p\u00e9 na Microsoft e outro p\u00e9 nas comunidades de c\u00f3digo aberto que ajudamos. Fazemos pull requests em projetos de c\u00f3digo aberto para adicionar suporte para plataformas Microsoft e/ou melhorar implementa\u00e7\u00f5es existentes. Constru\u00edmos frameworks e outras ferramentas para facilitar o uso de plataformas Microsoft pelos desenvolvedores. Obtemos todas as ideias para este trabalho mantendo conex\u00f5es muito profundas com essas comunidades e os clientes e parceiros que as utilizam. Se voc\u00ea gosta de variedade, de programar em v\u00e1rios idiomas, de usar qualquer tecnologia dispon\u00edvel em nossa ind\u00fastria, de mergulhar com nossos clientes, de hack fests, de viagens ocasionais e de contar a hist\u00f3ria do que voc\u00ea fez em postagens de blog e em confer\u00eancias, ent\u00e3o venha conversar conosco. Voc\u00ea pode conferir alguns de nossos trabalhos em nosso Blog para Desenvolvedores","title":"Quem Somos"},{"location":"SPRINT-STRUCTURE/","text":"Estrutura de um Sprint O objetivo deste documento \u00e9: Organizar o conte\u00fado no playbook para r\u00e1pida refer\u00eancia e descobrimento Fornecer conte\u00fado em uma estrutura l\u00f3gica que reflita o processo de engenharia Hierarquia extens\u00edvel para permitir que as equipes compartilhem conhecimento profundo em assuntos espec\u00edficos A primeira semana de um Projeto ISE Antes de iniciar o projeto Discutir e come\u00e7ar a escrever os Acordos da Equipe . Atualize esses documentos com quaisquer decis\u00f5es de processo feitas ao longo do projeto Acordo de Trabalho Defini\u00e7\u00e3o de Pronto Defini\u00e7\u00e3o de Conclu\u00eddo Estimativa Configurar o(s) reposit\u00f3rio(s) Decidir sobre a estrutura(s) do reposit\u00f3rio Adicionar README.md , LICENSE , CONTRIBUTING.md , .gitignore, etc Construir um Backlog de Produto Configurar um projeto na sua ferramenta de gerenciamento de projeto escolhida (ex. Azure DevOps) INVEST em boas Hist\u00f3rias de Usu\u00e1rio e Crit\u00e9rios de Aceita\u00e7\u00e3o Orienta\u00e7\u00e3o para Requisitos N\u00e3o Funcionais Dia 1 Planejar o primeiro sprint Concordar com um objetivo de sprint e como medir o progresso do sprint Determinar a capacidade da equipe Atribuir hist\u00f3rias de usu\u00e1rio ao sprint e dividir hist\u00f3rias de usu\u00e1rio em tarefas Configurar limites de Trabalho em Andamento (WIP) Decidir sobre frameworks de teste e discutir estrat\u00e9gias de teste Discutir o prop\u00f3sito e os objetivos dos testes e como medir a cobertura de teste Concordar em como separar testes unit\u00e1rios de testes de integra\u00e7\u00e3o, carga e fuma\u00e7a Projetar os primeiros casos de teste Decidir sobre a nomenclatura das branches Discutir necessidades de seguran\u00e7a e verificar que segredos s\u00e3o mantidos fora do controle de vers\u00e3o Dia 2 Configurar Controle de Fonte Concordar com melhores pr\u00e1ticas para commits Configurar Integra\u00e7\u00e3o Cont\u00ednua b\u00e1sica com linters e testes automatizados Configurar reuni\u00f5es para Stand-ups Di\u00e1rios e decidir sobre um L\u00edder de Processo Discutir prop\u00f3sito, objetivos, participantes e orienta\u00e7\u00f5es para facilita\u00e7\u00e3o Discutir o momento e como executar um stand-up eficiente Se o projeto tiver subequipes, configurar um Scrum de Scrums Dia 3 Concordar com o estilo de c\u00f3digo e sobre como atribuir Pull Requests Configurar Valida\u00e7\u00e3o de Build para Pull Requests (2 revisores, linters, testes automatizados) e concordar com Defini\u00e7\u00e3o de Conclu\u00eddo Concordar com uma estrat\u00e9gia de Mesclagem de C\u00f3digo e atualizar o CONTRIBUTING.md Concordar com frameworks e estrat\u00e9gias de registro e observabilidade Dia 4 Configurar Implanta\u00e7\u00e3o Cont\u00ednua Determinar quais ambientes s\u00e3o apropriados para esta solu\u00e7\u00e3o Para cada ambiente, discutir o prop\u00f3sito, quando a implanta\u00e7\u00e3o deve ser acionada, aprovadores pr\u00e9-implanta\u00e7\u00e3o, aprova\u00e7\u00e3o para promo\u00e7\u00e3o. Decidir sobre uma estrat\u00e9gia de versionamento Concordar em como Projetar um recurso e conduzir uma Revis\u00e3o de Design Dia 5 Realizar uma Demonstra\u00e7\u00e3o de Sprint Conduzir uma Retrospectiva Determinar participantes necess\u00e1rios, como capturar entrada (ferramentas) e resultado Definir um cronograma e discutir facilita\u00e7\u00e3o, estrutura da reuni\u00e3o, etc. Refinar o Backlog Determinar participantes necess\u00e1rios Atualizar a Defini\u00e7\u00e3o de Pronto Atualizar estimativas e o documento Estimativa Enviar Feedback de Engenharia para problemas encontrados","title":"Estrutura de um Sprint"},{"location":"SPRINT-STRUCTURE/#estrutura-de-um-sprint","text":"O objetivo deste documento \u00e9: Organizar o conte\u00fado no playbook para r\u00e1pida refer\u00eancia e descobrimento Fornecer conte\u00fado em uma estrutura l\u00f3gica que reflita o processo de engenharia Hierarquia extens\u00edvel para permitir que as equipes compartilhem conhecimento profundo em assuntos espec\u00edficos","title":"Estrutura de um Sprint"},{"location":"SPRINT-STRUCTURE/#a-primeira-semana-de-um-projeto-ise","text":"","title":"A primeira semana de um Projeto ISE"},{"location":"SPRINT-STRUCTURE/#antes-de-iniciar-o-projeto","text":"Discutir e come\u00e7ar a escrever os Acordos da Equipe . Atualize esses documentos com quaisquer decis\u00f5es de processo feitas ao longo do projeto Acordo de Trabalho Defini\u00e7\u00e3o de Pronto Defini\u00e7\u00e3o de Conclu\u00eddo Estimativa Configurar o(s) reposit\u00f3rio(s) Decidir sobre a estrutura(s) do reposit\u00f3rio Adicionar README.md , LICENSE , CONTRIBUTING.md , .gitignore, etc Construir um Backlog de Produto Configurar um projeto na sua ferramenta de gerenciamento de projeto escolhida (ex. Azure DevOps) INVEST em boas Hist\u00f3rias de Usu\u00e1rio e Crit\u00e9rios de Aceita\u00e7\u00e3o Orienta\u00e7\u00e3o para Requisitos N\u00e3o Funcionais","title":"Antes de iniciar o projeto"},{"location":"SPRINT-STRUCTURE/#dia-1","text":"Planejar o primeiro sprint Concordar com um objetivo de sprint e como medir o progresso do sprint Determinar a capacidade da equipe Atribuir hist\u00f3rias de usu\u00e1rio ao sprint e dividir hist\u00f3rias de usu\u00e1rio em tarefas Configurar limites de Trabalho em Andamento (WIP) Decidir sobre frameworks de teste e discutir estrat\u00e9gias de teste Discutir o prop\u00f3sito e os objetivos dos testes e como medir a cobertura de teste Concordar em como separar testes unit\u00e1rios de testes de integra\u00e7\u00e3o, carga e fuma\u00e7a Projetar os primeiros casos de teste Decidir sobre a nomenclatura das branches Discutir necessidades de seguran\u00e7a e verificar que segredos s\u00e3o mantidos fora do controle de vers\u00e3o","title":"Dia 1"},{"location":"SPRINT-STRUCTURE/#dia-2","text":"Configurar Controle de Fonte Concordar com melhores pr\u00e1ticas para commits Configurar Integra\u00e7\u00e3o Cont\u00ednua b\u00e1sica com linters e testes automatizados Configurar reuni\u00f5es para Stand-ups Di\u00e1rios e decidir sobre um L\u00edder de Processo Discutir prop\u00f3sito, objetivos, participantes e orienta\u00e7\u00f5es para facilita\u00e7\u00e3o Discutir o momento e como executar um stand-up eficiente Se o projeto tiver subequipes, configurar um Scrum de Scrums","title":"Dia 2"},{"location":"SPRINT-STRUCTURE/#dia-3","text":"Concordar com o estilo de c\u00f3digo e sobre como atribuir Pull Requests Configurar Valida\u00e7\u00e3o de Build para Pull Requests (2 revisores, linters, testes automatizados) e concordar com Defini\u00e7\u00e3o de Conclu\u00eddo Concordar com uma estrat\u00e9gia de Mesclagem de C\u00f3digo e atualizar o CONTRIBUTING.md Concordar com frameworks e estrat\u00e9gias de registro e observabilidade","title":"Dia 3"},{"location":"SPRINT-STRUCTURE/#dia-4","text":"Configurar Implanta\u00e7\u00e3o Cont\u00ednua Determinar quais ambientes s\u00e3o apropriados para esta solu\u00e7\u00e3o Para cada ambiente, discutir o prop\u00f3sito, quando a implanta\u00e7\u00e3o deve ser acionada, aprovadores pr\u00e9-implanta\u00e7\u00e3o, aprova\u00e7\u00e3o para promo\u00e7\u00e3o. Decidir sobre uma estrat\u00e9gia de versionamento Concordar em como Projetar um recurso e conduzir uma Revis\u00e3o de Design","title":"Dia 4"},{"location":"SPRINT-STRUCTURE/#dia-5","text":"Realizar uma Demonstra\u00e7\u00e3o de Sprint Conduzir uma Retrospectiva Determinar participantes necess\u00e1rios, como capturar entrada (ferramentas) e resultado Definir um cronograma e discutir facilita\u00e7\u00e3o, estrutura da reuni\u00e3o, etc. Refinar o Backlog Determinar participantes necess\u00e1rios Atualizar a Defini\u00e7\u00e3o de Pronto Atualizar estimativas e o documento Estimativa Enviar Feedback de Engenharia para problemas encontrados","title":"Dia 5"},{"location":"accessibility/","text":"Acessibilidade A acessibilidade \u00e9 um componente cr\u00edtico de qualquer projeto bem-sucedido e garante que as solu\u00e7\u00f5es que constru\u00edmos sejam utiliz\u00e1veis e apreciadas pelo maior n\u00famero poss\u00edvel de pessoas. Embora o cumprimento das normas de acessibilidade seja obrigat\u00f3rio, a acessibilidade vai muito al\u00e9m do mero cumprimento. A acessibilidade \u00e9 sobre usar t\u00e9cnicas como design inclusivo para infundir diferentes perspectivas e toda a gama de diversidade humana nos produtos que constru\u00edmos. Ao incorporar acessibilidade em seu projeto desde a vis\u00e3o inicial at\u00e9 o MVP e al\u00e9m, voc\u00ea est\u00e1 promovendo um ambiente mais inclusivo para sua equipe e ajudando a fechar o \"Divis\u00e3o de Defici\u00eancia\" que existe para muitas pessoas que vivem com defici\u00eancias. Come\u00e7ando Se voc\u00ea \u00e9 novo em acessibilidade ou est\u00e1 procurando uma vis\u00e3o geral dos fundamentos da acessibilidade, o Microsoft Learn oferece um \u00f3timo curso de treinamento que abrange uma ampla gama de t\u00f3picos, desde a cria\u00e7\u00e3o de conte\u00fado acess\u00edvel no Office at\u00e9 o design de recursos de acessibilidade em seus pr\u00f3prios aplicativos. Voc\u00ea pode aprender mais sobre o curso ou come\u00e7ar em Microsoft Learn: Fundamentos de Acessibilidade . Design Inclusivo O design inclusivo \u00e9 uma metodologia que abra\u00e7a toda a gama de diversidade humana como um recurso para ajudar a construir melhores produtos e servi\u00e7os. O design inclusivo complementa a acessibilidade, indo al\u00e9m das normas de conformidade de acessibilidade para garantir que os produtos sejam utiliz\u00e1veis e apreciados por todas as pessoas. Ao aproveitar a metodologia de design inclusivo no in\u00edcio de um projeto, voc\u00ea pode esperar uma solu\u00e7\u00e3o mais inclusiva e melhor para todos. O site Microsoft Design Inclusivo oferece uma variedade de recursos para incorporar design inclusivo em seus projetos, incluindo atividades de design inclusivo que podem ser usadas em sess\u00f5es de vis\u00e3o e design de arquitetura. A metodologia de Design Inclusivo da Microsoft inclui os seguintes princ\u00edpios: Reconhecer a exclus\u00e3o Projetar para inclusividade n\u00e3o apenas abre nossos produtos e servi\u00e7os para mais pessoas, mas tamb\u00e9m reflete como as pessoas realmente s\u00e3o. Todos os seres humanos crescem e se adaptam ao mundo ao seu redor, e queremos que nossos designs reflitam isso. Resolver para um, estender para muitos Todos t\u00eam habilidades e limites para essas habilidades. Projetar para pessoas com defici\u00eancias permanentes realmente resulta em designs que beneficiam as pessoas universalmente. Restri\u00e7\u00f5es s\u00e3o uma coisa linda. Aprender com a diversidade Os seres humanos s\u00e3o os verdadeiros especialistas em se adaptar \u00e0 diversidade. O design inclusivo coloca as pessoas no centro desde o in\u00edcio do processo, e essas perspectivas frescas e diversas s\u00e3o a chave para uma verdadeira percep\u00e7\u00e3o. Ferramentas Insights de Acessibilidade Insights de Acessibilidade \u00e9 uma solu\u00e7\u00e3o gratuita e de c\u00f3digo aberto para identificar problemas de acessibilidade em aplicativos Windows, Android e web. Insights de Acessibilidade podem identificar uma ampla gama de problemas de acessibilidade, incluindo problemas com tags de imagem alternativas ausentes, organiza\u00e7\u00e3o de cabe\u00e7alhos, ordem de tabula\u00e7\u00e3o, contraste de cores e muito mais. Al\u00e9m disso, voc\u00ea pode usar Insights de Acessibilidade para simular daltonismo para garantir que sua interface do usu\u00e1rio seja acess\u00edvel \u00e0queles que experimentam alguma forma de daltonismo. Voc\u00ea pode baixar Insights de Acessibilidade aqui: https://accessibilityinsights.io/downloads/ Linter de Acessibilidade Deque Systems s\u00e3o especialistas em acessibilidade na web que fornecem treinamento e ferramentas de acessibilidade para muitas organiza\u00e7\u00f5es, incluindo a Microsoft. Uma das muitas ferramentas oferecidas pela Deque \u00e9 o axe Linter de Acessibilidade para VS Code . Esta extens\u00e3o do VS Code usa o mecanismo de regras axe-core para identificar problemas de acessibilidade em HTML, Angular, React, Markdown e Vue. Usar","title":"Acessibilidade"},{"location":"accessibility/#acessibilidade","text":"A acessibilidade \u00e9 um componente cr\u00edtico de qualquer projeto bem-sucedido e garante que as solu\u00e7\u00f5es que constru\u00edmos sejam utiliz\u00e1veis e apreciadas pelo maior n\u00famero poss\u00edvel de pessoas. Embora o cumprimento das normas de acessibilidade seja obrigat\u00f3rio, a acessibilidade vai muito al\u00e9m do mero cumprimento. A acessibilidade \u00e9 sobre usar t\u00e9cnicas como design inclusivo para infundir diferentes perspectivas e toda a gama de diversidade humana nos produtos que constru\u00edmos. Ao incorporar acessibilidade em seu projeto desde a vis\u00e3o inicial at\u00e9 o MVP e al\u00e9m, voc\u00ea est\u00e1 promovendo um ambiente mais inclusivo para sua equipe e ajudando a fechar o \"Divis\u00e3o de Defici\u00eancia\" que existe para muitas pessoas que vivem com defici\u00eancias.","title":"Acessibilidade"},{"location":"accessibility/#comecando","text":"Se voc\u00ea \u00e9 novo em acessibilidade ou est\u00e1 procurando uma vis\u00e3o geral dos fundamentos da acessibilidade, o Microsoft Learn oferece um \u00f3timo curso de treinamento que abrange uma ampla gama de t\u00f3picos, desde a cria\u00e7\u00e3o de conte\u00fado acess\u00edvel no Office at\u00e9 o design de recursos de acessibilidade em seus pr\u00f3prios aplicativos. Voc\u00ea pode aprender mais sobre o curso ou come\u00e7ar em Microsoft Learn: Fundamentos de Acessibilidade .","title":"Come\u00e7ando"},{"location":"accessibility/#design-inclusivo","text":"O design inclusivo \u00e9 uma metodologia que abra\u00e7a toda a gama de diversidade humana como um recurso para ajudar a construir melhores produtos e servi\u00e7os. O design inclusivo complementa a acessibilidade, indo al\u00e9m das normas de conformidade de acessibilidade para garantir que os produtos sejam utiliz\u00e1veis e apreciados por todas as pessoas. Ao aproveitar a metodologia de design inclusivo no in\u00edcio de um projeto, voc\u00ea pode esperar uma solu\u00e7\u00e3o mais inclusiva e melhor para todos. O site Microsoft Design Inclusivo oferece uma variedade de recursos para incorporar design inclusivo em seus projetos, incluindo atividades de design inclusivo que podem ser usadas em sess\u00f5es de vis\u00e3o e design de arquitetura. A metodologia de Design Inclusivo da Microsoft inclui os seguintes princ\u00edpios:","title":"Design Inclusivo"},{"location":"accessibility/#reconhecer-a-exclusao","text":"Projetar para inclusividade n\u00e3o apenas abre nossos produtos e servi\u00e7os para mais pessoas, mas tamb\u00e9m reflete como as pessoas realmente s\u00e3o. Todos os seres humanos crescem e se adaptam ao mundo ao seu redor, e queremos que nossos designs reflitam isso.","title":"Reconhecer a exclus\u00e3o"},{"location":"accessibility/#resolver-para-um-estender-para-muitos","text":"Todos t\u00eam habilidades e limites para essas habilidades. Projetar para pessoas com defici\u00eancias permanentes realmente resulta em designs que beneficiam as pessoas universalmente. Restri\u00e7\u00f5es s\u00e3o uma coisa linda.","title":"Resolver para um, estender para muitos"},{"location":"accessibility/#aprender-com-a-diversidade","text":"Os seres humanos s\u00e3o os verdadeiros especialistas em se adaptar \u00e0 diversidade. O design inclusivo coloca as pessoas no centro desde o in\u00edcio do processo, e essas perspectivas frescas e diversas s\u00e3o a chave para uma verdadeira percep\u00e7\u00e3o.","title":"Aprender com a diversidade"},{"location":"accessibility/#ferramentas","text":"","title":"Ferramentas"},{"location":"accessibility/#insights-de-acessibilidade","text":"Insights de Acessibilidade \u00e9 uma solu\u00e7\u00e3o gratuita e de c\u00f3digo aberto para identificar problemas de acessibilidade em aplicativos Windows, Android e web. Insights de Acessibilidade podem identificar uma ampla gama de problemas de acessibilidade, incluindo problemas com tags de imagem alternativas ausentes, organiza\u00e7\u00e3o de cabe\u00e7alhos, ordem de tabula\u00e7\u00e3o, contraste de cores e muito mais. Al\u00e9m disso, voc\u00ea pode usar Insights de Acessibilidade para simular daltonismo para garantir que sua interface do usu\u00e1rio seja acess\u00edvel \u00e0queles que experimentam alguma forma de daltonismo. Voc\u00ea pode baixar Insights de Acessibilidade aqui: https://accessibilityinsights.io/downloads/","title":"Insights de Acessibilidade"},{"location":"accessibility/#linter-de-acessibilidade","text":"Deque Systems s\u00e3o especialistas em acessibilidade na web que fornecem treinamento e ferramentas de acessibilidade para muitas organiza\u00e7\u00f5es, incluindo a Microsoft. Uma das muitas ferramentas oferecidas pela Deque \u00e9 o axe Linter de Acessibilidade para VS Code . Esta extens\u00e3o do VS Code usa o mecanismo de regras axe-core para identificar problemas de acessibilidade em HTML, Angular, React, Markdown e Vue. Usar","title":"Linter de Acessibilidade"},{"location":"agile-development/","text":"Documenta\u00e7\u00e3o \u00c1gil Conceitos B\u00e1sicos de \u00c1gil : Aprenda ou atualize seu conhecimento b\u00e1sico sobre m\u00e9todos \u00e1geis. Expectativas Centrais do \u00c1gil : Quais s\u00e3o as nossas expectativas centrais de uma equipe \u00c1gil. T\u00f3picos Avan\u00e7ados em \u00c1gil : V\u00e1 al\u00e9m dos conceitos b\u00e1sicos.","title":"Documenta\u00e7\u00e3o \u00c1gil"},{"location":"agile-development/#documentacao-agil","text":"Conceitos B\u00e1sicos de \u00c1gil : Aprenda ou atualize seu conhecimento b\u00e1sico sobre m\u00e9todos \u00e1geis. Expectativas Centrais do \u00c1gil : Quais s\u00e3o as nossas expectativas centrais de uma equipe \u00c1gil. T\u00f3picos Avan\u00e7ados em \u00c1gil : V\u00e1 al\u00e9m dos conceitos b\u00e1sicos.","title":"Documenta\u00e7\u00e3o \u00c1gil"},{"location":"agile-development/advanced-topics/","text":"T\u00f3picos Avan\u00e7ados em Desenvolvimento \u00c1gil Documenta\u00e7\u00e3o que ajuda voc\u00ea a ir al\u00e9m dos conceitos b\u00e1sicos e expectativas centrais. Gerenciamento de Backlog Colabora\u00e7\u00e3o Organiza\u00e7\u00e3o Efetiva Acordos de Equipe","title":"T\u00f3picos Avan\u00e7ados em Desenvolvimento \u00c1gil"},{"location":"agile-development/advanced-topics/#topicos-avancados-em-desenvolvimento-agil","text":"Documenta\u00e7\u00e3o que ajuda voc\u00ea a ir al\u00e9m dos conceitos b\u00e1sicos e expectativas centrais. Gerenciamento de Backlog Colabora\u00e7\u00e3o Organiza\u00e7\u00e3o Efetiva Acordos de Equipe","title":"T\u00f3picos Avan\u00e7ados em Desenvolvimento \u00c1gil"},{"location":"agile-development/advanced-topics/backlog-management/","text":"Recomenda\u00e7\u00f5es Avan\u00e7adas para Gerenciamento de Backlog Feedback Externo Fatias Minimalistas","title":"Recomenda\u00e7\u00f5es Avan\u00e7adas para Gerenciamento de Backlog"},{"location":"agile-development/advanced-topics/backlog-management/#recomendacoes-avancadas-para-gerenciamento-de-backlog","text":"Feedback Externo Fatias Minimalistas","title":"Recomenda\u00e7\u00f5es Avan\u00e7adas para Gerenciamento de Backlog"},{"location":"agile-development/advanced-topics/backlog-management/external-feedback/","text":"Feedback Externo V\u00e1rios interessados podem fornecer feedback para o produto em desenvolvimento durante um projeto, al\u00e9m de qualquer sess\u00e3o formal de revis\u00e3o e feedback exigida pela organiza\u00e7\u00e3o. A frequ\u00eancia e o m\u00e9todo de coleta de feedback por meio de revis\u00f5es variam dependendo do caso, mas algumas boas pr\u00e1ticas s\u00e3o: Capture cada revis\u00e3o no backlog como uma hist\u00f3ria de usu\u00e1rio separada. Padronize as tarefas que implementam essa hist\u00f3ria de usu\u00e1rio. Planeje proativamente uma hist\u00f3ria de usu\u00e1rio de revis\u00e3o para cada \u00c9pico / Funcionalidade em seu backlog.","title":"Feedback Externo"},{"location":"agile-development/advanced-topics/backlog-management/external-feedback/#feedback-externo","text":"V\u00e1rios interessados podem fornecer feedback para o produto em desenvolvimento durante um projeto, al\u00e9m de qualquer sess\u00e3o formal de revis\u00e3o e feedback exigida pela organiza\u00e7\u00e3o. A frequ\u00eancia e o m\u00e9todo de coleta de feedback por meio de revis\u00f5es variam dependendo do caso, mas algumas boas pr\u00e1ticas s\u00e3o: Capture cada revis\u00e3o no backlog como uma hist\u00f3ria de usu\u00e1rio separada. Padronize as tarefas que implementam essa hist\u00f3ria de usu\u00e1rio. Planeje proativamente uma hist\u00f3ria de usu\u00e1rio de revis\u00e3o para cada \u00c9pico / Funcionalidade em seu backlog.","title":"Feedback Externo"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/","text":"Fatias Minimalistas Sempre entregue seu trabalho usando fatias m\u00ednimas valiosas Divida seu item de trabalho em pequenos peda\u00e7os que s\u00e3o contribu\u00eddos em commits incrementais. Contribua com seus peda\u00e7os frequentemente. Siga uma abordagem iterativa, fornecendo atualiza\u00e7\u00f5es e mudan\u00e7as regularmente para a equipe. Isso permite feedback instant\u00e2neo e descoberta precoce de problemas, garantindo que voc\u00ea est\u00e1 desenvolvendo na dire\u00e7\u00e3o certa, tanto tecnicamente quanto funcionalmente. N\u00c3O trabalhe independentemente em sua tarefa sem fornecer atualiza\u00e7\u00f5es para sua equipe. Exemplo Imagine que voc\u00ea est\u00e1 trabalhando na adi\u00e7\u00e3o de funcionalidade de constru\u00e7\u00e3o de aplicativos UWP (Universal Windows Platform) para um servi\u00e7o de integra\u00e7\u00e3o cont\u00ednua que j\u00e1 possui suporte para Android/iOS. Abordagem Ruim Ap\u00f3s seis semanas de trabalho, voc\u00ea criou um PR com toda a funcionalidade necess\u00e1ria, incluindo a interface do portal (configura\u00e7\u00f5es de constru\u00e7\u00e3o), API REST do backend (funcionalidade de constru\u00e7\u00e3o UWP), telemetria, testes unit\u00e1rios e de integra\u00e7\u00e3o, etc. Boa Abordagem Voc\u00ea dividiu seu recurso em hist\u00f3rias de usu\u00e1rio menores (que por sua vez foram divididas em v\u00e1rias tarefas) e come\u00e7ou a trabalhar nelas uma de cada vez: Como usu\u00e1rio, posso construir aplicativos UWP com sucesso usando o servi\u00e7o atual Como usu\u00e1rio, posso ver a telemetria ao construir os aplicativos Como usu\u00e1rio, tenho a capacidade de selecionar a configura\u00e7\u00e3o de constru\u00e7\u00e3o (debug, release) Como usu\u00e1rio, tenho a capacidade de selecionar a plataforma de destino (arm, x86, x64) ... Voc\u00ea tamb\u00e9m dividiu suas hist\u00f3rias em tarefas menores e enviou PRs com base nessas tarefas. Por exemplo, voc\u00ea tem as seguintes tarefas para a primeira hist\u00f3ria de usu\u00e1rio acima: Habilitar a plataforma UWP no backend Adicionar bot\u00e3o construir \u00e0 interface do usu\u00e1rio (construir o primeiro arquivo de solu\u00e7\u00e3o encontrado) Adicionar um menu suspenso selecionar arquivo de solu\u00e7\u00e3o \u00e0 interface do usu\u00e1rio Implementar testes unit\u00e1rios Implementar testes de integra\u00e7\u00e3o para verificar se a constru\u00e7\u00e3o foi bem-sucedida Atualizar documenta\u00e7\u00e3o ... Recursos Regras do Minimalismo","title":"Fatias Minimalistas"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/#fatias-minimalistas","text":"","title":"Fatias Minimalistas"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/#sempre-entregue-seu-trabalho-usando-fatias-minimas-valiosas","text":"Divida seu item de trabalho em pequenos peda\u00e7os que s\u00e3o contribu\u00eddos em commits incrementais. Contribua com seus peda\u00e7os frequentemente. Siga uma abordagem iterativa, fornecendo atualiza\u00e7\u00f5es e mudan\u00e7as regularmente para a equipe. Isso permite feedback instant\u00e2neo e descoberta precoce de problemas, garantindo que voc\u00ea est\u00e1 desenvolvendo na dire\u00e7\u00e3o certa, tanto tecnicamente quanto funcionalmente. N\u00c3O trabalhe independentemente em sua tarefa sem fornecer atualiza\u00e7\u00f5es para sua equipe.","title":"Sempre entregue seu trabalho usando fatias m\u00ednimas valiosas"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/#exemplo","text":"Imagine que voc\u00ea est\u00e1 trabalhando na adi\u00e7\u00e3o de funcionalidade de constru\u00e7\u00e3o de aplicativos UWP (Universal Windows Platform) para um servi\u00e7o de integra\u00e7\u00e3o cont\u00ednua que j\u00e1 possui suporte para Android/iOS.","title":"Exemplo"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/#abordagem-ruim","text":"Ap\u00f3s seis semanas de trabalho, voc\u00ea criou um PR com toda a funcionalidade necess\u00e1ria, incluindo a interface do portal (configura\u00e7\u00f5es de constru\u00e7\u00e3o), API REST do backend (funcionalidade de constru\u00e7\u00e3o UWP), telemetria, testes unit\u00e1rios e de integra\u00e7\u00e3o, etc.","title":"Abordagem Ruim"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/#boa-abordagem","text":"Voc\u00ea dividiu seu recurso em hist\u00f3rias de usu\u00e1rio menores (que por sua vez foram divididas em v\u00e1rias tarefas) e come\u00e7ou a trabalhar nelas uma de cada vez: Como usu\u00e1rio, posso construir aplicativos UWP com sucesso usando o servi\u00e7o atual Como usu\u00e1rio, posso ver a telemetria ao construir os aplicativos Como usu\u00e1rio, tenho a capacidade de selecionar a configura\u00e7\u00e3o de constru\u00e7\u00e3o (debug, release) Como usu\u00e1rio, tenho a capacidade de selecionar a plataforma de destino (arm, x86, x64) ... Voc\u00ea tamb\u00e9m dividiu suas hist\u00f3rias em tarefas menores e enviou PRs com base nessas tarefas. Por exemplo, voc\u00ea tem as seguintes tarefas para a primeira hist\u00f3ria de usu\u00e1rio acima: Habilitar a plataforma UWP no backend Adicionar bot\u00e3o construir \u00e0 interface do usu\u00e1rio (construir o primeiro arquivo de solu\u00e7\u00e3o encontrado) Adicionar um menu suspenso selecionar arquivo de solu\u00e7\u00e3o \u00e0 interface do usu\u00e1rio Implementar testes unit\u00e1rios Implementar testes de integra\u00e7\u00e3o para verificar se a constru\u00e7\u00e3o foi bem-sucedida Atualizar documenta\u00e7\u00e3o ...","title":"Boa Abordagem"},{"location":"agile-development/advanced-topics/backlog-management/minimal-slices/#recursos","text":"Regras do Minimalismo","title":"Recursos"},{"location":"agile-development/advanced-topics/collaboration/","text":"Recomenda\u00e7\u00f5es Avan\u00e7adas para Colabora\u00e7\u00e3o Por que Colaborar Como usar a \"Pergunta Social do Dia\" Desenvolvimento de Equipe de Engajamento Programa\u00e7\u00e3o em Par e em Grupo (Swarm) Colabora\u00e7\u00e3o Virtual e Programa\u00e7\u00e3o em Par Como adicionar um Campo Personalizado de Emparelhamento em Hist\u00f3rias de Usu\u00e1rio do Azure DevOps Programa\u00e7\u00e3o em Par Sem Esfor\u00e7o com GitHub Codespaces e VSCode","title":"Recomenda\u00e7\u00f5es Avan\u00e7adas para Colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/#recomendacoes-avancadas-para-colaboracao","text":"Por que Colaborar Como usar a \"Pergunta Social do Dia\" Desenvolvimento de Equipe de Engajamento","title":"Recomenda\u00e7\u00f5es Avan\u00e7adas para Colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/#programacao-em-par-e-em-grupo-swarm","text":"Colabora\u00e7\u00e3o Virtual e Programa\u00e7\u00e3o em Par Como adicionar um Campo Personalizado de Emparelhamento em Hist\u00f3rias de Usu\u00e1rio do Azure DevOps Programa\u00e7\u00e3o em Par Sem Esfor\u00e7o com GitHub Codespaces e VSCode","title":"Programa\u00e7\u00e3o em Par e em Grupo (Swarm)"},{"location":"agile-development/advanced-topics/collaboration/add-pairing-field-azure-devops-cards/","text":"Como adicionar um Campo Personalizado de Emparelhamento em Hist\u00f3rias de Usu\u00e1rio do Azure DevOps Este documento descreve os benef\u00edcios de adicionar um campo personalizado do tipo Identidade nas hist\u00f3rias de usu\u00e1rio do Azure DevOps , pr\u00e9-requisitos e um guia passo a passo. Benef\u00edcios de adicionar um campo personalizado Ter os nomes de ambos os indiv\u00edduos trabalhando em uma hist\u00f3ria vis\u00edveis nos cart\u00f5es do Azure DevOps pode ser \u00fatil durante as cerim\u00f4nias de sprint e levar a uma maior responsabilidade pelo respons\u00e1vel pelo emparelhamento. Por exemplo, \u00e9 mais f\u00e1cil acompanhar os indiv\u00edduos designados para hist\u00f3rias como parte de um par durante o planejamento do sprint usando o campo \"nomes de emparelhamento\". Durante o stand-up, isso tamb\u00e9m pode ajudar o L\u00edder de Processo a filtrar hist\u00f3rias atribu\u00eddas ao indiv\u00edduo (tanto como propriet\u00e1rio quanto como respons\u00e1vel pelo emparelhamento) e mostr\u00e1-las no quadro. Al\u00e9m disso, o campo de emparelhamento pode fornecer um ponto de dados adicional para relat\u00f3rios e taxas de queima. Pr\u00e9-requisitos Antes de personalizar o Azure DevOps, revise Configurar e personalizar o Azure Boards . Para adicionar um campo personalizado \u00e0s hist\u00f3rias de usu\u00e1rio no Azure DevOps, as altera\u00e7\u00f5es devem ser feitas como uma Configura\u00e7\u00e3o Organizacional . Este documento, portanto, pressup\u00f5e o uso de uma Organiza\u00e7\u00e3o existente no Azure DevOps e que a conta de usu\u00e1rio usada para fazer essas altera\u00e7\u00f5es \u00e9 membro do Grupo de Administradores da Cole\u00e7\u00e3o de Projetos . Alterar as configura\u00e7\u00f5es da organiza\u00e7\u00e3o Duplicar o processo atualmente em uso. Navegue at\u00e9 as Configura\u00e7\u00f5es da Organiza\u00e7\u00e3o , dentro da aba Boards / Process. Selecione o tipo de Processo , clique no \u00edcone com tr\u00eas pontos ... e clique em Criar processo herdado . Clique no processo herdado rec\u00e9m-criado. Como voc\u00ea pode ver no exemplo abaixo, n\u00f3s o chamamos de 'Emparelhamento'. Clique no tipo de item de trabalho Hist\u00f3ria de Usu\u00e1rio . Clique em Novo Campo . D\u00ea um Nome e selecione Identidade em Tipo. Clique em Adicionar Campo . Isso completa a mudan\u00e7a nas Configura\u00e7\u00f5es da Organiza\u00e7\u00e3o. O restante das instru\u00e7\u00f5es deve ser conclu\u00eddo nas Configura\u00e7\u00f5es do Projeto. Alterar as configura\u00e7\u00f5es do projeto V\u00e1 para o Projeto que ser\u00e1 modificado, selecione Configura\u00e7\u00f5es do Projeto . Selecione Configura\u00e7\u00e3o do Projeto . Clique na p\u00e1gina de personaliza\u00e7\u00e3o de processo . Clique em Projetos e depois clique em Alterar processo . Altere o processo alvo para Emparelhamento e clique em Salvar. V\u00e1 para Boards . Clique no \u00edcone de engrenagem para abrir Configura\u00e7\u00f5es. Adicione o campo ao cart\u00e3o. Clique no \u00edcone verde + para adicionar e selecionar o campo de Emparelhamento. Marque a caixa para exibir campos, mesmo quando estiverem vazios. Salvar e fechar . Veja o cart\u00e3o modificado. Observe o novo campo de Emparelhamento. A Hist\u00f3ria agora pode ser atribu\u00edda a um Propriet\u00e1rio e a um Respons\u00e1vel pelo Emparelhamento!","title":"Como adicionar um Campo Personalizado de Emparelhamento em Hist\u00f3rias de Usu\u00e1rio do Azure DevOps"},{"location":"agile-development/advanced-topics/collaboration/add-pairing-field-azure-devops-cards/#como-adicionar-um-campo-personalizado-de-emparelhamento-em-historias-de-usuario-do-azure-devops","text":"Este documento descreve os benef\u00edcios de adicionar um campo personalizado do tipo Identidade nas hist\u00f3rias de usu\u00e1rio do Azure DevOps , pr\u00e9-requisitos e um guia passo a passo.","title":"Como adicionar um Campo Personalizado de Emparelhamento em Hist\u00f3rias de Usu\u00e1rio do Azure DevOps"},{"location":"agile-development/advanced-topics/collaboration/add-pairing-field-azure-devops-cards/#beneficios-de-adicionar-um-campo-personalizado","text":"Ter os nomes de ambos os indiv\u00edduos trabalhando em uma hist\u00f3ria vis\u00edveis nos cart\u00f5es do Azure DevOps pode ser \u00fatil durante as cerim\u00f4nias de sprint e levar a uma maior responsabilidade pelo respons\u00e1vel pelo emparelhamento. Por exemplo, \u00e9 mais f\u00e1cil acompanhar os indiv\u00edduos designados para hist\u00f3rias como parte de um par durante o planejamento do sprint usando o campo \"nomes de emparelhamento\". Durante o stand-up, isso tamb\u00e9m pode ajudar o L\u00edder de Processo a filtrar hist\u00f3rias atribu\u00eddas ao indiv\u00edduo (tanto como propriet\u00e1rio quanto como respons\u00e1vel pelo emparelhamento) e mostr\u00e1-las no quadro. Al\u00e9m disso, o campo de emparelhamento pode fornecer um ponto de dados adicional para relat\u00f3rios e taxas de queima.","title":"Benef\u00edcios de adicionar um campo personalizado"},{"location":"agile-development/advanced-topics/collaboration/add-pairing-field-azure-devops-cards/#pre-requisitos","text":"Antes de personalizar o Azure DevOps, revise Configurar e personalizar o Azure Boards . Para adicionar um campo personalizado \u00e0s hist\u00f3rias de usu\u00e1rio no Azure DevOps, as altera\u00e7\u00f5es devem ser feitas como uma Configura\u00e7\u00e3o Organizacional . Este documento, portanto, pressup\u00f5e o uso de uma Organiza\u00e7\u00e3o existente no Azure DevOps e que a conta de usu\u00e1rio usada para fazer essas altera\u00e7\u00f5es \u00e9 membro do Grupo de Administradores da Cole\u00e7\u00e3o de Projetos .","title":"Pr\u00e9-requisitos"},{"location":"agile-development/advanced-topics/collaboration/add-pairing-field-azure-devops-cards/#alterar-as-configuracoes-da-organizacao","text":"Duplicar o processo atualmente em uso. Navegue at\u00e9 as Configura\u00e7\u00f5es da Organiza\u00e7\u00e3o , dentro da aba Boards / Process. Selecione o tipo de Processo , clique no \u00edcone com tr\u00eas pontos ... e clique em Criar processo herdado . Clique no processo herdado rec\u00e9m-criado. Como voc\u00ea pode ver no exemplo abaixo, n\u00f3s o chamamos de 'Emparelhamento'. Clique no tipo de item de trabalho Hist\u00f3ria de Usu\u00e1rio . Clique em Novo Campo . D\u00ea um Nome e selecione Identidade em Tipo. Clique em Adicionar Campo . Isso completa a mudan\u00e7a nas Configura\u00e7\u00f5es da Organiza\u00e7\u00e3o. O restante das instru\u00e7\u00f5es deve ser conclu\u00eddo nas Configura\u00e7\u00f5es do Projeto.","title":"Alterar as configura\u00e7\u00f5es da organiza\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/add-pairing-field-azure-devops-cards/#alterar-as-configuracoes-do-projeto","text":"V\u00e1 para o Projeto que ser\u00e1 modificado, selecione Configura\u00e7\u00f5es do Projeto . Selecione Configura\u00e7\u00e3o do Projeto . Clique na p\u00e1gina de personaliza\u00e7\u00e3o de processo . Clique em Projetos e depois clique em Alterar processo . Altere o processo alvo para Emparelhamento e clique em Salvar. V\u00e1 para Boards . Clique no \u00edcone de engrenagem para abrir Configura\u00e7\u00f5es. Adicione o campo ao cart\u00e3o. Clique no \u00edcone verde + para adicionar e selecionar o campo de Emparelhamento. Marque a caixa para exibir campos, mesmo quando estiverem vazios. Salvar e fechar . Veja o cart\u00e3o modificado. Observe o novo campo de Emparelhamento. A Hist\u00f3ria agora pode ser atribu\u00edda a um Propriet\u00e1rio e a um Respons\u00e1vel pelo Emparelhamento!","title":"Alterar as configura\u00e7\u00f5es do projeto"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/","text":"Programa\u00e7\u00e3o em Par Sem Esfor\u00e7o com GitHub Codespaces e VSCode A programa\u00e7\u00e3o em par costumava ser uma t\u00e9cnica de desenvolvimento de software na qual dois programadores trabalham juntos em um \u00fanico computador, compartilhando um teclado e um mouse, para projetar, codificar, testar e depurar software conjuntamente. \u00c9 um dos padr\u00f5es explorados na se\u00e7\u00e3o por que colaborar? deste playbook. No entanto, com equipes que trabalham principalmente de forma remota, compartilhar um computador f\u00edsico tornou-se um desafio, mas abriu a porta para uma abordagem mais eficiente da programa\u00e7\u00e3o em par. Por meio da utiliza\u00e7\u00e3o eficaz de uma variedade de ferramentas e t\u00e9cnicas, implementamos com sucesso tanto as metodologias de programa\u00e7\u00e3o em par quanto em enxame. Como tal, estamos ansiosos para compartilhar alguns dos valiosos insights e conhecimentos adquiridos com essa experi\u00eancia. Como tornar a programa\u00e7\u00e3o em par uma experi\u00eancia indolor? Sess\u00f5es de Trabalho Para aprimorar as capacidades de programa\u00e7\u00e3o em par, voc\u00ea pode criar sess\u00f5es de trabalho regulares que est\u00e3o abertas a todos os membros da equipe. Isso facilita uma colabora\u00e7\u00e3o suave e eficiente, pois todos podem simplesmente participar e trabalhar juntos antes de se dividirem em grupos menores. Essa abordagem se mostrou particularmente ben\u00e9fica para novos membros da equipe que, de outra forma, poderiam se sentir sobrecarregados por uma grande base de c\u00f3digo. Ela emula o conceito do \" bebedouro humilde \", que promove um senso de conex\u00e3o entre os membros da equipe por meio de seu trabalho compartilhado. Al\u00e9m disso, agendar essas sess\u00f5es de trabalho com anteced\u00eancia garante colabora\u00e7\u00e3o intencional e fornece clareza sobre as responsabilidades da hist\u00f3ria do usu\u00e1rio. Para esse fim, atribua uma \u00fanica pessoa a cada hist\u00f3ria do usu\u00e1rio para garantir propriedade clara e eliminar ambiguidades. Ao fazer isso, isso poderia eliminar o problema comum de engenheiros hesitarem em modificar o c\u00f3digo fora de suas tarefas atribu\u00eddas devido ao sentimento de falta de propriedade. Essas sess\u00f5es de trabalho s\u00e3o fundamentais para promover uma din\u00e2mica de equipe coesa, permitindo o compartilhamento eficaz de conhecimento e a resolu\u00e7\u00e3o coletiva de problemas. GitHub Codespaces GitHub Codespaces \u00e9 um componente vital em um ambiente de desenvolvimento eficiente, particularmente no contexto da programa\u00e7\u00e3o em par. Priorize a configura\u00e7\u00e3o de um Codespace como a etapa inicial do projeto, precedendo tarefas como compila\u00e7\u00e3o do projeto na m\u00e1quina local ou instala\u00e7\u00e3o de plugins do VSCode. Para isso, certifique-se de atualizar a documenta\u00e7\u00e3o do Codespace antes de incorporar quaisquer instru\u00e7\u00f5es de in\u00edcio r\u00e1pido para ambientes locais. Al\u00e9m disso, demonstre consistentemente demos no ambiente de codespaces para garantir sua integra\u00e7\u00e3o proeminente em nosso fluxo de trabalho. Com sua infraestrutura baseada em nuvem, o GitHub Codespaces apresenta uma abordagem altamente eficiente e simplificada para codifica\u00e7\u00e3o colaborativa em tempo real. Como resultado, novos membros da equipe podem acessar facilmente o projeto GitHub e come\u00e7ar a codificar em segundos, sem necessidade de instala\u00e7\u00e3o em suas m\u00e1quinas locais. Esta solu\u00e7\u00e3o integrada e cont\u00ednua para programa\u00e7\u00e3o em par oferece um fluxo de trabalho simplificado, permitindo que voc\u00ea direcione sua aten\u00e7\u00e3o para a produ\u00e7\u00e3o de c\u00f3digo exemplar, livre das distra\u00e7\u00f5es de processos de configura\u00e7\u00e3o complicados. VSCode Live Share VSCode Live Share \u00e9 especificamente projetado para programa\u00e7\u00e3o em par e permite que voc\u00ea trabalhe na mesma base de c\u00f3digo, em tempo real, com os membros da sua equipe. O \u00e1rduo processo de configurar configura\u00e7\u00f5es complexas, lidar com configura\u00e7\u00f5es confusas, for\u00e7ar os olhos para trabalhar em telas pequenas ou trocar fisicamente de teclados n\u00e3o \u00e9 um problema com o LiveShare. Esta solu\u00e7\u00e3o inovadora permite o compartilhamento cont\u00ednuo do seu ambiente de desenvolvimento com os membros da sua equipe, facilitando experi\u00eancias suaves de codifica\u00e7\u00e3o colaborativa. Totalmente integrado ao Visual Studio Code e ao Visual Studio, o LiveShare oferece o benef\u00edcio adicional de compartilhamento de terminal, colabora\u00e7\u00e3o em sess\u00e3o de depura\u00e7\u00e3o e controle da m\u00e1quina host. Quando combinado com o GitHub Codespaces, ele apresenta um conjunto de ferramentas potente para programa\u00e7\u00e3o em par eficaz. Dica: Compartilhe extens\u00f5es do VSCode (incluindo Live Share) usando um devcontainer.json base. Isso garante que todos os membros da equipe tenham dispon\u00edvel o mesmo conjunto de extens\u00f5es e lhes permita focar na resolu\u00e7\u00e3o das necessidades de neg\u00f3cios desde o primeiro dia. Recursos GitHub Codespaces . VSCode Live Share . Criar um Dev Container . Como as empresas otimizaram o bebedouro humilde do escrit\u00f3rio .","title":"Programa\u00e7\u00e3o em Par Sem Esfor\u00e7o com GitHub Codespaces e VSCode"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/#programacao-em-par-sem-esforco-com-github-codespaces-e-vscode","text":"A programa\u00e7\u00e3o em par costumava ser uma t\u00e9cnica de desenvolvimento de software na qual dois programadores trabalham juntos em um \u00fanico computador, compartilhando um teclado e um mouse, para projetar, codificar, testar e depurar software conjuntamente. \u00c9 um dos padr\u00f5es explorados na se\u00e7\u00e3o por que colaborar? deste playbook. No entanto, com equipes que trabalham principalmente de forma remota, compartilhar um computador f\u00edsico tornou-se um desafio, mas abriu a porta para uma abordagem mais eficiente da programa\u00e7\u00e3o em par. Por meio da utiliza\u00e7\u00e3o eficaz de uma variedade de ferramentas e t\u00e9cnicas, implementamos com sucesso tanto as metodologias de programa\u00e7\u00e3o em par quanto em enxame. Como tal, estamos ansiosos para compartilhar alguns dos valiosos insights e conhecimentos adquiridos com essa experi\u00eancia.","title":"Programa\u00e7\u00e3o em Par Sem Esfor\u00e7o com GitHub Codespaces e VSCode"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/#como-tornar-a-programacao-em-par-uma-experiencia-indolor","text":"","title":"Como tornar a programa\u00e7\u00e3o em par uma experi\u00eancia indolor?"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/#sessoes-de-trabalho","text":"Para aprimorar as capacidades de programa\u00e7\u00e3o em par, voc\u00ea pode criar sess\u00f5es de trabalho regulares que est\u00e3o abertas a todos os membros da equipe. Isso facilita uma colabora\u00e7\u00e3o suave e eficiente, pois todos podem simplesmente participar e trabalhar juntos antes de se dividirem em grupos menores. Essa abordagem se mostrou particularmente ben\u00e9fica para novos membros da equipe que, de outra forma, poderiam se sentir sobrecarregados por uma grande base de c\u00f3digo. Ela emula o conceito do \" bebedouro humilde \", que promove um senso de conex\u00e3o entre os membros da equipe por meio de seu trabalho compartilhado. Al\u00e9m disso, agendar essas sess\u00f5es de trabalho com anteced\u00eancia garante colabora\u00e7\u00e3o intencional e fornece clareza sobre as responsabilidades da hist\u00f3ria do usu\u00e1rio. Para esse fim, atribua uma \u00fanica pessoa a cada hist\u00f3ria do usu\u00e1rio para garantir propriedade clara e eliminar ambiguidades. Ao fazer isso, isso poderia eliminar o problema comum de engenheiros hesitarem em modificar o c\u00f3digo fora de suas tarefas atribu\u00eddas devido ao sentimento de falta de propriedade. Essas sess\u00f5es de trabalho s\u00e3o fundamentais para promover uma din\u00e2mica de equipe coesa, permitindo o compartilhamento eficaz de conhecimento e a resolu\u00e7\u00e3o coletiva de problemas.","title":"Sess\u00f5es de Trabalho"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/#github-codespaces","text":"GitHub Codespaces \u00e9 um componente vital em um ambiente de desenvolvimento eficiente, particularmente no contexto da programa\u00e7\u00e3o em par. Priorize a configura\u00e7\u00e3o de um Codespace como a etapa inicial do projeto, precedendo tarefas como compila\u00e7\u00e3o do projeto na m\u00e1quina local ou instala\u00e7\u00e3o de plugins do VSCode. Para isso, certifique-se de atualizar a documenta\u00e7\u00e3o do Codespace antes de incorporar quaisquer instru\u00e7\u00f5es de in\u00edcio r\u00e1pido para ambientes locais. Al\u00e9m disso, demonstre consistentemente demos no ambiente de codespaces para garantir sua integra\u00e7\u00e3o proeminente em nosso fluxo de trabalho. Com sua infraestrutura baseada em nuvem, o GitHub Codespaces apresenta uma abordagem altamente eficiente e simplificada para codifica\u00e7\u00e3o colaborativa em tempo real. Como resultado, novos membros da equipe podem acessar facilmente o projeto GitHub e come\u00e7ar a codificar em segundos, sem necessidade de instala\u00e7\u00e3o em suas m\u00e1quinas locais. Esta solu\u00e7\u00e3o integrada e cont\u00ednua para programa\u00e7\u00e3o em par oferece um fluxo de trabalho simplificado, permitindo que voc\u00ea direcione sua aten\u00e7\u00e3o para a produ\u00e7\u00e3o de c\u00f3digo exemplar, livre das distra\u00e7\u00f5es de processos de configura\u00e7\u00e3o complicados.","title":"GitHub Codespaces"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/#vscode-live-share","text":"VSCode Live Share \u00e9 especificamente projetado para programa\u00e7\u00e3o em par e permite que voc\u00ea trabalhe na mesma base de c\u00f3digo, em tempo real, com os membros da sua equipe. O \u00e1rduo processo de configurar configura\u00e7\u00f5es complexas, lidar com configura\u00e7\u00f5es confusas, for\u00e7ar os olhos para trabalhar em telas pequenas ou trocar fisicamente de teclados n\u00e3o \u00e9 um problema com o LiveShare. Esta solu\u00e7\u00e3o inovadora permite o compartilhamento cont\u00ednuo do seu ambiente de desenvolvimento com os membros da sua equipe, facilitando experi\u00eancias suaves de codifica\u00e7\u00e3o colaborativa. Totalmente integrado ao Visual Studio Code e ao Visual Studio, o LiveShare oferece o benef\u00edcio adicional de compartilhamento de terminal, colabora\u00e7\u00e3o em sess\u00e3o de depura\u00e7\u00e3o e controle da m\u00e1quina host. Quando combinado com o GitHub Codespaces, ele apresenta um conjunto de ferramentas potente para programa\u00e7\u00e3o em par eficaz. Dica: Compartilhe extens\u00f5es do VSCode (incluindo Live Share) usando um devcontainer.json base. Isso garante que todos os membros da equipe tenham dispon\u00edvel o mesmo conjunto de extens\u00f5es e lhes permita focar na resolu\u00e7\u00e3o das necessidades de neg\u00f3cios desde o primeiro dia.","title":"VSCode Live Share"},{"location":"agile-development/advanced-topics/collaboration/pair-programming-tools/#recursos","text":"GitHub Codespaces . VSCode Live Share . Criar um Dev Container . Como as empresas otimizaram o bebedouro humilde do escrit\u00f3rio .","title":"Recursos"},{"location":"agile-development/advanced-topics/collaboration/social-question/","text":"Pergunta Social do Dia A pergunta social do dia \u00e9 uma quest\u00e3o curta opcional a ser feita ap\u00f3s as tr\u00eas perguntas do projeto no stand-up di\u00e1rio. Ela desenvolve a coes\u00e3o da equipe e a confian\u00e7a interpessoal ao longo de um projeto, facilitando o compartilhamento de prefer\u00eancias pessoais, estilo de vida ou outros contextos. A pergunta social deve ser escolhida antes do stand-up. O facilitador deve selecionar a pergunta de forma independente ou a partir das sugest\u00f5es ass\u00edncronas da equipe. Isso minimiza atrasos no in\u00edcio do stand-up. Dica: fazer o papel de facilitador do stand-up rodar a cada sprint permite que o facilitador escolha a pergunta social de forma independente, sem sobrecarregar nenhum membro da equipe. Propriedades de uma Boa Pergunta Uma boa pergunta tem uma resposta breve com pequena elabora\u00e7\u00e3o opcional. Uma resposta sim ou n\u00e3o n\u00e3o diz muito sobre algu\u00e9m, enquanto saber que sua fruta favorita \u00e9 um durian \u00e9 informativo. Boas perguntas s\u00e3o de baixa consequ\u00eancia, mas permitem controv\u00e9rsia. Ver algu\u00e9m afirmar fortemente que salm\u00e3o e lox em bagel de canela e uva-passa \u00e9 o melhor pedido \u00e9 cativante. Como corol\u00e1rio, uma boa pergunta \u00e9 aquela sobre a qual algu\u00e9m provavelmente \u00e9 apaixonado. Voc\u00ea sabe um pouco mais sobre a personalidade de um membro da equipe se os olhos dele se iluminam ao descrever sua m\u00fasica de karaok\u00ea favorita. Lista Inicial de Perguntas Perguntas potencialmente boas incluem: Qual \u00e9 o seu pedido no Starbucks? Qual \u00e9 o seu sistema operacional favorito? Qual \u00e9 a sua vers\u00e3o favorita do Windows? Qual \u00e9 a sua planta favorita, de casa ou de outro tipo? Qual \u00e9 a sua fruta favorita? Qual \u00e9 o seu fast-food favorito? Qual \u00e9 o seu macarr\u00e3o favorito? Qual \u00e9 o seu editor de texto favorito? Montanhas ou praia? DC ou Marvel? Caf\u00e9 com uma pessoa da hist\u00f3ria: quem? Qual foi a sua compra online mais tola? Qual \u00e9 a sua carreira alternativa? Qual \u00e9 o melhor recheio para bagel? Qual \u00e9 o seu prazer culposo na TV? Qual \u00e9 a sua m\u00fasica de karaok\u00ea preferida? Voc\u00ea preferiria ver o passado ou o futuro? Voc\u00ea preferiria ser capaz de se teleportar ou voar? Voc\u00ea preferiria viver debaixo d'\u00e1gua ou no espa\u00e7o por um ano? Qual \u00e9 o seu aplicativo de telefone favorito? Qual \u00e9 o seu peixe favorito, para comer ou de outra forma? Qual foi a sua melhor fantasia? Quem \u00e9 algu\u00e9m que voc\u00ea admira (da hist\u00f3ria, da sua vida pessoal, etc.)? D\u00ea um motivo. Qual foi o melhor elogio que voc\u00ea j\u00e1 recebeu? Qual \u00e9 o seu emoji favorito ou mais usado no momento? Qual foi o seu maior projeto de fa\u00e7a voc\u00ea mesmo? Qual \u00e9 o tempero que voc\u00ea usa em tudo? Qual \u00e9 o seu g\u00eanero/artista mais ouvido no Spotify (ou apenas o seu favorito) para este ano? Qual foi o seu primeiro computador? Qual \u00e9 o seu tipo favorito de taco? Qual \u00e9 a sua d\u00e9cada favorita? Qual \u00e9 a melhor forma de comer batatas? Qual foi a sua melhor f\u00e9rias (ficar em casa \u00e9 aceit\u00e1vel)? Desenho animado favorito? Escolha algu\u00e9m da sua fam\u00edlia e nos diga algo incr\u00edvel sobre ele. Qual foi a sua viagem de carro mais longa? O que voc\u00ea se lembra de ter aprendido quando era jovem e que \u00e9 ensinado de forma diferente agora? Qual era o seu brinquedo favorito quando crian\u00e7a?","title":"Pergunta Social do Dia"},{"location":"agile-development/advanced-topics/collaboration/social-question/#pergunta-social-do-dia","text":"A pergunta social do dia \u00e9 uma quest\u00e3o curta opcional a ser feita ap\u00f3s as tr\u00eas perguntas do projeto no stand-up di\u00e1rio. Ela desenvolve a coes\u00e3o da equipe e a confian\u00e7a interpessoal ao longo de um projeto, facilitando o compartilhamento de prefer\u00eancias pessoais, estilo de vida ou outros contextos. A pergunta social deve ser escolhida antes do stand-up. O facilitador deve selecionar a pergunta de forma independente ou a partir das sugest\u00f5es ass\u00edncronas da equipe. Isso minimiza atrasos no in\u00edcio do stand-up. Dica: fazer o papel de facilitador do stand-up rodar a cada sprint permite que o facilitador escolha a pergunta social de forma independente, sem sobrecarregar nenhum membro da equipe.","title":"Pergunta Social do Dia"},{"location":"agile-development/advanced-topics/collaboration/social-question/#propriedades-de-uma-boa-pergunta","text":"Uma boa pergunta tem uma resposta breve com pequena elabora\u00e7\u00e3o opcional. Uma resposta sim ou n\u00e3o n\u00e3o diz muito sobre algu\u00e9m, enquanto saber que sua fruta favorita \u00e9 um durian \u00e9 informativo. Boas perguntas s\u00e3o de baixa consequ\u00eancia, mas permitem controv\u00e9rsia. Ver algu\u00e9m afirmar fortemente que salm\u00e3o e lox em bagel de canela e uva-passa \u00e9 o melhor pedido \u00e9 cativante. Como corol\u00e1rio, uma boa pergunta \u00e9 aquela sobre a qual algu\u00e9m provavelmente \u00e9 apaixonado. Voc\u00ea sabe um pouco mais sobre a personalidade de um membro da equipe se os olhos dele se iluminam ao descrever sua m\u00fasica de karaok\u00ea favorita.","title":"Propriedades de uma Boa Pergunta"},{"location":"agile-development/advanced-topics/collaboration/social-question/#lista-inicial-de-perguntas","text":"Perguntas potencialmente boas incluem: Qual \u00e9 o seu pedido no Starbucks? Qual \u00e9 o seu sistema operacional favorito? Qual \u00e9 a sua vers\u00e3o favorita do Windows? Qual \u00e9 a sua planta favorita, de casa ou de outro tipo? Qual \u00e9 a sua fruta favorita? Qual \u00e9 o seu fast-food favorito? Qual \u00e9 o seu macarr\u00e3o favorito? Qual \u00e9 o seu editor de texto favorito? Montanhas ou praia? DC ou Marvel? Caf\u00e9 com uma pessoa da hist\u00f3ria: quem? Qual foi a sua compra online mais tola? Qual \u00e9 a sua carreira alternativa? Qual \u00e9 o melhor recheio para bagel? Qual \u00e9 o seu prazer culposo na TV? Qual \u00e9 a sua m\u00fasica de karaok\u00ea preferida? Voc\u00ea preferiria ver o passado ou o futuro? Voc\u00ea preferiria ser capaz de se teleportar ou voar? Voc\u00ea preferiria viver debaixo d'\u00e1gua ou no espa\u00e7o por um ano? Qual \u00e9 o seu aplicativo de telefone favorito? Qual \u00e9 o seu peixe favorito, para comer ou de outra forma? Qual foi a sua melhor fantasia? Quem \u00e9 algu\u00e9m que voc\u00ea admira (da hist\u00f3ria, da sua vida pessoal, etc.)? D\u00ea um motivo. Qual foi o melhor elogio que voc\u00ea j\u00e1 recebeu? Qual \u00e9 o seu emoji favorito ou mais usado no momento? Qual foi o seu maior projeto de fa\u00e7a voc\u00ea mesmo? Qual \u00e9 o tempero que voc\u00ea usa em tudo? Qual \u00e9 o seu g\u00eanero/artista mais ouvido no Spotify (ou apenas o seu favorito) para este ano? Qual foi o seu primeiro computador? Qual \u00e9 o seu tipo favorito de taco? Qual \u00e9 a sua d\u00e9cada favorita? Qual \u00e9 a melhor forma de comer batatas? Qual foi a sua melhor f\u00e9rias (ficar em casa \u00e9 aceit\u00e1vel)? Desenho animado favorito? Escolha algu\u00e9m da sua fam\u00edlia e nos diga algo incr\u00edvel sobre ele. Qual foi a sua viagem de carro mais longa? O que voc\u00ea se lembra de ter aprendido quando era jovem e que \u00e9 ensinado de forma diferente agora? Qual era o seu brinquedo favorito quando crian\u00e7a?","title":"Lista Inicial de Perguntas"},{"location":"agile-development/advanced-topics/collaboration/teaming-up/","text":"Desenvolvimento da Equipe de Engajamento Em cada envolvimento ISE, as din\u00e2micas s\u00e3o diferentes, assim como as necessidades da equipe. Com base na transfer\u00eancia de aprendizado entre equipes, nosso objetivo \u00e9 construir os ambientes certos de \"c\u00f3digo com\" em cada equipe. Esta documenta\u00e7\u00e3o oferece um modelo de alto n\u00edvel com algumas sugest\u00f5es, visando acelerar a fase de forma\u00e7\u00e3o da equipe para alcan\u00e7ar uma agilidade de alta velocidade, mas n\u00e3o tem a inten\u00e7\u00e3o de fornecer uma lista de itens \"obrigat\u00f3rios\". Identifica\u00e7\u00e3o Como \u00e9 afirmado nas fases de equipe de Tuckman, o desenvolvimento tradicional de equipe tem v\u00e1rias etapas. No entanto, essas fases podem ser extremamente r\u00e1pidas ou \u00e0s vezes incompat\u00edveis em equipes devido a fatores externos, o que se aplica aos envolvimentos ISE. Para minimizar o risco e definir as expectativas de forma correta para todas as partes, uma fase de identifica\u00e7\u00e3o \u00e9 importante para entender uns aos outros. Alguns passos potenciais nesta fase podem ser os seguintes (n\u00e3o limitados): Acordo de Trabalho Identifica\u00e7\u00e3o dos estilos/prefer\u00eancias na comunica\u00e7\u00e3o, compartilhamento, aprendizado e tomada de decis\u00e3o de cada membro da equipe Discuss\u00e3o sobre a necessidade de programa\u00e7\u00e3o em pares Decis\u00f5es sobre gerenciamento e refinamento do backlog, reuni\u00f5es de design semanais, sess\u00f5es de tempo social... etc. M\u00e9todos de comunica\u00e7\u00e3o s\u00edncronos/ass\u00edncronos, hor\u00e1rios de trabalho/flex\u00edveis Decis\u00f5es e identifica\u00e7\u00f5es de gr\u00e1ficos que ser\u00e3o \u00fateis para fornecer informa\u00e7\u00f5es transparentes e verdadeiras para todos Identifica\u00e7\u00e3o das \u00e1reas de \"Artesanato de Software\", o que significa que as ferramentas e m\u00e9todos ser\u00e3o amplamente utilizados durante o envolvimento e tomar as a\u00e7\u00f5es necess\u00e1rias no lado de aprimoramento da equipe, se necess\u00e1rio. GitHub, VSCode LiveShare, AzDevOps, ferramentas e bibliotecas de desenvolvimento necess\u00e1rias... mais. Se o aprimoramento em determinado(s) t\u00f3pico(s) for necess\u00e1rio, identificar as \u00e1reas e organizar picos de c\u00f3digo para aumentar o conhecimento da equipe sobre o(s) t\u00f3pico(s) em quest\u00e3o. Identifica\u00e7\u00e3o de canais de comunica\u00e7\u00e3o, loops de feedback e hor\u00e1rios recorrentes de chamadas da equipe fora das reuni\u00f5es regulares de sprint Introdu\u00e7\u00e3o ao Manifesto da Equipe de Agilidade T\u00e9cnica e planejamento da entrega t\u00e9cnica, visando manter o risco da d\u00edvida t\u00e9cnica m\u00ednimo. Seguindo o Plano e Depura\u00e7\u00e3o \u00c1gil A fase de identifica\u00e7\u00e3o acelera o processo de constru\u00e7\u00e3o de um ambiente seguro para cada indiv\u00edduo na equipe; posteriormente, a equipe tem os ativos necess\u00e1rios para seguir o plano. E \u00e9 responsabilidade da pr\u00f3pria equipe (engenheiros, PO, L\u00edder de Processo) depurar seu n\u00edvel de agilidade. Em cada equipe, a estabiliza\u00e7\u00e3o leva tempo, e a depura\u00e7\u00e3o \u00e1gil proativa \u00e9 o melhor acelerador para diminuir a distra\u00e7\u00e3o longe do objetivo do sprint/envolvimento. A equipe tamb\u00e9m \u00e9 respons\u00e1vel por manter o plano atualizado com base nas mudan\u00e7as/necessidades da equipe e nos resultados da depura\u00e7\u00e3o. Apenas como exemplo, as atividades de depura\u00e7\u00e3o de agilidade podem incluir: Pain\u00e9is relacionados com \"Objetivo\", como queima de trabalho/queima de sa\u00edda, envelhecimento de itens/PR, gr\u00e1fico de humor... etc. s\u00e3o acess\u00edveis \u00e0 equipe e a equipe est\u00e1 sempre atualizada Reuni\u00f5es de Refinamento do Backlog Tamanho das hist\u00f3rias (Muito grande? Muito pequeno?) As \"Hist\u00f3rias de Usu\u00e1rio\" e \"Tarefas\" est\u00e3o claras? Os Crit\u00e9rios de Aceita\u00e7\u00e3o s\u00e3o suficientes e corretos? Todos est\u00e3o prontos para come\u00e7ar ap\u00f3s pegar a Hist\u00f3ria de Usu\u00e1rio/Tarefa? Execu\u00e7\u00e3o de Retrospectivas Eficientes O Objetivo do Sprint est\u00e1 claro em cada itera\u00e7\u00e3o? O processo de estimativa na equipe est\u00e1 melhorando ao longo do tempo ou atende \u00e0 previs\u00e3o de entrega/carga de trabalho? Consulte gentilmente os Valores do Scrum para ter uma melhor compre ens\u00e3o para melhorar o comprometimento da equipe. Seguindo isso, as sugest\u00f5es acima visam remover disfuncionalidades \u00e1geis/equipe e fornecer uma compreens\u00e3o mais ampla da equipe, economia de tempo potencial e total transpar\u00eancia. Recursos Fases de Grupo de Tuckman Valores do Scrum","title":"Desenvolvimento da Equipe de Engajamento"},{"location":"agile-development/advanced-topics/collaboration/teaming-up/#desenvolvimento-da-equipe-de-engajamento","text":"Em cada envolvimento ISE, as din\u00e2micas s\u00e3o diferentes, assim como as necessidades da equipe. Com base na transfer\u00eancia de aprendizado entre equipes, nosso objetivo \u00e9 construir os ambientes certos de \"c\u00f3digo com\" em cada equipe. Esta documenta\u00e7\u00e3o oferece um modelo de alto n\u00edvel com algumas sugest\u00f5es, visando acelerar a fase de forma\u00e7\u00e3o da equipe para alcan\u00e7ar uma agilidade de alta velocidade, mas n\u00e3o tem a inten\u00e7\u00e3o de fornecer uma lista de itens \"obrigat\u00f3rios\".","title":"Desenvolvimento da Equipe de Engajamento"},{"location":"agile-development/advanced-topics/collaboration/teaming-up/#identificacao","text":"Como \u00e9 afirmado nas fases de equipe de Tuckman, o desenvolvimento tradicional de equipe tem v\u00e1rias etapas. No entanto, essas fases podem ser extremamente r\u00e1pidas ou \u00e0s vezes incompat\u00edveis em equipes devido a fatores externos, o que se aplica aos envolvimentos ISE. Para minimizar o risco e definir as expectativas de forma correta para todas as partes, uma fase de identifica\u00e7\u00e3o \u00e9 importante para entender uns aos outros. Alguns passos potenciais nesta fase podem ser os seguintes (n\u00e3o limitados): Acordo de Trabalho Identifica\u00e7\u00e3o dos estilos/prefer\u00eancias na comunica\u00e7\u00e3o, compartilhamento, aprendizado e tomada de decis\u00e3o de cada membro da equipe Discuss\u00e3o sobre a necessidade de programa\u00e7\u00e3o em pares Decis\u00f5es sobre gerenciamento e refinamento do backlog, reuni\u00f5es de design semanais, sess\u00f5es de tempo social... etc. M\u00e9todos de comunica\u00e7\u00e3o s\u00edncronos/ass\u00edncronos, hor\u00e1rios de trabalho/flex\u00edveis Decis\u00f5es e identifica\u00e7\u00f5es de gr\u00e1ficos que ser\u00e3o \u00fateis para fornecer informa\u00e7\u00f5es transparentes e verdadeiras para todos Identifica\u00e7\u00e3o das \u00e1reas de \"Artesanato de Software\", o que significa que as ferramentas e m\u00e9todos ser\u00e3o amplamente utilizados durante o envolvimento e tomar as a\u00e7\u00f5es necess\u00e1rias no lado de aprimoramento da equipe, se necess\u00e1rio. GitHub, VSCode LiveShare, AzDevOps, ferramentas e bibliotecas de desenvolvimento necess\u00e1rias... mais. Se o aprimoramento em determinado(s) t\u00f3pico(s) for necess\u00e1rio, identificar as \u00e1reas e organizar picos de c\u00f3digo para aumentar o conhecimento da equipe sobre o(s) t\u00f3pico(s) em quest\u00e3o. Identifica\u00e7\u00e3o de canais de comunica\u00e7\u00e3o, loops de feedback e hor\u00e1rios recorrentes de chamadas da equipe fora das reuni\u00f5es regulares de sprint Introdu\u00e7\u00e3o ao Manifesto da Equipe de Agilidade T\u00e9cnica e planejamento da entrega t\u00e9cnica, visando manter o risco da d\u00edvida t\u00e9cnica m\u00ednimo.","title":"Identifica\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/teaming-up/#seguindo-o-plano-e-depuracao-agil","text":"A fase de identifica\u00e7\u00e3o acelera o processo de constru\u00e7\u00e3o de um ambiente seguro para cada indiv\u00edduo na equipe; posteriormente, a equipe tem os ativos necess\u00e1rios para seguir o plano. E \u00e9 responsabilidade da pr\u00f3pria equipe (engenheiros, PO, L\u00edder de Processo) depurar seu n\u00edvel de agilidade. Em cada equipe, a estabiliza\u00e7\u00e3o leva tempo, e a depura\u00e7\u00e3o \u00e1gil proativa \u00e9 o melhor acelerador para diminuir a distra\u00e7\u00e3o longe do objetivo do sprint/envolvimento. A equipe tamb\u00e9m \u00e9 respons\u00e1vel por manter o plano atualizado com base nas mudan\u00e7as/necessidades da equipe e nos resultados da depura\u00e7\u00e3o. Apenas como exemplo, as atividades de depura\u00e7\u00e3o de agilidade podem incluir: Pain\u00e9is relacionados com \"Objetivo\", como queima de trabalho/queima de sa\u00edda, envelhecimento de itens/PR, gr\u00e1fico de humor... etc. s\u00e3o acess\u00edveis \u00e0 equipe e a equipe est\u00e1 sempre atualizada Reuni\u00f5es de Refinamento do Backlog Tamanho das hist\u00f3rias (Muito grande? Muito pequeno?) As \"Hist\u00f3rias de Usu\u00e1rio\" e \"Tarefas\" est\u00e3o claras? Os Crit\u00e9rios de Aceita\u00e7\u00e3o s\u00e3o suficientes e corretos? Todos est\u00e3o prontos para come\u00e7ar ap\u00f3s pegar a Hist\u00f3ria de Usu\u00e1rio/Tarefa? Execu\u00e7\u00e3o de Retrospectivas Eficientes O Objetivo do Sprint est\u00e1 claro em cada itera\u00e7\u00e3o? O processo de estimativa na equipe est\u00e1 melhorando ao longo do tempo ou atende \u00e0 previs\u00e3o de entrega/carga de trabalho? Consulte gentilmente os Valores do Scrum para ter uma melhor compre ens\u00e3o para melhorar o comprometimento da equipe. Seguindo isso, as sugest\u00f5es acima visam remover disfuncionalidades \u00e1geis/equipe e fornecer uma compreens\u00e3o mais ampla da equipe, economia de tempo potencial e total transpar\u00eancia.","title":"Seguindo o Plano e Depura\u00e7\u00e3o \u00c1gil"},{"location":"agile-development/advanced-topics/collaboration/teaming-up/#recursos","text":"Fases de Grupo de Tuckman Valores do Scrum","title":"Recursos"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/","text":"Colabora\u00e7\u00e3o Virtual e Programa\u00e7\u00e3o em Par A programa\u00e7\u00e3o em par \u00e9 o m\u00e9todo de trabalho padr\u00e3o que a maioria das grandes organiza\u00e7\u00f5es de engenharia usa para codifica\u00e7\u00e3o \"m\u00e3os no teclado\". Dois desenvolvedores, trabalhando de forma s\u00edncrona, olhando para a mesma tela e tentando codificar e projetar juntos, o que frequentemente resulta em um c\u00f3digo melhor e mais claro do que qualquer um poderia produzir individualmente. A programa\u00e7\u00e3o em par funciona bem nas circunst\u00e2ncias corretas, mas perde parte de seu charme quando executada em um ambiente completamente virtual. O ambiente virtual ainda envolve dois desenvolvedores olhando para a mesma tela e discutindo seus projetos, mas frequentemente h\u00e1 quest\u00f5es log\u00edsticas a serem tratadas, incluindo lat\u00eancia, problemas de configura\u00e7\u00e3o de microfone, considera\u00e7\u00f5es de espa\u00e7o de trabalho e pessoais, e muitos outros pequenos problemas individualmente triviais que pioram a experi\u00eancia. Os padr\u00f5es de trabalho virtual s\u00e3o diferentes dos padr\u00f5es presenciais aos quais estamos acostumados. A programa\u00e7\u00e3o em par, em sua ess\u00eancia, \u00e9 baseada nos seguintes princ\u00edpios: Gerar clareza atrav\u00e9s da comunica\u00e7\u00e3o Produzir maior qualidade atrav\u00e9s da colabora\u00e7\u00e3o Criar propriedade atrav\u00e9s da contribui\u00e7\u00e3o igual A programa\u00e7\u00e3o em par \u00e9 uma forma de alcan\u00e7ar esses resultados. O Teste de Equipe Vermelha (RTT, Red Team Testing) \u00e9 um m\u00e9todo de programa\u00e7\u00e3o alternativo que usa os mesmos princ\u00edpios, mas com algumas das vantagens que os m\u00e9todos de trabalho virtual oferecem. Teste de Equipe Vermelha (Red Team Testing - RTT) O Teste de Equipe Vermelha toma seu nome do paradigma de \"Equipe Vermelha\" e \"Equipe Azul\" de testes de penetra\u00e7\u00e3o e \u00e9 uma forma colaborativa e paralela de trabalhar virtualmente. No RTT, dois desenvolvedores decidem conjuntamente sobre a interface, arquitetura e design do programa, e ent\u00e3o se separam para a fase de implementa\u00e7\u00e3o. Um desenvolvedor escreve testes usando a interface p\u00fablica, tentando realizar testes de casos extremos, valida\u00e7\u00e3o de entrada e outros testes de estresse na interface. O segundo desenvolvedor est\u00e1 simultaneamente escrevendo a implementa\u00e7\u00e3o que eventualmente ser\u00e1 testada. O RTT tem a mesma filosofia que qualquer outro ciclo de vida de Desenvolvimento Orientado a Testes: toda implementa\u00e7\u00e3o \u00e9 separada da interface, e a interface pode ser testada sem conhecimento da implementa\u00e7\u00e3o. Etapas Fase de Design: Ambos os desenvolvedores projetam a interface juntos. Isso inclui: * Assinaturas e nomes de m\u00e9todos * Escrever documenta\u00e7\u00e3o ou docstrings para o que os m\u00e9todos pretendem fazer. * Decis\u00f5es de arquitetura que influenciariam os testes (padr\u00f5es de f\u00e1brica, etc.) Fase de Implementa\u00e7\u00e3o: Os desenvolvedores se separam e paralelizam o trabalho, continuando a se comunicar. * O Desenvolvedor A projetar\u00e1 a implementa\u00e7\u00e3o dos m\u00e9todos, aderindo ao design previamente decidido. * O Desenvolvedor B escrever\u00e1 testes simultaneamente para as mesmas assinaturas de m\u00e9todo, sem conhecer os detalhes da implementa\u00e7\u00e3o. Fase de Integra\u00e7\u00e3o e Teste: Ambos os desenvolvedores fazem o commit de seu c\u00f3digo e executam os testes. * Cen\u00e1rio ut\u00f3pico: Todos os testes s\u00e3o executados e passam corretamente. * Cen\u00e1rio realista: Os testes falharam ou quebraram devido a falhas nos testes. Isso leva a um esclarecimento adicional do design e uma discuss\u00e3o sobre por que os testes falharam. Os desenvolvedores repetir\u00e3o as tr\u00eas fases at\u00e9 que o c\u00f3digo esteja funcional e testado. Quando seguir a estrat\u00e9gia RTT O RTT funciona bem em circunst\u00e2ncias espec\u00edficas. Se a colabora\u00e7\u00e3o precisa acontecer virtualmente, e toda a comunica\u00e7\u00e3o \u00e9 virtual, o RTT reduz a necessidade de comunica\u00e7\u00e3o constante enquanto mant\u00e9m os benef\u00edcios de uma sess\u00e3o de design conjunta. Isso considera o elemento humano: a comunica\u00e7\u00e3o virtual \u00e9 mais exaustiva do que a comunica\u00e7\u00e3o presencial. O RTT tamb\u00e9m funciona bem quando h\u00e1 consenso completo, ou nenhum consenso, sobre qual prop\u00f3sito o c\u00f3digo serve. Como criar o design em conjunto e concordar em implementar e testar contra ele fazem parte do m\u00e9todo RTT, o RTT cria clareza for\u00e7ada atrav\u00e9s da itera\u00e7\u00e3o e comunica\u00e7\u00e3o. Benef\u00edcios O RTT tem muitos dos mesmos benef\u00edcios que a Programa\u00e7\u00e3o em Par e o Desenvolvimento Orientado a Testes, mas tenta atualiz\u00e1-los para um ambiente virtual. A implementa\u00e7\u00e3o e os testes de c\u00f3digo podem ser feitos em paralelo, a grandes dist\u00e2ncias ou em fusos hor\u00e1rios diferentes, o que reduz o tempo total necess\u00e1rio para terminar de escrever o c\u00f3digo. O RTT mant\u00e9m o paradigma de programa\u00e7\u00e3o em par, enquanto reduz a necessidade de comunica\u00e7\u00e3o constante por v\u00eddeo ou entre desenvolvedores. O RTT permite um foco detalhado em design e alinhamento de engenharia antes de implementar qualquer c\u00f3digo, levando a interfaces mais limpas e simples. O RTT incentiva que os testes sejam priorizados ao lado da implementa\u00e7\u00e3o, em vez de seguir ou ser influenciado pela implementa\u00e7\u00e3o do c\u00f3digo. A documenta\u00e7\u00e3o \u00e9 inerentemente uma parte do RTT, j\u00e1 que tanto o implementador quanto o testador precisam de documenta\u00e7\u00e3o correta e atualizada na fase de implementa\u00e7\u00e3o. O que voc\u00ea precisa para o RTT funcionar bem A demanda por comunica\u00e7\u00e3o constante e bom trabalho em equipe pode representar um desafio; atualiza\u00e7\u00f5es di\u00e1rias entre os membros da equipe s\u00e3o essenciais para man","title":"Colabora\u00e7\u00e3o Virtual e Programa\u00e7\u00e3o em Par"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/#colaboracao-virtual-e-programacao-em-par","text":"A programa\u00e7\u00e3o em par \u00e9 o m\u00e9todo de trabalho padr\u00e3o que a maioria das grandes organiza\u00e7\u00f5es de engenharia usa para codifica\u00e7\u00e3o \"m\u00e3os no teclado\". Dois desenvolvedores, trabalhando de forma s\u00edncrona, olhando para a mesma tela e tentando codificar e projetar juntos, o que frequentemente resulta em um c\u00f3digo melhor e mais claro do que qualquer um poderia produzir individualmente. A programa\u00e7\u00e3o em par funciona bem nas circunst\u00e2ncias corretas, mas perde parte de seu charme quando executada em um ambiente completamente virtual. O ambiente virtual ainda envolve dois desenvolvedores olhando para a mesma tela e discutindo seus projetos, mas frequentemente h\u00e1 quest\u00f5es log\u00edsticas a serem tratadas, incluindo lat\u00eancia, problemas de configura\u00e7\u00e3o de microfone, considera\u00e7\u00f5es de espa\u00e7o de trabalho e pessoais, e muitos outros pequenos problemas individualmente triviais que pioram a experi\u00eancia. Os padr\u00f5es de trabalho virtual s\u00e3o diferentes dos padr\u00f5es presenciais aos quais estamos acostumados. A programa\u00e7\u00e3o em par, em sua ess\u00eancia, \u00e9 baseada nos seguintes princ\u00edpios: Gerar clareza atrav\u00e9s da comunica\u00e7\u00e3o Produzir maior qualidade atrav\u00e9s da colabora\u00e7\u00e3o Criar propriedade atrav\u00e9s da contribui\u00e7\u00e3o igual A programa\u00e7\u00e3o em par \u00e9 uma forma de alcan\u00e7ar esses resultados. O Teste de Equipe Vermelha (RTT, Red Team Testing) \u00e9 um m\u00e9todo de programa\u00e7\u00e3o alternativo que usa os mesmos princ\u00edpios, mas com algumas das vantagens que os m\u00e9todos de trabalho virtual oferecem.","title":"Colabora\u00e7\u00e3o Virtual e Programa\u00e7\u00e3o em Par"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/#teste-de-equipe-vermelha-red-team-testing-rtt","text":"O Teste de Equipe Vermelha toma seu nome do paradigma de \"Equipe Vermelha\" e \"Equipe Azul\" de testes de penetra\u00e7\u00e3o e \u00e9 uma forma colaborativa e paralela de trabalhar virtualmente. No RTT, dois desenvolvedores decidem conjuntamente sobre a interface, arquitetura e design do programa, e ent\u00e3o se separam para a fase de implementa\u00e7\u00e3o. Um desenvolvedor escreve testes usando a interface p\u00fablica, tentando realizar testes de casos extremos, valida\u00e7\u00e3o de entrada e outros testes de estresse na interface. O segundo desenvolvedor est\u00e1 simultaneamente escrevendo a implementa\u00e7\u00e3o que eventualmente ser\u00e1 testada. O RTT tem a mesma filosofia que qualquer outro ciclo de vida de Desenvolvimento Orientado a Testes: toda implementa\u00e7\u00e3o \u00e9 separada da interface, e a interface pode ser testada sem conhecimento da implementa\u00e7\u00e3o.","title":"Teste de Equipe Vermelha (Red Team Testing - RTT)"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/#etapas","text":"Fase de Design: Ambos os desenvolvedores projetam a interface juntos. Isso inclui: * Assinaturas e nomes de m\u00e9todos * Escrever documenta\u00e7\u00e3o ou docstrings para o que os m\u00e9todos pretendem fazer. * Decis\u00f5es de arquitetura que influenciariam os testes (padr\u00f5es de f\u00e1brica, etc.) Fase de Implementa\u00e7\u00e3o: Os desenvolvedores se separam e paralelizam o trabalho, continuando a se comunicar. * O Desenvolvedor A projetar\u00e1 a implementa\u00e7\u00e3o dos m\u00e9todos, aderindo ao design previamente decidido. * O Desenvolvedor B escrever\u00e1 testes simultaneamente para as mesmas assinaturas de m\u00e9todo, sem conhecer os detalhes da implementa\u00e7\u00e3o. Fase de Integra\u00e7\u00e3o e Teste: Ambos os desenvolvedores fazem o commit de seu c\u00f3digo e executam os testes. * Cen\u00e1rio ut\u00f3pico: Todos os testes s\u00e3o executados e passam corretamente. * Cen\u00e1rio realista: Os testes falharam ou quebraram devido a falhas nos testes. Isso leva a um esclarecimento adicional do design e uma discuss\u00e3o sobre por que os testes falharam. Os desenvolvedores repetir\u00e3o as tr\u00eas fases at\u00e9 que o c\u00f3digo esteja funcional e testado.","title":"Etapas"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/#quando-seguir-a-estrategia-rtt","text":"O RTT funciona bem em circunst\u00e2ncias espec\u00edficas. Se a colabora\u00e7\u00e3o precisa acontecer virtualmente, e toda a comunica\u00e7\u00e3o \u00e9 virtual, o RTT reduz a necessidade de comunica\u00e7\u00e3o constante enquanto mant\u00e9m os benef\u00edcios de uma sess\u00e3o de design conjunta. Isso considera o elemento humano: a comunica\u00e7\u00e3o virtual \u00e9 mais exaustiva do que a comunica\u00e7\u00e3o presencial. O RTT tamb\u00e9m funciona bem quando h\u00e1 consenso completo, ou nenhum consenso, sobre qual prop\u00f3sito o c\u00f3digo serve. Como criar o design em conjunto e concordar em implementar e testar contra ele fazem parte do m\u00e9todo RTT, o RTT cria clareza for\u00e7ada atrav\u00e9s da itera\u00e7\u00e3o e comunica\u00e7\u00e3o.","title":"Quando seguir a estrat\u00e9gia RTT"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/#beneficios","text":"O RTT tem muitos dos mesmos benef\u00edcios que a Programa\u00e7\u00e3o em Par e o Desenvolvimento Orientado a Testes, mas tenta atualiz\u00e1-los para um ambiente virtual. A implementa\u00e7\u00e3o e os testes de c\u00f3digo podem ser feitos em paralelo, a grandes dist\u00e2ncias ou em fusos hor\u00e1rios diferentes, o que reduz o tempo total necess\u00e1rio para terminar de escrever o c\u00f3digo. O RTT mant\u00e9m o paradigma de programa\u00e7\u00e3o em par, enquanto reduz a necessidade de comunica\u00e7\u00e3o constante por v\u00eddeo ou entre desenvolvedores. O RTT permite um foco detalhado em design e alinhamento de engenharia antes de implementar qualquer c\u00f3digo, levando a interfaces mais limpas e simples. O RTT incentiva que os testes sejam priorizados ao lado da implementa\u00e7\u00e3o, em vez de seguir ou ser influenciado pela implementa\u00e7\u00e3o do c\u00f3digo. A documenta\u00e7\u00e3o \u00e9 inerentemente uma parte do RTT, j\u00e1 que tanto o implementador quanto o testador precisam de documenta\u00e7\u00e3o correta e atualizada na fase de implementa\u00e7\u00e3o.","title":"Benef\u00edcios"},{"location":"agile-development/advanced-topics/collaboration/virtual-collaboration/#o-que-voce-precisa-para-o-rtt-funcionar-bem","text":"A demanda por comunica\u00e7\u00e3o constante e bom trabalho em equipe pode representar um desafio; atualiza\u00e7\u00f5es di\u00e1rias entre os membros da equipe s\u00e3o essenciais para man","title":"O que voc\u00ea precisa para o RTT funcionar bem"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/","text":"Por que Colabora\u00e7\u00e3o Por que a colabora\u00e7\u00e3o \u00e9 importante Em engajamentos, visamos ser altamente colaborativos porque, quando codificamos juntos, temos um melhor desempenho, uma maior velocidade de sprint e um maior grau de compartilhamento de conhecimento entre a equipe. Existem dois padr\u00f5es comuns que usamos para colabora\u00e7\u00e3o: Programa\u00e7\u00e3o em Par e Enxameamento. Programa\u00e7\u00e3o em Par (\"pairing\") - dois engenheiros de software atribu\u00eddos a, e trabalhando em, uma \u00fanica hist\u00f3ria compartilhada de cada vez durante o sprint. O L\u00edder de Desenvolvimento atribui uma hist\u00f3ria de usu\u00e1rio a dois engenheiros - um engenheiro principal (dono da hist\u00f3ria) e um engenheiro secund\u00e1rio (par atribu\u00eddo). Programa\u00e7\u00e3o em Enxame (\"swarming\") - tr\u00eas ou mais engenheiros de software colaborando em um item de alta prioridade para lev\u00e1-lo \u00e0 conclus\u00e3o. Como programar em par Como mencionado, cada hist\u00f3ria \u00e9 intencionalmente atribu\u00edda a um par. O par atribu\u00eddo pode estar no processo de aprimoramento de habilidades, no entanto, eles s\u00e3o parceiros iguais no esfor\u00e7o de desenvolvimento. A seguir est\u00e3o algumas diretrizes gerais para programa\u00e7\u00e3o em par: Ap\u00f3s a atribui\u00e7\u00e3o da hist\u00f3ria/item do backlog do produto (PBI), o par precisa ser deliberado sobre como definir o trabalho a ser conclu\u00eddo. Essa informa\u00e7\u00e3o deve ser expressa claramente na descri\u00e7\u00e3o da hist\u00f3ria e nos crit\u00e9rios de aceita\u00e7\u00e3o. As expectativas sobre isso precisam ser comunicadas e acordadas por ambos os engenheiros e devem ser feitas antes de qualquer sess\u00e3o de trabalho real. O dono da hist\u00f3ria e o par atribu\u00eddo n\u00e3o dividem simplesmente o trabalho e sincronizam regularmente - eles trabalham ativamente juntos nas mesmas tarefas e podem compartilhar suas telas por meio de uma sess\u00e3o online do Teams. Ferramentas colaborativas como VS Live Share podem ser prefer\u00edveis ao compartilhamento de telas. Nem toda colabora\u00e7\u00e3o precisa ser baseada em compartilhamento de tela. Durante as sess\u00f5es colaborativas, um engenheiro fornece o ambiente de desenvolvimento enquanto o outro visualiza ativamente e comenta verbalmente. Os engenheiros trocam de lugar frequentemente de uma sess\u00e3o para a pr\u00f3xima, para que todos tenham tempo no controle do teclado. Os engenheiros utilizam branches de recursos para a colabora\u00e7\u00e3o durante o desenvolvimento de cada hist\u00f3ria, para ter pequenos Pull Requests (PRs) (em oposi\u00e7\u00e3o a um \u00fanico PR gigante) no final do sprint. O c\u00f3digo \u00e9 enviado ao reposit\u00f3rio por ambos os membros do par atribu\u00eddo onde e quando faz sentido, \u00e0 medida que as tarefas foram conclu\u00eddas. O par atribu\u00eddo \u00e9 a voz que representa o par durante o standup di\u00e1rio, enquanto \u00e9 apoiado pelo dono da hist\u00f3ria. Ter os nomes de ambos os indiv\u00edduos (dono e par atribu\u00eddo) vis\u00edveis no PBI pode ser \u00fatil durante as cerim\u00f4nias de sprint e levar a uma maior responsabilidade por parte do par atribu\u00eddo. Um exemplo disso usando cart\u00f5es do Azure DevOps pode ser encontrado aqui . Por que a programa\u00e7\u00e3o em par ajuda na colabora\u00e7\u00e3o A programa\u00e7\u00e3o em par ajuda na colabora\u00e7\u00e3o porque ambos os engenheiros compartilham igual responsabilidade por levar a hist\u00f3ria \u00e0 conclus\u00e3o. Este \u00e9 um exerc\u00edcio mutuamente ben\u00e9fico porque, enquanto o dono da hist\u00f3ria geralmente tem mais experi\u00eancia para se apoiar, o par atribu\u00eddo traz uma vis\u00e3o fresca que n\u00e3o \u00e9 nublada pela repeti\u00e7\u00e3o. Alguns outros benef\u00edcios incluem: Menos defeitos e maior responsabilidade. Ter dois conjuntos de olhos permite que os engenheiros tenham mais oportunidades de detectar erros e de lembrar tarefas frequentemente esquecidas, como escrever testes unit\u00e1rios e de integra\u00e7\u00e3o. A programa\u00e7\u00e3o em par permite que engenheiros com diferentes experi\u00eancias e conhecimentos aprendam um com o outro, colaborando e recebendo feedback em tempo real. Em vez de ter um engenheiro trabalhando sozinho em uma tarefa por longas horas e atingindo um ponto de isolamento, a programa\u00e7\u00e3o em par permite que o par se atualize mutuamente. Mesmo algo t\u00e3o simples quanto descrever o problema em voz alta pode ajudar a descobrir problemas ou bugs no c\u00f3digo. A programa\u00e7\u00e3o em par pode ajudar no brainstorming, bem como na valida\u00e7\u00e3o de detalhes, como tornar os nomes de vari\u00e1veis consistentes. Quando programar em enxame \u00c9 importante saber que nem todo PBI precisa usar enxameamento. Alguns sprints podem nem mesmo justificar o enxameamento. Programar em enxame quando: O trabalho \u00e9 complexo o suficiente para ter mentes coletivas colaborando (n\u00e3o porque a quantidade de trabalho \u00e9 mais do que o que seria conclu\u00eddo em um sprint). A tarefa em que o enxame trabalha se tornou (ou est\u00e1 em perigo iminente de se tornar) um bloqueador para outras hist\u00f3rias. Um desconhecido \u00e9 descoberto que precisa de um esfor\u00e7o colaborativo para formar uma decis\u00e3o sobre como seguir em frente. O conhecimento e a experi\u00eancia coletivos ajudam a mover a hist\u00f3ria mais rapidamente e, em \u00faltima an\u00e1lise, produzem um c\u00f3digo de melhor qualidade. - Um conflito ou diferen\u00e7a de opini\u00e3o n\u00e3o resolvida surge durante uma sess\u00e3o de programa\u00e7\u00e3o em par. Promova o trabalho para se tornar uma sess\u00e3o de enxameamento para ajudar a resolver o conflito. Como programar em enxame Assim que o par descobre que o PBI vai justificar o enxameamento, o par o traz para o resto da equipe (via estacionamento durante o stand-up ou de forma ass\u00edncrona). Os membros da equipe concordam ou se voluntariam para ajudar. O dono da hist\u00f3ria (ou par atribu\u00eddo) envia um convite de chamada do Teams para as partes interessadas. Isso permite que o enxame tenha um tempo de foco dedicado, bloqueando o tempo nos calend\u00e1rios. Durante uma sess\u00e3o de enxameamento, um engenheiro pode se ramificar se houver algo que precise ser tratado enquanto o enxame aborda o problema principal, depois se reconecta e relata. Isso permite que o enxame se concentre em um aspecto central e esteja todos na mesma p\u00e1gina. A chamada do Teams \u00e9 repetida at\u00e9 que uma resolu\u00e7\u00e3o seja encontrada ou um caminho alternativo para seguir em frente seja formulado. Por que a programa\u00e7\u00e3o em enxame ajuda na colabora\u00e7\u00e3o O enxameamento permite que o conhecimento e a expertise coletivos da equipe se unam de forma focada e unificada. N\u00e3o s\u00f3 o enxameamento ajuda a fechar o item mais rapidamente, mas tamb\u00e9m ajuda a equipe a entender os pontos fortes e fracos uns dos outros. Permite que a equipe construa um maior n\u00edvel de confian\u00e7a e trabalhe como uma unidade coesa. Quando decidir enxamear, programar em par e/ou dividir Embora muito tempo possa ser gasto na programa\u00e7\u00e3o em par, faz sentido dividir o trabalho quando as pessoas entendem como o trabalho ser\u00e1 realizado, e o trabalho a ser feito \u00e9 em grande parte prescritivo. Uma vez que a hist\u00f3ria foi conjuntamente distribu\u00edda por ambos os engenheiros, os engenheiros podem optar por abordar algumas tarefas separadamente e depois combinar o trabalho no final. A programa\u00e7\u00e3o em par \u00e9 mais \u00fatil quando os engenheiros n\u00e3o t\u00eam clareza perfeita sobre o que precisa ser feito ou como pode ser feito. O enxameamento \u00e9 feito quando os dois engenheiros atribu\u00eddos \u00e0 hist\u00f3ria precisam de uma placa de som adicional ou precisam de expertise que outros membros da equipe poderiam fornecer. Benef\u00edcios do aumento da colabora\u00e7\u00e3o O compartilhamento de conhecimento e a uni\u00e3o de engenheiros de ISE e clientes de uma forma \"code-with\" \u00e9 um aspecto importante dos engajamentos de ISE. Isso aumenta tanto a capacidade de nossos clientes quanto de nossa equipe de ISE para construir no Azure. Somos respons\u00e1veis por demonstrar fundamentos de engenharia e deixar o cliente em um lugar melhor depois que nos desengajamos. Isso s\u00f3 pode acontecer se colaborarmos e nos envolvermos juntos como equipe. Al\u00e9m de melhorar a qualidade do software, isso tamb\u00e9m adiciona um aspecto social ben\u00e9fico aos engajamentos. Recursos Como adicionar um campo personalizado de programa\u00e7\u00e3o em par nas Hist\u00f3rias de Usu\u00e1rio do Azure DevOps - adicionando um campo personalizado do tipo Identity no Azure DevOps para programa\u00e7\u00e3o em par Sobre Programa\u00e7\u00e3o em Par - Martin Fowler Li\u00e7\u00f5es pr\u00e1ticas de Programa\u00e7\u00e3o em Par - essas podem ser usadas (e adaptadas) para apoiar a introdu\u00e7\u00e3o da programa\u00e7\u00e3o em par em sua equipe (interna da MS ou incluindo clientes) Programa\u00e7\u00e3o em Par sem Esfor\u00e7o com GitHub Codespaces e VSCode","title":"Por que Colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#por-que-colaboracao","text":"","title":"Por que Colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#por-que-a-colaboracao-e-importante","text":"Em engajamentos, visamos ser altamente colaborativos porque, quando codificamos juntos, temos um melhor desempenho, uma maior velocidade de sprint e um maior grau de compartilhamento de conhecimento entre a equipe. Existem dois padr\u00f5es comuns que usamos para colabora\u00e7\u00e3o: Programa\u00e7\u00e3o em Par e Enxameamento. Programa\u00e7\u00e3o em Par (\"pairing\") - dois engenheiros de software atribu\u00eddos a, e trabalhando em, uma \u00fanica hist\u00f3ria compartilhada de cada vez durante o sprint. O L\u00edder de Desenvolvimento atribui uma hist\u00f3ria de usu\u00e1rio a dois engenheiros - um engenheiro principal (dono da hist\u00f3ria) e um engenheiro secund\u00e1rio (par atribu\u00eddo). Programa\u00e7\u00e3o em Enxame (\"swarming\") - tr\u00eas ou mais engenheiros de software colaborando em um item de alta prioridade para lev\u00e1-lo \u00e0 conclus\u00e3o.","title":"Por que a colabora\u00e7\u00e3o \u00e9 importante"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#como-programar-em-par","text":"Como mencionado, cada hist\u00f3ria \u00e9 intencionalmente atribu\u00edda a um par. O par atribu\u00eddo pode estar no processo de aprimoramento de habilidades, no entanto, eles s\u00e3o parceiros iguais no esfor\u00e7o de desenvolvimento. A seguir est\u00e3o algumas diretrizes gerais para programa\u00e7\u00e3o em par: Ap\u00f3s a atribui\u00e7\u00e3o da hist\u00f3ria/item do backlog do produto (PBI), o par precisa ser deliberado sobre como definir o trabalho a ser conclu\u00eddo. Essa informa\u00e7\u00e3o deve ser expressa claramente na descri\u00e7\u00e3o da hist\u00f3ria e nos crit\u00e9rios de aceita\u00e7\u00e3o. As expectativas sobre isso precisam ser comunicadas e acordadas por ambos os engenheiros e devem ser feitas antes de qualquer sess\u00e3o de trabalho real. O dono da hist\u00f3ria e o par atribu\u00eddo n\u00e3o dividem simplesmente o trabalho e sincronizam regularmente - eles trabalham ativamente juntos nas mesmas tarefas e podem compartilhar suas telas por meio de uma sess\u00e3o online do Teams. Ferramentas colaborativas como VS Live Share podem ser prefer\u00edveis ao compartilhamento de telas. Nem toda colabora\u00e7\u00e3o precisa ser baseada em compartilhamento de tela. Durante as sess\u00f5es colaborativas, um engenheiro fornece o ambiente de desenvolvimento enquanto o outro visualiza ativamente e comenta verbalmente. Os engenheiros trocam de lugar frequentemente de uma sess\u00e3o para a pr\u00f3xima, para que todos tenham tempo no controle do teclado. Os engenheiros utilizam branches de recursos para a colabora\u00e7\u00e3o durante o desenvolvimento de cada hist\u00f3ria, para ter pequenos Pull Requests (PRs) (em oposi\u00e7\u00e3o a um \u00fanico PR gigante) no final do sprint. O c\u00f3digo \u00e9 enviado ao reposit\u00f3rio por ambos os membros do par atribu\u00eddo onde e quando faz sentido, \u00e0 medida que as tarefas foram conclu\u00eddas. O par atribu\u00eddo \u00e9 a voz que representa o par durante o standup di\u00e1rio, enquanto \u00e9 apoiado pelo dono da hist\u00f3ria. Ter os nomes de ambos os indiv\u00edduos (dono e par atribu\u00eddo) vis\u00edveis no PBI pode ser \u00fatil durante as cerim\u00f4nias de sprint e levar a uma maior responsabilidade por parte do par atribu\u00eddo. Um exemplo disso usando cart\u00f5es do Azure DevOps pode ser encontrado aqui .","title":"Como programar em par"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#por-que-a-programacao-em-par-ajuda-na-colaboracao","text":"A programa\u00e7\u00e3o em par ajuda na colabora\u00e7\u00e3o porque ambos os engenheiros compartilham igual responsabilidade por levar a hist\u00f3ria \u00e0 conclus\u00e3o. Este \u00e9 um exerc\u00edcio mutuamente ben\u00e9fico porque, enquanto o dono da hist\u00f3ria geralmente tem mais experi\u00eancia para se apoiar, o par atribu\u00eddo traz uma vis\u00e3o fresca que n\u00e3o \u00e9 nublada pela repeti\u00e7\u00e3o. Alguns outros benef\u00edcios incluem: Menos defeitos e maior responsabilidade. Ter dois conjuntos de olhos permite que os engenheiros tenham mais oportunidades de detectar erros e de lembrar tarefas frequentemente esquecidas, como escrever testes unit\u00e1rios e de integra\u00e7\u00e3o. A programa\u00e7\u00e3o em par permite que engenheiros com diferentes experi\u00eancias e conhecimentos aprendam um com o outro, colaborando e recebendo feedback em tempo real. Em vez de ter um engenheiro trabalhando sozinho em uma tarefa por longas horas e atingindo um ponto de isolamento, a programa\u00e7\u00e3o em par permite que o par se atualize mutuamente. Mesmo algo t\u00e3o simples quanto descrever o problema em voz alta pode ajudar a descobrir problemas ou bugs no c\u00f3digo. A programa\u00e7\u00e3o em par pode ajudar no brainstorming, bem como na valida\u00e7\u00e3o de detalhes, como tornar os nomes de vari\u00e1veis consistentes.","title":"Por que a programa\u00e7\u00e3o em par ajuda na colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#quando-programar-em-enxame","text":"\u00c9 importante saber que nem todo PBI precisa usar enxameamento. Alguns sprints podem nem mesmo justificar o enxameamento. Programar em enxame quando: O trabalho \u00e9 complexo o suficiente para ter mentes coletivas colaborando (n\u00e3o porque a quantidade de trabalho \u00e9 mais do que o que seria conclu\u00eddo em um sprint). A tarefa em que o enxame trabalha se tornou (ou est\u00e1 em perigo iminente de se tornar) um bloqueador para outras hist\u00f3rias. Um desconhecido \u00e9 descoberto que precisa de um esfor\u00e7o colaborativo para formar uma decis\u00e3o sobre como seguir em frente. O conhecimento e a experi\u00eancia coletivos ajudam a mover a hist\u00f3ria mais rapidamente e, em \u00faltima an\u00e1lise, produzem um c\u00f3digo de melhor qualidade. - Um conflito ou diferen\u00e7a de opini\u00e3o n\u00e3o resolvida surge durante uma sess\u00e3o de programa\u00e7\u00e3o em par. Promova o trabalho para se tornar uma sess\u00e3o de enxameamento para ajudar a resolver o conflito.","title":"Quando programar em enxame"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#como-programar-em-enxame","text":"Assim que o par descobre que o PBI vai justificar o enxameamento, o par o traz para o resto da equipe (via estacionamento durante o stand-up ou de forma ass\u00edncrona). Os membros da equipe concordam ou se voluntariam para ajudar. O dono da hist\u00f3ria (ou par atribu\u00eddo) envia um convite de chamada do Teams para as partes interessadas. Isso permite que o enxame tenha um tempo de foco dedicado, bloqueando o tempo nos calend\u00e1rios. Durante uma sess\u00e3o de enxameamento, um engenheiro pode se ramificar se houver algo que precise ser tratado enquanto o enxame aborda o problema principal, depois se reconecta e relata. Isso permite que o enxame se concentre em um aspecto central e esteja todos na mesma p\u00e1gina. A chamada do Teams \u00e9 repetida at\u00e9 que uma resolu\u00e7\u00e3o seja encontrada ou um caminho alternativo para seguir em frente seja formulado.","title":"Como programar em enxame"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#por-que-a-programacao-em-enxame-ajuda-na-colaboracao","text":"O enxameamento permite que o conhecimento e a expertise coletivos da equipe se unam de forma focada e unificada. N\u00e3o s\u00f3 o enxameamento ajuda a fechar o item mais rapidamente, mas tamb\u00e9m ajuda a equipe a entender os pontos fortes e fracos uns dos outros. Permite que a equipe construa um maior n\u00edvel de confian\u00e7a e trabalhe como uma unidade coesa.","title":"Por que a programa\u00e7\u00e3o em enxame ajuda na colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#quando-decidir-enxamear-programar-em-par-eou-dividir","text":"Embora muito tempo possa ser gasto na programa\u00e7\u00e3o em par, faz sentido dividir o trabalho quando as pessoas entendem como o trabalho ser\u00e1 realizado, e o trabalho a ser feito \u00e9 em grande parte prescritivo. Uma vez que a hist\u00f3ria foi conjuntamente distribu\u00edda por ambos os engenheiros, os engenheiros podem optar por abordar algumas tarefas separadamente e depois combinar o trabalho no final. A programa\u00e7\u00e3o em par \u00e9 mais \u00fatil quando os engenheiros n\u00e3o t\u00eam clareza perfeita sobre o que precisa ser feito ou como pode ser feito. O enxameamento \u00e9 feito quando os dois engenheiros atribu\u00eddos \u00e0 hist\u00f3ria precisam de uma placa de som adicional ou precisam de expertise que outros membros da equipe poderiam fornecer.","title":"Quando decidir enxamear, programar em par e/ou dividir"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#beneficios-do-aumento-da-colaboracao","text":"O compartilhamento de conhecimento e a uni\u00e3o de engenheiros de ISE e clientes de uma forma \"code-with\" \u00e9 um aspecto importante dos engajamentos de ISE. Isso aumenta tanto a capacidade de nossos clientes quanto de nossa equipe de ISE para construir no Azure. Somos respons\u00e1veis por demonstrar fundamentos de engenharia e deixar o cliente em um lugar melhor depois que nos desengajamos. Isso s\u00f3 pode acontecer se colaborarmos e nos envolvermos juntos como equipe. Al\u00e9m de melhorar a qualidade do software, isso tamb\u00e9m adiciona um aspecto social ben\u00e9fico aos engajamentos.","title":"Benef\u00edcios do aumento da colabora\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/collaboration/why-collaboration/#recursos","text":"Como adicionar um campo personalizado de programa\u00e7\u00e3o em par nas Hist\u00f3rias de Usu\u00e1rio do Azure DevOps - adicionando um campo personalizado do tipo Identity no Azure DevOps para programa\u00e7\u00e3o em par Sobre Programa\u00e7\u00e3o em Par - Martin Fowler Li\u00e7\u00f5es pr\u00e1ticas de Programa\u00e7\u00e3o em Par - essas podem ser usadas (e adaptadas) para apoiar a introdu\u00e7\u00e3o da programa\u00e7\u00e3o em par em sua equipe (interna da MS ou incluindo clientes) Programa\u00e7\u00e3o em Par sem Esfor\u00e7o com GitHub Codespaces e VSCode","title":"Recursos"},{"location":"agile-development/advanced-topics/effective-organization/","text":"Recomenda\u00e7\u00f5es Avan\u00e7adas para uma Organiza\u00e7\u00e3o Mais Eficiente Plano de Entrega/Lan\u00e7amento Scrum de Scrums","title":"Recomenda\u00e7\u00f5es Avan\u00e7adas para uma Organiza\u00e7\u00e3o Mais Eficiente"},{"location":"agile-development/advanced-topics/effective-organization/#recomendacoes-avancadas-para-uma-organizacao-mais-eficiente","text":"Plano de Entrega/Lan\u00e7amento Scrum de Scrums","title":"Recomenda\u00e7\u00f5es Avan\u00e7adas para uma Organiza\u00e7\u00e3o Mais Eficiente"},{"location":"agile-development/advanced-topics/effective-organization/delivery-plan/","text":"Plano de Entrega Objetivos Embora o Scrum n\u00e3o exija e desencoraje o planejamento de mais de um sprint por vez, a maioria de n\u00f3s trabalha em empresas onde somos dependentes de equipes externas (por exemplo: marketing, vendas, suporte). Uma avalia\u00e7\u00e3o aproximada do escopo do projeto planejado \u00e9 alcan\u00e7\u00e1vel dentro de um prazo e recursos razo\u00e1veis. O objetivo \u00e9 ter um plano e uma estimativa aproximados como ponto de partida, e n\u00e3o implementar o \"Agilefall\". Note que este \u00e9 apenas um ponto de partida para permitir discuss\u00f5es de planejamento. Esperamos que o cronograma real evolua e mude ao longo do tempo e que voc\u00ea atualize o escopo e o cronograma \u00e0 medida que avan\u00e7a. Os Planos de Entrega garantem que suas equipes estejam alinhadas com os objetivos organizacionais. Benef\u00edcios Ao concluir a avalia\u00e7\u00e3o, voc\u00ea pode questionar o escopo, o prazo ou pedir mais recursos. \u00c0 medida que avan\u00e7a na entrega do seu projeto/produto, voc\u00ea pode destacar riscos para o escopo, prazo e recursos. Abordagem Uma abordagem que voc\u00ea pode adotar \u00e9 com post-its e uma planilha. Etapa 1: Classifique as funcionalidades por ordem de import\u00e2ncia para tudo em seu backlog Funcionalidades Funcionais Funcionalidades N\u00e3o-funcionais Pesquisa e Design de Usu\u00e1rio Testes Documenta\u00e7\u00e3o Transfer\u00eancia de Conhecimento/Processos de Suporte Etapa 2: Classifique as funcionalidades em termos de semanas de trabalho por pessoa. Em alguns cen\u00e1rios, voc\u00ea n\u00e3o tem ideia de qu\u00e3o complexo \u00e9 o trabalho. Nessa situa\u00e7\u00e3o, voc\u00ea pode pedir tempo para realizar um spike (limitar o esfor\u00e7o para que voc\u00ea possa voltar a tempo). Etapa 3: Calcule a capacidade da equipe com base no n\u00famero de semanas por pessoa com sua data de in\u00edcio e t\u00e9rmino e menos feriados, f\u00e9rias, confer\u00eancias, treinamentos e dias de integra\u00e7\u00e3o. Al\u00e9m disso, subtraia o tempo se a pessoa tamb\u00e9m estiver trabalhando em defeitos e suporte. Etapa 4: Com base em sua capacidade, voc\u00ea agora tem as op\u00e7\u00f5es Pedir mais recursos. Aten\u00e7\u00e3o: integrar novos recursos leva tempo. Reduzir o escopo para o MVP mais b\u00e1sico. Aten\u00e7\u00e3o: ao reduzir mais o escopo, ele pode n\u00e3o ser mais valioso para o cliente. Considere um cupcake que \u00e9 tudo o que voc\u00ea precisa. Voc\u00ea n\u00e3o quer retirar a cobertura. Pedir mais tempo. Geralmente, isso \u00e9 o mais flex\u00edvel, mas se houver uma data de marketing que voc\u00ea precisa cumprir, isso pode n\u00e3o ser t\u00e3o flex\u00edvel. Ferramentas Voc\u00ea tamb\u00e9m pode aproveitar uma dessas ferramentas criando seus \u00e9picos e funcionalidades e adicionando as estimativas de semanas. O recurso Planos (Pr\u00e9-visualiza\u00e7\u00e3o) no Azure DevOps ajudar\u00e1 voc\u00ea a fazer um plano. Os Planos de Entrega fornecem um cronograma de hist\u00f3rias ou funcionalidades que sua equipe planeja entregar. Os Planos de Entrega mostram os itens de trabalho agendados por um sprint (caminho de itera\u00e7\u00e3o) de equipes selecionadas contra uma vis\u00e3o de calend\u00e1rio. Confluence JIRA, Trello, Rally, Asana, Basecamp e GitHub Issues s\u00e3o outras ferramentas semelhantes no mercado (algumas s\u00e3o gratuitas, outras voc\u00ea paga uma taxa mensal, ou voc\u00ea pode instalar no local) que voc\u00ea pode aproveitar.","title":"Plano de Entrega"},{"location":"agile-development/advanced-topics/effective-organization/delivery-plan/#plano-de-entrega","text":"","title":"Plano de Entrega"},{"location":"agile-development/advanced-topics/effective-organization/delivery-plan/#objetivos","text":"Embora o Scrum n\u00e3o exija e desencoraje o planejamento de mais de um sprint por vez, a maioria de n\u00f3s trabalha em empresas onde somos dependentes de equipes externas (por exemplo: marketing, vendas, suporte). Uma avalia\u00e7\u00e3o aproximada do escopo do projeto planejado \u00e9 alcan\u00e7\u00e1vel dentro de um prazo e recursos razo\u00e1veis. O objetivo \u00e9 ter um plano e uma estimativa aproximados como ponto de partida, e n\u00e3o implementar o \"Agilefall\". Note que este \u00e9 apenas um ponto de partida para permitir discuss\u00f5es de planejamento. Esperamos que o cronograma real evolua e mude ao longo do tempo e que voc\u00ea atualize o escopo e o cronograma \u00e0 medida que avan\u00e7a. Os Planos de Entrega garantem que suas equipes estejam alinhadas com os objetivos organizacionais.","title":"Objetivos"},{"location":"agile-development/advanced-topics/effective-organization/delivery-plan/#beneficios","text":"Ao concluir a avalia\u00e7\u00e3o, voc\u00ea pode questionar o escopo, o prazo ou pedir mais recursos. \u00c0 medida que avan\u00e7a na entrega do seu projeto/produto, voc\u00ea pode destacar riscos para o escopo, prazo e recursos.","title":"Benef\u00edcios"},{"location":"agile-development/advanced-topics/effective-organization/delivery-plan/#abordagem","text":"Uma abordagem que voc\u00ea pode adotar \u00e9 com post-its e uma planilha. Etapa 1: Classifique as funcionalidades por ordem de import\u00e2ncia para tudo em seu backlog Funcionalidades Funcionais Funcionalidades N\u00e3o-funcionais Pesquisa e Design de Usu\u00e1rio Testes Documenta\u00e7\u00e3o Transfer\u00eancia de Conhecimento/Processos de Suporte Etapa 2: Classifique as funcionalidades em termos de semanas de trabalho por pessoa. Em alguns cen\u00e1rios, voc\u00ea n\u00e3o tem ideia de qu\u00e3o complexo \u00e9 o trabalho. Nessa situa\u00e7\u00e3o, voc\u00ea pode pedir tempo para realizar um spike (limitar o esfor\u00e7o para que voc\u00ea possa voltar a tempo). Etapa 3: Calcule a capacidade da equipe com base no n\u00famero de semanas por pessoa com sua data de in\u00edcio e t\u00e9rmino e menos feriados, f\u00e9rias, confer\u00eancias, treinamentos e dias de integra\u00e7\u00e3o. Al\u00e9m disso, subtraia o tempo se a pessoa tamb\u00e9m estiver trabalhando em defeitos e suporte. Etapa 4: Com base em sua capacidade, voc\u00ea agora tem as op\u00e7\u00f5es Pedir mais recursos. Aten\u00e7\u00e3o: integrar novos recursos leva tempo. Reduzir o escopo para o MVP mais b\u00e1sico. Aten\u00e7\u00e3o: ao reduzir mais o escopo, ele pode n\u00e3o ser mais valioso para o cliente. Considere um cupcake que \u00e9 tudo o que voc\u00ea precisa. Voc\u00ea n\u00e3o quer retirar a cobertura. Pedir mais tempo. Geralmente, isso \u00e9 o mais flex\u00edvel, mas se houver uma data de marketing que voc\u00ea precisa cumprir, isso pode n\u00e3o ser t\u00e3o flex\u00edvel.","title":"Abordagem"},{"location":"agile-development/advanced-topics/effective-organization/delivery-plan/#ferramentas","text":"Voc\u00ea tamb\u00e9m pode aproveitar uma dessas ferramentas criando seus \u00e9picos e funcionalidades e adicionando as estimativas de semanas. O recurso Planos (Pr\u00e9-visualiza\u00e7\u00e3o) no Azure DevOps ajudar\u00e1 voc\u00ea a fazer um plano. Os Planos de Entrega fornecem um cronograma de hist\u00f3rias ou funcionalidades que sua equipe planeja entregar. Os Planos de Entrega mostram os itens de trabalho agendados por um sprint (caminho de itera\u00e7\u00e3o) de equipes selecionadas contra uma vis\u00e3o de calend\u00e1rio. Confluence JIRA, Trello, Rally, Asana, Basecamp e GitHub Issues s\u00e3o outras ferramentas semelhantes no mercado (algumas s\u00e3o gratuitas, outras voc\u00ea paga uma taxa mensal, ou voc\u00ea pode instalar no local) que voc\u00ea pode aproveitar.","title":"Ferramentas"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/","text":"Scrum de Scrums Scrum de Scrums \u00e9 uma t\u00e9cnica usada para escalar o Scrum para um grupo maior trabalhando em dire\u00e7\u00e3o ao mesmo objetivo de projeto. No Scrum, consideramos uma equipe grande demais quando ultrapassa 10-12 indiv\u00edduos. Isso deve ser decidido caso a caso. Se o projeto for configurado em v\u00e1rias correntes de trabalho que cont\u00eam um grupo fixo de pessoas e uma reuni\u00e3o de stand-up comum est\u00e1 diminuindo a produtividade, o Scrum de Scrums deve ser considerado. A equipe identificaria os diferentes subgrupos que atuariam como equipes Scrum separadas com seu pr\u00f3prio backlog, quadro e stand-up . Objetivos O objetivo da cerim\u00f4nia de Scrum de Scrums \u00e9 dar \u00e0s subequipes a agilidade de que precisam sem perder visibilidade e coordena\u00e7\u00e3o. Tamb\u00e9m ajuda a garantir que as subequipes estejam alcan\u00e7ando seus objetivos de sprint e que estejam indo na dire\u00e7\u00e3o certa para alcan\u00e7ar o objetivo geral do projeto. A cerim\u00f4nia de Scrum de Scrums acontece todos os dias e pode ser vista como um stand-up regular: O que foi feito no dia anterior pela subequipe. O que ser\u00e1 feito hoje pela subequipe. Quais s\u00e3o os bloqueadores ou outros problemas para a subequipe. Quais s\u00e3o os bloqueadores ou problemas que podem impactar outras subequipes. O resultado da reuni\u00e3o resultar\u00e1 em uma lista de impedimentos relacionados \u00e0 coordena\u00e7\u00e3o de todo o projeto. As solu\u00e7\u00f5es podem ser: concordar com interfaces entre equipes, discutir mudan\u00e7as de arquitetura, evoluir limites de responsabilidade, etc. Esta lista de impedimentos geralmente \u00e9 gerenciada em um backlog separado, mas n\u00e3o precisa ser. Participa\u00e7\u00e3o A orienta\u00e7\u00e3o comum \u00e9 ter, em m\u00e9dia, uma pessoa por subequipe para participar do Scrum de Scrums. Idealmente, o L\u00edder de Processo de cada subequipe os representaria nesta cerim\u00f4nia. Em alguns casos, o representante do dia \u00e9 selecionado no final de cada stand-up di\u00e1rio da subequipe e pode mudar todos os dias. Na pr\u00e1tica, ter um representante fixo tende a ser mais eficiente a longo prazo. Impacto Esta pr\u00e1tica \u00e9 \u00fatil em casos de projetos mais longos e com um escopo maior, exigindo mais pessoas. Ao ter mais pessoas, geralmente \u00e9 mais f\u00e1cil dividir o projeto em subequipes. Ter um Scrum de Scrums di\u00e1rio melhora a comunica\u00e7\u00e3o, reduz o risco de problemas de integra\u00e7\u00e3o e aumenta as chances de sucesso do projeto. Ao escolher implementar o Scrum de Scrums, voc\u00ea precisa ter em mente que alguns membros da equipe ter\u00e3o reuni\u00f5es adicionais para coordenar e participar. Al\u00e9m disso: todos os membros da equipe de cada subequipe precisam ser atualizados sobre as decis\u00f5es em um momento posterior para garantir um bom fluxo de informa\u00e7\u00f5es. Medidas A maneira mais f\u00e1cil de medir o impacto \u00e9 acompanhando o tempo para resolver problemas no backlog do Scrum de Scrums. Voc\u00ea tamb\u00e9m pode acompanhar problemas relatados durante a retrospectiva relacionados \u00e0 coordena\u00e7\u00e3o global (est\u00e1 bem feito? pode ser melhorado?). Orienta\u00e7\u00f5es para Facilita\u00e7\u00e3o Isso deve ser facilitado como um stand-up regular.","title":"Scrum de Scrums"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/#scrum-de-scrums","text":"Scrum de Scrums \u00e9 uma t\u00e9cnica usada para escalar o Scrum para um grupo maior trabalhando em dire\u00e7\u00e3o ao mesmo objetivo de projeto. No Scrum, consideramos uma equipe grande demais quando ultrapassa 10-12 indiv\u00edduos. Isso deve ser decidido caso a caso. Se o projeto for configurado em v\u00e1rias correntes de trabalho que cont\u00eam um grupo fixo de pessoas e uma reuni\u00e3o de stand-up comum est\u00e1 diminuindo a produtividade, o Scrum de Scrums deve ser considerado. A equipe identificaria os diferentes subgrupos que atuariam como equipes Scrum separadas com seu pr\u00f3prio backlog, quadro e stand-up .","title":"Scrum de Scrums"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/#objetivos","text":"O objetivo da cerim\u00f4nia de Scrum de Scrums \u00e9 dar \u00e0s subequipes a agilidade de que precisam sem perder visibilidade e coordena\u00e7\u00e3o. Tamb\u00e9m ajuda a garantir que as subequipes estejam alcan\u00e7ando seus objetivos de sprint e que estejam indo na dire\u00e7\u00e3o certa para alcan\u00e7ar o objetivo geral do projeto. A cerim\u00f4nia de Scrum de Scrums acontece todos os dias e pode ser vista como um stand-up regular: O que foi feito no dia anterior pela subequipe. O que ser\u00e1 feito hoje pela subequipe. Quais s\u00e3o os bloqueadores ou outros problemas para a subequipe. Quais s\u00e3o os bloqueadores ou problemas que podem impactar outras subequipes. O resultado da reuni\u00e3o resultar\u00e1 em uma lista de impedimentos relacionados \u00e0 coordena\u00e7\u00e3o de todo o projeto. As solu\u00e7\u00f5es podem ser: concordar com interfaces entre equipes, discutir mudan\u00e7as de arquitetura, evoluir limites de responsabilidade, etc. Esta lista de impedimentos geralmente \u00e9 gerenciada em um backlog separado, mas n\u00e3o precisa ser.","title":"Objetivos"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/#participacao","text":"A orienta\u00e7\u00e3o comum \u00e9 ter, em m\u00e9dia, uma pessoa por subequipe para participar do Scrum de Scrums. Idealmente, o L\u00edder de Processo de cada subequipe os representaria nesta cerim\u00f4nia. Em alguns casos, o representante do dia \u00e9 selecionado no final de cada stand-up di\u00e1rio da subequipe e pode mudar todos os dias. Na pr\u00e1tica, ter um representante fixo tende a ser mais eficiente a longo prazo.","title":"Participa\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/#impacto","text":"Esta pr\u00e1tica \u00e9 \u00fatil em casos de projetos mais longos e com um escopo maior, exigindo mais pessoas. Ao ter mais pessoas, geralmente \u00e9 mais f\u00e1cil dividir o projeto em subequipes. Ter um Scrum de Scrums di\u00e1rio melhora a comunica\u00e7\u00e3o, reduz o risco de problemas de integra\u00e7\u00e3o e aumenta as chances de sucesso do projeto. Ao escolher implementar o Scrum de Scrums, voc\u00ea precisa ter em mente que alguns membros da equipe ter\u00e3o reuni\u00f5es adicionais para coordenar e participar. Al\u00e9m disso: todos os membros da equipe de cada subequipe precisam ser atualizados sobre as decis\u00f5es em um momento posterior para garantir um bom fluxo de informa\u00e7\u00f5es.","title":"Impacto"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/#medidas","text":"A maneira mais f\u00e1cil de medir o impacto \u00e9 acompanhando o tempo para resolver problemas no backlog do Scrum de Scrums. Voc\u00ea tamb\u00e9m pode acompanhar problemas relatados durante a retrospectiva relacionados \u00e0 coordena\u00e7\u00e3o global (est\u00e1 bem feito? pode ser melhorado?).","title":"Medidas"},{"location":"agile-development/advanced-topics/effective-organization/scrum-of-scrums/#orientacoes-para-facilitacao","text":"Isso deve ser facilitado como um stand-up regular.","title":"Orienta\u00e7\u00f5es para Facilita\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/team-agreements/","text":"Acordos de Equipe Defini\u00e7\u00e3o de Conclu\u00eddo Defini\u00e7\u00e3o de Pronto Acordos de Trabalho Manifesto da Equipe Objetivos Os acordos de equipe ajudam a esclarecer as expectativas para todos os membros da equipe, seja em rela\u00e7\u00e3o a como a equipe trabalha junta (Acordos de Trabalho) ou como julgar se uma hist\u00f3ria est\u00e1 completa (Defini\u00e7\u00e3o de Conclu\u00eddo).","title":"Acordos de Equipe"},{"location":"agile-development/advanced-topics/team-agreements/#acordos-de-equipe","text":"Defini\u00e7\u00e3o de Conclu\u00eddo Defini\u00e7\u00e3o de Pronto Acordos de Trabalho Manifesto da Equipe","title":"Acordos de Equipe"},{"location":"agile-development/advanced-topics/team-agreements/#objetivos","text":"Os acordos de equipe ajudam a esclarecer as expectativas para todos os membros da equipe, seja em rela\u00e7\u00e3o a como a equipe trabalha junta (Acordos de Trabalho) ou como julgar se uma hist\u00f3ria est\u00e1 completa (Defini\u00e7\u00e3o de Conclu\u00eddo).","title":"Objetivos"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-done/","text":"Defini\u00e7\u00e3o de Conclu\u00eddo Para fechar uma hist\u00f3ria de usu\u00e1rio, um sprint ou um marco, \u00e9 importante verificar se as tarefas est\u00e3o completas. A equipe de desenvolvimento deve decidir em conjunto qual \u00e9 a sua Defini\u00e7\u00e3o de Conclu\u00eddo e documentar isso no projeto. Abaixo est\u00e3o alguns exemplos de verifica\u00e7\u00f5es para garantir que a hist\u00f3ria de usu\u00e1rio, sprint, tarefa esteja conclu\u00edda. Funcionalidade/Hist\u00f3ria de Usu\u00e1rio Crit\u00e9rios de aceita\u00e7\u00e3o s\u00e3o atendidos Refatora\u00e7\u00e3o est\u00e1 completa O c\u00f3digo \u00e9 compilado sem erros Testes unit\u00e1rios s\u00e3o escritos e aprovados Testes unit\u00e1rios existentes s\u00e3o aprovados Diagn\u00f3sticos/telemetria suficientes s\u00e3o registrados Revis\u00e3o de c\u00f3digo est\u00e1 completa Revis\u00e3o de UX est\u00e1 completa (se aplic\u00e1vel) Documenta\u00e7\u00e3o est\u00e1 atualizada A funcionalidade \u00e9 mesclada na branch de desenvolvimento A funcionalidade \u00e9 aprovada pelo propriet\u00e1rio do produto Objetivo do Sprint Defini\u00e7\u00e3o de Conclu\u00eddo para todas as hist\u00f3rias de usu\u00e1rio inclu\u00eddas no sprint s\u00e3o atendidas Backlog do produto est\u00e1 atualizado Testes funcionais e de integra\u00e7\u00e3o s\u00e3o aprovados Testes de desempenho s\u00e3o aprovados Testes de ponta a ponta s\u00e3o aprovados Todos os bugs s\u00e3o corrigidos O sprint \u00e9 aprovado por desenvolvedores, arquitetos de software, gerente de projeto, propriet\u00e1rio do produto, etc. Lan\u00e7amento/Marco C\u00f3digo Completo (objetivos dos sprints s\u00e3o atendidos) O lan\u00e7amento \u00e9 marcado como pronto para implanta\u00e7\u00e3o em produ\u00e7\u00e3o pelo propriet\u00e1rio do produto","title":"Defini\u00e7\u00e3o de Conclu\u00eddo"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-done/#definicao-de-concluido","text":"Para fechar uma hist\u00f3ria de usu\u00e1rio, um sprint ou um marco, \u00e9 importante verificar se as tarefas est\u00e3o completas. A equipe de desenvolvimento deve decidir em conjunto qual \u00e9 a sua Defini\u00e7\u00e3o de Conclu\u00eddo e documentar isso no projeto. Abaixo est\u00e3o alguns exemplos de verifica\u00e7\u00f5es para garantir que a hist\u00f3ria de usu\u00e1rio, sprint, tarefa esteja conclu\u00edda.","title":"Defini\u00e7\u00e3o de Conclu\u00eddo"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-done/#funcionalidadehistoria-de-usuario","text":"Crit\u00e9rios de aceita\u00e7\u00e3o s\u00e3o atendidos Refatora\u00e7\u00e3o est\u00e1 completa O c\u00f3digo \u00e9 compilado sem erros Testes unit\u00e1rios s\u00e3o escritos e aprovados Testes unit\u00e1rios existentes s\u00e3o aprovados Diagn\u00f3sticos/telemetria suficientes s\u00e3o registrados Revis\u00e3o de c\u00f3digo est\u00e1 completa Revis\u00e3o de UX est\u00e1 completa (se aplic\u00e1vel) Documenta\u00e7\u00e3o est\u00e1 atualizada A funcionalidade \u00e9 mesclada na branch de desenvolvimento A funcionalidade \u00e9 aprovada pelo propriet\u00e1rio do produto","title":"Funcionalidade/Hist\u00f3ria de Usu\u00e1rio"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-done/#objetivo-do-sprint","text":"Defini\u00e7\u00e3o de Conclu\u00eddo para todas as hist\u00f3rias de usu\u00e1rio inclu\u00eddas no sprint s\u00e3o atendidas Backlog do produto est\u00e1 atualizado Testes funcionais e de integra\u00e7\u00e3o s\u00e3o aprovados Testes de desempenho s\u00e3o aprovados Testes de ponta a ponta s\u00e3o aprovados Todos os bugs s\u00e3o corrigidos O sprint \u00e9 aprovado por desenvolvedores, arquitetos de software, gerente de projeto, propriet\u00e1rio do produto, etc.","title":"Objetivo do Sprint"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-done/#lancamentomarco","text":"C\u00f3digo Completo (objetivos dos sprints s\u00e3o atendidos) O lan\u00e7amento \u00e9 marcado como pronto para implanta\u00e7\u00e3o em produ\u00e7\u00e3o pelo propriet\u00e1rio do produto","title":"Lan\u00e7amento/Marco"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/","text":"Defini\u00e7\u00e3o de Pronto Quando a equipe de desenvolvimento escolhe uma hist\u00f3ria de usu\u00e1rio do topo do backlog, a hist\u00f3ria precisa ter detalhes suficientes para estimar o trabalho necess\u00e1rio para complet\u00e1-la dentro do sprint. Se tiver detalhes suficientes para a estimativa, ela est\u00e1 Pronta para ser desenvolvida. Se uma hist\u00f3ria de usu\u00e1rio n\u00e3o estiver Pronta no in\u00edcio do Sprint, aumenta a chance de que a hist\u00f3ria n\u00e3o ser\u00e1 conclu\u00edda no final deste sprint. O que \u00e9 Defini\u00e7\u00e3o de Pronto \u00e9 o acordo feito pela equipe Scrum sobre qu\u00e3o completa uma hist\u00f3ria de usu\u00e1rio deve estar para ser selecionada como candidata \u00e0 estimativa no planejamento do sprint. Estes podem ser codificados como uma lista de verifica\u00e7\u00e3o nas hist\u00f3rias de usu\u00e1rio usando Modelos de Issue do GitHub ou Modelos de Item de Trabalho do Azure DevOps . Pode ser entendido como uma lista de verifica\u00e7\u00e3o que ajuda o Propriet\u00e1rio do Produto a garantir que a hist\u00f3ria de usu\u00e1rio que escreveu cont\u00e9m todos os detalhes necess\u00e1rios para a equipe Scrum entender o trabalho a ser feito. Exemplos de itens da lista de verifica\u00e7\u00e3o de pronto A descri\u00e7\u00e3o cont\u00e9m os detalhes, incluindo quaisquer valores de entrada necess\u00e1rios para implementar a hist\u00f3ria de usu\u00e1rio? A hist\u00f3ria de usu\u00e1rio tem crit\u00e9rios de aceita\u00e7\u00e3o claros e completos? A hist\u00f3ria de usu\u00e1rio aborda a necessidade de neg\u00f3cios? Podemos medir os crit\u00e9rios de aceita\u00e7\u00e3o? A hist\u00f3ria de usu\u00e1rio \u00e9 pequena o suficiente para ser implementada em um curto per\u00edodo de tempo, mas grande o suficiente para fornecer valor ao cliente? A hist\u00f3ria de usu\u00e1rio est\u00e1 bloqueada? Por exemplo, ela depende de algum dos seguintes: A conclus\u00e3o de um trabalho n\u00e3o terminado Um entreg\u00e1vel fornecido por outra equipe (artefato de c\u00f3digo, dados, etc...) Quem escreve A lista de verifica\u00e7\u00e3o de pronto pode ser escrita por um Propriet\u00e1rio do Produto em acordo com a equipe de desenvolvimento e o L\u00edder do Processo. Quando a Defini\u00e7\u00e3o de Pronto deve ser atualizada Atualize ou altere a defini\u00e7\u00e3o de pronto sempre que a equipe Scrum observar que h\u00e1 informa\u00e7\u00f5es faltando nas hist\u00f3rias de usu\u00e1rio que impactam recorrentemente o planejamento. O que deve ser evitado A lista de verifica\u00e7\u00e3o de pronto deve conter itens que se aplicam de forma ampla. N\u00e3o inclua itens ou detalhes que se aplicam apenas a uma ou duas hist\u00f3rias de usu\u00e1rio. Isso pode se tornar um excesso ao escrever as hist\u00f3rias de usu\u00e1rio. Como preparar hist\u00f3rias para estarem prontas No caso de o trabalho de maior prioridade ainda n\u00e3o estar pronto, ainda pode ser poss\u00edvel fazer progresso. Aqui est\u00e3o algumas estrat\u00e9gias que podem ajudar: Sess\u00f5es de Refinamento do Backlog s\u00e3o um bom momento para validar que hist\u00f3rias de usu\u00e1rio de alta prioridade s\u00e3o verificadas para ter uma descri\u00e7\u00e3o clara, crit\u00e9rios de aceita\u00e7\u00e3o e valor comercial demonstr\u00e1vel. Tamb\u00e9m \u00e9 um bom momento para dividir grandes hist\u00f3rias que provavelmente n\u00e3o ser\u00e3o conclu\u00eddas em um \u00fanico sprint. Sess\u00f5es de prioriza\u00e7\u00e3o s\u00e3o um bom momento para priorizar hist\u00f3rias de usu\u00e1rio que desbloqueiam outros trabalhos de alta prioridade bloqueados. Hist\u00f3rias de usu\u00e1rio bloqueadas muitas vezes podem ser divididas de forma a desbloquear uma parte do escopo original. Esta \u00e9 uma boa maneira de fazer progresso, mesmo quando algum trabalho est\u00e1 bloqueado.","title":"Defini\u00e7\u00e3o de Pronto"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#definicao-de-pronto","text":"Quando a equipe de desenvolvimento escolhe uma hist\u00f3ria de usu\u00e1rio do topo do backlog, a hist\u00f3ria precisa ter detalhes suficientes para estimar o trabalho necess\u00e1rio para complet\u00e1-la dentro do sprint. Se tiver detalhes suficientes para a estimativa, ela est\u00e1 Pronta para ser desenvolvida. Se uma hist\u00f3ria de usu\u00e1rio n\u00e3o estiver Pronta no in\u00edcio do Sprint, aumenta a chance de que a hist\u00f3ria n\u00e3o ser\u00e1 conclu\u00edda no final deste sprint.","title":"Defini\u00e7\u00e3o de Pronto"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#o-que-e","text":"Defini\u00e7\u00e3o de Pronto \u00e9 o acordo feito pela equipe Scrum sobre qu\u00e3o completa uma hist\u00f3ria de usu\u00e1rio deve estar para ser selecionada como candidata \u00e0 estimativa no planejamento do sprint. Estes podem ser codificados como uma lista de verifica\u00e7\u00e3o nas hist\u00f3rias de usu\u00e1rio usando Modelos de Issue do GitHub ou Modelos de Item de Trabalho do Azure DevOps . Pode ser entendido como uma lista de verifica\u00e7\u00e3o que ajuda o Propriet\u00e1rio do Produto a garantir que a hist\u00f3ria de usu\u00e1rio que escreveu cont\u00e9m todos os detalhes necess\u00e1rios para a equipe Scrum entender o trabalho a ser feito.","title":"O que \u00e9"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#exemplos-de-itens-da-lista-de-verificacao-de-pronto","text":"A descri\u00e7\u00e3o cont\u00e9m os detalhes, incluindo quaisquer valores de entrada necess\u00e1rios para implementar a hist\u00f3ria de usu\u00e1rio? A hist\u00f3ria de usu\u00e1rio tem crit\u00e9rios de aceita\u00e7\u00e3o claros e completos? A hist\u00f3ria de usu\u00e1rio aborda a necessidade de neg\u00f3cios? Podemos medir os crit\u00e9rios de aceita\u00e7\u00e3o? A hist\u00f3ria de usu\u00e1rio \u00e9 pequena o suficiente para ser implementada em um curto per\u00edodo de tempo, mas grande o suficiente para fornecer valor ao cliente? A hist\u00f3ria de usu\u00e1rio est\u00e1 bloqueada? Por exemplo, ela depende de algum dos seguintes: A conclus\u00e3o de um trabalho n\u00e3o terminado Um entreg\u00e1vel fornecido por outra equipe (artefato de c\u00f3digo, dados, etc...)","title":"Exemplos de itens da lista de verifica\u00e7\u00e3o de pronto"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#quem-escreve","text":"A lista de verifica\u00e7\u00e3o de pronto pode ser escrita por um Propriet\u00e1rio do Produto em acordo com a equipe de desenvolvimento e o L\u00edder do Processo.","title":"Quem escreve"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#quando-a-definicao-de-pronto-deve-ser-atualizada","text":"Atualize ou altere a defini\u00e7\u00e3o de pronto sempre que a equipe Scrum observar que h\u00e1 informa\u00e7\u00f5es faltando nas hist\u00f3rias de usu\u00e1rio que impactam recorrentemente o planejamento.","title":"Quando a Defini\u00e7\u00e3o de Pronto deve ser atualizada"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#o-que-deve-ser-evitado","text":"A lista de verifica\u00e7\u00e3o de pronto deve conter itens que se aplicam de forma ampla. N\u00e3o inclua itens ou detalhes que se aplicam apenas a uma ou duas hist\u00f3rias de usu\u00e1rio. Isso pode se tornar um excesso ao escrever as hist\u00f3rias de usu\u00e1rio.","title":"O que deve ser evitado"},{"location":"agile-development/advanced-topics/team-agreements/definition-of-ready/#como-preparar-historias-para-estarem-prontas","text":"No caso de o trabalho de maior prioridade ainda n\u00e3o estar pronto, ainda pode ser poss\u00edvel fazer progresso. Aqui est\u00e3o algumas estrat\u00e9gias que podem ajudar: Sess\u00f5es de Refinamento do Backlog s\u00e3o um bom momento para validar que hist\u00f3rias de usu\u00e1rio de alta prioridade s\u00e3o verificadas para ter uma descri\u00e7\u00e3o clara, crit\u00e9rios de aceita\u00e7\u00e3o e valor comercial demonstr\u00e1vel. Tamb\u00e9m \u00e9 um bom momento para dividir grandes hist\u00f3rias que provavelmente n\u00e3o ser\u00e3o conclu\u00eddas em um \u00fanico sprint. Sess\u00f5es de prioriza\u00e7\u00e3o s\u00e3o um bom momento para priorizar hist\u00f3rias de usu\u00e1rio que desbloqueiam outros trabalhos de alta prioridade bloqueados. Hist\u00f3rias de usu\u00e1rio bloqueadas muitas vezes podem ser divididas de forma a desbloquear uma parte do escopo original. Esta \u00e9 uma boa maneira de fazer progresso, mesmo quando algum trabalho est\u00e1 bloqueado.","title":"Como preparar hist\u00f3rias para estarem prontas"},{"location":"agile-development/advanced-topics/team-agreements/team-manifesto/","text":"Manifesto da Equipe Introdu\u00e7\u00e3o As equipes da ISE trabalham com uma nova equipe de desenvolvimento em cada envolvimento com o cliente, o que requer uma fase de introdu\u00e7\u00e3o e transfer\u00eancia de conhecimento antes de iniciar um envolvimento. A conclus\u00e3o desta fase de quebra-gelos e discuss\u00f5es sobre os padr\u00f5es leva tempo, mas \u00e9 necess\u00e1ria para come\u00e7ar a aumentar a curva de aprendizado da nova equipe. Um manifesto da equipe \u00e9 um documento \u00e1gil de uma p\u00e1gina entre os membros da equipe que resume os princ\u00edpios e valores b\u00e1sicos da equipe e visa fornecer um consenso sobre as expectativas t\u00e9cnicas de cada membro da equipe para entregar um resultado de alta qualidade no final de cada envolvimento. O objetivo \u00e9 reduzir o tempo na defini\u00e7\u00e3o das expectativas corretas sem organizar reuni\u00f5es mais longas de \"leitura de documentos da equipe\" e fornecer um consenso entre os membros da equipe para responder \u00e0 pergunta - \"Como a nova equipe desenvolve o software?\" - abrangendo todos os t\u00f3picos fundamentais de engenharia e excel\u00eancia, como processo de lan\u00e7amento, codifica\u00e7\u00e3o limpa, testes. Outro objetivo principal de escrever o manifesto \u00e9 iniciar uma conversa durante a \"sess\u00e3o de constru\u00e7\u00e3o do manifesto\" para detectar quaisquer diferen\u00e7as de opini\u00e3o sobre como a equipe deve trabalhar. Ele tamb\u00e9m serve da mesma forma quando um novo membro da equipe se junta \u00e0 equipe. Novos integrantes podem se atualizar rapidamente sobre os padr\u00f5es acordados. Como Construir um Manifesto da Equipe Pode-se dizer que o melhor momento para come\u00e7ar a constru\u00ed-lo \u00e9 na fase muito inicial do envolvimento, quando as equipes se encontram umas com as outras para swarming ou durante a fase de prepara\u00e7\u00e3o. \u00c9 recomendado manter o manifesto da equipe o mais simples poss\u00edvel, ent\u00e3o, de prefer\u00eancia, um documento simples de uma p\u00e1gina que n\u00e3o inclui quaisquer refer\u00eancias ou links \u00e9 um bom formato para ele. Se houver necessidade de fornecer conhecimento sobre certos t\u00f3picos, a forma de fazer isso \u00e9 realizar sess\u00f5es brown-bag, katas t\u00e9cnicas, pr\u00e1ticas de equipe, documenta\u00e7\u00f5es e outros posteriormente. Alguns pontos importantes sobre o manifesto da equipe: O manifesto da equipe \u00e9 constru\u00eddo pela pr\u00f3pria equipe de desenvolvimento Deve cobrir todos os pontos t\u00e9cnicos de engenharia necess\u00e1rios para a excel\u00eancia, bem como itens de mentalidade de agilidade comportamental que a equipe considera relevantes Visa dar um entendimento comum sobre a expertise, pr\u00e1ticas e/ou mentalidade desejadas dentro da equipe Com base nas necessidades da equipe e nos resultados da retrospectiva, ele pode ser modificado durante o envolvimento. Na ISE, buscamos qualidade em vez de quantidade, e software bem elaborado, bem como um ambiente confort\u00e1vel/transparente onde cada membro da equipe possa alcan\u00e7ar seu maior potencial. A diferen\u00e7a entre o manifesto da equipe e outros documentos da equipe \u00e9 que ele \u00e9 usado para dar um breve resumo das expectativas em torno da forma t\u00e9cnica de trabalhar e da mentalidade apoiada na equipe, antes que os sprints de code-with comecem. Abaixo, voc\u00ea pode encontrar alguns t\u00f3picos que muitas equipes abordam durante os envolvimentos, T\u00f3pico Sobre o que \u00e9? Propriedade Coletiva A equipe possui o c\u00f3digo em vez de indiv\u00edduos? Qual \u00e9 a expectativa? Respeito Qualquer declara\u00e7\u00e3o preferida sobre ser um valor \"obrigat\u00f3rio\" da equipe Colabora\u00e7\u00e3o Qualquer declara\u00e7\u00e3o preferida sobre como a equipe deseja colaborar? Transpar\u00eancia Uma simples declara\u00e7\u00e3o sobre ser um valor \"obrigat\u00f3rio\" da equipe e, se preferir, como isso \u00e9 fornecido pela equipe? reuni\u00f5es, retrospectivas, mecanismos de feedback, etc. Expertise em Ferramentas de Desenvolvimento Quais ferramentas, como Git, VS Code LiveShare, etc., est\u00e3o sendo usadas? Qual \u00e9 a defini\u00e7\u00e3o do uso esperado delas? Dimensionamento de PR O que a equipe prefere em PRs? Branching Estrat\u00e9gia e padr\u00f5es de branches da equipe Padr\u00f5es de Commit Formato preferido nas mensagens de commit, regras e mais C\u00f3digo Limpo A equipe segue princ\u00edpios de c\u00f3digo limpo? Programa\u00e7\u00e3o em Par/Enxame A equipe aplicar\u00e1 programa\u00e7\u00e3o em par/enxame? Se sim, quais estilos de programa\u00e7\u00e3o s\u00e3o adequados para a equipe? Processo de Lan\u00e7amento Princ\u00edpios em torno do processo de lan\u00e7amento, como port\u00f5es de qualidade, processo de revis\u00e3o...etc. Revis\u00e3o de C\u00f3digo Qualquer regra para revis\u00e3o de c\u00f3digo, como n\u00famero m\u00ednimo de revisores, regras da equipe...etc. Prontid\u00e3o para A\u00e7\u00e3o Como o backlog ser\u00e1 refinado? Como garantimos uma clara Defini\u00e7\u00e3o de Conclu\u00eddo e Crit\u00e9rios de Aceita\u00e7\u00e3o? TDD A equipe seguir\u00e1 TDD? Cobertura de Teste Existe algum n\u00famero, porcentagem ou medida esperada? Dimens\u00f5es em Testes Testes necess\u00e1rios para software de alta qualidade, por exemplo: unit\u00e1rios, integra\u00e7\u00e3o, funcionais, desempenho, regress\u00e3o, aceita\u00e7\u00e3o Processo de Constru\u00e7\u00e3o Construir para todos? ou n\u00e3o; A declara\u00e7\u00e3o clara de onde o c\u00f3digo e sob quais condi\u00e7\u00f5es o c\u00f3digo deve funcionar? por exemplo: SO, DevOps, depend\u00eancia de ferramenta Corre\u00e7\u00e3o de Bugs As regras para corre\u00e7\u00e3o de bugs na equipe? por exemplo: pessoas de contato, anexando PR ao problema, etc. D\u00edvida T\u00e9cnica Como a equipe gerencia/segue isso? Refatora\u00e7\u00e3o Como a equipe gerencia/segue isso? Documenta\u00e7\u00e3o \u00c1gil A equipe deseja usar diagramas e tabelas mais do que artigos detalhados do KB? Documenta\u00e7\u00e3o Eficiente Quando \u00e9 necess\u00e1rio? \u00c9 um pr\u00e9-requisito para concluir tarefas/PRs etc.? Defini\u00e7\u00e3o de Divers\u00e3o Como nos divertiremos para relaxar/desfrutar do esp\u00edrito de equipe durante o envolvimento no projeto? Ferramentas Geralmente, sess\u00f5es de equipe s\u00e3o suficientes para construir um manifesto e chegar a um consenso em torno dele, e se houver necessidade de melhor\u00e1-lo de forma estruturada, existem muitos blogs e ferramentas online, qualquer ferramenta de retrospectiva pode ser usada. Recursos Agilidade T\u00e9cnica*","title":"Manifesto da Equipe"},{"location":"agile-development/advanced-topics/team-agreements/team-manifesto/#manifesto-da-equipe","text":"","title":"Manifesto da Equipe"},{"location":"agile-development/advanced-topics/team-agreements/team-manifesto/#introducao","text":"As equipes da ISE trabalham com uma nova equipe de desenvolvimento em cada envolvimento com o cliente, o que requer uma fase de introdu\u00e7\u00e3o e transfer\u00eancia de conhecimento antes de iniciar um envolvimento. A conclus\u00e3o desta fase de quebra-gelos e discuss\u00f5es sobre os padr\u00f5es leva tempo, mas \u00e9 necess\u00e1ria para come\u00e7ar a aumentar a curva de aprendizado da nova equipe. Um manifesto da equipe \u00e9 um documento \u00e1gil de uma p\u00e1gina entre os membros da equipe que resume os princ\u00edpios e valores b\u00e1sicos da equipe e visa fornecer um consenso sobre as expectativas t\u00e9cnicas de cada membro da equipe para entregar um resultado de alta qualidade no final de cada envolvimento. O objetivo \u00e9 reduzir o tempo na defini\u00e7\u00e3o das expectativas corretas sem organizar reuni\u00f5es mais longas de \"leitura de documentos da equipe\" e fornecer um consenso entre os membros da equipe para responder \u00e0 pergunta - \"Como a nova equipe desenvolve o software?\" - abrangendo todos os t\u00f3picos fundamentais de engenharia e excel\u00eancia, como processo de lan\u00e7amento, codifica\u00e7\u00e3o limpa, testes. Outro objetivo principal de escrever o manifesto \u00e9 iniciar uma conversa durante a \"sess\u00e3o de constru\u00e7\u00e3o do manifesto\" para detectar quaisquer diferen\u00e7as de opini\u00e3o sobre como a equipe deve trabalhar. Ele tamb\u00e9m serve da mesma forma quando um novo membro da equipe se junta \u00e0 equipe. Novos integrantes podem se atualizar rapidamente sobre os padr\u00f5es acordados.","title":"Introdu\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/team-agreements/team-manifesto/#como-construir-um-manifesto-da-equipe","text":"Pode-se dizer que o melhor momento para come\u00e7ar a constru\u00ed-lo \u00e9 na fase muito inicial do envolvimento, quando as equipes se encontram umas com as outras para swarming ou durante a fase de prepara\u00e7\u00e3o. \u00c9 recomendado manter o manifesto da equipe o mais simples poss\u00edvel, ent\u00e3o, de prefer\u00eancia, um documento simples de uma p\u00e1gina que n\u00e3o inclui quaisquer refer\u00eancias ou links \u00e9 um bom formato para ele. Se houver necessidade de fornecer conhecimento sobre certos t\u00f3picos, a forma de fazer isso \u00e9 realizar sess\u00f5es brown-bag, katas t\u00e9cnicas, pr\u00e1ticas de equipe, documenta\u00e7\u00f5es e outros posteriormente. Alguns pontos importantes sobre o manifesto da equipe: O manifesto da equipe \u00e9 constru\u00eddo pela pr\u00f3pria equipe de desenvolvimento Deve cobrir todos os pontos t\u00e9cnicos de engenharia necess\u00e1rios para a excel\u00eancia, bem como itens de mentalidade de agilidade comportamental que a equipe considera relevantes Visa dar um entendimento comum sobre a expertise, pr\u00e1ticas e/ou mentalidade desejadas dentro da equipe Com base nas necessidades da equipe e nos resultados da retrospectiva, ele pode ser modificado durante o envolvimento. Na ISE, buscamos qualidade em vez de quantidade, e software bem elaborado, bem como um ambiente confort\u00e1vel/transparente onde cada membro da equipe possa alcan\u00e7ar seu maior potencial. A diferen\u00e7a entre o manifesto da equipe e outros documentos da equipe \u00e9 que ele \u00e9 usado para dar um breve resumo das expectativas em torno da forma t\u00e9cnica de trabalhar e da mentalidade apoiada na equipe, antes que os sprints de code-with comecem. Abaixo, voc\u00ea pode encontrar alguns t\u00f3picos que muitas equipes abordam durante os envolvimentos, T\u00f3pico Sobre o que \u00e9? Propriedade Coletiva A equipe possui o c\u00f3digo em vez de indiv\u00edduos? Qual \u00e9 a expectativa? Respeito Qualquer declara\u00e7\u00e3o preferida sobre ser um valor \"obrigat\u00f3rio\" da equipe Colabora\u00e7\u00e3o Qualquer declara\u00e7\u00e3o preferida sobre como a equipe deseja colaborar? Transpar\u00eancia Uma simples declara\u00e7\u00e3o sobre ser um valor \"obrigat\u00f3rio\" da equipe e, se preferir, como isso \u00e9 fornecido pela equipe? reuni\u00f5es, retrospectivas, mecanismos de feedback, etc. Expertise em Ferramentas de Desenvolvimento Quais ferramentas, como Git, VS Code LiveShare, etc., est\u00e3o sendo usadas? Qual \u00e9 a defini\u00e7\u00e3o do uso esperado delas? Dimensionamento de PR O que a equipe prefere em PRs? Branching Estrat\u00e9gia e padr\u00f5es de branches da equipe Padr\u00f5es de Commit Formato preferido nas mensagens de commit, regras e mais C\u00f3digo Limpo A equipe segue princ\u00edpios de c\u00f3digo limpo? Programa\u00e7\u00e3o em Par/Enxame A equipe aplicar\u00e1 programa\u00e7\u00e3o em par/enxame? Se sim, quais estilos de programa\u00e7\u00e3o s\u00e3o adequados para a equipe? Processo de Lan\u00e7amento Princ\u00edpios em torno do processo de lan\u00e7amento, como port\u00f5es de qualidade, processo de revis\u00e3o...etc. Revis\u00e3o de C\u00f3digo Qualquer regra para revis\u00e3o de c\u00f3digo, como n\u00famero m\u00ednimo de revisores, regras da equipe...etc. Prontid\u00e3o para A\u00e7\u00e3o Como o backlog ser\u00e1 refinado? Como garantimos uma clara Defini\u00e7\u00e3o de Conclu\u00eddo e Crit\u00e9rios de Aceita\u00e7\u00e3o? TDD A equipe seguir\u00e1 TDD? Cobertura de Teste Existe algum n\u00famero, porcentagem ou medida esperada? Dimens\u00f5es em Testes Testes necess\u00e1rios para software de alta qualidade, por exemplo: unit\u00e1rios, integra\u00e7\u00e3o, funcionais, desempenho, regress\u00e3o, aceita\u00e7\u00e3o Processo de Constru\u00e7\u00e3o Construir para todos? ou n\u00e3o; A declara\u00e7\u00e3o clara de onde o c\u00f3digo e sob quais condi\u00e7\u00f5es o c\u00f3digo deve funcionar? por exemplo: SO, DevOps, depend\u00eancia de ferramenta Corre\u00e7\u00e3o de Bugs As regras para corre\u00e7\u00e3o de bugs na equipe? por exemplo: pessoas de contato, anexando PR ao problema, etc. D\u00edvida T\u00e9cnica Como a equipe gerencia/segue isso? Refatora\u00e7\u00e3o Como a equipe gerencia/segue isso? Documenta\u00e7\u00e3o \u00c1gil A equipe deseja usar diagramas e tabelas mais do que artigos detalhados do KB? Documenta\u00e7\u00e3o Eficiente Quando \u00e9 necess\u00e1rio? \u00c9 um pr\u00e9-requisito para concluir tarefas/PRs etc.? Defini\u00e7\u00e3o de Divers\u00e3o Como nos divertiremos para relaxar/desfrutar do esp\u00edrito de equipe durante o envolvimento no projeto?","title":"Como Construir um Manifesto da Equipe"},{"location":"agile-development/advanced-topics/team-agreements/team-manifesto/#ferramentas","text":"Geralmente, sess\u00f5es de equipe s\u00e3o suficientes para construir um manifesto e chegar a um consenso em torno dele, e se houver necessidade de melhor\u00e1-lo de forma estruturada, existem muitos blogs e ferramentas online, qualquer ferramenta de retrospectiva pode ser usada.","title":"Ferramentas"},{"location":"agile-development/advanced-topics/team-agreements/team-manifesto/#recursos","text":"Agilidade T\u00e9cnica*","title":"Recursos"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/","text":"Se\u00e7\u00f5es de um Acordo de Trabalho Um acordo de trabalho \u00e9 um documento ou um conjunto de documentos que descrevem como trabalhamos juntos como uma equipe e quais s\u00e3o nossas expectativas e princ\u00edpios. O acordo de trabalho \u00e9 criado pela equipe no in\u00edcio do projeto e \u00e9 armazenado no reposit\u00f3rio para que esteja prontamente dispon\u00edvel para todos que trabalham no projeto. A seguir est\u00e3o exemplos de se\u00e7\u00f5es e pontos que podem fazer parte de um acordo de trabalho, mas cada equipe deve compor o seu pr\u00f3prio e ajustar hor\u00e1rios, canais de comunica\u00e7\u00e3o, pol\u00edticas de nomea\u00e7\u00e3o de branches, etc., para atender \u00e0s necessidades da equipe. Geral Trabalhamos como uma \u00fanica equipe em dire\u00e7\u00e3o a um objetivo comum e escopo claro Certificamo-nos de que a voz de todos seja ouvida e escutada Mostramos igual respeito a todos os membros da equipe Trabalhamos como uma equipe para ter expectativas comuns para a entrega t\u00e9cnica que s\u00e3o documentadas em um Manifesto da Equipe . Certificamo-nos de disseminar nossa expertise e habilidades na equipe, para que nenhuma \u00fanica pessoa seja a \u00fanica respons\u00e1vel por uma habilidade Todos os hor\u00e1rios abaixo est\u00e3o listados em CET Comunica\u00e7\u00e3o Comunicamos todas as informa\u00e7\u00f5es relevantes para a equipe atrav\u00e9s do canal de Equipes do Projeto Adicionamos todos os spikes t\u00e9cnicos , estudos de trade-off e outra documenta\u00e7\u00e3o t\u00e9cnica ao reposit\u00f3rio do projeto atrav\u00e9s de revis\u00f5es de design ass\u00edncronas em PRs Equil\u00edbrio entre Trabalho e Vida Pessoal Nosso hor\u00e1rio de expediente, quando podemos esperar colaborar via Microsoft Teams, telefone ou presencialmente, \u00e9 de segunda a sexta-feira, das 10h \u00e0s 17h N\u00e3o somos obrigados a responder e-mails ap\u00f3s as 18h, nos fins de semana ou quando estamos de f\u00e9rias ou feriados. Trabalhamos em diferentes fusos hor\u00e1rios e respeitamos isso, especialmente ao marcar reuni\u00f5es recorrentes. Gravamos reuni\u00f5es sempre que poss\u00edvel, para que os membros da equipe que n\u00e3o puderam participar ao vivo possam ouvir mais tarde. Qualidade e n\u00e3o Quantidade Concordamos com uma Defini\u00e7\u00e3o de Conclu\u00eddo para nossas hist\u00f3rias de usu\u00e1rio e sprints e vivemos de acordo com ela. Seguimos as melhores pr\u00e1ticas de engenharia, como o Code With Engineering Playbook Ritmo do Scrum Atividade Quando Dura\u00e7\u00e3o Quem Respons\u00e1vel Objetivo Reuni\u00e3o Di\u00e1ria do Projeto Ter-Sex 9h 15 min Todos L\u00edder de Processo O que foi realizado, pr\u00f3ximos passos, bloqueios Demonstra\u00e7\u00e3o do Sprint Segunda 9h 1 hora Todos L\u00edder de Desenvolvimento Apresentar o trabalho realizado e aprovar a conclus\u00e3o da hist\u00f3ria de usu\u00e1rio Retrospectiva do Sprint Segunda 10h 1 hora Todos L\u00edder de Processo A equipe de desenvolvimento compartilha aprendizados e o que pode ser melhorado Planejamento do Sprint Segunda 11h 1 hora Todos PO Dimensionar e planejar hist\u00f3rias de usu\u00e1rio para o sprint Cria\u00e7\u00e3o de Tarefas Ap\u00f3s o Planejamento do Sprint - Equipe de Desenvolvimento L\u00edder de Desenvolvimento Criar tarefas para esclarecer e determinar a velocidade Refinamento do Backlog Quarta 14h 1 hora L\u00edder de Desenvolvimento, PO PO Preparar para o pr\u00f3ximo sprint e garantir que as hist\u00f3rias estejam prontas para o pr\u00f3ximo sprint. L\u00edder de Processo O L\u00edder de Processo \u00e9 respons\u00e1vel por liderar quaisquer pr\u00e1ticas de scrum ou \u00e1geis para permitir que o projeto avance. Facilitar reuni\u00f5es di\u00e1rias e responsabilizar a equipe pela presen\u00e7a e participa\u00e7\u00e3o. Manter a reuni\u00e3o em movimento conforme descrito na p\u00e1gina Reuni\u00e3o Di\u00e1ria do Projeto . Certificar-se de que todas as a\u00e7\u00f5es est\u00e3o documentadas e garantir que cada uma tenha um respons\u00e1vel e uma data de vencimento e rastrear as quest\u00f5es em aberto. Anota\u00e7\u00f5es conforme necess\u00e1rio ap\u00f3s o planejamento/reuni\u00f5es di\u00e1rias. Certificar-se de que os itens s\u00e3o movidos para o estacionamento e garantir o acompanhamento posterior. Manter um local mostrando o trabalho e o status da equipe e remover impedimentos que est\u00e3o bloqueando a equipe. Responsabilizar a equipe pelos resultados de forma solid\u00e1ria. - Certificar-se de que a documenta\u00e7\u00e3o do projeto e do programa est\u00e3o atualizadas. - Garantir o rastreamento/seguimento de a\u00e7\u00f5es da retrospectiva (planejamento de itera\u00e7\u00e3o e libera\u00e7\u00e3o) e das reuni\u00f5es di\u00e1rias. - Facilitar a retrospectiva do sprint. - Treinar o Product Owner e a equipe no processo, conforme necess\u00e1rio. Gerenciamento de Backlog Trabalhamos juntos em uma Defini\u00e7\u00e3o de Pronto e todas as hist\u00f3rias de usu\u00e1rio atribu\u00eddas a um sprint precisam seguir isso Comunicamos o que estamos trabalhando atrav\u00e9s do quadro Atribu\u00edmos a n\u00f3s mesmos uma tarefa quando estamos prontos para trabalhar nela (n\u00e3o antes) e a movemos para ativo Capturamos qualquer trabalho que fazemos relacionado ao projeto em uma hist\u00f3ria de usu\u00e1rio/tarefa Fechamos nossas tarefas/hist\u00f3rias de usu\u00e1rio apenas quando est\u00e3o conclu\u00eddas (conforme descrito na Defini\u00e7\u00e3o de Conclu\u00eddo ) Trabalhamos com o PM se quisermos adicionar uma nova hist\u00f3ria de usu\u00e1rio ao sprint Se adicionarmos novas tarefas ao quadro, certificamo-nos de que ela corresponde aos crit\u00e9rios de aceita\u00e7\u00e3o da hist\u00f3ria de usu\u00e1rio (para evitar o aumento do escopo). Se n\u00e3o corresponder aos crit\u00e9rios de aceita\u00e7\u00e3o, devemos discutir com o PM para ver se precisamos de uma nova hist\u00f3ria de usu\u00e1rio para a tarefa ou se devemos ajustar os crit\u00e9rios de aceita\u00e7\u00e3o. Gerenciamento de C\u00f3digo Seguimos a conven\u00e7\u00e3o de nomenclatura de branch do git flow para branches e identificamos o n\u00famero da tarefa, por exemplo, feature/123-add-working-agreement Mesclamos todo o c\u00f3digo em branches principais atrav\u00e9s de PRs Todos os PRs s\u00e3o revisados por uma pessoa de [Nome do Cliente/Parceiro] e uma da Microsoft (para transfer\u00eancia de conhecimento e para garantir que os padr\u00f5es de c\u00f3digo e seguran\u00e7a sejam atendidos) Sempre revisamos os PRs existentes antes de come\u00e7ar a trabalhar em uma nova tarefa Olhamos os PRs abertos no final da reuni\u00e3o di\u00e1ria para garantir que todos os PRs tenham revisores. Tratamos a documenta\u00e7\u00e3o como c\u00f3digo e aplicamos os mesmos padr\u00f5es ao Markdown como c\u00f3digo.","title":"Se\u00e7\u00f5es de um Acordo de Trabalho"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#secoes-de-um-acordo-de-trabalho","text":"Um acordo de trabalho \u00e9 um documento ou um conjunto de documentos que descrevem como trabalhamos juntos como uma equipe e quais s\u00e3o nossas expectativas e princ\u00edpios. O acordo de trabalho \u00e9 criado pela equipe no in\u00edcio do projeto e \u00e9 armazenado no reposit\u00f3rio para que esteja prontamente dispon\u00edvel para todos que trabalham no projeto. A seguir est\u00e3o exemplos de se\u00e7\u00f5es e pontos que podem fazer parte de um acordo de trabalho, mas cada equipe deve compor o seu pr\u00f3prio e ajustar hor\u00e1rios, canais de comunica\u00e7\u00e3o, pol\u00edticas de nomea\u00e7\u00e3o de branches, etc., para atender \u00e0s necessidades da equipe.","title":"Se\u00e7\u00f5es de um Acordo de Trabalho"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#geral","text":"Trabalhamos como uma \u00fanica equipe em dire\u00e7\u00e3o a um objetivo comum e escopo claro Certificamo-nos de que a voz de todos seja ouvida e escutada Mostramos igual respeito a todos os membros da equipe Trabalhamos como uma equipe para ter expectativas comuns para a entrega t\u00e9cnica que s\u00e3o documentadas em um Manifesto da Equipe . Certificamo-nos de disseminar nossa expertise e habilidades na equipe, para que nenhuma \u00fanica pessoa seja a \u00fanica respons\u00e1vel por uma habilidade Todos os hor\u00e1rios abaixo est\u00e3o listados em CET","title":"Geral"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#comunicacao","text":"Comunicamos todas as informa\u00e7\u00f5es relevantes para a equipe atrav\u00e9s do canal de Equipes do Projeto Adicionamos todos os spikes t\u00e9cnicos , estudos de trade-off e outra documenta\u00e7\u00e3o t\u00e9cnica ao reposit\u00f3rio do projeto atrav\u00e9s de revis\u00f5es de design ass\u00edncronas em PRs","title":"Comunica\u00e7\u00e3o"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#equilibrio-entre-trabalho-e-vida-pessoal","text":"Nosso hor\u00e1rio de expediente, quando podemos esperar colaborar via Microsoft Teams, telefone ou presencialmente, \u00e9 de segunda a sexta-feira, das 10h \u00e0s 17h N\u00e3o somos obrigados a responder e-mails ap\u00f3s as 18h, nos fins de semana ou quando estamos de f\u00e9rias ou feriados. Trabalhamos em diferentes fusos hor\u00e1rios e respeitamos isso, especialmente ao marcar reuni\u00f5es recorrentes. Gravamos reuni\u00f5es sempre que poss\u00edvel, para que os membros da equipe que n\u00e3o puderam participar ao vivo possam ouvir mais tarde.","title":"Equil\u00edbrio entre Trabalho e Vida Pessoal"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#qualidade-e-nao-quantidade","text":"Concordamos com uma Defini\u00e7\u00e3o de Conclu\u00eddo para nossas hist\u00f3rias de usu\u00e1rio e sprints e vivemos de acordo com ela. Seguimos as melhores pr\u00e1ticas de engenharia, como o Code With Engineering Playbook","title":"Qualidade e n\u00e3o Quantidade"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#ritmo-do-scrum","text":"Atividade Quando Dura\u00e7\u00e3o Quem Respons\u00e1vel Objetivo Reuni\u00e3o Di\u00e1ria do Projeto Ter-Sex 9h 15 min Todos L\u00edder de Processo O que foi realizado, pr\u00f3ximos passos, bloqueios Demonstra\u00e7\u00e3o do Sprint Segunda 9h 1 hora Todos L\u00edder de Desenvolvimento Apresentar o trabalho realizado e aprovar a conclus\u00e3o da hist\u00f3ria de usu\u00e1rio Retrospectiva do Sprint Segunda 10h 1 hora Todos L\u00edder de Processo A equipe de desenvolvimento compartilha aprendizados e o que pode ser melhorado Planejamento do Sprint Segunda 11h 1 hora Todos PO Dimensionar e planejar hist\u00f3rias de usu\u00e1rio para o sprint Cria\u00e7\u00e3o de Tarefas Ap\u00f3s o Planejamento do Sprint - Equipe de Desenvolvimento L\u00edder de Desenvolvimento Criar tarefas para esclarecer e determinar a velocidade Refinamento do Backlog Quarta 14h 1 hora L\u00edder de Desenvolvimento, PO PO Preparar para o pr\u00f3ximo sprint e garantir que as hist\u00f3rias estejam prontas para o pr\u00f3ximo sprint.","title":"Ritmo do Scrum"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#lider-de-processo","text":"O L\u00edder de Processo \u00e9 respons\u00e1vel por liderar quaisquer pr\u00e1ticas de scrum ou \u00e1geis para permitir que o projeto avance. Facilitar reuni\u00f5es di\u00e1rias e responsabilizar a equipe pela presen\u00e7a e participa\u00e7\u00e3o. Manter a reuni\u00e3o em movimento conforme descrito na p\u00e1gina Reuni\u00e3o Di\u00e1ria do Projeto . Certificar-se de que todas as a\u00e7\u00f5es est\u00e3o documentadas e garantir que cada uma tenha um respons\u00e1vel e uma data de vencimento e rastrear as quest\u00f5es em aberto. Anota\u00e7\u00f5es conforme necess\u00e1rio ap\u00f3s o planejamento/reuni\u00f5es di\u00e1rias. Certificar-se de que os itens s\u00e3o movidos para o estacionamento e garantir o acompanhamento posterior. Manter um local mostrando o trabalho e o status da equipe e remover impedimentos que est\u00e3o bloqueando a equipe. Responsabilizar a equipe pelos resultados de forma solid\u00e1ria. - Certificar-se de que a documenta\u00e7\u00e3o do projeto e do programa est\u00e3o atualizadas. - Garantir o rastreamento/seguimento de a\u00e7\u00f5es da retrospectiva (planejamento de itera\u00e7\u00e3o e libera\u00e7\u00e3o) e das reuni\u00f5es di\u00e1rias. - Facilitar a retrospectiva do sprint. - Treinar o Product Owner e a equipe no processo, conforme necess\u00e1rio.","title":"L\u00edder de Processo"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#gerenciamento-de-backlog","text":"Trabalhamos juntos em uma Defini\u00e7\u00e3o de Pronto e todas as hist\u00f3rias de usu\u00e1rio atribu\u00eddas a um sprint precisam seguir isso Comunicamos o que estamos trabalhando atrav\u00e9s do quadro Atribu\u00edmos a n\u00f3s mesmos uma tarefa quando estamos prontos para trabalhar nela (n\u00e3o antes) e a movemos para ativo Capturamos qualquer trabalho que fazemos relacionado ao projeto em uma hist\u00f3ria de usu\u00e1rio/tarefa Fechamos nossas tarefas/hist\u00f3rias de usu\u00e1rio apenas quando est\u00e3o conclu\u00eddas (conforme descrito na Defini\u00e7\u00e3o de Conclu\u00eddo ) Trabalhamos com o PM se quisermos adicionar uma nova hist\u00f3ria de usu\u00e1rio ao sprint Se adicionarmos novas tarefas ao quadro, certificamo-nos de que ela corresponde aos crit\u00e9rios de aceita\u00e7\u00e3o da hist\u00f3ria de usu\u00e1rio (para evitar o aumento do escopo). Se n\u00e3o corresponder aos crit\u00e9rios de aceita\u00e7\u00e3o, devemos discutir com o PM para ver se precisamos de uma nova hist\u00f3ria de usu\u00e1rio para a tarefa ou se devemos ajustar os crit\u00e9rios de aceita\u00e7\u00e3o.","title":"Gerenciamento de Backlog"},{"location":"agile-development/advanced-topics/team-agreements/working-agreements/#gerenciamento-de-codigo","text":"Seguimos a conven\u00e7\u00e3o de nomenclatura de branch do git flow para branches e identificamos o n\u00famero da tarefa, por exemplo, feature/123-add-working-agreement Mesclamos todo o c\u00f3digo em branches principais atrav\u00e9s de PRs Todos os PRs s\u00e3o revisados por uma pessoa de [Nome do Cliente/Parceiro] e uma da Microsoft (para transfer\u00eancia de conhecimento e para garantir que os padr\u00f5es de c\u00f3digo e seguran\u00e7a sejam atendidos) Sempre revisamos os PRs existentes antes de come\u00e7ar a trabalhar em uma nova tarefa Olhamos os PRs abertos no final da reuni\u00e3o di\u00e1ria para garantir que todos os PRs tenham revisores. Tratamos a documenta\u00e7\u00e3o como c\u00f3digo e aplicamos os mesmos padr\u00f5es ao Markdown como c\u00f3digo.","title":"Gerenciamento de C\u00f3digo"},{"location":"agile-development/basics/","text":"Fundamentos do Desenvolvimento \u00c1gil Se voc\u00ea \u00e9 novo no desenvolvimento \u00c1gil ou est\u00e1 procurando uma atualiza\u00e7\u00e3o, esta se\u00e7\u00e3o fornecer\u00e1 links para informa\u00e7\u00f5es que oferecem melhores pr\u00e1ticas para Gerenciamento de Backlog, Cerim\u00f4nias \u00c1geis, Pap\u00e9is dentro do \u00c1gil e Sprints \u00c1geis. O que \u00e9 \u00c1gil O que \u00e9 Desenvolvimento \u00c1gil Gerenciamento de Backlog Cerim\u00f4nias Pap\u00e9is Sprints","title":"Fundamentos do Desenvolvimento \u00c1gil"},{"location":"agile-development/basics/#fundamentos-do-desenvolvimento-agil","text":"Se voc\u00ea \u00e9 novo no desenvolvimento \u00c1gil ou est\u00e1 procurando uma atualiza\u00e7\u00e3o, esta se\u00e7\u00e3o fornecer\u00e1 links para informa\u00e7\u00f5es que oferecem melhores pr\u00e1ticas para Gerenciamento de Backlog, Cerim\u00f4nias \u00c1geis, Pap\u00e9is dentro do \u00c1gil e Sprints \u00c1geis. O que \u00e9 \u00c1gil O que \u00e9 Desenvolvimento \u00c1gil Gerenciamento de Backlog Cerim\u00f4nias Pap\u00e9is Sprints","title":"Fundamentos do Desenvolvimento \u00c1gil"},{"location":"agile-development/basics/Backlog%20Management/","text":"Fundamentos do Gerenciamento de Backlog para o Backlog do Produto e do Sprint Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as melhores pr\u00e1ticas de gerenciamento de Backlogs do Produto e do Sprint. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico de como gerenciar ambos os backlogs do produto e do sprint, como criar crit\u00e9rios de aceita\u00e7\u00e3o para hist\u00f3rias de usu\u00e1rios, criar uma defini\u00e7\u00e3o de \"feito\" e defini\u00e7\u00e3o de \"pronto\" para hist\u00f3rias de usu\u00e1rios e os fundamentos sobre a estimativa de hist\u00f3rias de usu\u00e1rios. Backlog do Produto Backlog do Sprint Crit\u00e9rios de Aceita\u00e7\u00e3o Defini\u00e7\u00e3o de Feito Defini\u00e7\u00e3o de Pronto Fundamentos da Estimativa em \u00c1gil","title":"Fundamentos do Gerenciamento de Backlog para o Backlog do Produto e do Sprint"},{"location":"agile-development/basics/Backlog%20Management/#fundamentos-do-gerenciamento-de-backlog-para-o-backlog-do-produto-e-do-sprint","text":"Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as melhores pr\u00e1ticas de gerenciamento de Backlogs do Produto e do Sprint. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico de como gerenciar ambos os backlogs do produto e do sprint, como criar crit\u00e9rios de aceita\u00e7\u00e3o para hist\u00f3rias de usu\u00e1rios, criar uma defini\u00e7\u00e3o de \"feito\" e defini\u00e7\u00e3o de \"pronto\" para hist\u00f3rias de usu\u00e1rios e os fundamentos sobre a estimativa de hist\u00f3rias de usu\u00e1rios. Backlog do Produto Backlog do Sprint Crit\u00e9rios de Aceita\u00e7\u00e3o Defini\u00e7\u00e3o de Feito Defini\u00e7\u00e3o de Pronto Fundamentos da Estimativa em \u00c1gil","title":"Fundamentos do Gerenciamento de Backlog para o Backlog do Produto e do Sprint"},{"location":"agile-development/basics/Ceremonies/","text":"Fundamentos das Cerim\u00f4nias \u00c1geis Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as melhores pr\u00e1ticas para conduzir as cerim\u00f4nias \u00e1geis. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico das principais cerim\u00f4nias \u00e1geis em termos de prop\u00f3sito, valor e melhores pr\u00e1ticas para conduzir e facilitar essas cerim\u00f4nias. Planejamento Refinamento Retrospectiva Revis\u00e3o/Demo do Sprint Stand-Up/Scrum Di\u00e1rio","title":"Fundamentos das Cerim\u00f4nias \u00c1geis"},{"location":"agile-development/basics/Ceremonies/#fundamentos-das-cerimonias-ageis","text":"Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as melhores pr\u00e1ticas para conduzir as cerim\u00f4nias \u00e1geis. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico das principais cerim\u00f4nias \u00e1geis em termos de prop\u00f3sito, valor e melhores pr\u00e1ticas para conduzir e facilitar essas cerim\u00f4nias. Planejamento Refinamento Retrospectiva Revis\u00e3o/Demo do Sprint Stand-Up/Scrum Di\u00e1rio","title":"Fundamentos das Cerim\u00f4nias \u00c1geis"},{"location":"agile-development/basics/Roles/","text":"Pap\u00e9is no Agile/Scrum Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as defini\u00e7\u00f5es dos pap\u00e9is tradicionais dentro do Agile/Scrum. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico dos principais pap\u00e9is \u00e1geis em termos do que eles s\u00e3o e das expectativas para o papel. Product Owner (Dono do Produto) Scrum Master Equipe de Desenvolvimento","title":"Pap\u00e9is no Agile/Scrum"},{"location":"agile-development/basics/Roles/#papeis-no-agilescrum","text":"Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as defini\u00e7\u00f5es dos pap\u00e9is tradicionais dentro do Agile/Scrum. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico dos principais pap\u00e9is \u00e1geis em termos do que eles s\u00e3o e das expectativas para o papel. Product Owner (Dono do Produto) Scrum Master Equipe de Desenvolvimento","title":"Pap\u00e9is no Agile/Scrum"},{"location":"agile-development/basics/Sprints/","text":"O Sprint Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as melhores pr\u00e1ticas em rela\u00e7\u00e3o ao que \u00e9 um sprint dentro do agile e as pr\u00e1ticas em torno do sprint. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico do Planejamento do Sprint e do Backlog do Sprint, Execu\u00e7\u00e3o do Sprint e o Standup Di\u00e1rio, Revis\u00e3o do Sprint e Retrospectiva do Sprint, e a principal entrega do sprint, que \u00e9 chamada de Incremento. Planejamento do Sprint e o Backlog do Sprint Execu\u00e7\u00e3o do Sprint e o Standup Di\u00e1rio Revis\u00e3o do Sprint e Retrospectiva do Sprint Incremento","title":"O Sprint"},{"location":"agile-development/basics/Sprints/#o-sprint","text":"Esta se\u00e7\u00e3o cont\u00e9m links que direcionam voc\u00ea para as melhores pr\u00e1ticas em rela\u00e7\u00e3o ao que \u00e9 um sprint dentro do agile e as pr\u00e1ticas em torno do sprint. Ap\u00f3s ler as melhores pr\u00e1ticas, voc\u00ea deve ter um entendimento b\u00e1sico do Planejamento do Sprint e do Backlog do Sprint, Execu\u00e7\u00e3o do Sprint e o Standup Di\u00e1rio, Revis\u00e3o do Sprint e Retrospectiva do Sprint, e a principal entrega do sprint, que \u00e9 chamada de Incremento. Planejamento do Sprint e o Backlog do Sprint Execu\u00e7\u00e3o do Sprint e o Standup Di\u00e1rio Revis\u00e3o do Sprint e Retrospectiva do Sprint Incremento","title":"O Sprint"},{"location":"agile-development/core-expectations/","text":"Expectativas Centrais do Agile Esta se\u00e7\u00e3o cont\u00e9m as expectativas centrais para as pr\u00e1ticas \u00e1geis na ISE: Deve permanecer concisa e vincular \u00e0 documenta\u00e7\u00e3o externa para detalhes. Cada se\u00e7\u00e3o cont\u00e9m uma lista de expectativas centrais e sugest\u00f5es: Expectativas centrais s\u00e3o o que cada equipe de desenvolvimento deve almejar. Sugest\u00f5es n\u00e3o s\u00e3o expectativas. S\u00e3o nossa experi\u00eancia aprendida para atender a essas expectativas e podem ser adotadas e modificadas para se adequar ao projeto. Notas: Preferimos o uso de \"l\u00edder de processo\" em vez de \"scrum master\". Descreve o mesmo papel. \"Equipe\" , neste documento, refere-se a toda a equipe trabalhando em um projeto (equipe de desenvolvimento, l\u00edder de desenvolvimento, gerente de projeto, etc.). Seguimos os princ\u00edpios \u00e1geis e geralmente Scrum Expectativas Gerais para um Projeto A equipe \u00e9 previs\u00edvel em sua entrega. A equipe faz ajustes relevantes e os compartilha de forma transparente. Pap\u00e9is e responsabilidades s\u00e3o esclarecidos e acordados antes do in\u00edcio do projeto. A equipe est\u00e1 impulsionando a melhoria cont\u00ednua de seu pr\u00f3prio processo para atender \u00e0s expectativas centrais e aumentar o sucesso do projeto. Expectativas e Sugest\u00f5es Centrais Sprints Expectativas: A estrutura do sprint oferece oportunidades frequentes para feedback e ajuste no contexto de projetos relativamente pequenos. As cerim\u00f4nias do sprint devem ser planejadas para acomodar os hor\u00e1rios de trabalho da equipe e levar em considera\u00e7\u00e3o restri\u00e7\u00f5es de tempo r\u00edgidas e flex\u00edveis. Sugest\u00f5es: O sprint come\u00e7a no dia 1: a cria\u00e7\u00e3o do plano de jogo, a revis\u00e3o do plano de jogo e o compartilhamento est\u00e3o inclu\u00eddos nos sprints e devem ser refletidos no backlog. Defina um objetivo de sprint que ser\u00e1 usado para determinar o sucesso do sprint. Nota: Os sprints geralmente duram 1 semana para aumentar o n\u00famero de oportunidades para ajustes. E minimizar o risco de perder o objetivo do sprint. Estimativa Expectativas: A estimativa suporta a previsibilidade do trabalho e entrega da equipe. A estimativa refor\u00e7a o valor da responsabilidade para a equipe. O processo de estimativa \u00e9 aprimorado ao longo do tempo e discutido regularmente. A estimativa \u00e9 inclusiva dos diferentes indiv\u00edduos na equipe. Sugest\u00f5es: A estimativa aproximada geralmente \u00e9 feita para um SE 2 gen\u00e9rico de desenvolvimento. Exemplo 1 A equipe usa tamanhos de camiseta (P, M, G, GG) e concorda antecipadamente qual tamanho se encaixa em um sprint. Neste exemplo: P, M se encaixam em um sprint, G, GG s\u00e3o muito grandes para um sprint e precisam ser divididos / refinados O l\u00edder de desenvolvimento, com o apoio da equipe, estima aproximadamente quantas hist\u00f3rias P e M podem ser feitas nos primeiros sprints Essa estimativa aproximada \u00e9 refinada ao longo do tempo e usada como uma entrada para o planejamento futuro do sprint e para ajustar a previs\u00e3o da data de t\u00e9rmino do projeto Exemplo 2 A equipe usa um \u00fanico indicador: \"essa hist\u00f3ria cabe em um sprint?\", se n\u00e3o, a hist\u00f3ria precisa ser dividida O l\u00edder de desenvolvimento, com o apoio da equipe, estima aproximadamente quantas hist\u00f3rias podem ser feitas nos primeiros sprints Quantas hist\u00f3rias s\u00e3o feitas em cada sprint, em m\u00e9dia, \u00e9 usado como uma entrada para o planejamento futuro do sprint e como um indicador para ajustar a previs\u00e3o da data de t\u00e9rmino do projeto Exemplo 3 A equipe faz o planejamento do poker e estima em pontos de hist\u00f3ria Os pontos de hist\u00f3ria s\u00e3o usados aproximadamente para estimar quanto pode ser feito no pr\u00f3ximo sprint O l\u00edder de desenvolvimento e o TPM usam os sprints passados e a velocidade observada para ajustar a previs\u00e3o da data de t\u00e9rmino do projeto Outras considera\u00e7\u00f5es Estimar hist\u00f3rias usando pontos de hist\u00f3ria em projetos menores nem sempre fornece o valor que forneceria em maiores. Evite converter pontos de hist\u00f3ria ou tamanhos de camiseta para dias. Medir a precis\u00e3o da estimativa: Colete dados para monitorar a precis\u00e3o da estimativa e a conclus\u00e3o do sprint ao longo do tempo para impulsionar melhorias. Use o objetivo do sprint para entender se a estimativa estava correta. Se o objetivo do sprint for atingido: mais alguma coisa importa? Pr\u00e1ticas de Scrum: Embora o Scrum n\u00e3o prescreva como dimensionar o trabalho, o Scrum Profissional \u00e9 tendencioso contra a estimativa absoluta (horas, pontos de fun\u00e7\u00e3o, dias ideais, etc.) e em dire\u00e7\u00e3o ao dimensionamento relativo. Planejamento do Poker: \u00e9 uma t\u00e9cnica colaborativa para atribuir tamanho relativo. Os desenvolvedores podem escolher quaisquer unidades que desejarem - pontos de hist\u00f3ria e tamanhos de camiseta s\u00e3o exemplos de unidades. PBIs do 'Mesmo Tamanho' \u00e9 uma abordagem de estimativa relativa que envolve dividir os itens em partes pequenas o suficiente para que sejam mais ou menos do mesmo tamanho. A velocidade pode ser entendida como uma contagem de PBIs; isso \u00e0s vezes \u00e9 usado por equipes que fazem entrega cont\u00ednua. PBIs do 'Tamanho Certo' \u00e9 uma abordagem de estimativa relativa que envolve dividir as coisas em partes pequenas o suficiente para entregar valor em um determinado per\u00edodo de tempo (ou seja, chegar a Feito at\u00e9 o final de um Sprint). Isso \u00e0s vezes est\u00e1 associado a equipes que utilizam fluxo para previs\u00e3o. As equipes usam dados hist\u00f3ricos para determinar se acham que podem concluir o PBI dentro do n\u00edvel de confian\u00e7a que seus dados hist\u00f3ricos dizem que normalmente concluem um PBI. Links: A coisa mais importante que voc\u00ea est\u00e1 perdendo sobre estimativa Planejamento do Sprint Expectativas: O planejamento su porta princ\u00edpios de Diversidade e Inclus\u00e3o e oferece oportunidades iguais. - O Planejamento define como o trabalho ser\u00e1 conclu\u00eddo no sprint. - As hist\u00f3rias se encaixam em um sprint e s\u00e3o projetadas e prontas antes do planejamento. Sugest\u00f5es: Objetivo do Sprint: Considere definir um objetivo de sprint ou uma lista de objetivos para cada sprint. Objetivos de sprint eficazes s\u00e3o uma lista concisa de itens em forma de t\u00f3picos. Um objetivo de sprint pode ser criado primeiro e usado como uma entrada para escolher as hist\u00f3rias para o sprint. Um objetivo de sprint tamb\u00e9m pode ser criado a partir da lista de hist\u00f3rias que foram escolhidas para o Sprint. O objetivo do sprint pode ser usado: No final de cada reuni\u00e3o de stand-up, para lembrar a estrela do norte para o Sprint e ajudar todos a dar um passo atr\u00e1s *Durante a revis\u00e3o do sprint (\"o objetivo foi alcan\u00e7ado?\", \"Se n\u00e3o, por qu\u00ea?\") Nota: Uma maneira simples de definir um objetivo de sprint \u00e9 criar uma hist\u00f3ria de usu\u00e1rio em cada backlog de sprint e nome\u00e1-la \"Objetivo do Sprint XX\". Voc\u00ea pode adicionar os t\u00f3picos na descri\u00e7\u00e3o. Hist\u00f3rias: Exemplo 1 - Preparando com anteced\u00eancia: O l\u00edder de desenvolvimento e o propriet\u00e1rio do produto planejam tempo para preparar o backlog do sprint antes do planejamento do sprint. O l\u00edder de desenvolvimento usa sua experi\u00eancia (passada e no projeto atual) e a estimativa feita para essas hist\u00f3rias para avaliar quantas devem estar no sprint. O l\u00edder de desenvolvimento pede \u00e0 equipe inteira para olhar o backlog provis\u00f3rio do sprint antes do planejamento do sprint. O l\u00edder de desenvolvimento atribui hist\u00f3rias a desenvolvedores espec\u00edficos ap\u00f3s confirmar com eles que faz sentido Durante a reuni\u00e3o de planejamento do sprint, a equipe revisa o objetivo do sprint e as hist\u00f3rias. Todos confirmam que entendem o plano e acham que \u00e9 razo\u00e1vel. Exemplo 2 - Construindo durante a reuni\u00e3o de planejamento: O propriet\u00e1rio do produto garante que os itens de maior prioridade do backlog do produto sejam refinados e estimados seguindo o processo de estimativa da equipe. Durante a reuni\u00e3o de planejamento do Sprint, o propriet\u00e1rio do produto descreve cada hist\u00f3ria, uma a uma, come\u00e7ando pela de maior prioridade. Para cada hist\u00f3ria, o l\u00edder de desenvolvimento e a equipe confirmam que entendem o que precisa ser feito e adicionam a hist\u00f3ria ao backlog do sprint. A equipe continua considerando mais hist\u00f3rias at\u00e9 um ponto em que concordam que o backlog do sprint est\u00e1 cheio. Isso deve ser informado pela estimativa, experi\u00eancia passada do desenvolvedor e experi\u00eancia passada neste projeto espec\u00edfico. As hist\u00f3rias s\u00e3o atribu\u00eddas durante a reuni\u00e3o de planejamento: Op\u00e7\u00e3o 1: O l\u00edder de desenvolvimento faz sugest\u00f5es sobre quem poderia trabalhar em cada hist\u00f3ria. Cada engenheiro concorda ou discute, se necess\u00e1rio. Op\u00e7\u00e3o 2: A equipe revisa cada hist\u00f3ria e os engenheiros volunt\u00e1rios selecionam a que desejam ser atribu\u00eddos. ( Nota : esta op\u00e7\u00e3o pode causar problemas com as primeiras expectativas centrais. Quem trabalha no qu\u00ea? Em \u00faltima an\u00e1lise, \u00e9 responsabilidade do l\u00edder de desenvolvimento garantir que cada engenheiro tenha a oportunidade de trabalhar no que faz sentido para seu crescimento.) Tarefas: Exemplos de abordagens para cria\u00e7\u00e3o e atribui\u00e7\u00e3o de tarefas: As hist\u00f3rias s\u00e3o divididas em tarefas com anteced\u00eancia pelo l\u00edder de desenvolvimento e atribu\u00eddas antes/durante o planejamento do sprint aos engenheiros. As hist\u00f3rias s\u00e3o atribu\u00eddas a engenheiros mais experientes, que s\u00e3o respons\u00e1veis por dividi-las em tarefas. As hist\u00f3rias s\u00e3o divididas em tarefas durante a reuni\u00e3o de planejamento do Sprint pela equipe inteira. Nota : Dependendo da senioridade da equipe, considere dividir em tarefas antes do planejamento do sprint. Isso pode ajudar a sair do planejamento do sprint com todo o trabalho atribu\u00eddo. Tamb\u00e9m aumenta a clareza para engenheiros j\u00fanior. Links: Defini\u00e7\u00e3o de Pronto Modelo de Objetivo de Sprint *Notas: A autoatribui\u00e7\u00e3o por membros da equipe pode dar uma sensa\u00e7\u00e3o de justi\u00e7a na forma como o trabalho \u00e9 dividido na equipe. \u00c0s vezes, isso acaba n\u00e3o sendo o caso, pois pode dar vantagem \u00e0s vozes mais altas ou mais experientes na equipe. Os indiv\u00edduos tamb\u00e9m tendem a permanecer em sua zona de conforto, o que pode n\u00e3o ser a abordagem certa para o pr\u00f3prio crescimento.* Backlog Expectativas: As hist\u00f3rias de usu\u00e1rio t\u00eam crit\u00e9rios de aceita\u00e7\u00e3o claros e defini\u00e7\u00e3o de pronto. As atividades de design s\u00e3o planejadas como parte do backlog (um design para uma hist\u00f3ria que precisa dele deve ser feito antes de ser adicionado em um Sprint). Sugest\u00f5es: Considere o refinamento do backlog como uma atividade cont\u00ednua, que se expande fora da t\u00edpica \"Reuni\u00e3o de Refinamento\". A d\u00edvida t\u00e9cnica \u00e9 principalmente devida a atalhos feitos na implementa\u00e7\u00e3o, bem como ao custo de manuten\u00e7\u00e3o futuro como resultado natural da melhoria cont\u00ednua. Atalhos devem geralmente ser evitados. Em alguns casos raros em que ocorrem, priorizar e planejar atividades de melhoria para reduzir essa d\u00edvida em um momento posterior \u00e9 a abordagem recomendada. Retrospectivas Expectativas: As retrospectivas levam a itens acion\u00e1veis que ajudam a crescer as pr\u00e1ticas de engenharia da equipe. Esses itens est\u00e3o no backlog, atribu\u00eddos e priorizados para serem corrigidos at\u00e9 uma data acordada (o padr\u00e3o sendo a pr\u00f3xima retrospectiva). \u00c9 usado para fazer as perguntas dif\u00edceis (\"geralmente n\u00e3o terminamos o que planejamos, vamos falar sobre isso\") quando necess\u00e1rio. Sugest\u00f5es: Considere outros formatos de retro dispon\u00edveis fora de Mad Sad Glad. Coletar dados: Triple Nickels, Linha do Tempo, Mad Sad Glad, Radar da Equipe Gerar Insights: 5 Porqu\u00eas, Espinha de Peixe, Padr\u00f5es e Mudan\u00e7as Considere definir uma \u00e1rea de foco para a retro. Agende tempo suficiente para garantir que voc\u00ea possa ter a conversa de que precisa para obter o plano correto de a\u00e7\u00e3o e melhorar a forma como voc\u00ea trabalha. Traga um facilitador neutro para retrospectivas de projeto ou retrospectivas que introspectam ap\u00f3s um per\u00edodo dif\u00edcil. Use as seguintes t\u00e9cnicas de retrospectivas para abordar tend\u00eancias espec\u00edficas que possam estar surgindo em um projeto: 5 porqu\u00eas: Se uma equipe est\u00e1 enfrentando um problema e n\u00e3o tem certeza da causa raiz exata, o exerc\u00edcio dos 5 porqu\u00eas, retirado do setor de an\u00e1lise de neg\u00f3cios, pode ajudar a chegar ao fundo dele. Por exemplo, se uma equipe n\u00e3o consegue chegar a Pronto a cada Sprint, isso iria para o topo do quadro branco. A equipe ent\u00e3o pergunta por que esse problema existe, escrevendo essa resposta na caixa abaixo. Em seguida, a equipe pergunta por que novamente, mas desta vez em resposta ao porqu\u00ea que acabaram de identificar. Continue esse processo at\u00e9 que a equipe identifique uma causa raiz real, que geralmente se torna aparente em cinco etapas. Processos, ferramentas, indiv\u00edduos, intera\u00e7\u00f5es e a Defini\u00e7\u00e3o de Pronto: Esta abordagem incentiva os membros da equipe a pensar de forma mais ampla. Pe\u00e7a aos membros da equipe para identificar o que est\u00e1 indo bem e ideias para melhoria nas categorias de processos, ferramentas, indiv\u00edduos/intera\u00e7\u00f5es e a Defini\u00e7\u00e3o de Pronto. Em seguida, pe\u00e7a aos membros da equipe para votar em quais ideias de melhoria focar durante o pr\u00f3ximo Sprint. Foco: Esta t\u00e9cnica de retrospectiva incorpora o conceito de vis\u00e3o. Usando esta t\u00e9cnica, voc\u00ea pergunta aos membros da equipe para onde gostariam de ir? Decida como a equipe deve ser em 4 semanas e, em seguida, pergunte o que est\u00e1 impedindo-os de chegar l\u00e1 e como podem resolver o impedimento. Se voc\u00ea est\u00e1 focando em melhorias espec\u00edficas, voc\u00ea pode usar esta t\u00e9cnica para uma ou duas retrospectivas seguidas, para que a equipe possa ver o progresso ao longo do tempo. Demonstra\u00e7\u00e3o do Sprint Expectativas: Cada sprint tem demonstra\u00e7\u00f5es que ilustram o objetivo do sprint e como ele se encaixa no objetivo do projeto. Sugest\u00f5es: Considere n\u00e3o pr\u00e9-gravar demonstra\u00e7\u00f5es de sprint com anteced\u00eancia. Voc\u00ea pode gravar a reuni\u00e3o de demonstra\u00e7\u00e3o e arquiv\u00e1-la. Uma demonstra\u00e7\u00e3o n\u00e3o precisa ser sobre c\u00f3digo em execu\u00e7\u00e3o. Pode ser mostrando documenta\u00e7\u00e3o que foi escrita. Stand-up Expectativas: O stand-up \u00e9 executado de forma eficiente. O stand-up ajuda a equipe a entender o que foi feito, o que ser\u00e1 feito e quais s\u00e3o os bloqueadores. O stand-up ajuda a equipe a entender se eles atender\u00e3o ao objetivo do sprint ou n\u00e3o. Sugest\u00f5es: Mantenha o stand-up curto e eficiente. Reserve as conversas mais longas para uma se\u00e7\u00e3o de estacionamento ou para uma conversa que ser\u00e1 planejada posteriormente. Fa\u00e7a stand-ups di\u00e1rios: 15 minutos de stand-up e 15 minutos de estacionamento. Se algu\u00e9m n\u00e3o puder comparecer ao stand-up excepcionalmente: Pe\u00e7a-lhes para fazer um stand-up escrito com anteced\u00eancia. Os stand-ups devem incluir todos os envolvidos no projeto, incluindo o cliente. Projetos com fusos hor\u00e1rios amplamente divergentes devem ser evitados, se poss\u00edvel, mas se voc\u00ea estiver em um, voc\u00ea deve adaptar os stand-ups para atender \u00e0s necessidades e restri\u00e7\u00f5es de tempo de todos os membros da equipe. Documenta\u00e7\u00e3o O que \u00e9 Scrum? Retrospectiva \u00c1gil: Tornando Boas Equipes \u00d3timas Hist\u00f3rias de Usu\u00e1rios Aplicadas: Para Desenvolvimento de Software Scrum Essencial: Um Guia Pr\u00e1tico para o Processo \u00c1gil Mais Popular","title":"Expectativas Centrais do Agile"},{"location":"agile-development/core-expectations/#expectativas-centrais-do-agile","text":"Esta se\u00e7\u00e3o cont\u00e9m as expectativas centrais para as pr\u00e1ticas \u00e1geis na ISE: Deve permanecer concisa e vincular \u00e0 documenta\u00e7\u00e3o externa para detalhes. Cada se\u00e7\u00e3o cont\u00e9m uma lista de expectativas centrais e sugest\u00f5es: Expectativas centrais s\u00e3o o que cada equipe de desenvolvimento deve almejar. Sugest\u00f5es n\u00e3o s\u00e3o expectativas. S\u00e3o nossa experi\u00eancia aprendida para atender a essas expectativas e podem ser adotadas e modificadas para se adequar ao projeto. Notas: Preferimos o uso de \"l\u00edder de processo\" em vez de \"scrum master\". Descreve o mesmo papel. \"Equipe\" , neste documento, refere-se a toda a equipe trabalhando em um projeto (equipe de desenvolvimento, l\u00edder de desenvolvimento, gerente de projeto, etc.). Seguimos os princ\u00edpios \u00e1geis e geralmente Scrum","title":"Expectativas Centrais do Agile"},{"location":"agile-development/core-expectations/#expectativas-gerais-para-um-projeto","text":"A equipe \u00e9 previs\u00edvel em sua entrega. A equipe faz ajustes relevantes e os compartilha de forma transparente. Pap\u00e9is e responsabilidades s\u00e3o esclarecidos e acordados antes do in\u00edcio do projeto. A equipe est\u00e1 impulsionando a melhoria cont\u00ednua de seu pr\u00f3prio processo para atender \u00e0s expectativas centrais e aumentar o sucesso do projeto.","title":"Expectativas Gerais para um Projeto"},{"location":"agile-development/core-expectations/#expectativas-e-sugestoes-centrais","text":"","title":"Expectativas e Sugest\u00f5es Centrais"},{"location":"agile-development/core-expectations/#sprints","text":"Expectativas: A estrutura do sprint oferece oportunidades frequentes para feedback e ajuste no contexto de projetos relativamente pequenos. As cerim\u00f4nias do sprint devem ser planejadas para acomodar os hor\u00e1rios de trabalho da equipe e levar em considera\u00e7\u00e3o restri\u00e7\u00f5es de tempo r\u00edgidas e flex\u00edveis. Sugest\u00f5es: O sprint come\u00e7a no dia 1: a cria\u00e7\u00e3o do plano de jogo, a revis\u00e3o do plano de jogo e o compartilhamento est\u00e3o inclu\u00eddos nos sprints e devem ser refletidos no backlog. Defina um objetivo de sprint que ser\u00e1 usado para determinar o sucesso do sprint. Nota: Os sprints geralmente duram 1 semana para aumentar o n\u00famero de oportunidades para ajustes. E minimizar o risco de perder o objetivo do sprint.","title":"Sprints"},{"location":"agile-development/core-expectations/#estimativa","text":"Expectativas: A estimativa suporta a previsibilidade do trabalho e entrega da equipe. A estimativa refor\u00e7a o valor da responsabilidade para a equipe. O processo de estimativa \u00e9 aprimorado ao longo do tempo e discutido regularmente. A estimativa \u00e9 inclusiva dos diferentes indiv\u00edduos na equipe. Sugest\u00f5es: A estimativa aproximada geralmente \u00e9 feita para um SE 2 gen\u00e9rico de desenvolvimento. Exemplo 1 A equipe usa tamanhos de camiseta (P, M, G, GG) e concorda antecipadamente qual tamanho se encaixa em um sprint. Neste exemplo: P, M se encaixam em um sprint, G, GG s\u00e3o muito grandes para um sprint e precisam ser divididos / refinados O l\u00edder de desenvolvimento, com o apoio da equipe, estima aproximadamente quantas hist\u00f3rias P e M podem ser feitas nos primeiros sprints Essa estimativa aproximada \u00e9 refinada ao longo do tempo e usada como uma entrada para o planejamento futuro do sprint e para ajustar a previs\u00e3o da data de t\u00e9rmino do projeto Exemplo 2 A equipe usa um \u00fanico indicador: \"essa hist\u00f3ria cabe em um sprint?\", se n\u00e3o, a hist\u00f3ria precisa ser dividida O l\u00edder de desenvolvimento, com o apoio da equipe, estima aproximadamente quantas hist\u00f3rias podem ser feitas nos primeiros sprints Quantas hist\u00f3rias s\u00e3o feitas em cada sprint, em m\u00e9dia, \u00e9 usado como uma entrada para o planejamento futuro do sprint e como um indicador para ajustar a previs\u00e3o da data de t\u00e9rmino do projeto Exemplo 3 A equipe faz o planejamento do poker e estima em pontos de hist\u00f3ria Os pontos de hist\u00f3ria s\u00e3o usados aproximadamente para estimar quanto pode ser feito no pr\u00f3ximo sprint O l\u00edder de desenvolvimento e o TPM usam os sprints passados e a velocidade observada para ajustar a previs\u00e3o da data de t\u00e9rmino do projeto Outras considera\u00e7\u00f5es Estimar hist\u00f3rias usando pontos de hist\u00f3ria em projetos menores nem sempre fornece o valor que forneceria em maiores. Evite converter pontos de hist\u00f3ria ou tamanhos de camiseta para dias. Medir a precis\u00e3o da estimativa: Colete dados para monitorar a precis\u00e3o da estimativa e a conclus\u00e3o do sprint ao longo do tempo para impulsionar melhorias. Use o objetivo do sprint para entender se a estimativa estava correta. Se o objetivo do sprint for atingido: mais alguma coisa importa? Pr\u00e1ticas de Scrum: Embora o Scrum n\u00e3o prescreva como dimensionar o trabalho, o Scrum Profissional \u00e9 tendencioso contra a estimativa absoluta (horas, pontos de fun\u00e7\u00e3o, dias ideais, etc.) e em dire\u00e7\u00e3o ao dimensionamento relativo. Planejamento do Poker: \u00e9 uma t\u00e9cnica colaborativa para atribuir tamanho relativo. Os desenvolvedores podem escolher quaisquer unidades que desejarem - pontos de hist\u00f3ria e tamanhos de camiseta s\u00e3o exemplos de unidades. PBIs do 'Mesmo Tamanho' \u00e9 uma abordagem de estimativa relativa que envolve dividir os itens em partes pequenas o suficiente para que sejam mais ou menos do mesmo tamanho. A velocidade pode ser entendida como uma contagem de PBIs; isso \u00e0s vezes \u00e9 usado por equipes que fazem entrega cont\u00ednua. PBIs do 'Tamanho Certo' \u00e9 uma abordagem de estimativa relativa que envolve dividir as coisas em partes pequenas o suficiente para entregar valor em um determinado per\u00edodo de tempo (ou seja, chegar a Feito at\u00e9 o final de um Sprint). Isso \u00e0s vezes est\u00e1 associado a equipes que utilizam fluxo para previs\u00e3o. As equipes usam dados hist\u00f3ricos para determinar se acham que podem concluir o PBI dentro do n\u00edvel de confian\u00e7a que seus dados hist\u00f3ricos dizem que normalmente concluem um PBI. Links: A coisa mais importante que voc\u00ea est\u00e1 perdendo sobre estimativa","title":"Estimativa"},{"location":"agile-development/core-expectations/#planejamento-do-sprint","text":"Expectativas: O planejamento su porta princ\u00edpios de Diversidade e Inclus\u00e3o e oferece oportunidades iguais. - O Planejamento define como o trabalho ser\u00e1 conclu\u00eddo no sprint. - As hist\u00f3rias se encaixam em um sprint e s\u00e3o projetadas e prontas antes do planejamento. Sugest\u00f5es: Objetivo do Sprint: Considere definir um objetivo de sprint ou uma lista de objetivos para cada sprint. Objetivos de sprint eficazes s\u00e3o uma lista concisa de itens em forma de t\u00f3picos. Um objetivo de sprint pode ser criado primeiro e usado como uma entrada para escolher as hist\u00f3rias para o sprint. Um objetivo de sprint tamb\u00e9m pode ser criado a partir da lista de hist\u00f3rias que foram escolhidas para o Sprint. O objetivo do sprint pode ser usado: No final de cada reuni\u00e3o de stand-up, para lembrar a estrela do norte para o Sprint e ajudar todos a dar um passo atr\u00e1s *Durante a revis\u00e3o do sprint (\"o objetivo foi alcan\u00e7ado?\", \"Se n\u00e3o, por qu\u00ea?\") Nota: Uma maneira simples de definir um objetivo de sprint \u00e9 criar uma hist\u00f3ria de usu\u00e1rio em cada backlog de sprint e nome\u00e1-la \"Objetivo do Sprint XX\". Voc\u00ea pode adicionar os t\u00f3picos na descri\u00e7\u00e3o. Hist\u00f3rias: Exemplo 1 - Preparando com anteced\u00eancia: O l\u00edder de desenvolvimento e o propriet\u00e1rio do produto planejam tempo para preparar o backlog do sprint antes do planejamento do sprint. O l\u00edder de desenvolvimento usa sua experi\u00eancia (passada e no projeto atual) e a estimativa feita para essas hist\u00f3rias para avaliar quantas devem estar no sprint. O l\u00edder de desenvolvimento pede \u00e0 equipe inteira para olhar o backlog provis\u00f3rio do sprint antes do planejamento do sprint. O l\u00edder de desenvolvimento atribui hist\u00f3rias a desenvolvedores espec\u00edficos ap\u00f3s confirmar com eles que faz sentido Durante a reuni\u00e3o de planejamento do sprint, a equipe revisa o objetivo do sprint e as hist\u00f3rias. Todos confirmam que entendem o plano e acham que \u00e9 razo\u00e1vel. Exemplo 2 - Construindo durante a reuni\u00e3o de planejamento: O propriet\u00e1rio do produto garante que os itens de maior prioridade do backlog do produto sejam refinados e estimados seguindo o processo de estimativa da equipe. Durante a reuni\u00e3o de planejamento do Sprint, o propriet\u00e1rio do produto descreve cada hist\u00f3ria, uma a uma, come\u00e7ando pela de maior prioridade. Para cada hist\u00f3ria, o l\u00edder de desenvolvimento e a equipe confirmam que entendem o que precisa ser feito e adicionam a hist\u00f3ria ao backlog do sprint. A equipe continua considerando mais hist\u00f3rias at\u00e9 um ponto em que concordam que o backlog do sprint est\u00e1 cheio. Isso deve ser informado pela estimativa, experi\u00eancia passada do desenvolvedor e experi\u00eancia passada neste projeto espec\u00edfico. As hist\u00f3rias s\u00e3o atribu\u00eddas durante a reuni\u00e3o de planejamento: Op\u00e7\u00e3o 1: O l\u00edder de desenvolvimento faz sugest\u00f5es sobre quem poderia trabalhar em cada hist\u00f3ria. Cada engenheiro concorda ou discute, se necess\u00e1rio. Op\u00e7\u00e3o 2: A equipe revisa cada hist\u00f3ria e os engenheiros volunt\u00e1rios selecionam a que desejam ser atribu\u00eddos. ( Nota : esta op\u00e7\u00e3o pode causar problemas com as primeiras expectativas centrais. Quem trabalha no qu\u00ea? Em \u00faltima an\u00e1lise, \u00e9 responsabilidade do l\u00edder de desenvolvimento garantir que cada engenheiro tenha a oportunidade de trabalhar no que faz sentido para seu crescimento.) Tarefas: Exemplos de abordagens para cria\u00e7\u00e3o e atribui\u00e7\u00e3o de tarefas: As hist\u00f3rias s\u00e3o divididas em tarefas com anteced\u00eancia pelo l\u00edder de desenvolvimento e atribu\u00eddas antes/durante o planejamento do sprint aos engenheiros. As hist\u00f3rias s\u00e3o atribu\u00eddas a engenheiros mais experientes, que s\u00e3o respons\u00e1veis por dividi-las em tarefas. As hist\u00f3rias s\u00e3o divididas em tarefas durante a reuni\u00e3o de planejamento do Sprint pela equipe inteira. Nota : Dependendo da senioridade da equipe, considere dividir em tarefas antes do planejamento do sprint. Isso pode ajudar a sair do planejamento do sprint com todo o trabalho atribu\u00eddo. Tamb\u00e9m aumenta a clareza para engenheiros j\u00fanior. Links: Defini\u00e7\u00e3o de Pronto Modelo de Objetivo de Sprint *Notas: A autoatribui\u00e7\u00e3o por membros da equipe pode dar uma sensa\u00e7\u00e3o de justi\u00e7a na forma como o trabalho \u00e9 dividido na equipe. \u00c0s vezes, isso acaba n\u00e3o sendo o caso, pois pode dar vantagem \u00e0s vozes mais altas ou mais experientes na equipe. Os indiv\u00edduos tamb\u00e9m tendem a permanecer em sua zona de conforto, o que pode n\u00e3o ser a abordagem certa para o pr\u00f3prio crescimento.*","title":"Planejamento do Sprint"},{"location":"agile-development/core-expectations/#backlog","text":"Expectativas: As hist\u00f3rias de usu\u00e1rio t\u00eam crit\u00e9rios de aceita\u00e7\u00e3o claros e defini\u00e7\u00e3o de pronto. As atividades de design s\u00e3o planejadas como parte do backlog (um design para uma hist\u00f3ria que precisa dele deve ser feito antes de ser adicionado em um Sprint). Sugest\u00f5es: Considere o refinamento do backlog como uma atividade cont\u00ednua, que se expande fora da t\u00edpica \"Reuni\u00e3o de Refinamento\". A d\u00edvida t\u00e9cnica \u00e9 principalmente devida a atalhos feitos na implementa\u00e7\u00e3o, bem como ao custo de manuten\u00e7\u00e3o futuro como resultado natural da melhoria cont\u00ednua. Atalhos devem geralmente ser evitados. Em alguns casos raros em que ocorrem, priorizar e planejar atividades de melhoria para reduzir essa d\u00edvida em um momento posterior \u00e9 a abordagem recomendada.","title":"Backlog"},{"location":"agile-development/core-expectations/#retrospectivas","text":"Expectativas: As retrospectivas levam a itens acion\u00e1veis que ajudam a crescer as pr\u00e1ticas de engenharia da equipe. Esses itens est\u00e3o no backlog, atribu\u00eddos e priorizados para serem corrigidos at\u00e9 uma data acordada (o padr\u00e3o sendo a pr\u00f3xima retrospectiva). \u00c9 usado para fazer as perguntas dif\u00edceis (\"geralmente n\u00e3o terminamos o que planejamos, vamos falar sobre isso\") quando necess\u00e1rio. Sugest\u00f5es: Considere outros formatos de retro dispon\u00edveis fora de Mad Sad Glad. Coletar dados: Triple Nickels, Linha do Tempo, Mad Sad Glad, Radar da Equipe Gerar Insights: 5 Porqu\u00eas, Espinha de Peixe, Padr\u00f5es e Mudan\u00e7as Considere definir uma \u00e1rea de foco para a retro. Agende tempo suficiente para garantir que voc\u00ea possa ter a conversa de que precisa para obter o plano correto de a\u00e7\u00e3o e melhorar a forma como voc\u00ea trabalha. Traga um facilitador neutro para retrospectivas de projeto ou retrospectivas que introspectam ap\u00f3s um per\u00edodo dif\u00edcil. Use as seguintes t\u00e9cnicas de retrospectivas para abordar tend\u00eancias espec\u00edficas que possam estar surgindo em um projeto: 5 porqu\u00eas: Se uma equipe est\u00e1 enfrentando um problema e n\u00e3o tem certeza da causa raiz exata, o exerc\u00edcio dos 5 porqu\u00eas, retirado do setor de an\u00e1lise de neg\u00f3cios, pode ajudar a chegar ao fundo dele. Por exemplo, se uma equipe n\u00e3o consegue chegar a Pronto a cada Sprint, isso iria para o topo do quadro branco. A equipe ent\u00e3o pergunta por que esse problema existe, escrevendo essa resposta na caixa abaixo. Em seguida, a equipe pergunta por que novamente, mas desta vez em resposta ao porqu\u00ea que acabaram de identificar. Continue esse processo at\u00e9 que a equipe identifique uma causa raiz real, que geralmente se torna aparente em cinco etapas. Processos, ferramentas, indiv\u00edduos, intera\u00e7\u00f5es e a Defini\u00e7\u00e3o de Pronto: Esta abordagem incentiva os membros da equipe a pensar de forma mais ampla. Pe\u00e7a aos membros da equipe para identificar o que est\u00e1 indo bem e ideias para melhoria nas categorias de processos, ferramentas, indiv\u00edduos/intera\u00e7\u00f5es e a Defini\u00e7\u00e3o de Pronto. Em seguida, pe\u00e7a aos membros da equipe para votar em quais ideias de melhoria focar durante o pr\u00f3ximo Sprint. Foco: Esta t\u00e9cnica de retrospectiva incorpora o conceito de vis\u00e3o. Usando esta t\u00e9cnica, voc\u00ea pergunta aos membros da equipe para onde gostariam de ir? Decida como a equipe deve ser em 4 semanas e, em seguida, pergunte o que est\u00e1 impedindo-os de chegar l\u00e1 e como podem resolver o impedimento. Se voc\u00ea est\u00e1 focando em melhorias espec\u00edficas, voc\u00ea pode usar esta t\u00e9cnica para uma ou duas retrospectivas seguidas, para que a equipe possa ver o progresso ao longo do tempo.","title":"Retrospectivas"},{"location":"agile-development/core-expectations/#demonstracao-do-sprint","text":"Expectativas: Cada sprint tem demonstra\u00e7\u00f5es que ilustram o objetivo do sprint e como ele se encaixa no objetivo do projeto. Sugest\u00f5es: Considere n\u00e3o pr\u00e9-gravar demonstra\u00e7\u00f5es de sprint com anteced\u00eancia. Voc\u00ea pode gravar a reuni\u00e3o de demonstra\u00e7\u00e3o e arquiv\u00e1-la. Uma demonstra\u00e7\u00e3o n\u00e3o precisa ser sobre c\u00f3digo em execu\u00e7\u00e3o. Pode ser mostrando documenta\u00e7\u00e3o que foi escrita.","title":"Demonstra\u00e7\u00e3o do Sprint"},{"location":"agile-development/core-expectations/#stand-up","text":"Expectativas: O stand-up \u00e9 executado de forma eficiente. O stand-up ajuda a equipe a entender o que foi feito, o que ser\u00e1 feito e quais s\u00e3o os bloqueadores. O stand-up ajuda a equipe a entender se eles atender\u00e3o ao objetivo do sprint ou n\u00e3o. Sugest\u00f5es: Mantenha o stand-up curto e eficiente. Reserve as conversas mais longas para uma se\u00e7\u00e3o de estacionamento ou para uma conversa que ser\u00e1 planejada posteriormente. Fa\u00e7a stand-ups di\u00e1rios: 15 minutos de stand-up e 15 minutos de estacionamento. Se algu\u00e9m n\u00e3o puder comparecer ao stand-up excepcionalmente: Pe\u00e7a-lhes para fazer um stand-up escrito com anteced\u00eancia. Os stand-ups devem incluir todos os envolvidos no projeto, incluindo o cliente. Projetos com fusos hor\u00e1rios amplamente divergentes devem ser evitados, se poss\u00edvel, mas se voc\u00ea estiver em um, voc\u00ea deve adaptar os stand-ups para atender \u00e0s necessidades e restri\u00e7\u00f5es de tempo de todos os membros da equipe.","title":"Stand-up"},{"location":"agile-development/core-expectations/#documentacao","text":"O que \u00e9 Scrum? Retrospectiva \u00c1gil: Tornando Boas Equipes \u00d3timas Hist\u00f3rias de Usu\u00e1rios Aplicadas: Para Desenvolvimento de Software Scrum Essencial: Um Guia Pr\u00e1tico para o Processo \u00c1gil Mais Popular","title":"Documenta\u00e7\u00e3o"},{"location":"automated-testing/","text":"Testando Mapa de Resultados para T\u00e9cnicas de Teste A tabela abaixo mapeia resultados -- os resultados que voc\u00ea pode querer alcan\u00e7ar em seus esfor\u00e7os de valida\u00e7\u00e3o -- para uma ou mais t\u00e9cnicas que podem ser usadas para alcan\u00e7ar esse resultado. Quando estou trabalhando em... Quero obter este resultado... ...ent\u00e3o devo considerar Desenvolvimento Comprovar compatibilidade retroativa com chamadores e clientes existentes Shadow testing Desenvolvimento Garantir que a l\u00f3gica do programa esteja correta para uma variedade de entradas esperadas, principais, de borda e inesperadas Unit testing ; Testes funcionais; Consumer-driven Contract Testing ; Integration testing Desenvolvimento Prevenir regress\u00f5es na corre\u00e7\u00e3o l\u00f3gica; quanto mais cedo, melhor Unit testing ; Testes funcionais; Consumer-driven Contract Testing ; Integration testing ; An\u00e9is (cada um desses s\u00e3o escopos de cobertura em expans\u00e3o) Desenvolvimento Validar rapidamente a corre\u00e7\u00e3o principal de um ponto de funcionalidade (por exemplo, uma \u00fanica API), manualmente Testes de fuma\u00e7a manuais Ferramentas: postman, powershell, curl Desenvolvimento Validar intera\u00e7\u00f5es entre componentes isoladamente, garantindo que componentes consumidores e provedores sejam compat\u00edveis e estejam de acordo com um entendimento compartilhado documentado em um contrato Consumer-driven Contract Testing Desenvolvimento; Integration testing Validar que m\u00faltiplos componentes funcionem juntos em v\u00e1rias interfaces em uma cadeia de chamadas, incluindo saltos de rede Integration testing ; Testes de ponta a ponta ( End-to-End testing ); Testes de ponta a ponta segmentados ( End-to-End testing ) Desenvolvimento Comprovar recupera\u00e7\u00e3o de desastres \u2013 recupera\u00e7\u00e3o de corrup\u00e7\u00e3o de dados Simula\u00e7\u00f5es de DR Desenvolvimento Encontrar vulnerabilidades na autentica\u00e7\u00e3o ou autoriza\u00e7\u00e3o do servi\u00e7o Cen\u00e1rio (seguran\u00e7a) Desenvolvimento Comprovar interpreta\u00e7\u00e3o correta de RBAC e reivindica\u00e7\u00f5es no c\u00f3digo de autoriza\u00e7\u00e3o Cen\u00e1rio (seguran\u00e7a) Desenvolvimento Documentar e/ou impor uso v\u00e1lido da API Unit testing ; Testes funcionais; Consumer-driven Contract Testing Desenvolvimento Comprovar a corre\u00e7\u00e3o da implementa\u00e7\u00e3o antes de uma depend\u00eancia ou na aus\u00eancia de uma depend\u00eancia Unit testing (com mocks); Unit testing (com emuladores); Consumer-driven Contract Testing Desenvolvimento Garantir que a interface do usu\u00e1rio seja acess\u00edvel Accessibility Desenvolvimento Garantir que os usu\u00e1rios possam operar a interface UI testing (automated) (observa\u00e7\u00e3o de usabilidade humana) Desenvolvimento Prevenir regress\u00e3o na experi\u00eancia do usu\u00e1rio Automa\u00e7\u00e3o de UI; End-to-End testing Desenvolvimento Detectar e prevenir fen\u00f4menos de 'vizinho barulhento' Load testing Desenvolvimento Detectar quedas de disponibilidade Synthetic Transaction testing ; Sondas externas Desenvolvimento Prevenir regress\u00e3o em casos de uso / fluxos de trabalho de cen\u00e1rio 'composto' (por exemplo, um sistema de com\u00e9rcio eletr\u00f4nico pode ter muitas APIs que, usadas juntas em uma sequ\u00eancia, executam um cen\u00e1rio de \"compra e venda\") End-to-End testing ; Cen\u00e1rio Desenvolvimento; Opera\u00e7\u00f5es Prevenir regress\u00f5es em m\u00e9tricas de desempenho em tempo de execu\u00e7\u00e3o, por exemplo, lat\u00eancia / custo / consumo de recursos; quanto mais cedo, melhor An\u00e9is; Synthetic Transaction testing / Transa\u00e7\u00e3o; C\u00e3es de guarda de revers\u00e3o Desenvolvimento; Otimiza\u00e7\u00e3o Comparar qualquer m\u00e9trica dada entre 2 implementa\u00e7\u00f5es candidatas ou varia\u00e7\u00f5es na funcionalidade Testes A/B; Flighting Desenvolvimento; Staging Comprovar que o sistema de produ\u00e7\u00e3o de capacidade provisionada atende aos objetivos de confiabilidade, disponibilidade, consumo de recursos, desempenho Load testing (stress) ; Pico; Soak; Performance testing Desenvolvimento; Staging Entender as principais caracter\u00edsticas de desempenho da experi\u00eancia do usu\u00e1rio \u2013 lat\u00eancia, conversa\u00e7\u00e3o, resili\u00eancia a erros de rede Carga; Performance testing ; Cen\u00e1rio (particionamento de rede) Desenvolvimento; Staging; Opera\u00e7\u00e3o Descobrir pontos de fus\u00e3o (as cargas nas quais ocorre falha ou consumo m\u00e1ximo toler\u00e1vel de recursos) para cada componente individual na pilha Squeeze; Load testing (stress) Desenvolvimento; Staging; Opera\u00e7\u00e3o Descobrir o ponto de fus\u00e3o geral do sistema (as cargas nas quais o sistema de ponta a ponta falha) e qual componente \u00e9 o elo mais fraco em toda a pilha Squeeze; Load testing (stress) Desenvolvimento; Staging; Opera\u00e7\u00e3o Medir limites de capacidade para provisionamento dado para prever ou satisfazer necessidades futuras de provisionamento Squeeze; Load testing (stress) Desenvolvimento; Staging; Opera\u00e7\u00e3o Criar / exercitar manual de failover Simula\u00e7\u00f5es de Failover Desenvolvimento; Staging; Opera\u00e7\u00e3o Comprovar recupera\u00e7\u00e3o de desastres \u2013 perda de data center (o cen\u00e1rio do meteoro); medir MTTR Simula\u00e7\u00f5es de DR Desenvolvimento; Staging; Opera\u00e7\u00e3o Entender se os pain\u00e9is de observabilidade est\u00e3o corretos e se a telemetria est\u00e1 completa e fluindo Valida\u00e7\u00e3o de Rastreamento; Load testing (stress) ; Cen\u00e1rio; End-to-End testing Desenvolvimento; Staging; Opera\u00e7\u00e3o Medir impacto da sazonalidade do tr\u00e1fego Load testing Desenvolvimento; Staging; Opera\u00e7\u00e3o Comprovar que transa\u00e7\u00f5es e alertas notificam / tomam a\u00e7\u00f5es corretamente Synthetic Transaction testing (casos negativos); Load testing Desenvolvimento; Staging; Opera\u00e7\u00e3o; Otimiza\u00e7\u00e3o Entender a curva de escalabilidade, ou seja, como o sistema consome recursos com carga Load testing (stress) ; Performance testing Opera\u00e7\u00e3o; Otimiza\u00e7\u00e3o Descobrir o comportamento do sistema ao longo do tempo Soak Otimiza\u00e7\u00e3o Encontrar oportunidades de economia de custos Squeeze Staging; Opera\u00e7\u00e3o Medir impacto de failover / aumento de escala (reparticionamento, aumento de provisionamento) / redu\u00e7\u00e3o de escala Simula\u00e7\u00f5es de Failover; Simula\u00e7\u00f5es de Escala Staging; Opera\u00e7\u00e3o Criar/Exercitar manual para aumento/redu\u00e7\u00e3o de provisionamento Simula\u00e7\u00f5es de Escala Staging; Opera\u00e7\u00e3o Medir comportamento sob mudan\u00e7as r\u00e1pidas no tr\u00e1fego Spike Staging; Otimiza\u00e7\u00e3o Descobrir m\u00e9tricas de custo por unidade de volume de carga (quais fatores influenciam o custo em quais pontos de carga, por exemplo, custo por milh\u00e3o de usu\u00e1rios simult\u00e2neos) Carga (stress) Desenvolvimento; Opera\u00e7\u00e3o Descobrir pontos onde um sistema n\u00e3o \u00e9 resiliente a falhas imprevis\u00edveis, mas inevit\u00e1veis (queda de rede, falha de hardware, manuten\u00e7\u00e3o de host de VM, falhas de rack/switch, atos aleat\u00f3rios do Divino Mal\u00e9volo, flares solares, tubar\u00f5es que comem rel\u00e9s de cabos submarinos, radia\u00e7\u00e3o c\u00f3smica, quedas de energia, operadores de retroescavadeiras renegados, lobos mastigando caixas de jun\u00e7\u00e3o, ...) Caos Desenvolvimento Realizar testes unit\u00e1rios em conectores personalizados da plataforma Power Custom Connector Testing Se\u00e7\u00f5es dentro de Testes Consumer-driven contract (CDC) testing End-to-End testing Fault Injection testing Integration testing Performance testing Shadow testing Smoke testing Synthetic Transaction testing UI testing Unit testing Testes Espec\u00edficos de Tecnologia Usando o padr\u00e3o DevTest para construir cont\u00eaineres com AzDO Usando Azurite para executar testes de armazenamento de blob no pipeline","title":"Testando"},{"location":"automated-testing/#testando","text":"","title":"Testando"},{"location":"automated-testing/#mapa-de-resultados-para-tecnicas-de-teste","text":"A tabela abaixo mapeia resultados -- os resultados que voc\u00ea pode querer alcan\u00e7ar em seus esfor\u00e7os de valida\u00e7\u00e3o -- para uma ou mais t\u00e9cnicas que podem ser usadas para alcan\u00e7ar esse resultado. Quando estou trabalhando em... Quero obter este resultado... ...ent\u00e3o devo considerar Desenvolvimento Comprovar compatibilidade retroativa com chamadores e clientes existentes Shadow testing Desenvolvimento Garantir que a l\u00f3gica do programa esteja correta para uma variedade de entradas esperadas, principais, de borda e inesperadas Unit testing ; Testes funcionais; Consumer-driven Contract Testing ; Integration testing Desenvolvimento Prevenir regress\u00f5es na corre\u00e7\u00e3o l\u00f3gica; quanto mais cedo, melhor Unit testing ; Testes funcionais; Consumer-driven Contract Testing ; Integration testing ; An\u00e9is (cada um desses s\u00e3o escopos de cobertura em expans\u00e3o) Desenvolvimento Validar rapidamente a corre\u00e7\u00e3o principal de um ponto de funcionalidade (por exemplo, uma \u00fanica API), manualmente Testes de fuma\u00e7a manuais Ferramentas: postman, powershell, curl Desenvolvimento Validar intera\u00e7\u00f5es entre componentes isoladamente, garantindo que componentes consumidores e provedores sejam compat\u00edveis e estejam de acordo com um entendimento compartilhado documentado em um contrato Consumer-driven Contract Testing Desenvolvimento; Integration testing Validar que m\u00faltiplos componentes funcionem juntos em v\u00e1rias interfaces em uma cadeia de chamadas, incluindo saltos de rede Integration testing ; Testes de ponta a ponta ( End-to-End testing ); Testes de ponta a ponta segmentados ( End-to-End testing ) Desenvolvimento Comprovar recupera\u00e7\u00e3o de desastres \u2013 recupera\u00e7\u00e3o de corrup\u00e7\u00e3o de dados Simula\u00e7\u00f5es de DR Desenvolvimento Encontrar vulnerabilidades na autentica\u00e7\u00e3o ou autoriza\u00e7\u00e3o do servi\u00e7o Cen\u00e1rio (seguran\u00e7a) Desenvolvimento Comprovar interpreta\u00e7\u00e3o correta de RBAC e reivindica\u00e7\u00f5es no c\u00f3digo de autoriza\u00e7\u00e3o Cen\u00e1rio (seguran\u00e7a) Desenvolvimento Documentar e/ou impor uso v\u00e1lido da API Unit testing ; Testes funcionais; Consumer-driven Contract Testing Desenvolvimento Comprovar a corre\u00e7\u00e3o da implementa\u00e7\u00e3o antes de uma depend\u00eancia ou na aus\u00eancia de uma depend\u00eancia Unit testing (com mocks); Unit testing (com emuladores); Consumer-driven Contract Testing Desenvolvimento Garantir que a interface do usu\u00e1rio seja acess\u00edvel Accessibility Desenvolvimento Garantir que os usu\u00e1rios possam operar a interface UI testing (automated) (observa\u00e7\u00e3o de usabilidade humana) Desenvolvimento Prevenir regress\u00e3o na experi\u00eancia do usu\u00e1rio Automa\u00e7\u00e3o de UI; End-to-End testing Desenvolvimento Detectar e prevenir fen\u00f4menos de 'vizinho barulhento' Load testing Desenvolvimento Detectar quedas de disponibilidade Synthetic Transaction testing ; Sondas externas Desenvolvimento Prevenir regress\u00e3o em casos de uso / fluxos de trabalho de cen\u00e1rio 'composto' (por exemplo, um sistema de com\u00e9rcio eletr\u00f4nico pode ter muitas APIs que, usadas juntas em uma sequ\u00eancia, executam um cen\u00e1rio de \"compra e venda\") End-to-End testing ; Cen\u00e1rio Desenvolvimento; Opera\u00e7\u00f5es Prevenir regress\u00f5es em m\u00e9tricas de desempenho em tempo de execu\u00e7\u00e3o, por exemplo, lat\u00eancia / custo / consumo de recursos; quanto mais cedo, melhor An\u00e9is; Synthetic Transaction testing / Transa\u00e7\u00e3o; C\u00e3es de guarda de revers\u00e3o Desenvolvimento; Otimiza\u00e7\u00e3o Comparar qualquer m\u00e9trica dada entre 2 implementa\u00e7\u00f5es candidatas ou varia\u00e7\u00f5es na funcionalidade Testes A/B; Flighting Desenvolvimento; Staging Comprovar que o sistema de produ\u00e7\u00e3o de capacidade provisionada atende aos objetivos de confiabilidade, disponibilidade, consumo de recursos, desempenho Load testing (stress) ; Pico; Soak; Performance testing Desenvolvimento; Staging Entender as principais caracter\u00edsticas de desempenho da experi\u00eancia do usu\u00e1rio \u2013 lat\u00eancia, conversa\u00e7\u00e3o, resili\u00eancia a erros de rede Carga; Performance testing ; Cen\u00e1rio (particionamento de rede) Desenvolvimento; Staging; Opera\u00e7\u00e3o Descobrir pontos de fus\u00e3o (as cargas nas quais ocorre falha ou consumo m\u00e1ximo toler\u00e1vel de recursos) para cada componente individual na pilha Squeeze; Load testing (stress) Desenvolvimento; Staging; Opera\u00e7\u00e3o Descobrir o ponto de fus\u00e3o geral do sistema (as cargas nas quais o sistema de ponta a ponta falha) e qual componente \u00e9 o elo mais fraco em toda a pilha Squeeze; Load testing (stress) Desenvolvimento; Staging; Opera\u00e7\u00e3o Medir limites de capacidade para provisionamento dado para prever ou satisfazer necessidades futuras de provisionamento Squeeze; Load testing (stress) Desenvolvimento; Staging; Opera\u00e7\u00e3o Criar / exercitar manual de failover Simula\u00e7\u00f5es de Failover Desenvolvimento; Staging; Opera\u00e7\u00e3o Comprovar recupera\u00e7\u00e3o de desastres \u2013 perda de data center (o cen\u00e1rio do meteoro); medir MTTR Simula\u00e7\u00f5es de DR Desenvolvimento; Staging; Opera\u00e7\u00e3o Entender se os pain\u00e9is de observabilidade est\u00e3o corretos e se a telemetria est\u00e1 completa e fluindo Valida\u00e7\u00e3o de Rastreamento; Load testing (stress) ; Cen\u00e1rio; End-to-End testing Desenvolvimento; Staging; Opera\u00e7\u00e3o Medir impacto da sazonalidade do tr\u00e1fego Load testing Desenvolvimento; Staging; Opera\u00e7\u00e3o Comprovar que transa\u00e7\u00f5es e alertas notificam / tomam a\u00e7\u00f5es corretamente Synthetic Transaction testing (casos negativos); Load testing Desenvolvimento; Staging; Opera\u00e7\u00e3o; Otimiza\u00e7\u00e3o Entender a curva de escalabilidade, ou seja, como o sistema consome recursos com carga Load testing (stress) ; Performance testing Opera\u00e7\u00e3o; Otimiza\u00e7\u00e3o Descobrir o comportamento do sistema ao longo do tempo Soak Otimiza\u00e7\u00e3o Encontrar oportunidades de economia de custos Squeeze Staging; Opera\u00e7\u00e3o Medir impacto de failover / aumento de escala (reparticionamento, aumento de provisionamento) / redu\u00e7\u00e3o de escala Simula\u00e7\u00f5es de Failover; Simula\u00e7\u00f5es de Escala Staging; Opera\u00e7\u00e3o Criar/Exercitar manual para aumento/redu\u00e7\u00e3o de provisionamento Simula\u00e7\u00f5es de Escala Staging; Opera\u00e7\u00e3o Medir comportamento sob mudan\u00e7as r\u00e1pidas no tr\u00e1fego Spike Staging; Otimiza\u00e7\u00e3o Descobrir m\u00e9tricas de custo por unidade de volume de carga (quais fatores influenciam o custo em quais pontos de carga, por exemplo, custo por milh\u00e3o de usu\u00e1rios simult\u00e2neos) Carga (stress) Desenvolvimento; Opera\u00e7\u00e3o Descobrir pontos onde um sistema n\u00e3o \u00e9 resiliente a falhas imprevis\u00edveis, mas inevit\u00e1veis (queda de rede, falha de hardware, manuten\u00e7\u00e3o de host de VM, falhas de rack/switch, atos aleat\u00f3rios do Divino Mal\u00e9volo, flares solares, tubar\u00f5es que comem rel\u00e9s de cabos submarinos, radia\u00e7\u00e3o c\u00f3smica, quedas de energia, operadores de retroescavadeiras renegados, lobos mastigando caixas de jun\u00e7\u00e3o, ...) Caos Desenvolvimento Realizar testes unit\u00e1rios em conectores personalizados da plataforma Power Custom Connector Testing","title":"Mapa de Resultados para T\u00e9cnicas de Teste"},{"location":"automated-testing/#secoes-dentro-de-testes","text":"Consumer-driven contract (CDC) testing End-to-End testing Fault Injection testing Integration testing Performance testing Shadow testing Smoke testing Synthetic Transaction testing UI testing Unit testing","title":"Se\u00e7\u00f5es dentro de Testes"},{"location":"automated-testing/#testes-especificos-de-tecnologia","text":"Usando o padr\u00e3o DevTest para construir cont\u00eaineres com AzDO Usando Azurite para executar testes de armazenamento de blob no pipeline","title":"Testes Espec\u00edficos de Tecnologia"},{"location":"automated-testing/cdc-testing/","text":"Teste de Contrato Orientado pelo Consumidor (CDC) O Teste de Contrato Orientado pelo Consumidor (ou CDC, na sigla em ingl\u00eas) \u00e9 uma metodologia de teste de software usada para testar componentes de um sistema isoladamente, garantindo que os componentes provedores sejam compat\u00edveis com as expectativas que os componentes consumidores t\u00eam deles. Por que Teste de Contrato Orientado pelo Consumidor O CDC tenta superar as v\u00e1rias desvantagens dolorosas dos testes E2E automatizados com componentes interagindo juntos: Testes E2E s\u00e3o lentos Testes E2E quebram facilmente Testes E2E s\u00e3o caros e dif\u00edceis de manter Testes E2E de sistemas maiores podem ser dif\u00edceis ou imposs\u00edveis de serem executados fora de um ambiente de teste dedicado Embora as melhores pr\u00e1ticas de teste sugiram escrever apenas alguns testes E2E em compara\u00e7\u00e3o com os testes de integra\u00e7\u00e3o e unit\u00e1rios mais baratos, r\u00e1pidos e est\u00e1veis, como ilustrado na pir\u00e2mide de testes abaixo, a experi\u00eancia mostra que muitas equipes acabam escrevendo muitos testes E2E . Uma raz\u00e3o para isso \u00e9 que os testes E2E d\u00e3o aos desenvolvedores a maior confian\u00e7a para lan\u00e7ar, pois est\u00e3o testando o \"sistema real\". O CDC aborda essas quest\u00f5es testando intera\u00e7\u00f5es entre componentes isoladamente usando mocks que est\u00e3o de acordo com um entendimento compartilhado documentado em um \"contrato\". Contratos s\u00e3o acordados entre consumidor e provedor e s\u00e3o regularmente verificados contra uma inst\u00e2ncia real do componente provedor. Isso efetivamente divide um sistema maior em partes menores que podem ser testadas individualmente isoladas umas das outras, levando a testes mais simples, r\u00e1pidos e est\u00e1veis que tamb\u00e9m d\u00e3o confian\u00e7a para lan\u00e7ar. Alguns testes E2E ainda s\u00e3o necess\u00e1rios para verificar o sistema como um todo quando implantado no ambiente real, mas a maioria das intera\u00e7\u00f5es funcionais entre componentes pode ser coberta com testes CDC. O teste CDC foi inicialmente desenvolvido para testar APIs RESTful, mas o padr\u00e3o se aplica a todos os sistemas consumidor-provedor e existem ferramentas para outros protocolos de mensagens al\u00e9m do HTTP. Blocos de Design de Teste de Contrato Orientado pelo Consumidor Em uma abordagem orientada pelo consumidor , o consumidor direciona as mudan\u00e7as nos contratos entre um consumidor (o cliente) e um provedor (o servidor). Isso pode parecer contraintuitivo, mas ajuda os provedores a criar APIs que se ajustem \u00e0s necessidades reais dos consumidores, em vez de tentar adivinh\u00e1-las antecipadamente. A seguir, descrevemos os blocos de constru\u00e7\u00e3o do CDC ordenados por sua ocorr\u00eancia no ciclo de desenvolvimento. Testes do Consumidor com Mock do Provedor Os consumidores come\u00e7am criando testes de integra\u00e7\u00e3o contra um mock do provedor e executando-os como parte de seu pipeline de CI. Respostas esperadas s\u00e3o definidas no mock do provedor para solicita\u00e7\u00f5es disparadas a partir dos testes. Por meio disso, o consumidor essencialmente define o contrato que espera que o provedor cumpra. Contrato Contratos s\u00e3o gerados a partir das expectativas definidas no mock do provedor como resultado de uma execu\u00e7\u00e3o bem-sucedida do teste. Frameworks de CDC como o Pact fornecem uma especifica\u00e7\u00e3o para contratos no formato json, consistindo na lista de solicita\u00e7\u00f5es/respostas geradas a partir dos testes do consumidor, al\u00e9m de alguns metadados adicionais. Contratos n\u00e3o s\u00e3o um substituto para uma discuss\u00e3o entre a equipe do consumidor e do provedor. Este \u00e9 o momento em que essa discuss\u00e3o deve ocorrer (se j\u00e1 n\u00e3o tiver ocorrido antes). Os testes do consumidor e o contrato gerado s\u00e3o refinados com o feedback e a coopera\u00e7\u00e3o da equipe do provedor. Por \u00faltimo, o contrato finalizado \u00e9 versionado e armazenado em um local central acess\u00edvel por ambos, consumidor e provedor. Contratos complementam documentos de especifica\u00e7\u00e3o de API como o OpenAPI. Especifica\u00e7\u00f5es de API descrevem a estrutura e o formato da API. Um contrato, por outro lado, especifica que para uma determinada solicita\u00e7\u00e3o, uma determinada resposta \u00e9 esperada. Um documento de especifica\u00e7\u00f5es de API \u00e9 \u00fatil para escrever um contrato de API e pode ser usado para validar que o contrato est\u00e1 em conformidade com a especifica\u00e7\u00e3o da API. Verifica\u00e7\u00e3o de Contrato do Provedor Do lado do provedor, testes tamb\u00e9m s\u00e3o executados como parte de um pipeline separado que verifica contratos contra respostas reais do provedor. A verifica\u00e7\u00e3o do contrato falha se as respostas reais diferirem das respostas esperadas, conforme especificado no contrato. A causa disso pode ser: Expectativas inv\u00e1lidas do lado do consumidor, levando \u00e0 incompatibilidade com a implementa\u00e7\u00e3o atual do provedor. Implementa\u00e7\u00e3o defeituosa do provedor devido a alguma funcionalidade ausente ou a uma regress\u00e3o. De qualquer forma, gra\u00e7as ao CDC, \u00e9 f\u00e1cil identificar problemas de integra\u00e7\u00e3o at\u00e9 o consumidor/provedor da intera\u00e7\u00e3o afetada. Isso \u00e9 uma grande vantagem em compara\u00e7\u00e3o com a dor de depura\u00e7\u00e3o que isso poderia ter sido com uma abordagem de teste E2E. Frameworks e Ferramentas de Teste CDC Pact \u00e9 uma implementa\u00e7\u00e3o de teste CDC que permite a simula\u00e7\u00e3o de respostas no c\u00f3digo-base do consumidor e a verifica\u00e7\u00e3o das intera\u00e7\u00f5es no c\u00f3digo-base do provedor, enquanto define uma especifica\u00e7\u00e3o para contratos . Foi originalmente escrito em Ruby, mas tem wrappers dispon\u00edveis para v\u00e1rias linguagens. Pact \u00e9 o padr\u00e3o de facto a ser usado ao trabalhar com CDC. Spring Cloud Contract \u00e9 uma implementa\u00e7\u00e3o de teste CDC da Spring e oferece f\u00e1cil integra\u00e7\u00e3o no ecossistema Spring. Suporte para provedores e consumidores n\u00e3o-Spring e n\u00e3o-JVM tamb\u00e9m existe. Conclus\u00e3o O CDC tem v\u00e1rios benef\u00edcios que o tornam uma abordagem a ser considerada ao lidar com sistemas compostos por m\u00faltiplos componentes interagindo juntos. Os esfor\u00e7os de manuten\u00e7\u00e3o podem ser reduzidos testando intera\u00e7\u00f5es entre consumidor e provedor isoladamente, sem a necessidade de um ambiente integrado complexo, especialmente \u00e0 medida que as intera\u00e7\u00f5es entre componentes aumentam em n\u00famero e se tornam mais complexas. Al\u00e9m disso, uma colabora\u00e7\u00e3o pr\u00f3xima entre as equipes de consumidores e provedores \u00e9 fortemente incentivada atrav\u00e9s do processo de desenvolvimento do CDC, o que pode trazer muitos outros benef\u00edcios. Contratos oferecem uma forma formal de documentar o entendimento compartilhado de como os componentes interagem entre si e servem como base para a comunica\u00e7\u00e3o entre as equipes. De certa forma, o reposit\u00f3rio de contratos serve como uma documenta\u00e7\u00e3o ao vivo de todas as intera\u00e7\u00f5es entre consumidor e provedor de um sistema. O CDC tem algumas desvantagens tamb\u00e9m. Uma camada extra de teste \u00e9 adicionada, exigindo um investimento adequado em educa\u00e7\u00e3o para que os membros da equipe entendam e usem o CDC corretamente. Al\u00e9m disso, o escopo do teste CDC deve ser considerado cuidadosamente para evitar confundir o CDC com outras camadas de teste funcional de n\u00edvel superior. Testes de contrato n\u00e3o s\u00e3o o lugar para verificar a l\u00f3gica de neg\u00f3cios interna e a corre\u00e7\u00e3o do consumidor. Recursos Pir\u00e2mide de teste do blog de Kent C. Dodd Pact , uma ferramenta de teste de contrato orientada pelo consumidor baseada em c\u00f3digo com suporte para v\u00e1rias linguagens de programa\u00e7\u00e3o diferentes Contratos orientados pelo consumidor de Ian Robinson Teste de contrato de Martin Fowler Um exemplo simples de uso do teste de contrato orientado pelo consumidor Pact em uma aplica\u00e7\u00e3o cliente-servidor Java Workshop Pact dotnet","title":"Teste de Contrato Orientado pelo Consumidor (CDC)"},{"location":"automated-testing/cdc-testing/#teste-de-contrato-orientado-pelo-consumidor-cdc","text":"O Teste de Contrato Orientado pelo Consumidor (ou CDC, na sigla em ingl\u00eas) \u00e9 uma metodologia de teste de software usada para testar componentes de um sistema isoladamente, garantindo que os componentes provedores sejam compat\u00edveis com as expectativas que os componentes consumidores t\u00eam deles.","title":"Teste de Contrato Orientado pelo Consumidor (CDC)"},{"location":"automated-testing/cdc-testing/#por-que-teste-de-contrato-orientado-pelo-consumidor","text":"O CDC tenta superar as v\u00e1rias desvantagens dolorosas dos testes E2E automatizados com componentes interagindo juntos: Testes E2E s\u00e3o lentos Testes E2E quebram facilmente Testes E2E s\u00e3o caros e dif\u00edceis de manter Testes E2E de sistemas maiores podem ser dif\u00edceis ou imposs\u00edveis de serem executados fora de um ambiente de teste dedicado Embora as melhores pr\u00e1ticas de teste sugiram escrever apenas alguns testes E2E em compara\u00e7\u00e3o com os testes de integra\u00e7\u00e3o e unit\u00e1rios mais baratos, r\u00e1pidos e est\u00e1veis, como ilustrado na pir\u00e2mide de testes abaixo, a experi\u00eancia mostra que muitas equipes acabam escrevendo muitos testes E2E . Uma raz\u00e3o para isso \u00e9 que os testes E2E d\u00e3o aos desenvolvedores a maior confian\u00e7a para lan\u00e7ar, pois est\u00e3o testando o \"sistema real\". O CDC aborda essas quest\u00f5es testando intera\u00e7\u00f5es entre componentes isoladamente usando mocks que est\u00e3o de acordo com um entendimento compartilhado documentado em um \"contrato\". Contratos s\u00e3o acordados entre consumidor e provedor e s\u00e3o regularmente verificados contra uma inst\u00e2ncia real do componente provedor. Isso efetivamente divide um sistema maior em partes menores que podem ser testadas individualmente isoladas umas das outras, levando a testes mais simples, r\u00e1pidos e est\u00e1veis que tamb\u00e9m d\u00e3o confian\u00e7a para lan\u00e7ar. Alguns testes E2E ainda s\u00e3o necess\u00e1rios para verificar o sistema como um todo quando implantado no ambiente real, mas a maioria das intera\u00e7\u00f5es funcionais entre componentes pode ser coberta com testes CDC. O teste CDC foi inicialmente desenvolvido para testar APIs RESTful, mas o padr\u00e3o se aplica a todos os sistemas consumidor-provedor e existem ferramentas para outros protocolos de mensagens al\u00e9m do HTTP.","title":"Por que Teste de Contrato Orientado pelo Consumidor"},{"location":"automated-testing/cdc-testing/#blocos-de-design-de-teste-de-contrato-orientado-pelo-consumidor","text":"Em uma abordagem orientada pelo consumidor , o consumidor direciona as mudan\u00e7as nos contratos entre um consumidor (o cliente) e um provedor (o servidor). Isso pode parecer contraintuitivo, mas ajuda os provedores a criar APIs que se ajustem \u00e0s necessidades reais dos consumidores, em vez de tentar adivinh\u00e1-las antecipadamente. A seguir, descrevemos os blocos de constru\u00e7\u00e3o do CDC ordenados por sua ocorr\u00eancia no ciclo de desenvolvimento.","title":"Blocos de Design de Teste de Contrato Orientado pelo Consumidor"},{"location":"automated-testing/cdc-testing/#testes-do-consumidor-com-mock-do-provedor","text":"Os consumidores come\u00e7am criando testes de integra\u00e7\u00e3o contra um mock do provedor e executando-os como parte de seu pipeline de CI. Respostas esperadas s\u00e3o definidas no mock do provedor para solicita\u00e7\u00f5es disparadas a partir dos testes. Por meio disso, o consumidor essencialmente define o contrato que espera que o provedor cumpra.","title":"Testes do Consumidor com Mock do Provedor"},{"location":"automated-testing/cdc-testing/#contrato","text":"Contratos s\u00e3o gerados a partir das expectativas definidas no mock do provedor como resultado de uma execu\u00e7\u00e3o bem-sucedida do teste. Frameworks de CDC como o Pact fornecem uma especifica\u00e7\u00e3o para contratos no formato json, consistindo na lista de solicita\u00e7\u00f5es/respostas geradas a partir dos testes do consumidor, al\u00e9m de alguns metadados adicionais. Contratos n\u00e3o s\u00e3o um substituto para uma discuss\u00e3o entre a equipe do consumidor e do provedor. Este \u00e9 o momento em que essa discuss\u00e3o deve ocorrer (se j\u00e1 n\u00e3o tiver ocorrido antes). Os testes do consumidor e o contrato gerado s\u00e3o refinados com o feedback e a coopera\u00e7\u00e3o da equipe do provedor. Por \u00faltimo, o contrato finalizado \u00e9 versionado e armazenado em um local central acess\u00edvel por ambos, consumidor e provedor. Contratos complementam documentos de especifica\u00e7\u00e3o de API como o OpenAPI. Especifica\u00e7\u00f5es de API descrevem a estrutura e o formato da API. Um contrato, por outro lado, especifica que para uma determinada solicita\u00e7\u00e3o, uma determinada resposta \u00e9 esperada. Um documento de especifica\u00e7\u00f5es de API \u00e9 \u00fatil para escrever um contrato de API e pode ser usado para validar que o contrato est\u00e1 em conformidade com a especifica\u00e7\u00e3o da API.","title":"Contrato"},{"location":"automated-testing/cdc-testing/#verificacao-de-contrato-do-provedor","text":"Do lado do provedor, testes tamb\u00e9m s\u00e3o executados como parte de um pipeline separado que verifica contratos contra respostas reais do provedor. A verifica\u00e7\u00e3o do contrato falha se as respostas reais diferirem das respostas esperadas, conforme especificado no contrato. A causa disso pode ser: Expectativas inv\u00e1lidas do lado do consumidor, levando \u00e0 incompatibilidade com a implementa\u00e7\u00e3o atual do provedor. Implementa\u00e7\u00e3o defeituosa do provedor devido a alguma funcionalidade ausente ou a uma regress\u00e3o. De qualquer forma, gra\u00e7as ao CDC, \u00e9 f\u00e1cil identificar problemas de integra\u00e7\u00e3o at\u00e9 o consumidor/provedor da intera\u00e7\u00e3o afetada. Isso \u00e9 uma grande vantagem em compara\u00e7\u00e3o com a dor de depura\u00e7\u00e3o que isso poderia ter sido com uma abordagem de teste E2E.","title":"Verifica\u00e7\u00e3o de Contrato do Provedor"},{"location":"automated-testing/cdc-testing/#frameworks-e-ferramentas-de-teste-cdc","text":"Pact \u00e9 uma implementa\u00e7\u00e3o de teste CDC que permite a simula\u00e7\u00e3o de respostas no c\u00f3digo-base do consumidor e a verifica\u00e7\u00e3o das intera\u00e7\u00f5es no c\u00f3digo-base do provedor, enquanto define uma especifica\u00e7\u00e3o para contratos . Foi originalmente escrito em Ruby, mas tem wrappers dispon\u00edveis para v\u00e1rias linguagens. Pact \u00e9 o padr\u00e3o de facto a ser usado ao trabalhar com CDC. Spring Cloud Contract \u00e9 uma implementa\u00e7\u00e3o de teste CDC da Spring e oferece f\u00e1cil integra\u00e7\u00e3o no ecossistema Spring. Suporte para provedores e consumidores n\u00e3o-Spring e n\u00e3o-JVM tamb\u00e9m existe.","title":"Frameworks e Ferramentas de Teste CDC"},{"location":"automated-testing/cdc-testing/#conclusao","text":"O CDC tem v\u00e1rios benef\u00edcios que o tornam uma abordagem a ser considerada ao lidar com sistemas compostos por m\u00faltiplos componentes interagindo juntos. Os esfor\u00e7os de manuten\u00e7\u00e3o podem ser reduzidos testando intera\u00e7\u00f5es entre consumidor e provedor isoladamente, sem a necessidade de um ambiente integrado complexo, especialmente \u00e0 medida que as intera\u00e7\u00f5es entre componentes aumentam em n\u00famero e se tornam mais complexas. Al\u00e9m disso, uma colabora\u00e7\u00e3o pr\u00f3xima entre as equipes de consumidores e provedores \u00e9 fortemente incentivada atrav\u00e9s do processo de desenvolvimento do CDC, o que pode trazer muitos outros benef\u00edcios. Contratos oferecem uma forma formal de documentar o entendimento compartilhado de como os componentes interagem entre si e servem como base para a comunica\u00e7\u00e3o entre as equipes. De certa forma, o reposit\u00f3rio de contratos serve como uma documenta\u00e7\u00e3o ao vivo de todas as intera\u00e7\u00f5es entre consumidor e provedor de um sistema. O CDC tem algumas desvantagens tamb\u00e9m. Uma camada extra de teste \u00e9 adicionada, exigindo um investimento adequado em educa\u00e7\u00e3o para que os membros da equipe entendam e usem o CDC corretamente. Al\u00e9m disso, o escopo do teste CDC deve ser considerado cuidadosamente para evitar confundir o CDC com outras camadas de teste funcional de n\u00edvel superior. Testes de contrato n\u00e3o s\u00e3o o lugar para verificar a l\u00f3gica de neg\u00f3cios interna e a corre\u00e7\u00e3o do consumidor.","title":"Conclus\u00e3o"},{"location":"automated-testing/cdc-testing/#recursos","text":"Pir\u00e2mide de teste do blog de Kent C. Dodd Pact , uma ferramenta de teste de contrato orientada pelo consumidor baseada em c\u00f3digo com suporte para v\u00e1rias linguagens de programa\u00e7\u00e3o diferentes Contratos orientados pelo consumidor de Ian Robinson Teste de contrato de Martin Fowler Um exemplo simples de uso do teste de contrato orientado pelo consumidor Pact em uma aplica\u00e7\u00e3o cliente-servidor Java Workshop Pact dotnet","title":"Recursos"},{"location":"automated-testing/e2e-testing/","text":"Teste de Ponta a Ponta (E2E) O teste de ponta a ponta (E2E) \u00e9 uma metodologia de teste de software para verificar um fluxo funcional e de dados de uma aplica\u00e7\u00e3o composta por v\u00e1rios subsistemas trabalhando juntos do in\u00edcio ao fim. Muitas vezes, esses sistemas s\u00e3o desenvolvidos em diferentes tecnologias por diferentes equipes ou organiza\u00e7\u00f5es. Finalmente, eles se unem para formar uma aplica\u00e7\u00e3o de neg\u00f3cios funcional. Portanto, testar um \u00fanico sistema n\u00e3o seria suficiente. Assim, o teste de ponta a ponta verifica a aplica\u00e7\u00e3o do in\u00edcio ao fim, colocando todos os seus componentes juntos. Por que Teste E2E [O Porqu\u00ea] Em muitos cen\u00e1rios de aplicativos de software comerciais, um sistema de software moderno consiste em sua interconex\u00e3o com v\u00e1rios subsistemas. Esses subsistemas podem estar dentro da mesma organiza\u00e7\u00e3o ou podem ser componentes de diferentes organiza\u00e7\u00f5es. Al\u00e9m disso, esses subsistemas podem ter ciclos de lan\u00e7amento de vida \u00fatil semelhantes ou diferentes do sistema atual. Como resultado, se houver qualquer falha ou defeito em qualquer subsistema, isso pode afetar adversamente todo o sistema de software, levando ao seu colapso. A ilustra\u00e7\u00e3o acima \u00e9 uma pir\u00e2mide de teste do blog de Kent C. Dodd , que \u00e9 uma combina\u00e7\u00e3o das pir\u00e2mides do blog de Martin Fowler e do Google Testing Blog . A maioria dos seus testes est\u00e1 na parte inferior da pir\u00e2mide. \u00c0 medida que voc\u00ea sobe na pir\u00e2mide, o n\u00famero de testes diminui. Al\u00e9m disso, subindo na pir\u00e2mide, os testes ficam mais lentos e mais caros para escrever, executar e manter. Cada tipo de teste varia para o seu prop\u00f3sito, aplica\u00e7\u00e3o e as \u00e1reas que se destina a cobrir. Para mais informa\u00e7\u00f5es sobre a an\u00e1lise comparativa de diferentes tipos de testes, consulte este documento ## Unidade vs Integra\u00e7\u00e3o vs Sistema vs Teste E2E . Blocos de Design de Teste E2E [O Qu\u00ea] Vamos examinar todas as 3 categorias uma por uma: Fun\u00e7\u00f5es do Usu\u00e1rio As seguintes a\u00e7\u00f5es devem ser realizadas como parte da constru\u00e7\u00e3o de fun\u00e7\u00f5es do usu\u00e1rio: Liste as fun\u00e7\u00f5es iniciadas pelo usu\u00e1rio dos sistemas de software e seus subsistemas interconectados. Para qualquer fun\u00e7\u00e3o, acompanhe as a\u00e7\u00f5es realizadas, bem como os dados de entrada e sa\u00edda. Encontre as rela\u00e7\u00f5es, se houver, entre diferentes fun\u00e7\u00f5es do usu\u00e1rio. Descubra a natureza das diferentes fun\u00e7\u00f5es do usu\u00e1rio, ou seja, se s\u00e3o independentes ou reutiliz\u00e1veis. Condi\u00e7\u00f5es As seguintes atividades devem ser realizadas como parte da constru\u00e7\u00e3o de condi\u00e7\u00f5es com base nas fun\u00e7\u00f5es do usu\u00e1rio: Para cada uma das fun\u00e7\u00f5es do usu\u00e1rio, um conjunto de condi\u00e7\u00f5es deve ser preparado. O tempo, as condi\u00e7\u00f5es de dados e outros fatores que afetam as fun\u00e7\u00f5es do usu\u00e1rio podem ser considerados como par\u00e2metros. Casos de Teste Os seguintes fatores devem ser considerados para a constru\u00e7\u00e3o de casos de teste: Para cada cen\u00e1rio, um ou mais casos de teste devem ser criados para testar cada funcionalidade das fun\u00e7\u00f5es do usu\u00e1rio. Se poss\u00edvel, esses casos de teste devem ser automatizados por meio dos processos padr\u00e3o de pipeline de CI/CD com o acompanhamento de cada build bem-sucedido e falho no AzDO. Cada condi\u00e7\u00e3o deve ser listada como um caso de teste separado. Aplicando o Teste E2E [O Como] Como qualquer outro teste, o teste E2E tamb\u00e9m passa por fases formais de planejamento, execu\u00e7\u00e3o de teste e encerramento. O teste E2E \u00e9 feito com as seguintes etapas: Planejamento An\u00e1lise de requisitos de neg\u00f3cios e funcionais Desenvolvimento do plano de teste Desenvolvimento do caso de teste Configura\u00e7\u00e3o do ambiente de teste semelhante \u00e0 produ\u00e7\u00e3o Configura\u00e7\u00e3o dos dados de teste Decidir crit\u00e9rios de sa\u00edda Escolher os m\u00e9todos de teste mais aplic\u00e1veis ao seu sistema. Para a defini\u00e7\u00e3o dos v\u00e1rios m\u00e9todos de teste, consulte o documento M\u00e9todos de Teste . Pr\u00e9-requisito O teste do sistema deve estar completo para todos os sistemas participantes. Todos os subsistemas devem ser combinados para funcionar como uma aplica\u00e7\u00e3o completa. O ambiente de teste semelhante \u00e0 produ\u00e7\u00e3o deve estar pronto. Execu\u00e7\u00e3o do Teste Execute os casos de teste Registre os resultados do teste e decida sobre a aprova\u00e7\u00e3o e falha Relate os bugs na ferramenta de relat\u00f3rio de bugs Re-verifique as corre\u00e7\u00f5es de bugs Encerramento do Teste Prepara\u00e7\u00e3o do relat\u00f3rio de teste Avalia\u00e7\u00e3o dos crit\u00e9rios de sa\u00edda Encerramento da fase de teste M\u00e9tricas de Teste Rastrear as m\u00e9tricas de qualidade d\u00e1 uma vis\u00e3o sobre o status atual do teste. Algumas m\u00e9tricas comuns de teste E2E s\u00e3o: Status de prepara\u00e7\u00e3o do caso de teste : N\u00famero de casos de teste prontos versus o n\u00famero total de casos de teste. Progresso frequente do teste : N\u00famero de casos de teste executados de maneira frequente e consistente, por exemplo, semanalmente, versus um n\u00famero-alvo de casos de teste no mesmo per\u00edodo de tempo. Status dos defeitos : Esta m\u00e9trica representa o status dos defeitos encontrados durante o teste. Os defeitos devem ser registrados na ferramenta de rastreamento de defeitos (por exemplo, backlog do AzDO) e resolvidos de acordo com sua gravidade e prioridade. Portanto, a porcentagem de defeitos abertos e fechados de acordo com sua gravidade e prioridade deve ser calculada para rastrear esta m\u00e9trica. A consulta do painel AzDO pode ser usada para rastrear essa m\u00e9trica. Disponibilidade do ambiente de teste : Esta m\u00e9trica rastreia a dura\u00e7\u00e3o do ambiente de teste usado para o teste de ponta a ponta versus sua dura\u00e7\u00e3o de aloca\u00e7\u00e3o programada. Frameworks e Ferramentas de Teste E2E 1. Gauge Framework Gauge \u00e9 um framework gratuito e de c\u00f3digo aberto para escrever e executar testes E2E. Algumas caracter\u00edsticas-chave do Gauge que o tornam \u00fanico incluem: Sintaxe simples, flex\u00edvel e rica baseada em Markdown. Suporte consistente entre plataformas/linguagens para escrever c\u00f3digo de teste. Uma arquitetura modular com suporte a plugins. Suporta execu\u00e7\u00e3o orientada a dados e fontes de dados externas. Ajuda voc\u00ea a criar su\u00edtes de teste sustent\u00e1veis. Suporta Visual Studio Code, Intellij IDEA, IDE Support. Suporta relat\u00f3rios em html, json e XML. Site do Gauge Framework 2. Robot Framework Robot Framework \u00e9 um framework de automa\u00e7\u00e3o de c\u00f3digo aberto gen\u00e9rico. O framework tem uma sintaxe f\u00e1cil, utilizando palavras-chave leg\u00edveis por humanos. Suas capacidades podem ser estendidas por bibliotecas implementadas com Python ou Java. Robot compartilha muitos dos mesmos \"pr\u00f3s\" que o Gauge, exceto as ferramentas de desenvolvimento e a sintaxe. Em nosso uso, descobrimos que o Intellisense do VS Code oferecido com o Gauge era muito mais est\u00e1vel do que as ofertas para o Robot. Tamb\u00e9m achamos a sintaxe menos leg\u00edvel do que o que o Gauge oferecia. Embora ambos os frameworks permitam defini\u00e7\u00f5es de casos de teste baseadas em marca\u00e7\u00e3o, a sintaxe do Gauge l\u00ea muito mais como uma frase em portugu\u00eas do que o Robot. Finalmente, o Intellisense est\u00e1 incorporado nos arquivos de marca\u00e7\u00e3o para casos de teste do Gauge, o que criar\u00e1 um stub de fun\u00e7\u00e3o para a defini\u00e7\u00e3o de teste real se o desenvolvedor permitir. O mesmo n\u00e3o pode ser dito do Robot Framework. Site do Robot Framework 3. TestCraft TestCraft \u00e9 uma plataforma de automa\u00e7\u00e3o de teste Selenium sem c\u00f3digo. Sua tecnologia revolucion\u00e1ria de IA e modelagem visual \u00fanica permitem uma cria\u00e7\u00e3o e execu\u00e7\u00e3o de teste mais r\u00e1pida, eliminando a sobrecarga de manuten\u00e7\u00e3o de teste. Os testadores criam cen\u00e1rios de teste totalmente automatizados sem codifica\u00e7\u00e3o. Os clientes encontram bugs mais rapidamente, lan\u00e7am com mais frequ\u00eancia, integram-se com a abordagem CI/CD e melhoram a qualidade geral de seus produtos digitais. Isso cria uma experi\u00eancia completa de teste de ponta a ponta. Site do Perfecto (TestCraft) ou obtenha-o no Visual Studio Marketplace 4. Ranorex Studio Ranorex Studio \u00e9 uma ferramenta completa de automa\u00e7\u00e3o de teste de ponta a ponta para aplica\u00e7\u00f5es desktop, web e m\u00f3veis. Crie testes confi\u00e1veis rapidamente sem qualquer codifica\u00e7\u00e3o ou usando o IDE completo. Use arquivos CSV ou Excel externos ou um banco de dados SQL como entradas para seus testes. Execute testes em paralelo ou em uma grade Selenium com o Selenium WebDriver integrado. O Ranorex Studio se integra ao seu processo de CI/CD para encurtar seus ciclos de lan\u00e7amento sem sacrificar a qualidade. Os testes do Ranorex Studio tamb\u00e9m se integram ao Azure DevOps (AzDO), que podem ser executados como parte de um pipeline de build no AzDO. Site do Ranorex Studio 5. Katalon Studio Katalon Studio \u00e9 uma excelente solu\u00e7\u00e3o de automa\u00e7\u00e3o de ponta a ponta para testes web, API, m\u00f3veis e desktop com suporte DevOps. Com o Katalon Studio, o teste automatizado pode ser facilmente integrado a qualquer pipeline de CI/CD para lan\u00e7ar produtos mais rapidamente, garantindo alta qualidade. O Katalon Studio personaliza para usu\u00e1rios de iniciantes a especialistas. Fun\u00e7\u00f5es robustas como Espionagem, Grava\u00e7\u00e3o, Interface de editor duplo e Palavras-chave personalizadas tornam poss\u00edvel a configura\u00e7\u00e3o, cria\u00e7\u00e3o e manuten\u00e7\u00e3o de testes para os usu\u00e1rios. Constru\u00eddo em cima do Selenium e Appium, o Katalon Studio ajuda a padronizar seus testes de ponta a ponta. Ele tamb\u00e9m est\u00e1 em conformidade com os frameworks mais populares para trabalhar de forma integrada com outras ferramentas no ecossistema de teste automatizado. O Katalon \u00e9 endossado pela Gartner, profissionais de TI e uma grande comunidade de teste. Nota: No momento da escrita deste texto, a extens\u00e3o do Katalon Studio para AzDO N\u00c3O estava dispon\u00edvel para Linux. Site do Katalon Studio ou leia sobre sua integra\u00e7\u00e3o com o AzDO 6. BugBug.io BugBug \u00e9 uma maneira f\u00e1cil de automatizar testes para aplica\u00e7\u00f5es web. A ferramenta foca na simplicidade, mas ainda permite que voc\u00ea cubra todos os casos de teste essenciais sem codifica\u00e7\u00e3o. \u00c9 uma solu\u00e7\u00e3o completa - voc\u00ea pode criar testes facilmente e usar a nuvem integrada para execut\u00e1-los de acordo com um cronograma ou a partir do seu CI/CD, sem altera\u00e7\u00f5es na sua pr\u00f3pria infraestrutura. BugBug \u00e9 uma alternativa interessante ao Selenium porque \u00e9 realmente uma tecnologia completamente diferente. Ele \u00e9 baseado em uma extens\u00e3o do Chrome que permite ao BugBug gravar e executar testes mais rapidamente do que os frameworks da velha escola. A maior vantagem do BugBug \u00e9 sua facilidade de uso. A maioria dos testes criados com o BugBug simplesmente funciona imediatamente. Isso torna mais f\u00e1cil para pessoas n\u00e3o t\u00e9cnicas manterem os testes - com o BugBug, voc\u00ea pode economizar dinheiro na contrata\u00e7\u00e3o de um engenheiro de QA. Site do BugBug Conclus\u00e3o Espero que voc\u00ea tenha aprendido v\u00e1rios aspectos do teste E2E, como seus processos, m\u00e9tricas, a diferen\u00e7a entre testes Unit\u00e1rios, de Integra\u00e7\u00e3o e E2E, e os v\u00e1rios frameworks e ferramentas de teste E2E recomendados. Para qualquer lan\u00e7amento comercial do software, a verifica\u00e7\u00e3o do teste E2E desempenha um papel importante, pois testa toda a aplica\u00e7\u00e3o em um ambiente que imita exatamente os usu\u00e1rios do mundo real, como comunica\u00e7\u00e3o de rede, intera\u00e7\u00e3o com middleware e servi\u00e7os de back-end, etc. Por fim, o teste E2E \u00e9 frequentemente realizado manualmente, pois o custo de automatizar tais casos de teste \u00e9 muito alto para ser suportado por qualquer organiza\u00e7\u00e3o. Dito isso, o objetivo final de cada organiza\u00e7\u00e3o \u00e9 tornar o teste E2E o mais eficiente poss\u00edvel, adicionando componentes de teste totalmente e semi-automatizados ao processo. Portanto, os v\u00e1rios frameworks e ferramentas de teste E2E listados neste artigo v\u00eam em socorro. Recursos Wikipedia: Teste de Software Wikipedia: Teste Unit\u00e1rio Wikipedia: Teste de Integra\u00e7\u00e3o Wikipedia: Teste de Sistema","title":"Teste de Ponta a Ponta (E2E)"},{"location":"automated-testing/e2e-testing/#teste-de-ponta-a-ponta-e2e","text":"O teste de ponta a ponta (E2E) \u00e9 uma metodologia de teste de software para verificar um fluxo funcional e de dados de uma aplica\u00e7\u00e3o composta por v\u00e1rios subsistemas trabalhando juntos do in\u00edcio ao fim. Muitas vezes, esses sistemas s\u00e3o desenvolvidos em diferentes tecnologias por diferentes equipes ou organiza\u00e7\u00f5es. Finalmente, eles se unem para formar uma aplica\u00e7\u00e3o de neg\u00f3cios funcional. Portanto, testar um \u00fanico sistema n\u00e3o seria suficiente. Assim, o teste de ponta a ponta verifica a aplica\u00e7\u00e3o do in\u00edcio ao fim, colocando todos os seus componentes juntos.","title":"Teste de Ponta a Ponta (E2E)"},{"location":"automated-testing/e2e-testing/#por-que-teste-e2e-o-porque","text":"Em muitos cen\u00e1rios de aplicativos de software comerciais, um sistema de software moderno consiste em sua interconex\u00e3o com v\u00e1rios subsistemas. Esses subsistemas podem estar dentro da mesma organiza\u00e7\u00e3o ou podem ser componentes de diferentes organiza\u00e7\u00f5es. Al\u00e9m disso, esses subsistemas podem ter ciclos de lan\u00e7amento de vida \u00fatil semelhantes ou diferentes do sistema atual. Como resultado, se houver qualquer falha ou defeito em qualquer subsistema, isso pode afetar adversamente todo o sistema de software, levando ao seu colapso. A ilustra\u00e7\u00e3o acima \u00e9 uma pir\u00e2mide de teste do blog de Kent C. Dodd , que \u00e9 uma combina\u00e7\u00e3o das pir\u00e2mides do blog de Martin Fowler e do Google Testing Blog . A maioria dos seus testes est\u00e1 na parte inferior da pir\u00e2mide. \u00c0 medida que voc\u00ea sobe na pir\u00e2mide, o n\u00famero de testes diminui. Al\u00e9m disso, subindo na pir\u00e2mide, os testes ficam mais lentos e mais caros para escrever, executar e manter. Cada tipo de teste varia para o seu prop\u00f3sito, aplica\u00e7\u00e3o e as \u00e1reas que se destina a cobrir. Para mais informa\u00e7\u00f5es sobre a an\u00e1lise comparativa de diferentes tipos de testes, consulte este documento ## Unidade vs Integra\u00e7\u00e3o vs Sistema vs Teste E2E .","title":"Por que Teste E2E [O Porqu\u00ea]"},{"location":"automated-testing/e2e-testing/#blocos-de-design-de-teste-e2e-o-que","text":"Vamos examinar todas as 3 categorias uma por uma:","title":"Blocos de Design de Teste E2E [O Qu\u00ea]"},{"location":"automated-testing/e2e-testing/#funcoes-do-usuario","text":"As seguintes a\u00e7\u00f5es devem ser realizadas como parte da constru\u00e7\u00e3o de fun\u00e7\u00f5es do usu\u00e1rio: Liste as fun\u00e7\u00f5es iniciadas pelo usu\u00e1rio dos sistemas de software e seus subsistemas interconectados. Para qualquer fun\u00e7\u00e3o, acompanhe as a\u00e7\u00f5es realizadas, bem como os dados de entrada e sa\u00edda. Encontre as rela\u00e7\u00f5es, se houver, entre diferentes fun\u00e7\u00f5es do usu\u00e1rio. Descubra a natureza das diferentes fun\u00e7\u00f5es do usu\u00e1rio, ou seja, se s\u00e3o independentes ou reutiliz\u00e1veis.","title":"Fun\u00e7\u00f5es do Usu\u00e1rio"},{"location":"automated-testing/e2e-testing/#condicoes","text":"As seguintes atividades devem ser realizadas como parte da constru\u00e7\u00e3o de condi\u00e7\u00f5es com base nas fun\u00e7\u00f5es do usu\u00e1rio: Para cada uma das fun\u00e7\u00f5es do usu\u00e1rio, um conjunto de condi\u00e7\u00f5es deve ser preparado. O tempo, as condi\u00e7\u00f5es de dados e outros fatores que afetam as fun\u00e7\u00f5es do usu\u00e1rio podem ser considerados como par\u00e2metros.","title":"Condi\u00e7\u00f5es"},{"location":"automated-testing/e2e-testing/#casos-de-teste","text":"Os seguintes fatores devem ser considerados para a constru\u00e7\u00e3o de casos de teste: Para cada cen\u00e1rio, um ou mais casos de teste devem ser criados para testar cada funcionalidade das fun\u00e7\u00f5es do usu\u00e1rio. Se poss\u00edvel, esses casos de teste devem ser automatizados por meio dos processos padr\u00e3o de pipeline de CI/CD com o acompanhamento de cada build bem-sucedido e falho no AzDO. Cada condi\u00e7\u00e3o deve ser listada como um caso de teste separado.","title":"Casos de Teste"},{"location":"automated-testing/e2e-testing/#aplicando-o-teste-e2e-o-como","text":"Como qualquer outro teste, o teste E2E tamb\u00e9m passa por fases formais de planejamento, execu\u00e7\u00e3o de teste e encerramento. O teste E2E \u00e9 feito com as seguintes etapas:","title":"Aplicando o Teste E2E [O Como]"},{"location":"automated-testing/e2e-testing/#planejamento","text":"An\u00e1lise de requisitos de neg\u00f3cios e funcionais Desenvolvimento do plano de teste Desenvolvimento do caso de teste Configura\u00e7\u00e3o do ambiente de teste semelhante \u00e0 produ\u00e7\u00e3o Configura\u00e7\u00e3o dos dados de teste Decidir crit\u00e9rios de sa\u00edda Escolher os m\u00e9todos de teste mais aplic\u00e1veis ao seu sistema. Para a defini\u00e7\u00e3o dos v\u00e1rios m\u00e9todos de teste, consulte o documento M\u00e9todos de Teste .","title":"Planejamento"},{"location":"automated-testing/e2e-testing/#pre-requisito","text":"O teste do sistema deve estar completo para todos os sistemas participantes. Todos os subsistemas devem ser combinados para funcionar como uma aplica\u00e7\u00e3o completa. O ambiente de teste semelhante \u00e0 produ\u00e7\u00e3o deve estar pronto.","title":"Pr\u00e9-requisito"},{"location":"automated-testing/e2e-testing/#execucao-do-teste","text":"Execute os casos de teste Registre os resultados do teste e decida sobre a aprova\u00e7\u00e3o e falha Relate os bugs na ferramenta de relat\u00f3rio de bugs Re-verifique as corre\u00e7\u00f5es de bugs","title":"Execu\u00e7\u00e3o do Teste"},{"location":"automated-testing/e2e-testing/#encerramento-do-teste","text":"Prepara\u00e7\u00e3o do relat\u00f3rio de teste Avalia\u00e7\u00e3o dos crit\u00e9rios de sa\u00edda Encerramento da fase de teste","title":"Encerramento do Teste"},{"location":"automated-testing/e2e-testing/#metricas-de-teste","text":"Rastrear as m\u00e9tricas de qualidade d\u00e1 uma vis\u00e3o sobre o status atual do teste. Algumas m\u00e9tricas comuns de teste E2E s\u00e3o: Status de prepara\u00e7\u00e3o do caso de teste : N\u00famero de casos de teste prontos versus o n\u00famero total de casos de teste. Progresso frequente do teste : N\u00famero de casos de teste executados de maneira frequente e consistente, por exemplo, semanalmente, versus um n\u00famero-alvo de casos de teste no mesmo per\u00edodo de tempo. Status dos defeitos : Esta m\u00e9trica representa o status dos defeitos encontrados durante o teste. Os defeitos devem ser registrados na ferramenta de rastreamento de defeitos (por exemplo, backlog do AzDO) e resolvidos de acordo com sua gravidade e prioridade. Portanto, a porcentagem de defeitos abertos e fechados de acordo com sua gravidade e prioridade deve ser calculada para rastrear esta m\u00e9trica. A consulta do painel AzDO pode ser usada para rastrear essa m\u00e9trica. Disponibilidade do ambiente de teste : Esta m\u00e9trica rastreia a dura\u00e7\u00e3o do ambiente de teste usado para o teste de ponta a ponta versus sua dura\u00e7\u00e3o de aloca\u00e7\u00e3o programada.","title":"M\u00e9tricas de Teste"},{"location":"automated-testing/e2e-testing/#frameworks-e-ferramentas-de-teste-e2e","text":"","title":"Frameworks e Ferramentas de Teste E2E"},{"location":"automated-testing/e2e-testing/#1-gauge-framework","text":"Gauge \u00e9 um framework gratuito e de c\u00f3digo aberto para escrever e executar testes E2E. Algumas caracter\u00edsticas-chave do Gauge que o tornam \u00fanico incluem: Sintaxe simples, flex\u00edvel e rica baseada em Markdown. Suporte consistente entre plataformas/linguagens para escrever c\u00f3digo de teste. Uma arquitetura modular com suporte a plugins. Suporta execu\u00e7\u00e3o orientada a dados e fontes de dados externas. Ajuda voc\u00ea a criar su\u00edtes de teste sustent\u00e1veis. Suporta Visual Studio Code, Intellij IDEA, IDE Support. Suporta relat\u00f3rios em html, json e XML. Site do Gauge Framework","title":"1. Gauge Framework"},{"location":"automated-testing/e2e-testing/#2-robot-framework","text":"Robot Framework \u00e9 um framework de automa\u00e7\u00e3o de c\u00f3digo aberto gen\u00e9rico. O framework tem uma sintaxe f\u00e1cil, utilizando palavras-chave leg\u00edveis por humanos. Suas capacidades podem ser estendidas por bibliotecas implementadas com Python ou Java. Robot compartilha muitos dos mesmos \"pr\u00f3s\" que o Gauge, exceto as ferramentas de desenvolvimento e a sintaxe. Em nosso uso, descobrimos que o Intellisense do VS Code oferecido com o Gauge era muito mais est\u00e1vel do que as ofertas para o Robot. Tamb\u00e9m achamos a sintaxe menos leg\u00edvel do que o que o Gauge oferecia. Embora ambos os frameworks permitam defini\u00e7\u00f5es de casos de teste baseadas em marca\u00e7\u00e3o, a sintaxe do Gauge l\u00ea muito mais como uma frase em portugu\u00eas do que o Robot. Finalmente, o Intellisense est\u00e1 incorporado nos arquivos de marca\u00e7\u00e3o para casos de teste do Gauge, o que criar\u00e1 um stub de fun\u00e7\u00e3o para a defini\u00e7\u00e3o de teste real se o desenvolvedor permitir. O mesmo n\u00e3o pode ser dito do Robot Framework. Site do Robot Framework","title":"2. Robot Framework"},{"location":"automated-testing/e2e-testing/#3-testcraft","text":"TestCraft \u00e9 uma plataforma de automa\u00e7\u00e3o de teste Selenium sem c\u00f3digo. Sua tecnologia revolucion\u00e1ria de IA e modelagem visual \u00fanica permitem uma cria\u00e7\u00e3o e execu\u00e7\u00e3o de teste mais r\u00e1pida, eliminando a sobrecarga de manuten\u00e7\u00e3o de teste. Os testadores criam cen\u00e1rios de teste totalmente automatizados sem codifica\u00e7\u00e3o. Os clientes encontram bugs mais rapidamente, lan\u00e7am com mais frequ\u00eancia, integram-se com a abordagem CI/CD e melhoram a qualidade geral de seus produtos digitais. Isso cria uma experi\u00eancia completa de teste de ponta a ponta. Site do Perfecto (TestCraft) ou obtenha-o no Visual Studio Marketplace","title":"3. TestCraft"},{"location":"automated-testing/e2e-testing/#4-ranorex-studio","text":"Ranorex Studio \u00e9 uma ferramenta completa de automa\u00e7\u00e3o de teste de ponta a ponta para aplica\u00e7\u00f5es desktop, web e m\u00f3veis. Crie testes confi\u00e1veis rapidamente sem qualquer codifica\u00e7\u00e3o ou usando o IDE completo. Use arquivos CSV ou Excel externos ou um banco de dados SQL como entradas para seus testes. Execute testes em paralelo ou em uma grade Selenium com o Selenium WebDriver integrado. O Ranorex Studio se integra ao seu processo de CI/CD para encurtar seus ciclos de lan\u00e7amento sem sacrificar a qualidade. Os testes do Ranorex Studio tamb\u00e9m se integram ao Azure DevOps (AzDO), que podem ser executados como parte de um pipeline de build no AzDO. Site do Ranorex Studio","title":"4. Ranorex Studio"},{"location":"automated-testing/e2e-testing/#5-katalon-studio","text":"Katalon Studio \u00e9 uma excelente solu\u00e7\u00e3o de automa\u00e7\u00e3o de ponta a ponta para testes web, API, m\u00f3veis e desktop com suporte DevOps. Com o Katalon Studio, o teste automatizado pode ser facilmente integrado a qualquer pipeline de CI/CD para lan\u00e7ar produtos mais rapidamente, garantindo alta qualidade. O Katalon Studio personaliza para usu\u00e1rios de iniciantes a especialistas. Fun\u00e7\u00f5es robustas como Espionagem, Grava\u00e7\u00e3o, Interface de editor duplo e Palavras-chave personalizadas tornam poss\u00edvel a configura\u00e7\u00e3o, cria\u00e7\u00e3o e manuten\u00e7\u00e3o de testes para os usu\u00e1rios. Constru\u00eddo em cima do Selenium e Appium, o Katalon Studio ajuda a padronizar seus testes de ponta a ponta. Ele tamb\u00e9m est\u00e1 em conformidade com os frameworks mais populares para trabalhar de forma integrada com outras ferramentas no ecossistema de teste automatizado. O Katalon \u00e9 endossado pela Gartner, profissionais de TI e uma grande comunidade de teste. Nota: No momento da escrita deste texto, a extens\u00e3o do Katalon Studio para AzDO N\u00c3O estava dispon\u00edvel para Linux. Site do Katalon Studio ou leia sobre sua integra\u00e7\u00e3o com o AzDO","title":"5. Katalon Studio"},{"location":"automated-testing/e2e-testing/#6-bugbugio","text":"BugBug \u00e9 uma maneira f\u00e1cil de automatizar testes para aplica\u00e7\u00f5es web. A ferramenta foca na simplicidade, mas ainda permite que voc\u00ea cubra todos os casos de teste essenciais sem codifica\u00e7\u00e3o. \u00c9 uma solu\u00e7\u00e3o completa - voc\u00ea pode criar testes facilmente e usar a nuvem integrada para execut\u00e1-los de acordo com um cronograma ou a partir do seu CI/CD, sem altera\u00e7\u00f5es na sua pr\u00f3pria infraestrutura. BugBug \u00e9 uma alternativa interessante ao Selenium porque \u00e9 realmente uma tecnologia completamente diferente. Ele \u00e9 baseado em uma extens\u00e3o do Chrome que permite ao BugBug gravar e executar testes mais rapidamente do que os frameworks da velha escola. A maior vantagem do BugBug \u00e9 sua facilidade de uso. A maioria dos testes criados com o BugBug simplesmente funciona imediatamente. Isso torna mais f\u00e1cil para pessoas n\u00e3o t\u00e9cnicas manterem os testes - com o BugBug, voc\u00ea pode economizar dinheiro na contrata\u00e7\u00e3o de um engenheiro de QA. Site do BugBug","title":"6. BugBug.io"},{"location":"automated-testing/e2e-testing/#conclusao","text":"Espero que voc\u00ea tenha aprendido v\u00e1rios aspectos do teste E2E, como seus processos, m\u00e9tricas, a diferen\u00e7a entre testes Unit\u00e1rios, de Integra\u00e7\u00e3o e E2E, e os v\u00e1rios frameworks e ferramentas de teste E2E recomendados. Para qualquer lan\u00e7amento comercial do software, a verifica\u00e7\u00e3o do teste E2E desempenha um papel importante, pois testa toda a aplica\u00e7\u00e3o em um ambiente que imita exatamente os usu\u00e1rios do mundo real, como comunica\u00e7\u00e3o de rede, intera\u00e7\u00e3o com middleware e servi\u00e7os de back-end, etc. Por fim, o teste E2E \u00e9 frequentemente realizado manualmente, pois o custo de automatizar tais casos de teste \u00e9 muito alto para ser suportado por qualquer organiza\u00e7\u00e3o. Dito isso, o objetivo final de cada organiza\u00e7\u00e3o \u00e9 tornar o teste E2E o mais eficiente poss\u00edvel, adicionando componentes de teste totalmente e semi-automatizados ao processo. Portanto, os v\u00e1rios frameworks e ferramentas de teste E2E listados neste artigo v\u00eam em socorro.","title":"Conclus\u00e3o"},{"location":"automated-testing/e2e-testing/#recursos","text":"Wikipedia: Teste de Software Wikipedia: Teste Unit\u00e1rio Wikipedia: Teste de Integra\u00e7\u00e3o Wikipedia: Teste de Sistema","title":"Recursos"},{"location":"automated-testing/e2e-testing/testing-comparison/","text":"Teste Unit\u00e1rio vs Teste de Integra\u00e7\u00e3o vs Teste de Sistema vs Teste E2E A tabela abaixo ilustra as caracter\u00edsticas mais cr\u00edticas e diferen\u00e7as entre Teste Unit\u00e1rio, Teste de Integra\u00e7\u00e3o, Teste de Sistema e Teste de Ponta a Ponta (E2E), e quando aplicar cada metodologia em um projeto. Teste Unit\u00e1rio Teste de Integra\u00e7\u00e3o Teste de Sistema Teste E2E Escopo M\u00f3dulos, APIs M\u00f3dulos, interfaces Aplica\u00e7\u00e3o, sistema Todos os subsistemas, depend\u00eancias de rede, servi\u00e7os e bancos de dados Tamanho Pequeno Pequeno a m\u00e9dio Grande Extra Grande Ambiente Desenvolvimento Teste de integra\u00e7\u00e3o Teste de QA Similar \u00e0 produ\u00e7\u00e3o Dados Dados simulados Dados de teste Dados de teste C\u00f3pia de dados de produ\u00e7\u00e3o reais Sistema Sob Teste Teste unit\u00e1rio isolado Interfaces e fluxo de dados entre os m\u00f3dulos Sistema espec\u00edfico como um todo Fluxo da aplica\u00e7\u00e3o do in\u00edcio ao fim Cen\u00e1rios Perspectivas do desenvolvedor Perspectivas de desenvolvedores e testadores de TI Perspectivas de desenvolvedores e testadores de QA Perspectivas do usu\u00e1rio final Quando Ap\u00f3s cada build Ap\u00f3s o teste unit\u00e1rio Antes do teste E2E e ap\u00f3s os testes unit\u00e1rios e de integra\u00e7\u00e3o Ap\u00f3s o teste de sistema Automatizado ou Manual Automatizado Manual ou automatizado Manual ou automatizado Manual","title":"Teste Unit\u00e1rio vs Teste de Integra\u00e7\u00e3o vs Teste de Sistema vs Teste E2E"},{"location":"automated-testing/e2e-testing/testing-comparison/#teste-unitario-vs-teste-de-integracao-vs-teste-de-sistema-vs-teste-e2e","text":"A tabela abaixo ilustra as caracter\u00edsticas mais cr\u00edticas e diferen\u00e7as entre Teste Unit\u00e1rio, Teste de Integra\u00e7\u00e3o, Teste de Sistema e Teste de Ponta a Ponta (E2E), e quando aplicar cada metodologia em um projeto. Teste Unit\u00e1rio Teste de Integra\u00e7\u00e3o Teste de Sistema Teste E2E Escopo M\u00f3dulos, APIs M\u00f3dulos, interfaces Aplica\u00e7\u00e3o, sistema Todos os subsistemas, depend\u00eancias de rede, servi\u00e7os e bancos de dados Tamanho Pequeno Pequeno a m\u00e9dio Grande Extra Grande Ambiente Desenvolvimento Teste de integra\u00e7\u00e3o Teste de QA Similar \u00e0 produ\u00e7\u00e3o Dados Dados simulados Dados de teste Dados de teste C\u00f3pia de dados de produ\u00e7\u00e3o reais Sistema Sob Teste Teste unit\u00e1rio isolado Interfaces e fluxo de dados entre os m\u00f3dulos Sistema espec\u00edfico como um todo Fluxo da aplica\u00e7\u00e3o do in\u00edcio ao fim Cen\u00e1rios Perspectivas do desenvolvedor Perspectivas de desenvolvedores e testadores de TI Perspectivas de desenvolvedores e testadores de QA Perspectivas do usu\u00e1rio final Quando Ap\u00f3s cada build Ap\u00f3s o teste unit\u00e1rio Antes do teste E2E e ap\u00f3s os testes unit\u00e1rios e de integra\u00e7\u00e3o Ap\u00f3s o teste de sistema Automatizado ou Manual Automatizado Manual ou automatizado Manual ou automatizado Manual","title":"Teste Unit\u00e1rio vs Teste de Integra\u00e7\u00e3o vs Teste de Sistema vs Teste E2E"},{"location":"automated-testing/e2e-testing/testing-methods/","text":"M\u00e9todos de Teste E2E Teste Horizontal Este m\u00e9todo \u00e9 muito comumente usado. Ele ocorre horizontalmente no contexto de v\u00e1rias aplica\u00e7\u00f5es. Pegue, por exemplo, um sistema de gerenciamento de ingest\u00e3o de dados. Os dados de entrada podem ser injetados de v\u00e1rias fontes, mas depois s\u00e3o \"achatados\" em um pipeline de processamento horizontal que pode incluir v\u00e1rios componentes, como uma API de gateway, transforma\u00e7\u00e3o de dados, valida\u00e7\u00e3o de dados, armazenamento, etc. Ao longo de todo o processamento de Extra\u00e7\u00e3o-Transforma\u00e7\u00e3o-Carga (ETL), o fluxo de dados pode ser rastreado e monitorado sob o espectro horizontal com pequenos toques opcionais, e portanto n\u00e3o importantes para o caso de teste E2E geral, servi\u00e7os como registro, auditoria, autentica\u00e7\u00e3o. Teste Vertical Neste m\u00e9todo, todas as transa\u00e7\u00f5es mais cr\u00edticas de qualquer aplica\u00e7\u00e3o s\u00e3o verificadas e avaliadas desde o in\u00edcio at\u00e9 o fim. Cada camada individual da aplica\u00e7\u00e3o \u00e9 testada come\u00e7ando de cima para baixo. Pegue, por exemplo, uma aplica\u00e7\u00e3o baseada na web que usa servi\u00e7os de middleware para acessar recursos de back-end. Nesse caso, cada camada (n\u00edvel) precisa ser totalmente testada em conjunto com as camadas \"conectadas\" acima e abaixo, nas quais os servi\u00e7os \"conversam\" entre si durante o fluxo de dados de ponta a ponta. Todos esses cen\u00e1rios de teste complexos exigir\u00e3o valida\u00e7\u00e3o adequada e testes automatizados dedicados. Portanto, este m\u00e9todo \u00e9 muito mais dif\u00edcil. Diretrizes para o Design de Casos de Teste E2E A seguir est\u00e3o listadas algumas diretrizes que devem ser levadas em considera\u00e7\u00e3o ao projetar os casos de teste para a realiza\u00e7\u00e3o de testes E2E: Os casos de teste devem ser projetados a partir da perspectiva do usu\u00e1rio final. Deve-se focar em testar alguns recursos existentes do sistema. V\u00e1rios cen\u00e1rios devem ser considerados para criar m\u00faltiplos casos de teste. Diferentes conjuntos de casos de teste devem ser criados para focar em m\u00faltiplos cen\u00e1rios do sistema.","title":"M\u00e9todos de Teste E2E"},{"location":"automated-testing/e2e-testing/testing-methods/#metodos-de-teste-e2e","text":"","title":"M\u00e9todos de Teste E2E"},{"location":"automated-testing/e2e-testing/testing-methods/#teste-horizontal","text":"Este m\u00e9todo \u00e9 muito comumente usado. Ele ocorre horizontalmente no contexto de v\u00e1rias aplica\u00e7\u00f5es. Pegue, por exemplo, um sistema de gerenciamento de ingest\u00e3o de dados. Os dados de entrada podem ser injetados de v\u00e1rias fontes, mas depois s\u00e3o \"achatados\" em um pipeline de processamento horizontal que pode incluir v\u00e1rios componentes, como uma API de gateway, transforma\u00e7\u00e3o de dados, valida\u00e7\u00e3o de dados, armazenamento, etc. Ao longo de todo o processamento de Extra\u00e7\u00e3o-Transforma\u00e7\u00e3o-Carga (ETL), o fluxo de dados pode ser rastreado e monitorado sob o espectro horizontal com pequenos toques opcionais, e portanto n\u00e3o importantes para o caso de teste E2E geral, servi\u00e7os como registro, auditoria, autentica\u00e7\u00e3o.","title":"Teste Horizontal"},{"location":"automated-testing/e2e-testing/testing-methods/#teste-vertical","text":"Neste m\u00e9todo, todas as transa\u00e7\u00f5es mais cr\u00edticas de qualquer aplica\u00e7\u00e3o s\u00e3o verificadas e avaliadas desde o in\u00edcio at\u00e9 o fim. Cada camada individual da aplica\u00e7\u00e3o \u00e9 testada come\u00e7ando de cima para baixo. Pegue, por exemplo, uma aplica\u00e7\u00e3o baseada na web que usa servi\u00e7os de middleware para acessar recursos de back-end. Nesse caso, cada camada (n\u00edvel) precisa ser totalmente testada em conjunto com as camadas \"conectadas\" acima e abaixo, nas quais os servi\u00e7os \"conversam\" entre si durante o fluxo de dados de ponta a ponta. Todos esses cen\u00e1rios de teste complexos exigir\u00e3o valida\u00e7\u00e3o adequada e testes automatizados dedicados. Portanto, este m\u00e9todo \u00e9 muito mais dif\u00edcil.","title":"Teste Vertical"},{"location":"automated-testing/e2e-testing/testing-methods/#diretrizes-para-o-design-de-casos-de-teste-e2e","text":"A seguir est\u00e3o listadas algumas diretrizes que devem ser levadas em considera\u00e7\u00e3o ao projetar os casos de teste para a realiza\u00e7\u00e3o de testes E2E: Os casos de teste devem ser projetados a partir da perspectiva do usu\u00e1rio final. Deve-se focar em testar alguns recursos existentes do sistema. V\u00e1rios cen\u00e1rios devem ser considerados para criar m\u00faltiplos casos de teste. Diferentes conjuntos de casos de teste devem ser criados para focar em m\u00faltiplos cen\u00e1rios do sistema.","title":"Diretrizes para o Design de Casos de Teste E2E"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/","text":"Framework Gauge Gauge \u00e9 um framework gratuito e de c\u00f3digo aberto para escrever e executar testes E2E. Algumas caracter\u00edsticas-chave do Gauge que o tornam \u00fanico incluem: Sintaxe simples, flex\u00edvel e rica baseada em Markdown. Suporte consistente entre plataformas/linguagens para escrever c\u00f3digo de teste. Uma arquitetura modular com suporte a plugins. Extens\u00edvel atrav\u00e9s de plugins e personaliz\u00e1vel. Suporta execu\u00e7\u00e3o orientada a dados e fontes de dados externas. Ajuda voc\u00ea a criar su\u00edtes de teste sustent\u00e1veis. Suporta Visual Studio Code, Intellij IDEA, suporte IDE. O que \u00e9 uma Especifica\u00e7\u00e3o As especifica\u00e7\u00f5es do Gauge s\u00e3o escritas usando uma sintaxe Markdown. Por exemplo: # Procurar pelo blob de dados ## Procurar por arquivo * Ir para o blob do Azure Nesta especifica\u00e7\u00e3o, Procurar pelo blob de dados \u00e9 o cabe\u00e7alho da especifica\u00e7\u00e3o , Procurar por arquivo \u00e9 um cen\u00e1rio com um passo Ir para o blob do Azure . O que \u00e9 uma Implementa\u00e7\u00e3o Voc\u00ea pode implementar os passos em uma especifica\u00e7\u00e3o usando uma linguagem de programa\u00e7\u00e3o, por exemplo: from getgauge.python import step import os from step_impl.utils.driver import Driver @step ( \"Ir para o blob do Azure\" ) def gotoAzureStorage () : URL = os.getenv ( 'STORAGE_ENDPOINT' ) Driver.driver.get ( URL ) O runner do Gauge l\u00ea e executa passos e suas implementa\u00e7\u00f5es para cada cen\u00e1rio na especifica\u00e7\u00e3o e gera um relat\u00f3rio de cen\u00e1rios aprovados ou reprovados. # Procurar pelo blob de dados ## Procurar por arquivo \u2714 Relat\u00f3rio html gerado com sucesso para = > reports/html-report/index.html Especifica\u00e7\u00f5es: 1 executadas 1 aprovadas 0 reprovadas 0 ignoradas Cen\u00e1rios: 1 executados 1 aprovados 0 reprovados 0 ignorados Reutilizando Passos O Gauge ajuda voc\u00ea a se concentrar no teste do fluxo de uma aplica\u00e7\u00e3o. O Gauge faz isso tornando os passos t\u00e3o reutiliz\u00e1veis quanto poss\u00edvel. Com o Gauge, voc\u00ea n\u00e3o precisa construir frameworks personalizados usando uma linguagem de programa\u00e7\u00e3o. Por exemplo, os passos do Gauge podem passar par\u00e2metros para uma implementa\u00e7\u00e3o usando um texto entre aspas. # Procurar pelo blob de dados ## Procurar por arquivo * Ir para o blob do Azure * Procurar por \"store_data.csv\" A implementa\u00e7\u00e3o agora pode usar \"store_data.csv\" da seguinte forma: from getgauge.python import step import os @step ( \"Procurar por <query>\" ) def searchForQuery ( query ) : write ( query ) press ( \"Enter\" ) Voc\u00ea pode ent\u00e3o reutilizar este passo dentro ou entre cen\u00e1rios com diferentes par\u00e2metros: # Procurar pelo blob de dados ## Procurar por dados da loja #1 * Ir para o blob do Azure * Procurar por \"store_1.csv\" ## Procurar por dados da loja #2 * Ir para o blob do Azure * Procurar por \"store_2.csv\" Ou combinar mais de um passo em conceitos # Procurar no armazenamento do Azure por <query> * Ir para o blob do Azure * Procurar por \"store_1.csv\" O conceito, Procurar no armazenamento do Azure por <query> pode ser usado como um passo em uma especifica\u00e7\u00e3o. # Procurar pelo blob de dados ## Procurar por dados da loja #1 * Procurar no armazenamento do Azure por \"store_1.csv\" ## Procurar por dados da loja #2 * Procurar no armazenamento do Azure por \"store_2.csv\" Teste Orientado a Dados O Gauge tamb\u00e9m suporta teste orientado a dados usando tabelas Markdown, bem como arquivos csv externos, por exemplo: # Procurar pelo blob de dados | query | | --------- | | store_1 | | store_2 | | store_3 | ## Procurar por dados das lojas * Procurar no armazenamento do Azure por <query> Isso executar\u00e1 o cen\u00e1rio para todas as linhas da tabela. Nos exemplos acima, refatoramos uma especifica\u00e7\u00e3o para ser concisa e flex\u00edvel sem alterar a implementa\u00e7\u00e3o. Outros Recursos Esta \u00e9 uma breve introdu\u00e7\u00e3o a alguns recursos do Gauge. Consulte a documenta\u00e7\u00e3o do Gauge para recursos adicionais, como: Relat\u00f3rios Tags Execu\u00e7\u00e3o Paralela Ambientes Capturas de tela Plugins E muito mais Instalando o Gauge Este guia de introdu\u00e7\u00e3o o levar\u00e1 pelos recursos principais do Gauge. Ao final deste guia, voc\u00ea ser\u00e1 capaz de instalar o Gauge e aprender como criar seu primeiro projeto de automa\u00e7\u00e3o de teste com o Gauge. Instru\u00e7\u00f5es de Instala\u00e7\u00e3o para Windows OS Passo 1: Instalando o Gauge no Windows Esta se\u00e7\u00e3o fornece instru\u00e7\u00f5es espec\u00edficas sobre como configurar o Gauge em um ambiente Microsoft Windows. Baixe o seguinte pacote de instala\u00e7\u00e3o para obter a vers\u00e3o est\u00e1vel mais recente do Gauge. Passo 2: Instalando a extens\u00e3o Gauge para Visual Studio Code Siga os passos para adicionar o plugin Gauge Visual Studio Code a partir do IDE. Instale a seguinte extens\u00e3o Gauge para Visual Studio Code . Solu\u00e7\u00e3o de Problemas de Instala\u00e7\u00e3o Se, ao executar sua primeira especifica\u00e7\u00e3o do Gauge, voc\u00ea receber o erro de pacotes Python ausentes, abra a janela do terminal de linha de comando e execute este comando: python.exe -m pip install getgauge == 0 .3.7 --user Instru\u00e7\u00f5es de Instala\u00e7\u00e3opara macOS Passo 1: Instalando o Gauge no macOS Esta se\u00e7\u00e3o fornece instru\u00e7\u00f5es espec\u00edficas sobre como configurar o Gauge em um ambiente macOS. Instale o brew se ainda n\u00e3o o tiver feito: Acesse o site do brew e siga as instru\u00e7\u00f5es l\u00e1. Execute o comando brew para instalar o Gauge: > brew install gauge Se o HomeBrew estiver funcionando corretamente, voc\u00ea dever\u00e1 ver algo semelhante ao seguinte: == > Buscando gauge == > Baixando https://ghcr.io/v2/homebrew/core/gauge/manifests/1.4.3 ######################################################################## 100.0% == > Baixando https://ghcr.io/v2/homebrew/core/gauge/blobs/sha256:05117bb3c0b2efeafe41e817cd3ad86307c1d2ea7e0e835655c4b51ab2472893 == > Baixando de https://pkg-containers.githubusercontent.com/ghcr1/blobs/sha256:05117bb3c0b2efeafe41e817cd3ad86307c1d2ea7e0e835655c4b51ab2472893?se = 2022 -12-13T12%3A35%3A00Z & sig = I78SuuwNgSMFoBTT ######################################################################## 100.0% == > Despejando gauge--1.4.3.ventura.bottle.tar.gz /usr/local/Cellar/gauge/1.4.3: 6 arquivos, 18 .9MB Passo 2: Instalando a extens\u00e3o Gauge para Visual Studio Code Siga os passos para adicionar o plugin Gauge Visual Studio Code a partir do IDE: Instale a seguinte extens\u00e3o Gauge para Visual Studio Code . Solu\u00e7\u00e3o de Problemas P\u00f3s-Instala\u00e7\u00e3o Se, ao executar sua primeira especifica\u00e7\u00e3o do Gauge, voc\u00ea receber o erro de pacotes Python ausentes, abra a janela do terminal de linha de comando e execute este comando: python.exe -m pip install getgauge == 0 .3.7 --user","title":"Framework Gauge"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#framework-gauge","text":"Gauge \u00e9 um framework gratuito e de c\u00f3digo aberto para escrever e executar testes E2E. Algumas caracter\u00edsticas-chave do Gauge que o tornam \u00fanico incluem: Sintaxe simples, flex\u00edvel e rica baseada em Markdown. Suporte consistente entre plataformas/linguagens para escrever c\u00f3digo de teste. Uma arquitetura modular com suporte a plugins. Extens\u00edvel atrav\u00e9s de plugins e personaliz\u00e1vel. Suporta execu\u00e7\u00e3o orientada a dados e fontes de dados externas. Ajuda voc\u00ea a criar su\u00edtes de teste sustent\u00e1veis. Suporta Visual Studio Code, Intellij IDEA, suporte IDE.","title":"Framework Gauge"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#o-que-e-uma-especificacao","text":"As especifica\u00e7\u00f5es do Gauge s\u00e3o escritas usando uma sintaxe Markdown. Por exemplo: # Procurar pelo blob de dados ## Procurar por arquivo * Ir para o blob do Azure Nesta especifica\u00e7\u00e3o, Procurar pelo blob de dados \u00e9 o cabe\u00e7alho da especifica\u00e7\u00e3o , Procurar por arquivo \u00e9 um cen\u00e1rio com um passo Ir para o blob do Azure .","title":"O que \u00e9 uma Especifica\u00e7\u00e3o"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#o-que-e-uma-implementacao","text":"Voc\u00ea pode implementar os passos em uma especifica\u00e7\u00e3o usando uma linguagem de programa\u00e7\u00e3o, por exemplo: from getgauge.python import step import os from step_impl.utils.driver import Driver @step ( \"Ir para o blob do Azure\" ) def gotoAzureStorage () : URL = os.getenv ( 'STORAGE_ENDPOINT' ) Driver.driver.get ( URL ) O runner do Gauge l\u00ea e executa passos e suas implementa\u00e7\u00f5es para cada cen\u00e1rio na especifica\u00e7\u00e3o e gera um relat\u00f3rio de cen\u00e1rios aprovados ou reprovados. # Procurar pelo blob de dados ## Procurar por arquivo \u2714 Relat\u00f3rio html gerado com sucesso para = > reports/html-report/index.html Especifica\u00e7\u00f5es: 1 executadas 1 aprovadas 0 reprovadas 0 ignoradas Cen\u00e1rios: 1 executados 1 aprovados 0 reprovados 0 ignorados","title":"O que \u00e9 uma Implementa\u00e7\u00e3o"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#reutilizando-passos","text":"O Gauge ajuda voc\u00ea a se concentrar no teste do fluxo de uma aplica\u00e7\u00e3o. O Gauge faz isso tornando os passos t\u00e3o reutiliz\u00e1veis quanto poss\u00edvel. Com o Gauge, voc\u00ea n\u00e3o precisa construir frameworks personalizados usando uma linguagem de programa\u00e7\u00e3o. Por exemplo, os passos do Gauge podem passar par\u00e2metros para uma implementa\u00e7\u00e3o usando um texto entre aspas. # Procurar pelo blob de dados ## Procurar por arquivo * Ir para o blob do Azure * Procurar por \"store_data.csv\" A implementa\u00e7\u00e3o agora pode usar \"store_data.csv\" da seguinte forma: from getgauge.python import step import os @step ( \"Procurar por <query>\" ) def searchForQuery ( query ) : write ( query ) press ( \"Enter\" ) Voc\u00ea pode ent\u00e3o reutilizar este passo dentro ou entre cen\u00e1rios com diferentes par\u00e2metros: # Procurar pelo blob de dados ## Procurar por dados da loja #1 * Ir para o blob do Azure * Procurar por \"store_1.csv\" ## Procurar por dados da loja #2 * Ir para o blob do Azure * Procurar por \"store_2.csv\" Ou combinar mais de um passo em conceitos # Procurar no armazenamento do Azure por <query> * Ir para o blob do Azure * Procurar por \"store_1.csv\" O conceito, Procurar no armazenamento do Azure por <query> pode ser usado como um passo em uma especifica\u00e7\u00e3o. # Procurar pelo blob de dados ## Procurar por dados da loja #1 * Procurar no armazenamento do Azure por \"store_1.csv\" ## Procurar por dados da loja #2 * Procurar no armazenamento do Azure por \"store_2.csv\"","title":"Reutilizando Passos"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#teste-orientado-a-dados","text":"O Gauge tamb\u00e9m suporta teste orientado a dados usando tabelas Markdown, bem como arquivos csv externos, por exemplo: # Procurar pelo blob de dados | query | | --------- | | store_1 | | store_2 | | store_3 | ## Procurar por dados das lojas * Procurar no armazenamento do Azure por <query> Isso executar\u00e1 o cen\u00e1rio para todas as linhas da tabela. Nos exemplos acima, refatoramos uma especifica\u00e7\u00e3o para ser concisa e flex\u00edvel sem alterar a implementa\u00e7\u00e3o.","title":"Teste Orientado a Dados"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#outros-recursos","text":"Esta \u00e9 uma breve introdu\u00e7\u00e3o a alguns recursos do Gauge. Consulte a documenta\u00e7\u00e3o do Gauge para recursos adicionais, como: Relat\u00f3rios Tags Execu\u00e7\u00e3o Paralela Ambientes Capturas de tela Plugins E muito mais","title":"Outros Recursos"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#instalando-o-gauge","text":"Este guia de introdu\u00e7\u00e3o o levar\u00e1 pelos recursos principais do Gauge. Ao final deste guia, voc\u00ea ser\u00e1 capaz de instalar o Gauge e aprender como criar seu primeiro projeto de automa\u00e7\u00e3o de teste com o Gauge.","title":"Instalando o Gauge"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#instrucoes-de-instalacao-para-windows-os","text":"","title":"Instru\u00e7\u00f5es de Instala\u00e7\u00e3o para Windows OS"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#passo-1-instalando-o-gauge-no-windows","text":"Esta se\u00e7\u00e3o fornece instru\u00e7\u00f5es espec\u00edficas sobre como configurar o Gauge em um ambiente Microsoft Windows. Baixe o seguinte pacote de instala\u00e7\u00e3o para obter a vers\u00e3o est\u00e1vel mais recente do Gauge.","title":"Passo 1: Instalando o Gauge no Windows"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#passo-2-instalando-a-extensao-gauge-para-visual-studio-code","text":"Siga os passos para adicionar o plugin Gauge Visual Studio Code a partir do IDE. Instale a seguinte extens\u00e3o Gauge para Visual Studio Code .","title":"Passo 2: Instalando a extens\u00e3o Gauge para Visual Studio Code"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#solucao-de-problemas-de-instalacao","text":"Se, ao executar sua primeira especifica\u00e7\u00e3o do Gauge, voc\u00ea receber o erro de pacotes Python ausentes, abra a janela do terminal de linha de comando e execute este comando: python.exe -m pip install getgauge == 0 .3.7 --user","title":"Solu\u00e7\u00e3o de Problemas de Instala\u00e7\u00e3o"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#instrucoes-de-instalacaopara-macos","text":"","title":"Instru\u00e7\u00f5es de Instala\u00e7\u00e3opara macOS"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#passo-1-instalando-o-gauge-no-macos","text":"Esta se\u00e7\u00e3o fornece instru\u00e7\u00f5es espec\u00edficas sobre como configurar o Gauge em um ambiente macOS. Instale o brew se ainda n\u00e3o o tiver feito: Acesse o site do brew e siga as instru\u00e7\u00f5es l\u00e1. Execute o comando brew para instalar o Gauge: > brew install gauge Se o HomeBrew estiver funcionando corretamente, voc\u00ea dever\u00e1 ver algo semelhante ao seguinte: == > Buscando gauge == > Baixando https://ghcr.io/v2/homebrew/core/gauge/manifests/1.4.3 ######################################################################## 100.0% == > Baixando https://ghcr.io/v2/homebrew/core/gauge/blobs/sha256:05117bb3c0b2efeafe41e817cd3ad86307c1d2ea7e0e835655c4b51ab2472893 == > Baixando de https://pkg-containers.githubusercontent.com/ghcr1/blobs/sha256:05117bb3c0b2efeafe41e817cd3ad86307c1d2ea7e0e835655c4b51ab2472893?se = 2022 -12-13T12%3A35%3A00Z & sig = I78SuuwNgSMFoBTT ######################################################################## 100.0% == > Despejando gauge--1.4.3.ventura.bottle.tar.gz /usr/local/Cellar/gauge/1.4.3: 6 arquivos, 18 .9MB","title":"Passo 1: Instalando o Gauge no macOS"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#passo-2-instalando-a-extensao-gauge-para-visual-studio-code_1","text":"Siga os passos para adicionar o plugin Gauge Visual Studio Code a partir do IDE: Instale a seguinte extens\u00e3o Gauge para Visual Studio Code .","title":"Passo 2: Instalando a extens\u00e3o Gauge para Visual Studio Code"},{"location":"automated-testing/e2e-testing/recipes/gauge-framework/#solucao-de-problemas-pos-instalacao","text":"Se, ao executar sua primeira especifica\u00e7\u00e3o do Gauge, voc\u00ea receber o erro de pacotes Python ausentes, abra a janela do terminal de linha de comando e execute este comando: python.exe -m pip install getgauge == 0 .3.7 --user","title":"Solu\u00e7\u00e3o de Problemas P\u00f3s-Instala\u00e7\u00e3o"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/","text":"Testes com Postman O objetivo deste documento \u00e9 fornecer orienta\u00e7\u00f5es sobre como usar o Newman em seu pipeline de CI/CD para executar testes de ponta a ponta (E2E) definidos em Cole\u00e7\u00f5es do Postman, seguindo as melhores pr\u00e1ticas de seguran\u00e7a. Primeiramente, apresentaremos o Postman e o Newman e, em seguida, descreveremos v\u00e1rios casos de uso de testes com o Postman que explicam por que voc\u00ea pode querer ir al\u00e9m dos testes locais com Cole\u00e7\u00f5es do Postman. No caso de uso final, pretendemos usar um script shell que faz refer\u00eancia ao caminho do arquivo da Cole\u00e7\u00e3o do Postman e ao caminho do arquivo de Ambiente como entradas para o Newman. Abaixo est\u00e1 um diagrama de fluxo representando o resultado do caso de uso final: Postman e Newman Postman \u00e9 uma plataforma API gratuita para testar APIs. As principais funcionalidades destacadas neste guia incluem: Cole\u00e7\u00f5es do Postman Arquivos de Ambiente do Postman Scripts do Postman Newman \u00e9 um executor de Cole\u00e7\u00f5es do Postman via linha de comando. Ele permite que voc\u00ea execute e teste uma Cole\u00e7\u00e3o do Postman diretamente da linha de comando. As principais funcionalidades destacadas neste guia incluem: Comando Run do Newman O que \u00e9 uma Cole\u00e7\u00e3o Uma Cole\u00e7\u00e3o do Postman \u00e9 um grupo de requisi\u00e7\u00f5es salvas que podem ser executadas. Uma cole\u00e7\u00e3o pode ser exportada como um arquivo json. O que \u00e9 um Arquivo de Ambiente Um arquivo de Ambiente do Postman cont\u00e9m vari\u00e1veis de ambiente que podem ser referenciadas por uma Cole\u00e7\u00e3o do Postman v\u00e1lida. O que \u00e9 um Script do Postman Um Script do Postman \u00e9 um Javascript hospedado dentro de uma Cole\u00e7\u00e3o do Postman que pode ser escrito para executar contra sua Cole\u00e7\u00e3o do Postman e Arquivo de Ambiente. O que \u00e9 o Comando Run do Newman Um comando CLI do Newman que permite especificar uma Cole\u00e7\u00e3o do Postman a ser executada. Instalando o Postman e o Newman Para instru\u00e7\u00f5es espec\u00edficas sobre como instalar o Postman, visite a p\u00e1gina de Downloads do Postman . Para instru\u00e7\u00f5es espec\u00edficas sobre como instalar o Newman, visite a p\u00e1gina do pacote Newman no NPMJS . Implementando Testes Automatizados de Ponta a Ponta (E2E) com Cole\u00e7\u00f5es do Postman Para fornecer orienta\u00e7\u00f5es sobre como implementar testes E2E automatizados com o Postman, a se\u00e7\u00e3o abaixo come\u00e7a com um caso de uso que explica os compromissos que um desenvolvedor ou analista de QA pode enfrentar ao pretender usar o Postman para testes iniciais. Cada caso de uso representa cen\u00e1rios que facilitam o objetivo final de testes E2E automatizados. Caso de Uso - Teste Funcional Manual de Pontos de Extremidade Um desenvolvedor ou analista de QA gostaria de testar localmente dados de entrada contra servi\u00e7os de API que compartilham um token oauth2 comum. Como resultado, eles usam o Postman para criar uma su\u00edte de testes de API de Cole\u00e7\u00f5es do Postman que podem ser executadas localmente contra pontos de extremidade individuais em diferentes ambientes. Ap\u00f3s validar que sua Cole\u00e7\u00e3o do Postman funciona, eles a compartilham com sua equipe. Os passos podem ser os seguintes: Para cada um dos seus servi\u00e7os de API existentes, use o recurso de importa\u00e7\u00e3o do IDE do Postman para importar sua Especifica\u00e7\u00e3o OpenAPI (Swagger) como uma Cole\u00e7\u00e3o do Postman. Se um servi\u00e7o ainda n\u00e3o estiver usando o Swagger, procure orienta\u00e7\u00f5es espec\u00edficas de linguagem sobre como usar o Swagger para gerar uma Especifica\u00e7\u00e3o OpenAPI para o seu servi\u00e7o. Finalmente, se o seu servi\u00e7o tiver apenas alguns pontos de extremidade, leia a documenta\u00e7\u00e3o do Postman para orienta\u00e7\u00f5es sobre como criar manualmente uma Cole\u00e7\u00e3o do Postman. Forne\u00e7a clareza extra sobre uma requisi\u00e7\u00e3o em uma Cole\u00e7\u00e3o do Postman usando o recurso Exemplo do Postman para salvar suas respostas como exemplos. Voc\u00ea tamb\u00e9m pode simplesmente adicionar um exemplo manualmente. Por favor, leia a documenta\u00e7\u00e3o do Postman para orienta\u00e7\u00f5es sobre como especificar exemplos. Combine cada Cole\u00e7\u00e3o do Postman em uma Cole\u00e7\u00e3o do Postman centralizada. Construa arquivos de Ambiente do Postman (local, Dev e/ou QA) e parametrize todas as requisi\u00e7\u00f5es salvas da Cole\u00e7\u00e3o do Postman de forma que referencie os arquivos de Ambiente do Postman. Use o recurso de Script do Postman para criar um script de pr\u00e9-busca compartilhado que atualiza automaticamente os tokens de autentica\u00e7\u00e3o expirados por requisi\u00e7\u00e3o salva. Isso exigiria referenciar segredos de um arquivo de Ambiente do Postman. // Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. /* A requisi\u00e7\u00e3o para um ponto de extremidade de autoriza\u00e7\u00e3o oauth2 que emitir\u00e1 um token com base nas credenciais fornecidas. */ const oauth2Request = POST {...}; var getToken = true ; if ( pm . environment . get ( 'ACCESS_TOKEN_EXPIRY' ) <= ( new Date ()). getTime ()) { console . log ( 'Token expirou' ) } else { getToken = false ; console . log ( 'Token e data de expira\u00e7\u00e3o est\u00e3o bons' ); } if ( getToken === true ) { pm . sendRequest ( oauth2Request , function ( _ , res ) { console . log ( 'Salve o token' ) var responseJson = res . json (); pm . environment . set ( 'token' , responseJson . access_token ) console . log ( 'Salve a data de expira\u00e7\u00e3o' ) var expiryDate = new Date (); expiryDate . setSeconds ( expiryDate . getSeconds () + responseJson . expires_in ); pm . environment . set ( 'ACCESS_TOKEN_EXPIRY' , expiryDate . getTime ()); }); } Use o IDE do Postman para exercitar pontos de extremidade. Exporte a cole\u00e7\u00e3o e os arquivos de ambiente e, em seguida, remova quaisquer segredos antes de fazer o commit no seu reposit\u00f3rio. Come\u00e7ar com essa abordagem tem as seguintes vantagens: Voc\u00ea se preparou para as etapas iniciais de uma cole\u00e7\u00e3o de postman E2E, agregando as cole\u00e7\u00f5es em um \u00fanico arquivo e usando arquivos de ambiente para facilitar a troca de ambientes. O token \u00e9 atualizado automaticamente em cada chamada na cole\u00e7\u00e3o. Isso economiza tempo normalmente perdido ao ter que solicitar manualmente um token que expirou. Concede ao QA/Dev controle granular para enviar combina\u00e7\u00f5es de dados de entrada por ponto de extremidade. Concede aos desenvolvedores uma experi\u00eancia comum por meio dos recursos do IDE do Postman. Terminar com essa abordagem tem as seguintes desvantagens: Promove o compartilhamento inseguro de segredos. As credenciais necess\u00e1rias para solicitar o token JWT no script de pr\u00e9-busca est\u00e3o sendo compartilhadas manualmente. Segredos podem acabar sendo expostos no hist\u00f3rico de commits do git por v\u00e1rias raz\u00f5es (ex. Compartilhando os arquivos de Ambiente do Postman exportados). As cole\u00e7\u00f5es s\u00f3 podem ser usadas localmente para acessar APIs (locais ou implantadas). N\u00e3o \u00e9 baseado em CI. Cada desenvolvedor tem que manter atualizados tanto sua Cole\u00e7\u00e3o do Postman quanto seus arquivos de Ambiente do Postman para acompanhar as \u00faltimas altera\u00e7\u00f5es nos servi\u00e7os implantados. Caso de Uso - Teste Funcional Manual de Pontos de Extremidade com Azure Key Vault e Azure App Config Um desenvolvedor ou analista de QA pode ter uma su\u00edte de testes de API existente de Cole\u00e7\u00f5es do Postman; no entanto, agora eles querem desencorajar o compartilhamento inseguro de segredos. Como resultado, eles constroem um script que se conecta tanto ao Key Vault quanto ao Azure App Config para gerar automaticamente arquivos de Ambiente do Postman, em vez de registr\u00e1-los em um reposit\u00f3rio compartilhado. Os passos podem ser os seguintes: Crie um Azure Key Vault e armazene segredos de autentica\u00e7\u00e3o por ambiente: - \"Chave:valor\" (ex. \"dev-auth-password:12345\" ) - \"Chave:valor\" (ex. \"qa-auth-password:12345\" ) Crie uma inst\u00e2ncia compartilhada do Azure App Configuration e salve todas as suas vari\u00e1veis de ambiente do Postman. Esta inst\u00e2ncia ser\u00e1 dedicada a manter todas as suas vari\u00e1veis de ambiente do Postman: > NOTA: Use o recurso de R\u00f3tulo (Label) para distinguir entre ambientes. - \"Chave:valor\" -> \"apiRoute:url\" (ex. \"servicename:https://servicename.net\" & R\u00f3tulo = \"QA\" ) - \"Chave:valor\" -> \"Header:value\" (ex. \"token: \" & R\u00f3tulo = \"QA\" ) - \"Chave:valor\" -> \"KeyVaultKey:KeyVaultSecret\" (ex. \"authpassword:qa-auth-password\" & R\u00f3tulo = \"QA\" ) Instale o Powershell ou o Bash. O Powershell funciona tanto para o Azure Powershell quanto para o Azure CLI. Baixe o Azure CLI, fa\u00e7a login na assinatura apropriada e certifique-se de ter acesso aos recursos apropriados. Alguns comandos \u00fateis est\u00e3o abaixo: # fazer login na assinatura apropriada az login # validar o login az account show # validar o acesso ao Key Vault az keyvault secret list - -vault-name \"$KeyvaultName\" # validar o acesso ao App Configuration az appconfig kv list - -name \"$AppConfigName\" Construa um script que gere automaticamente seus arquivos de ambiente. > NOTA: O App Configuration faz refer\u00eancia ao Key Vault; no entanto, seu script \u00e9 respons\u00e1vel por autenticar adequadamente tanto no App Configuration quanto no Key Vault. Os dois servi\u00e7os n\u00e3o se comunicam diretamente. ```powershell (CreatePostmanEnvironmentFiles.ps1) # Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. ############################################################ env = $arg1 # 1. listar vari\u00e1veis de ambiente do app para um ambiente envVars = az appconfig kv list --name PostmanAppConfig --label $env | ConvertFrom-Json # 2. percorrer o array envVars para obter URIs do Key Vault keyvaultURI = \"\" $envVars | % {if($ .key -eq 'password'){keyvaultURI = $ .value}} # 3. analisar URIs para obter o nome do Key Vault e os nomes dos segredos # 4. obter segredo do Key Vault kvsecret = az keyvault secret show --name $secretName --vault-name $keyvaultName --query \"value\" # 5. definir o valor da senha para o segredo retornado do Key Vault $envVars | % {if($ .key -eq 'password'){$ .value=$kvsecret}} # 6. criar arquivo de ambiente envFile = @{ \"_postman_variable_scope\" = \"environment\", \"name\" = $env, values = @() } foreach($var in $envVars){ $envFile.values += @{ key = $var.key; value = $var.value; } } $envFile | ConvertTo-Json -depth 50 | Out-File -encoding ASCII -FilePath .\\$env.postman_environment.json ``` Use o IDE do Postman para importar os arquivos de Ambiente do Postman a serem referenciados pela sua cole\u00e7\u00e3o. Esta abordagem tem as seguintes vantagens: Herda todas as vantagens do caso anterior. Desencoraja o compartilhamento inseguro de segredos. Os segredos agora s\u00e3o retirados do Key Vault via Azure CLI. A URI do Key Vault tamb\u00e9m n\u00e3o precisa mais ser compartilhada para acesso aos tokens de autentica\u00e7\u00e3o. Fonte \u00fanica de verdade para arquivos de Ambiente do Postman. N\u00e3o h\u00e1 mais necessidade de compartilh\u00e1-los via reposit\u00f3rio. O desenvolvedor s\u00f3 precisa gerenciar uma \u00fanica Cole\u00e7\u00e3o do Postman. Terminar com essa abordagem tem as seguintes desvantagens: Segredos podem acabar sendo expostos no hist\u00f3rico de commits do git se .gitIgnore n\u00e3o for atualizado para ignorar arquivos de Ambiente do Postman. As cole\u00e7\u00f5es s\u00f3 podem ser usadas localmente para acessar APIs (locais ou implantadas). N\u00e3o \u00e9 baseado em CI. Caso de Uso - Testes E2E com Integra\u00e7\u00e3o Cont\u00ednua e Newman Um desenvolvedor ou analista de QA pode ter uma su\u00edte de testes de API existente de Cole\u00e7\u00f5es do Postman locais que seguem as melhores pr\u00e1ticas de seguran\u00e7a para desenvolvimento; no entanto, agora eles querem que os testes E2E sejam executados como parte de um pipeline de CI automatizado. Com o advento do Newman, voc\u00ea pode agora usar mais prontamente o Postman para criar uma su\u00edte de testes de API execut\u00e1vel no seu CI. Os passos podem ser os seguintes: Atualize sua Cole\u00e7\u00e3o do Postman para usar o recurso de Teste do Postman para criar afirma\u00e7\u00f5es de teste que cobrir\u00e3o todas as solicita\u00e7\u00f5es salvas de ponta a ponta. Leia a documenta\u00e7\u00e3o do Postman para orienta\u00e7\u00e3o sobre como usar o recurso de Teste do Postman. Use localmente o Newman para validar que os testes est\u00e3o funcionando conforme o esperado. newman run tests \\ e2e_Postman_collection . json -e qa . postman_environment . json Construa um script que execute automaticamente as afirma\u00e7\u00f5es de teste do Postman via Newman e Azure CLI. > NOTA: Um Service Principal do Azure deve ser configurado para continuar usando o azure cli neste exemplo de pipeline de CI. ```powershell (RunPostmanE2eTests.ps1) # Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. ############################################################ # 1. fa\u00e7a login no Azure usando um Service Principal az login --service-principal -u $APP_ID -p $AZURE_SECRET --tenant $AZURE_TENANT # 2. liste as vari\u00e1veis de ambiente do app para um ambiente envVars = az appconfig kv list --name PostmanAppConfig --label $env | ConvertFrom-Json # 3. percorra o array envVars para obter URIs do Key Vault keyvaultURI = \"\" @envVars | % {if($ .key -eq 'password'){keyvaultURI = $ .value}} # 4. analise URIs para obter o nome do Key Vault e os nomes dos segredos # 5. obtenha o segredo do Key Vault kvsecret = az keyvault secret show --name $secretName --vault-name $keyvaultName --query \"value\" # 6. defina o valor da senha para o segredo retornado do Key Vault $envVars | % {if($ .key -eq 'password'){$ .value=$kvsecret}} # 7. crie o arquivo de ambiente envFile = @{ \"_postman_variable_scope\" = \"environment\", \"name\" = $env, values = @() } foreach($var in $envVars){ $envFile.values += @{ key = $var.key; value = $var.value; } } $envFile | ConvertTo-Json -depth 50 | Out-File -encoding ASCII $env.postman_environment.json # 8. instale o Newman npm install --save-dev newman # 9. execute testes E2E automatizados via Newman node_modules.bin\\newman run tests\\e2e_Postman_collection.json -e $env.postman_environment.json ``` Crie um arquivo yaml e defina um passo que executar\u00e1 seu script de teste. (ex. Um arquivo yaml direcionado para o Azure Devops que executa um script Powershell.) # Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. ############################################################ displayName : 'Executar testes E2E do Postman' inputs : targetType : 'filePath' filePath : RunPostmanE2eTests.ps1 env : APP_ID : $(environment.appId) # credenciais para az cli AZURE_SECRET : $(environment.secret) AZURE_TENANT : $(environment.tenant) Esta abordagem tem a seguinte vantagem: Os testes E2E agora podem ser executados automaticamente como parte de um pipeline de CI. Terminar com essa abordagem tem a seguinte desvantagem: Os arquivos de Ambiente do Postman n\u00e3o est\u00e3o mais sendo gerados em um ambiente local para testes manuais pr\u00e1ticos. No entanto, isso pode ser resolvido gerenciando dois scripts.","title":"Testes com Postman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#testes-com-postman","text":"O objetivo deste documento \u00e9 fornecer orienta\u00e7\u00f5es sobre como usar o Newman em seu pipeline de CI/CD para executar testes de ponta a ponta (E2E) definidos em Cole\u00e7\u00f5es do Postman, seguindo as melhores pr\u00e1ticas de seguran\u00e7a. Primeiramente, apresentaremos o Postman e o Newman e, em seguida, descreveremos v\u00e1rios casos de uso de testes com o Postman que explicam por que voc\u00ea pode querer ir al\u00e9m dos testes locais com Cole\u00e7\u00f5es do Postman. No caso de uso final, pretendemos usar um script shell que faz refer\u00eancia ao caminho do arquivo da Cole\u00e7\u00e3o do Postman e ao caminho do arquivo de Ambiente como entradas para o Newman. Abaixo est\u00e1 um diagrama de fluxo representando o resultado do caso de uso final:","title":"Testes com Postman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#postman-e-newman","text":"Postman \u00e9 uma plataforma API gratuita para testar APIs. As principais funcionalidades destacadas neste guia incluem: Cole\u00e7\u00f5es do Postman Arquivos de Ambiente do Postman Scripts do Postman Newman \u00e9 um executor de Cole\u00e7\u00f5es do Postman via linha de comando. Ele permite que voc\u00ea execute e teste uma Cole\u00e7\u00e3o do Postman diretamente da linha de comando. As principais funcionalidades destacadas neste guia incluem: Comando Run do Newman","title":"Postman e Newman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#o-que-e-uma-colecao","text":"Uma Cole\u00e7\u00e3o do Postman \u00e9 um grupo de requisi\u00e7\u00f5es salvas que podem ser executadas. Uma cole\u00e7\u00e3o pode ser exportada como um arquivo json.","title":"O que \u00e9 uma Cole\u00e7\u00e3o"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#o-que-e-um-arquivo-de-ambiente","text":"Um arquivo de Ambiente do Postman cont\u00e9m vari\u00e1veis de ambiente que podem ser referenciadas por uma Cole\u00e7\u00e3o do Postman v\u00e1lida.","title":"O que \u00e9 um Arquivo de Ambiente"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#o-que-e-um-script-do-postman","text":"Um Script do Postman \u00e9 um Javascript hospedado dentro de uma Cole\u00e7\u00e3o do Postman que pode ser escrito para executar contra sua Cole\u00e7\u00e3o do Postman e Arquivo de Ambiente.","title":"O que \u00e9 um Script do Postman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#o-que-e-o-comando-run-do-newman","text":"Um comando CLI do Newman que permite especificar uma Cole\u00e7\u00e3o do Postman a ser executada.","title":"O que \u00e9 o Comando Run do Newman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#instalando-o-postman-e-o-newman","text":"Para instru\u00e7\u00f5es espec\u00edficas sobre como instalar o Postman, visite a p\u00e1gina de Downloads do Postman . Para instru\u00e7\u00f5es espec\u00edficas sobre como instalar o Newman, visite a p\u00e1gina do pacote Newman no NPMJS .","title":"Instalando o Postman e o Newman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#implementando-testes-automatizados-de-ponta-a-ponta-e2e-com-colecoes-do-postman","text":"Para fornecer orienta\u00e7\u00f5es sobre como implementar testes E2E automatizados com o Postman, a se\u00e7\u00e3o abaixo come\u00e7a com um caso de uso que explica os compromissos que um desenvolvedor ou analista de QA pode enfrentar ao pretender usar o Postman para testes iniciais. Cada caso de uso representa cen\u00e1rios que facilitam o objetivo final de testes E2E automatizados.","title":"Implementando Testes Automatizados de Ponta a Ponta (E2E) com Cole\u00e7\u00f5es do Postman"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#caso-de-uso-teste-funcional-manual-de-pontos-de-extremidade","text":"Um desenvolvedor ou analista de QA gostaria de testar localmente dados de entrada contra servi\u00e7os de API que compartilham um token oauth2 comum. Como resultado, eles usam o Postman para criar uma su\u00edte de testes de API de Cole\u00e7\u00f5es do Postman que podem ser executadas localmente contra pontos de extremidade individuais em diferentes ambientes. Ap\u00f3s validar que sua Cole\u00e7\u00e3o do Postman funciona, eles a compartilham com sua equipe. Os passos podem ser os seguintes: Para cada um dos seus servi\u00e7os de API existentes, use o recurso de importa\u00e7\u00e3o do IDE do Postman para importar sua Especifica\u00e7\u00e3o OpenAPI (Swagger) como uma Cole\u00e7\u00e3o do Postman. Se um servi\u00e7o ainda n\u00e3o estiver usando o Swagger, procure orienta\u00e7\u00f5es espec\u00edficas de linguagem sobre como usar o Swagger para gerar uma Especifica\u00e7\u00e3o OpenAPI para o seu servi\u00e7o. Finalmente, se o seu servi\u00e7o tiver apenas alguns pontos de extremidade, leia a documenta\u00e7\u00e3o do Postman para orienta\u00e7\u00f5es sobre como criar manualmente uma Cole\u00e7\u00e3o do Postman. Forne\u00e7a clareza extra sobre uma requisi\u00e7\u00e3o em uma Cole\u00e7\u00e3o do Postman usando o recurso Exemplo do Postman para salvar suas respostas como exemplos. Voc\u00ea tamb\u00e9m pode simplesmente adicionar um exemplo manualmente. Por favor, leia a documenta\u00e7\u00e3o do Postman para orienta\u00e7\u00f5es sobre como especificar exemplos. Combine cada Cole\u00e7\u00e3o do Postman em uma Cole\u00e7\u00e3o do Postman centralizada. Construa arquivos de Ambiente do Postman (local, Dev e/ou QA) e parametrize todas as requisi\u00e7\u00f5es salvas da Cole\u00e7\u00e3o do Postman de forma que referencie os arquivos de Ambiente do Postman. Use o recurso de Script do Postman para criar um script de pr\u00e9-busca compartilhado que atualiza automaticamente os tokens de autentica\u00e7\u00e3o expirados por requisi\u00e7\u00e3o salva. Isso exigiria referenciar segredos de um arquivo de Ambiente do Postman. // Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. /* A requisi\u00e7\u00e3o para um ponto de extremidade de autoriza\u00e7\u00e3o oauth2 que emitir\u00e1 um token com base nas credenciais fornecidas. */ const oauth2Request = POST {...}; var getToken = true ; if ( pm . environment . get ( 'ACCESS_TOKEN_EXPIRY' ) <= ( new Date ()). getTime ()) { console . log ( 'Token expirou' ) } else { getToken = false ; console . log ( 'Token e data de expira\u00e7\u00e3o est\u00e3o bons' ); } if ( getToken === true ) { pm . sendRequest ( oauth2Request , function ( _ , res ) { console . log ( 'Salve o token' ) var responseJson = res . json (); pm . environment . set ( 'token' , responseJson . access_token ) console . log ( 'Salve a data de expira\u00e7\u00e3o' ) var expiryDate = new Date (); expiryDate . setSeconds ( expiryDate . getSeconds () + responseJson . expires_in ); pm . environment . set ( 'ACCESS_TOKEN_EXPIRY' , expiryDate . getTime ()); }); } Use o IDE do Postman para exercitar pontos de extremidade. Exporte a cole\u00e7\u00e3o e os arquivos de ambiente e, em seguida, remova quaisquer segredos antes de fazer o commit no seu reposit\u00f3rio. Come\u00e7ar com essa abordagem tem as seguintes vantagens: Voc\u00ea se preparou para as etapas iniciais de uma cole\u00e7\u00e3o de postman E2E, agregando as cole\u00e7\u00f5es em um \u00fanico arquivo e usando arquivos de ambiente para facilitar a troca de ambientes. O token \u00e9 atualizado automaticamente em cada chamada na cole\u00e7\u00e3o. Isso economiza tempo normalmente perdido ao ter que solicitar manualmente um token que expirou. Concede ao QA/Dev controle granular para enviar combina\u00e7\u00f5es de dados de entrada por ponto de extremidade. Concede aos desenvolvedores uma experi\u00eancia comum por meio dos recursos do IDE do Postman. Terminar com essa abordagem tem as seguintes desvantagens: Promove o compartilhamento inseguro de segredos. As credenciais necess\u00e1rias para solicitar o token JWT no script de pr\u00e9-busca est\u00e3o sendo compartilhadas manualmente. Segredos podem acabar sendo expostos no hist\u00f3rico de commits do git por v\u00e1rias raz\u00f5es (ex. Compartilhando os arquivos de Ambiente do Postman exportados). As cole\u00e7\u00f5es s\u00f3 podem ser usadas localmente para acessar APIs (locais ou implantadas). N\u00e3o \u00e9 baseado em CI. Cada desenvolvedor tem que manter atualizados tanto sua Cole\u00e7\u00e3o do Postman quanto seus arquivos de Ambiente do Postman para acompanhar as \u00faltimas altera\u00e7\u00f5es nos servi\u00e7os implantados.","title":"Caso de Uso - Teste Funcional Manual de Pontos de Extremidade"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#caso-de-uso-teste-funcional-manual-de-pontos-de-extremidade-com-azure-key-vault-e-azure-app-config","text":"Um desenvolvedor ou analista de QA pode ter uma su\u00edte de testes de API existente de Cole\u00e7\u00f5es do Postman; no entanto, agora eles querem desencorajar o compartilhamento inseguro de segredos. Como resultado, eles constroem um script que se conecta tanto ao Key Vault quanto ao Azure App Config para gerar automaticamente arquivos de Ambiente do Postman, em vez de registr\u00e1-los em um reposit\u00f3rio compartilhado. Os passos podem ser os seguintes: Crie um Azure Key Vault e armazene segredos de autentica\u00e7\u00e3o por ambiente: - \"Chave:valor\" (ex. \"dev-auth-password:12345\" ) - \"Chave:valor\" (ex. \"qa-auth-password:12345\" ) Crie uma inst\u00e2ncia compartilhada do Azure App Configuration e salve todas as suas vari\u00e1veis de ambiente do Postman. Esta inst\u00e2ncia ser\u00e1 dedicada a manter todas as suas vari\u00e1veis de ambiente do Postman: > NOTA: Use o recurso de R\u00f3tulo (Label) para distinguir entre ambientes. - \"Chave:valor\" -> \"apiRoute:url\" (ex. \"servicename:https://servicename.net\" & R\u00f3tulo = \"QA\" ) - \"Chave:valor\" -> \"Header:value\" (ex. \"token: \" & R\u00f3tulo = \"QA\" ) - \"Chave:valor\" -> \"KeyVaultKey:KeyVaultSecret\" (ex. \"authpassword:qa-auth-password\" & R\u00f3tulo = \"QA\" ) Instale o Powershell ou o Bash. O Powershell funciona tanto para o Azure Powershell quanto para o Azure CLI. Baixe o Azure CLI, fa\u00e7a login na assinatura apropriada e certifique-se de ter acesso aos recursos apropriados. Alguns comandos \u00fateis est\u00e3o abaixo: # fazer login na assinatura apropriada az login # validar o login az account show # validar o acesso ao Key Vault az keyvault secret list - -vault-name \"$KeyvaultName\" # validar o acesso ao App Configuration az appconfig kv list - -name \"$AppConfigName\" Construa um script que gere automaticamente seus arquivos de ambiente. > NOTA: O App Configuration faz refer\u00eancia ao Key Vault; no entanto, seu script \u00e9 respons\u00e1vel por autenticar adequadamente tanto no App Configuration quanto no Key Vault. Os dois servi\u00e7os n\u00e3o se comunicam diretamente. ```powershell (CreatePostmanEnvironmentFiles.ps1) # Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. ############################################################ env = $arg1 # 1. listar vari\u00e1veis de ambiente do app para um ambiente envVars = az appconfig kv list --name PostmanAppConfig --label $env | ConvertFrom-Json # 2. percorrer o array envVars para obter URIs do Key Vault keyvaultURI = \"\" $envVars | % {if($ .key -eq 'password'){keyvaultURI = $ .value}} # 3. analisar URIs para obter o nome do Key Vault e os nomes dos segredos # 4. obter segredo do Key Vault kvsecret = az keyvault secret show --name $secretName --vault-name $keyvaultName --query \"value\" # 5. definir o valor da senha para o segredo retornado do Key Vault $envVars | % {if($ .key -eq 'password'){$ .value=$kvsecret}} # 6. criar arquivo de ambiente envFile = @{ \"_postman_variable_scope\" = \"environment\", \"name\" = $env, values = @() } foreach($var in $envVars){ $envFile.values += @{ key = $var.key; value = $var.value; } } $envFile | ConvertTo-Json -depth 50 | Out-File -encoding ASCII -FilePath .\\$env.postman_environment.json ``` Use o IDE do Postman para importar os arquivos de Ambiente do Postman a serem referenciados pela sua cole\u00e7\u00e3o. Esta abordagem tem as seguintes vantagens: Herda todas as vantagens do caso anterior. Desencoraja o compartilhamento inseguro de segredos. Os segredos agora s\u00e3o retirados do Key Vault via Azure CLI. A URI do Key Vault tamb\u00e9m n\u00e3o precisa mais ser compartilhada para acesso aos tokens de autentica\u00e7\u00e3o. Fonte \u00fanica de verdade para arquivos de Ambiente do Postman. N\u00e3o h\u00e1 mais necessidade de compartilh\u00e1-los via reposit\u00f3rio. O desenvolvedor s\u00f3 precisa gerenciar uma \u00fanica Cole\u00e7\u00e3o do Postman. Terminar com essa abordagem tem as seguintes desvantagens: Segredos podem acabar sendo expostos no hist\u00f3rico de commits do git se .gitIgnore n\u00e3o for atualizado para ignorar arquivos de Ambiente do Postman. As cole\u00e7\u00f5es s\u00f3 podem ser usadas localmente para acessar APIs (locais ou implantadas). N\u00e3o \u00e9 baseado em CI.","title":"Caso de Uso - Teste Funcional Manual de Pontos de Extremidade com Azure Key Vault e Azure App Config"},{"location":"automated-testing/e2e-testing/recipes/postman-testing/#caso-de-uso-testes-e2e-com-integracao-continua-e-newman","text":"Um desenvolvedor ou analista de QA pode ter uma su\u00edte de testes de API existente de Cole\u00e7\u00f5es do Postman locais que seguem as melhores pr\u00e1ticas de seguran\u00e7a para desenvolvimento; no entanto, agora eles querem que os testes E2E sejam executados como parte de um pipeline de CI automatizado. Com o advento do Newman, voc\u00ea pode agora usar mais prontamente o Postman para criar uma su\u00edte de testes de API execut\u00e1vel no seu CI. Os passos podem ser os seguintes: Atualize sua Cole\u00e7\u00e3o do Postman para usar o recurso de Teste do Postman para criar afirma\u00e7\u00f5es de teste que cobrir\u00e3o todas as solicita\u00e7\u00f5es salvas de ponta a ponta. Leia a documenta\u00e7\u00e3o do Postman para orienta\u00e7\u00e3o sobre como usar o recurso de Teste do Postman. Use localmente o Newman para validar que os testes est\u00e3o funcionando conforme o esperado. newman run tests \\ e2e_Postman_collection . json -e qa . postman_environment . json Construa um script que execute automaticamente as afirma\u00e7\u00f5es de teste do Postman via Newman e Azure CLI. > NOTA: Um Service Principal do Azure deve ser configurado para continuar usando o azure cli neste exemplo de pipeline de CI. ```powershell (RunPostmanE2eTests.ps1) # Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. ############################################################ # 1. fa\u00e7a login no Azure usando um Service Principal az login --service-principal -u $APP_ID -p $AZURE_SECRET --tenant $AZURE_TENANT # 2. liste as vari\u00e1veis de ambiente do app para um ambiente envVars = az appconfig kv list --name PostmanAppConfig --label $env | ConvertFrom-Json # 3. percorra o array envVars para obter URIs do Key Vault keyvaultURI = \"\" @envVars | % {if($ .key -eq 'password'){keyvaultURI = $ .value}} # 4. analise URIs para obter o nome do Key Vault e os nomes dos segredos # 5. obtenha o segredo do Key Vault kvsecret = az keyvault secret show --name $secretName --vault-name $keyvaultName --query \"value\" # 6. defina o valor da senha para o segredo retornado do Key Vault $envVars | % {if($ .key -eq 'password'){$ .value=$kvsecret}} # 7. crie o arquivo de ambiente envFile = @{ \"_postman_variable_scope\" = \"environment\", \"name\" = $env, values = @() } foreach($var in $envVars){ $envFile.values += @{ key = $var.key; value = $var.value; } } $envFile | ConvertTo-Json -depth 50 | Out-File -encoding ASCII $env.postman_environment.json # 8. instale o Newman npm install --save-dev newman # 9. execute testes E2E automatizados via Newman node_modules.bin\\newman run tests\\e2e_Postman_collection.json -e $env.postman_environment.json ``` Crie um arquivo yaml e defina um passo que executar\u00e1 seu script de teste. (ex. Um arquivo yaml direcionado para o Azure Devops que executa um script Powershell.) # Por favor, trate isso como pseudoc\u00f3digo e ajuste conforme necess\u00e1rio. ############################################################ displayName : 'Executar testes E2E do Postman' inputs : targetType : 'filePath' filePath : RunPostmanE2eTests.ps1 env : APP_ID : $(environment.appId) # credenciais para az cli AZURE_SECRET : $(environment.secret) AZURE_TENANT : $(environment.tenant) Esta abordagem tem a seguinte vantagem: Os testes E2E agora podem ser executados automaticamente como parte de um pipeline de CI. Terminar com essa abordagem tem a seguinte desvantagem: Os arquivos de Ambiente do Postman n\u00e3o est\u00e3o mais sendo gerados em um ambiente local para testes manuais pr\u00e1ticos. No entanto, isso pode ser resolvido gerenciando dois scripts.","title":"Caso de Uso - Testes E2E com Integra\u00e7\u00e3o Cont\u00ednua e Newman"},{"location":"automated-testing/fault-injection-testing/","text":"Teste de Inje\u00e7\u00e3o de Falhas O teste de inje\u00e7\u00e3o de falhas \u00e9 a introdu\u00e7\u00e3o deliberada de erros e falhas em um sistema para validar e fortalecer sua estabilidade e confiabilidade . O objetivo \u00e9 melhorar o design do sistema para resili\u00eancia e desempenho sob condi\u00e7\u00f5es intermitentes de falha ao longo do tempo. Quando Usar Problema Abordado Os sistemas precisam ser resilientes \u00e0s condi\u00e7\u00f5es que causam interrup\u00e7\u00f5es inevit\u00e1veis na produ\u00e7\u00e3o. Aplica\u00e7\u00f5es modernas s\u00e3o constru\u00eddas com um n\u00famero crescente de depend\u00eancias; em infraestrutura, plataforma, rede, software de terceiros ou APIs, etc. Tais sistemas aumentam o risco de impacto de interrup\u00e7\u00f5es de depend\u00eancia. Cada componente dependente pode falhar. Al\u00e9m disso, suas intera\u00e7\u00f5es com outros componentes podem propagar a falha. M\u00e9todos de inje\u00e7\u00e3o de falhas s\u00e3o uma forma de aumentar a cobertura e validar a robustez do software e o tratamento de erros, seja no momento da constru\u00e7\u00e3o ou em tempo de execu\u00e7\u00e3o, com a inten\u00e7\u00e3o de \"abra\u00e7ar a falha\" como parte do ciclo de vida do desenvolvimento. Esses m\u00e9todos auxiliam as equipes de engenharia no projeto e na valida\u00e7\u00e3o cont\u00ednua para falhas, contabilizando condi\u00e7\u00f5es de falha conhecidas e desconhecidas, arquitetura para redund\u00e2ncia, emprego de mecanismos de repeti\u00e7\u00e3o e retrocesso, etc. Aplic\u00e1vel a Software - Caminhos de c\u00f3digo para tratamento de erros, gerenciamento de mem\u00f3ria no processo. Exemplos de testes: Testes de unidade/integra\u00e7\u00e3o de casos extremos e/ou testes de carga (ou seja, stress e soak). Protocolo - Vulnerabilidades em interfaces de comunica\u00e7\u00e3o, como par\u00e2metros de linha de comando ou APIs. Exemplos de testes: Fuzzing fornece dados inv\u00e1lidos, inesperados ou aleat\u00f3rios como entrada, podemos avaliar o n\u00edvel de estabilidade do protocolo de um componente. Infraestrutura - Interrup\u00e7\u00f5es, problemas de rede, falhas de hardware. Exemplos de testes: Usar diferentes m\u00e9todos para causar falha na infraestrutura subjacente, como desligar inst\u00e2ncias de m\u00e1quinas virtuais (VM), travar processos, expirar certificados, introduzir lat\u00eancia de rede, etc. Esse n\u00edvel de teste depende de observa\u00e7\u00f5es de m\u00e9tricas estat\u00edsticas ao longo do tempo e da medi\u00e7\u00e3o dos desvios de seu comportamento observado durante a falha, ou de seu tempo de recupera\u00e7\u00e3o. Como Usar Arquitetura Terminologia Falha - A causa julgada ou hipotetizada de um erro. Erro - Aquela parte do estado do sistema que pode causar uma falha subsequente. Falha - Um evento que ocorre quando o servi\u00e7o prestado se desvia do estado correto. Ciclo Falha-Erro-Falha - Um mecanismo chave em confiabilidade : Uma falha pode causar um erro. Um erro pode causar mais erros dentro do limite do sistema; portanto, cada novo erro atua como uma falha. Quando estados de erro s\u00e3o observados no limite do sistema, eles s\u00e3o denominados falhas. (Modelado por Laprie/Avizienis ) Fundamentos do Teste de Inje\u00e7\u00e3o de Falhas A inje\u00e7\u00e3o de falhas \u00e9 uma forma avan\u00e7ada de teste em que o sistema \u00e9 submetido a diferentes modos de falha , e onde o engenheiro de teste pode saber antecipadamente qual \u00e9 o resultado esperado, como no caso de testes de valida\u00e7\u00e3o de lan\u00e7amento, ou em uma explora\u00e7\u00e3o para encontrar problemas potenciais no produto, que devem ser mitigados. Inje\u00e7\u00e3o de Falhas e Engenharia do Caos O teste de inje\u00e7\u00e3o de falhas \u00e9 uma abordagem espec\u00edfica para testar uma condi\u00e7\u00e3o. Ele introduz uma falha em um sistema para validar sua robustez. A engenharia do caos, cunhada pela Netflix, \u00e9 uma pr\u00e1tica para gerar novas informa\u00e7\u00f5es. H\u00e1 uma sobreposi\u00e7\u00e3o de preocupa\u00e7\u00f5es e muitas vezes de ferramentas entre os termos, e muitas vezes a engenharia do caos usa inje\u00e7\u00e3o de falhas para introduzir os efeitos necess\u00e1rios no sistema. Passos de Alto N\u00edvel Teste de inje\u00e7\u00e3o de falhas no ciclo de desenvolvimento A inje\u00e7\u00e3o de falhas \u00e9 uma forma eficaz de encontrar bugs de seguran\u00e7a no software, tanto que o Ciclo de Desenvolvimento de Seguran\u00e7a da Microsoft exige fuzzing em todas as interfaces n\u00e3o confi\u00e1veis de cada produto e teste de penetra\u00e7\u00e3o, que inclui a introdu\u00e7\u00e3o de falhas no sistema, para descobrir vulnerabilidades potenciais resultantes de erros de codifica\u00e7\u00e3o, falhas de configura\u00e7\u00e3o do sistema ou outras fraquezas operacionais de implanta\u00e7\u00e3o. A cobertura automatizada de inje\u00e7\u00e3o de falhas em um pipeline de CI promove uma abordagem Shift-Left de teste mais cedo no ciclo de vida para poss\u00edveis problemas. Exemplos de realiza\u00e7\u00e3o de inje\u00e7\u00e3o de falhas durante o ciclo de vida do desenvolvimento: Usando ferramentas de fuzzing no CI. Executar testes de cen\u00e1rio de ponta a ponta existentes (como testes de integra\u00e7\u00e3o ou de estresse), que s\u00e3o aumentados com inje\u00e7\u00e3o de falhas. Escrever testes de regress\u00e3o e aceita\u00e7\u00e3o com base em problemas que foram encontrados e corrigidos ou com base em incidentes de servi\u00e7o resolvidos. Valida\u00e7\u00f5es ad-hoc (manuais) de falha no ambiente de desenvolvimento para novos recursos. Teste de inje\u00e7\u00e3o de falhas no ciclo de lan\u00e7amento Muito parecido com Testes de Monitoramento Sint\u00e9tico , o teste de inje\u00e7\u00e3o de falhas no ciclo de lan\u00e7amento faz parte da abordagem de teste Shift-Right , que usa m\u00e9todos seguros para realizar testes em um ambiente de produ\u00e7\u00e3o ou pr\u00e9-produ\u00e7\u00e3o. Dada a natureza das aplica\u00e7\u00f5es distribu\u00eddas baseadas em nuvem, \u00e9 muito dif\u00edcil simular o comportamento real dos servi\u00e7os fora de seu ambiente de produ\u00e7\u00e3o. Os testadores s\u00e3o incentivados a executar testes onde realmente importa, em um sistema ao vivo com tr\u00e1fego de clientes. Os testes de inje\u00e7\u00e3o de falhas dependem da observabilidade de m\u00e9tricas e geralmente s\u00e3o estat\u00edsticos; Os seguintes passos de alto n\u00edvel fornecem uma amostra de como praticar inje\u00e7\u00e3o de falhas e engenharia do caos: Medir e definir um estado est\u00e1vel (saud\u00e1vel) para a interoperabilidade do sistema. Criar hip\u00f3teses com base no comportamento previsto quando uma falha \u00e9 introduzida. Introduzir eventos de falha do mundo real no sistema. Medir o estado e compar\u00e1-lo ao estado de refer\u00eancia. Documentar o processo e as observa\u00e7\u00f5es. Identificar e agir com base no resultado. Teste de inje\u00e7\u00e3o de falhas em Kubernetes Com o avan\u00e7o do Kubernetes (k8s) como plataforma de infraestrutura, o teste de inje\u00e7\u00e3o de falhas em Kubernetes tornou-se inevit\u00e1vel para garantir que o sistema se comporte de maneira confi\u00e1vel no caso de uma falha ou falha. Pode haver diferentes tipos de cargas de trabalho rodando dentro de um cluster k8s que s\u00e3o escritas em diferentes linguagens. Por exemplo, dentro de um cluster K8s, voc\u00ea pode executar um microservi\u00e7o, um aplicativo web e/ou um trabalho agendado. Portanto, voc\u00ea precisa ter um mecanismo para injetar falhas em qualquer tipo de carga de trabalho rodando dentro do cluster. Al\u00e9m disso, os clusters Kubernetes s\u00e3o gerenciados de forma diferente da infraestrutura tradicional. As ferramentas usadas para teste de inje\u00e7\u00e3o de falhas dentro do Kubernetes devem ter compatibilidade com a infraestrutura k8s. Estas s\u00e3o as principais caracter\u00edsticas que s\u00e3o necess\u00e1rias: Facilidade de injetar falhas em pods do Kubernetes. Suporte para instala\u00e7\u00e3o r\u00e1pida de ferramentas dentro do cluster. Suporte para configura\u00e7\u00f5es baseadas em YAML que funcionam bem com o Kubernetes. Facilidade de personaliza\u00e7\u00e3o para adicionar recursos personalizados. Suporte para fluxos de trabalho para implantar v\u00e1rias cargas de trabalho e falhas. Facilidade de manuten\u00e7\u00e3o da ferramenta. Facilidade de integra\u00e7\u00e3o com telemetria. Melhores Pr\u00e1ticas e Conselhos Experimentar na produ\u00e7\u00e3o tem o benef\u00edcio de executar testes contra um sistema ao vivo com tr\u00e1fego real de usu\u00e1rios, garantindo sua sa\u00fade ou construindo confian\u00e7a em sua capacidade de lidar com erros de forma elegante. No entanto, tem o potencial de causar dor desnecess\u00e1ria ao cliente. Um teste pode ter sucesso ou falhar. No caso de falha, \u00e9 prov\u00e1vel que haja algum impacto no ambiente de produ\u00e7\u00e3o. Pensar sobre o Raio de Explos\u00e3o do efeito, caso o teste falhe, \u00e9 um passo crucial a ser realizado previamente. As seguintes pr\u00e1ticas podem ajudar a minimizar esse risco: Execute testes em um ambiente n\u00e3o produtivo primeiro. Entenda como o sistema se comporta em um ambiente seguro, usando carga de trabalho sint\u00e9tica, antes de introduzir riscos potenciais ao tr\u00e1fego do cliente. Use inje\u00e7\u00e3o de falhas como port\u00f5es em diferentes est\u00e1gios ao longo do pipeline de CD. Implantar e testar em implanta\u00e7\u00f5es Blue/Green e Canary. Use m\u00e9todos como sombreamento de tr\u00e1fego (tamb\u00e9m conhecido como Tr\u00e1fego Escuro ) para levar o tr\u00e1fego do cliente ao slot de staging. Esforce-se para alcan\u00e7ar um equil\u00edbrio entre coletar dados de resultados reais, afetando o m\u00ednimo poss\u00edvel de usu\u00e1rios de produ\u00e7\u00e3o. Use princ\u00edpios de design defensivo, como circuit breaking e os padr\u00f5es de anteparo. Acordar um or\u00e7amento (em termos de Objetivo de N\u00edvel de Servi\u00e7o (SLO)) como um investimento em caos e inje\u00e7\u00e3o de falhas. Aumente o risco de forma incremental - Comece fortalecendo o n\u00facleo e expanda em camadas. Em cada ponto, o progresso deve ser consolidado com testes de regress\u00e3o automatizados. Frameworks e Ferramentas de Teste de Inje\u00e7\u00e3o de Falhas Fuzzing OneFuzz - \u00e9 uma plataforma de fuzzing como servi\u00e7o de c\u00f3digo aberto da Microsoft que \u00e9 f\u00e1cil de integrar em pipelines de CI. AFL e WinAFL - Ferramentas de fuzz populares da equipe do projeto zero do Google, que s\u00e3o usadas localmente para direcionar bin\u00e1rios no Linux ou Windows. WebScarab - Um fuzzer focado na web de propriedade da OWASP, que pode ser encontrado nas distribui\u00e7\u00f5es Kali Linux . Caos Azure Chaos Studio - Uma ferramenta em pr\u00e9-visualiza\u00e7\u00e3o para orquestrar experimentos controlados de inje\u00e7\u00e3o de falhas em recursos do Azure. Chaos toolkit - Uma plataforma de caos declarativa e modular com muitas extens\u00f5es, incluindo o kit de a\u00e7\u00f5es e sondas do Azure . Kraken - Uma ferramenta de caos espec\u00edfica do Openshift, mantida pela Redhat. Chaos Monkey - A plataforma da Netflix que popularizou a engenharia do caos (n\u00e3o suporta Azure OOTB). Simmy - Uma biblioteca .NET para testes de caos e inje\u00e7\u00e3o de falhas integrada \u00e0 biblioteca Polly para engenharia de resili\u00eancia. Litmus - Uma ferramenta de c\u00f3digo aberto do CNCF para testes de caos e inje\u00e7\u00e3o de falhas para clusters Kubernetes. Este post no blog de desenvolvimento da ISE fornece trechos de c\u00f3digo como um exemplo de como usar Polly e Simmy para implementar uma abordagem baseada em hip\u00f3teses para resili\u00eancia e testes de caos. Conclus\u00e3o A partir dos princ\u00edpios do caos: \"Quanto mais dif\u00edcil \u00e9 perturbar o estado est\u00e1vel, mais confian\u00e7a temos no comportamento do sistema. Se uma fraqueza \u00e9 descoberta, agora temos um alvo para melhoria antes que esse comportamento se manifeste no sistema como um todo\". As t\u00e9cnicas de inje\u00e7\u00e3o de falhas aumentam a resili\u00eancia e a confian\u00e7a nos produtos que enviamos. Elas s\u00e3o usadas em toda a ind\u00fastria para validar aplica\u00e7\u00f5es e plataformas antes e enquanto s\u00e3o entregues aos clientes. A inje\u00e7\u00e3o de falhas \u00e9 uma ferramenta poderosa e deve ser usada com cautela. Casos como o apag\u00e3o global de 30 minutos da Cloudflare , que foi causado devido a uma implanta\u00e7\u00e3o de c\u00f3digo que deveria ser \"lan\u00e7ada \u00e0s escuras\", destacam a import\u00e2ncia de limitar o raio de explos\u00e3o no sistema durante experimentos. Recursos Post no blog de Mark Russinovich sobre inje\u00e7\u00e3o de falhas e engenharia do caos Post no blog de Cindy Sridharan sobre testes em produ\u00e7\u00e3o Continua\u00e7\u00e3o do post no blog de Cindy Sridharan sobre testes em produ\u00e7\u00e3o Inje\u00e7\u00e3o de falhas na Azure Search Framework de Arquitetura Azure - Engenharia do Caos Framework de Arquitetura Azure - Testando resili\u00eancia Panorama dos Modelos de Causa de Falha de Software","title":"Teste de Inje\u00e7\u00e3o de Falhas"},{"location":"automated-testing/fault-injection-testing/#teste-de-injecao-de-falhas","text":"O teste de inje\u00e7\u00e3o de falhas \u00e9 a introdu\u00e7\u00e3o deliberada de erros e falhas em um sistema para validar e fortalecer sua estabilidade e confiabilidade . O objetivo \u00e9 melhorar o design do sistema para resili\u00eancia e desempenho sob condi\u00e7\u00f5es intermitentes de falha ao longo do tempo.","title":"Teste de Inje\u00e7\u00e3o de Falhas"},{"location":"automated-testing/fault-injection-testing/#quando-usar","text":"","title":"Quando Usar"},{"location":"automated-testing/fault-injection-testing/#problema-abordado","text":"Os sistemas precisam ser resilientes \u00e0s condi\u00e7\u00f5es que causam interrup\u00e7\u00f5es inevit\u00e1veis na produ\u00e7\u00e3o. Aplica\u00e7\u00f5es modernas s\u00e3o constru\u00eddas com um n\u00famero crescente de depend\u00eancias; em infraestrutura, plataforma, rede, software de terceiros ou APIs, etc. Tais sistemas aumentam o risco de impacto de interrup\u00e7\u00f5es de depend\u00eancia. Cada componente dependente pode falhar. Al\u00e9m disso, suas intera\u00e7\u00f5es com outros componentes podem propagar a falha. M\u00e9todos de inje\u00e7\u00e3o de falhas s\u00e3o uma forma de aumentar a cobertura e validar a robustez do software e o tratamento de erros, seja no momento da constru\u00e7\u00e3o ou em tempo de execu\u00e7\u00e3o, com a inten\u00e7\u00e3o de \"abra\u00e7ar a falha\" como parte do ciclo de vida do desenvolvimento. Esses m\u00e9todos auxiliam as equipes de engenharia no projeto e na valida\u00e7\u00e3o cont\u00ednua para falhas, contabilizando condi\u00e7\u00f5es de falha conhecidas e desconhecidas, arquitetura para redund\u00e2ncia, emprego de mecanismos de repeti\u00e7\u00e3o e retrocesso, etc.","title":"Problema Abordado"},{"location":"automated-testing/fault-injection-testing/#aplicavel-a","text":"Software - Caminhos de c\u00f3digo para tratamento de erros, gerenciamento de mem\u00f3ria no processo. Exemplos de testes: Testes de unidade/integra\u00e7\u00e3o de casos extremos e/ou testes de carga (ou seja, stress e soak). Protocolo - Vulnerabilidades em interfaces de comunica\u00e7\u00e3o, como par\u00e2metros de linha de comando ou APIs. Exemplos de testes: Fuzzing fornece dados inv\u00e1lidos, inesperados ou aleat\u00f3rios como entrada, podemos avaliar o n\u00edvel de estabilidade do protocolo de um componente. Infraestrutura - Interrup\u00e7\u00f5es, problemas de rede, falhas de hardware. Exemplos de testes: Usar diferentes m\u00e9todos para causar falha na infraestrutura subjacente, como desligar inst\u00e2ncias de m\u00e1quinas virtuais (VM), travar processos, expirar certificados, introduzir lat\u00eancia de rede, etc. Esse n\u00edvel de teste depende de observa\u00e7\u00f5es de m\u00e9tricas estat\u00edsticas ao longo do tempo e da medi\u00e7\u00e3o dos desvios de seu comportamento observado durante a falha, ou de seu tempo de recupera\u00e7\u00e3o.","title":"Aplic\u00e1vel a"},{"location":"automated-testing/fault-injection-testing/#como-usar","text":"","title":"Como Usar"},{"location":"automated-testing/fault-injection-testing/#arquitetura","text":"","title":"Arquitetura"},{"location":"automated-testing/fault-injection-testing/#terminologia","text":"Falha - A causa julgada ou hipotetizada de um erro. Erro - Aquela parte do estado do sistema que pode causar uma falha subsequente. Falha - Um evento que ocorre quando o servi\u00e7o prestado se desvia do estado correto. Ciclo Falha-Erro-Falha - Um mecanismo chave em confiabilidade : Uma falha pode causar um erro. Um erro pode causar mais erros dentro do limite do sistema; portanto, cada novo erro atua como uma falha. Quando estados de erro s\u00e3o observados no limite do sistema, eles s\u00e3o denominados falhas. (Modelado por Laprie/Avizienis )","title":"Terminologia"},{"location":"automated-testing/fault-injection-testing/#fundamentos-do-teste-de-injecao-de-falhas","text":"A inje\u00e7\u00e3o de falhas \u00e9 uma forma avan\u00e7ada de teste em que o sistema \u00e9 submetido a diferentes modos de falha , e onde o engenheiro de teste pode saber antecipadamente qual \u00e9 o resultado esperado, como no caso de testes de valida\u00e7\u00e3o de lan\u00e7amento, ou em uma explora\u00e7\u00e3o para encontrar problemas potenciais no produto, que devem ser mitigados.","title":"Fundamentos do Teste de Inje\u00e7\u00e3o de Falhas"},{"location":"automated-testing/fault-injection-testing/#injecao-de-falhas-e-engenharia-do-caos","text":"O teste de inje\u00e7\u00e3o de falhas \u00e9 uma abordagem espec\u00edfica para testar uma condi\u00e7\u00e3o. Ele introduz uma falha em um sistema para validar sua robustez. A engenharia do caos, cunhada pela Netflix, \u00e9 uma pr\u00e1tica para gerar novas informa\u00e7\u00f5es. H\u00e1 uma sobreposi\u00e7\u00e3o de preocupa\u00e7\u00f5es e muitas vezes de ferramentas entre os termos, e muitas vezes a engenharia do caos usa inje\u00e7\u00e3o de falhas para introduzir os efeitos necess\u00e1rios no sistema.","title":"Inje\u00e7\u00e3o de Falhas e Engenharia do Caos"},{"location":"automated-testing/fault-injection-testing/#passos-de-alto-nivel","text":"","title":"Passos de Alto N\u00edvel"},{"location":"automated-testing/fault-injection-testing/#teste-de-injecao-de-falhas-no-ciclo-de-desenvolvimento","text":"A inje\u00e7\u00e3o de falhas \u00e9 uma forma eficaz de encontrar bugs de seguran\u00e7a no software, tanto que o Ciclo de Desenvolvimento de Seguran\u00e7a da Microsoft exige fuzzing em todas as interfaces n\u00e3o confi\u00e1veis de cada produto e teste de penetra\u00e7\u00e3o, que inclui a introdu\u00e7\u00e3o de falhas no sistema, para descobrir vulnerabilidades potenciais resultantes de erros de codifica\u00e7\u00e3o, falhas de configura\u00e7\u00e3o do sistema ou outras fraquezas operacionais de implanta\u00e7\u00e3o. A cobertura automatizada de inje\u00e7\u00e3o de falhas em um pipeline de CI promove uma abordagem Shift-Left de teste mais cedo no ciclo de vida para poss\u00edveis problemas. Exemplos de realiza\u00e7\u00e3o de inje\u00e7\u00e3o de falhas durante o ciclo de vida do desenvolvimento: Usando ferramentas de fuzzing no CI. Executar testes de cen\u00e1rio de ponta a ponta existentes (como testes de integra\u00e7\u00e3o ou de estresse), que s\u00e3o aumentados com inje\u00e7\u00e3o de falhas. Escrever testes de regress\u00e3o e aceita\u00e7\u00e3o com base em problemas que foram encontrados e corrigidos ou com base em incidentes de servi\u00e7o resolvidos. Valida\u00e7\u00f5es ad-hoc (manuais) de falha no ambiente de desenvolvimento para novos recursos.","title":"Teste de inje\u00e7\u00e3o de falhas no ciclo de desenvolvimento"},{"location":"automated-testing/fault-injection-testing/#teste-de-injecao-de-falhas-no-ciclo-de-lancamento","text":"Muito parecido com Testes de Monitoramento Sint\u00e9tico , o teste de inje\u00e7\u00e3o de falhas no ciclo de lan\u00e7amento faz parte da abordagem de teste Shift-Right , que usa m\u00e9todos seguros para realizar testes em um ambiente de produ\u00e7\u00e3o ou pr\u00e9-produ\u00e7\u00e3o. Dada a natureza das aplica\u00e7\u00f5es distribu\u00eddas baseadas em nuvem, \u00e9 muito dif\u00edcil simular o comportamento real dos servi\u00e7os fora de seu ambiente de produ\u00e7\u00e3o. Os testadores s\u00e3o incentivados a executar testes onde realmente importa, em um sistema ao vivo com tr\u00e1fego de clientes. Os testes de inje\u00e7\u00e3o de falhas dependem da observabilidade de m\u00e9tricas e geralmente s\u00e3o estat\u00edsticos; Os seguintes passos de alto n\u00edvel fornecem uma amostra de como praticar inje\u00e7\u00e3o de falhas e engenharia do caos: Medir e definir um estado est\u00e1vel (saud\u00e1vel) para a interoperabilidade do sistema. Criar hip\u00f3teses com base no comportamento previsto quando uma falha \u00e9 introduzida. Introduzir eventos de falha do mundo real no sistema. Medir o estado e compar\u00e1-lo ao estado de refer\u00eancia. Documentar o processo e as observa\u00e7\u00f5es. Identificar e agir com base no resultado.","title":"Teste de inje\u00e7\u00e3o de falhas no ciclo de lan\u00e7amento"},{"location":"automated-testing/fault-injection-testing/#teste-de-injecao-de-falhas-em-kubernetes","text":"Com o avan\u00e7o do Kubernetes (k8s) como plataforma de infraestrutura, o teste de inje\u00e7\u00e3o de falhas em Kubernetes tornou-se inevit\u00e1vel para garantir que o sistema se comporte de maneira confi\u00e1vel no caso de uma falha ou falha. Pode haver diferentes tipos de cargas de trabalho rodando dentro de um cluster k8s que s\u00e3o escritas em diferentes linguagens. Por exemplo, dentro de um cluster K8s, voc\u00ea pode executar um microservi\u00e7o, um aplicativo web e/ou um trabalho agendado. Portanto, voc\u00ea precisa ter um mecanismo para injetar falhas em qualquer tipo de carga de trabalho rodando dentro do cluster. Al\u00e9m disso, os clusters Kubernetes s\u00e3o gerenciados de forma diferente da infraestrutura tradicional. As ferramentas usadas para teste de inje\u00e7\u00e3o de falhas dentro do Kubernetes devem ter compatibilidade com a infraestrutura k8s. Estas s\u00e3o as principais caracter\u00edsticas que s\u00e3o necess\u00e1rias: Facilidade de injetar falhas em pods do Kubernetes. Suporte para instala\u00e7\u00e3o r\u00e1pida de ferramentas dentro do cluster. Suporte para configura\u00e7\u00f5es baseadas em YAML que funcionam bem com o Kubernetes. Facilidade de personaliza\u00e7\u00e3o para adicionar recursos personalizados. Suporte para fluxos de trabalho para implantar v\u00e1rias cargas de trabalho e falhas. Facilidade de manuten\u00e7\u00e3o da ferramenta. Facilidade de integra\u00e7\u00e3o com telemetria.","title":"Teste de inje\u00e7\u00e3o de falhas em Kubernetes"},{"location":"automated-testing/fault-injection-testing/#melhores-praticas-e-conselhos","text":"Experimentar na produ\u00e7\u00e3o tem o benef\u00edcio de executar testes contra um sistema ao vivo com tr\u00e1fego real de usu\u00e1rios, garantindo sua sa\u00fade ou construindo confian\u00e7a em sua capacidade de lidar com erros de forma elegante. No entanto, tem o potencial de causar dor desnecess\u00e1ria ao cliente. Um teste pode ter sucesso ou falhar. No caso de falha, \u00e9 prov\u00e1vel que haja algum impacto no ambiente de produ\u00e7\u00e3o. Pensar sobre o Raio de Explos\u00e3o do efeito, caso o teste falhe, \u00e9 um passo crucial a ser realizado previamente. As seguintes pr\u00e1ticas podem ajudar a minimizar esse risco: Execute testes em um ambiente n\u00e3o produtivo primeiro. Entenda como o sistema se comporta em um ambiente seguro, usando carga de trabalho sint\u00e9tica, antes de introduzir riscos potenciais ao tr\u00e1fego do cliente. Use inje\u00e7\u00e3o de falhas como port\u00f5es em diferentes est\u00e1gios ao longo do pipeline de CD. Implantar e testar em implanta\u00e7\u00f5es Blue/Green e Canary. Use m\u00e9todos como sombreamento de tr\u00e1fego (tamb\u00e9m conhecido como Tr\u00e1fego Escuro ) para levar o tr\u00e1fego do cliente ao slot de staging. Esforce-se para alcan\u00e7ar um equil\u00edbrio entre coletar dados de resultados reais, afetando o m\u00ednimo poss\u00edvel de usu\u00e1rios de produ\u00e7\u00e3o. Use princ\u00edpios de design defensivo, como circuit breaking e os padr\u00f5es de anteparo. Acordar um or\u00e7amento (em termos de Objetivo de N\u00edvel de Servi\u00e7o (SLO)) como um investimento em caos e inje\u00e7\u00e3o de falhas. Aumente o risco de forma incremental - Comece fortalecendo o n\u00facleo e expanda em camadas. Em cada ponto, o progresso deve ser consolidado com testes de regress\u00e3o automatizados.","title":"Melhores Pr\u00e1ticas e Conselhos"},{"location":"automated-testing/fault-injection-testing/#frameworks-e-ferramentas-de-teste-de-injecao-de-falhas","text":"","title":"Frameworks e Ferramentas de Teste de Inje\u00e7\u00e3o de Falhas"},{"location":"automated-testing/fault-injection-testing/#fuzzing","text":"OneFuzz - \u00e9 uma plataforma de fuzzing como servi\u00e7o de c\u00f3digo aberto da Microsoft que \u00e9 f\u00e1cil de integrar em pipelines de CI. AFL e WinAFL - Ferramentas de fuzz populares da equipe do projeto zero do Google, que s\u00e3o usadas localmente para direcionar bin\u00e1rios no Linux ou Windows. WebScarab - Um fuzzer focado na web de propriedade da OWASP, que pode ser encontrado nas distribui\u00e7\u00f5es Kali Linux .","title":"Fuzzing"},{"location":"automated-testing/fault-injection-testing/#caos","text":"Azure Chaos Studio - Uma ferramenta em pr\u00e9-visualiza\u00e7\u00e3o para orquestrar experimentos controlados de inje\u00e7\u00e3o de falhas em recursos do Azure. Chaos toolkit - Uma plataforma de caos declarativa e modular com muitas extens\u00f5es, incluindo o kit de a\u00e7\u00f5es e sondas do Azure . Kraken - Uma ferramenta de caos espec\u00edfica do Openshift, mantida pela Redhat. Chaos Monkey - A plataforma da Netflix que popularizou a engenharia do caos (n\u00e3o suporta Azure OOTB). Simmy - Uma biblioteca .NET para testes de caos e inje\u00e7\u00e3o de falhas integrada \u00e0 biblioteca Polly para engenharia de resili\u00eancia. Litmus - Uma ferramenta de c\u00f3digo aberto do CNCF para testes de caos e inje\u00e7\u00e3o de falhas para clusters Kubernetes. Este post no blog de desenvolvimento da ISE fornece trechos de c\u00f3digo como um exemplo de como usar Polly e Simmy para implementar uma abordagem baseada em hip\u00f3teses para resili\u00eancia e testes de caos.","title":"Caos"},{"location":"automated-testing/fault-injection-testing/#conclusao","text":"A partir dos princ\u00edpios do caos: \"Quanto mais dif\u00edcil \u00e9 perturbar o estado est\u00e1vel, mais confian\u00e7a temos no comportamento do sistema. Se uma fraqueza \u00e9 descoberta, agora temos um alvo para melhoria antes que esse comportamento se manifeste no sistema como um todo\". As t\u00e9cnicas de inje\u00e7\u00e3o de falhas aumentam a resili\u00eancia e a confian\u00e7a nos produtos que enviamos. Elas s\u00e3o usadas em toda a ind\u00fastria para validar aplica\u00e7\u00f5es e plataformas antes e enquanto s\u00e3o entregues aos clientes. A inje\u00e7\u00e3o de falhas \u00e9 uma ferramenta poderosa e deve ser usada com cautela. Casos como o apag\u00e3o global de 30 minutos da Cloudflare , que foi causado devido a uma implanta\u00e7\u00e3o de c\u00f3digo que deveria ser \"lan\u00e7ada \u00e0s escuras\", destacam a import\u00e2ncia de limitar o raio de explos\u00e3o no sistema durante experimentos.","title":"Conclus\u00e3o"},{"location":"automated-testing/fault-injection-testing/#recursos","text":"Post no blog de Mark Russinovich sobre inje\u00e7\u00e3o de falhas e engenharia do caos Post no blog de Cindy Sridharan sobre testes em produ\u00e7\u00e3o Continua\u00e7\u00e3o do post no blog de Cindy Sridharan sobre testes em produ\u00e7\u00e3o Inje\u00e7\u00e3o de falhas na Azure Search Framework de Arquitetura Azure - Engenharia do Caos Framework de Arquitetura Azure - Testando resili\u00eancia Panorama dos Modelos de Causa de Falha de Software","title":"Recursos"},{"location":"automated-testing/integration-testing/","text":"Teste de Integra\u00e7\u00e3o O teste de integra\u00e7\u00e3o \u00e9 uma metodologia de teste de software usada para determinar o qu\u00e3o bem os componentes ou m\u00f3dulos de um sistema desenvolvidos individualmente se comunicam entre si. Este m\u00e9todo de teste confirma que um agregado de um sistema, ou sub-sistema, funciona corretamente em conjunto ou, caso contr\u00e1rio, exp\u00f5e comportamentos err\u00f4neos entre duas ou mais unidades de c\u00f3digo. Por que Teste de Integra\u00e7\u00e3o Como um componente de um sistema pode ser desenvolvido de forma independente ou isolada de outro, \u00e9 importante verificar a intera\u00e7\u00e3o de alguns ou todos os componentes. Um sistema complexo pode ser composto por bancos de dados, APIs, interfaces e mais, que interagem entre si ou com sistemas externos adicionais. Os testes de integra\u00e7\u00e3o exp\u00f5em problemas no n\u00edvel do sistema, como esquemas de banco de dados quebrados ou integra\u00e7\u00e3o defeituosa de APIs de terceiros. Ele garante uma maior cobertura de teste e serve como um importante ciclo de feedback ao longo do desenvolvimento. Blocos de Design de Teste de Integra\u00e7\u00e3o Considere um aplicativo banc\u00e1rio com tr\u00eas m\u00f3dulos: login, transfer\u00eancias e saldo atual, todos desenvolvidos de forma independente. Um teste de integra\u00e7\u00e3o pode verificar quando um usu\u00e1rio faz login, ele \u00e9 redirecionado para o seu saldo atual com o valor correto para o usu\u00e1rio fict\u00edcio espec\u00edfico. Outro teste de integra\u00e7\u00e3o pode realizar uma transfer\u00eancia de uma quantia espec\u00edfica de dinheiro. O teste pode confirmar que h\u00e1 fundos suficientes na conta para realizar a transfer\u00eancia e, ap\u00f3s a transfer\u00eancia, o saldo atual \u00e9 atualizado adequadamente para o usu\u00e1rio fict\u00edcio. A p\u00e1gina de login pode ser simulada com um usu\u00e1rio de teste e credenciais fict\u00edcias se este m\u00f3dulo n\u00e3o estiver conclu\u00eddo ao testar o m\u00f3dulo de transfer\u00eancias. O teste de integra\u00e7\u00e3o \u00e9 feito pelo desenvolvedor ou pelo testador de QA. No passado, o teste de integra\u00e7\u00e3o sempre acontecia ap\u00f3s o teste de unidade e antes do teste de sistema e E2E. Em compara\u00e7\u00e3o com os testes de unidade, os testes de integra\u00e7\u00e3o s\u00e3o menores em quantidade, geralmente mais lentos e mais caros para configurar e desenvolver. Agora, se uma equipe est\u00e1 seguindo princ\u00edpios \u00e1geis, os testes de integra\u00e7\u00e3o podem ser realizados antes ou depois dos testes de unidade, cedo e frequentemente, pois n\u00e3o h\u00e1 necessidade de esperar por processos sequenciais. Al\u00e9m disso, os testes de integra\u00e7\u00e3o podem utilizar dados fict\u00edcios para simular um sistema completo. H\u00e1 uma abund\u00e2ncia de frameworks de teste espec\u00edficos para cada linguagem que podem ser usados ao longo de todo o ciclo de desenvolvimento. ** \u00c9 importante notar a diferen\u00e7a entre teste de integra\u00e7\u00e3o e teste de aceita\u00e7\u00e3o. O teste de integra\u00e7\u00e3o confirma que um grupo de componentes funciona em conjunto como pretendido do ponto de vista t\u00e9cnico, enquanto o teste de aceita\u00e7\u00e3o confirma que um grupo de componentes funciona em conjunto como pretendido a partir de um cen\u00e1rio de neg\u00f3cios. Aplicando Teste de Integra\u00e7\u00e3o Antes de escrever testes de integra\u00e7\u00e3o, os engenheiros devem identificar os diferentes componentes do sistema e seus comportamentos, entradas e sa\u00eddas pretendidos. A arquitetura do projeto deve estar totalmente documentada ou especificada em algum lugar que possa ser prontamente consultado (por exemplo, o diagrama de arquitetura). Existem duas t\u00e9cnicas principais para teste de integra\u00e7\u00e3o. Big Bang O teste de integra\u00e7\u00e3o Big Bang \u00e9 quando todos os componentes s\u00e3o testados como uma \u00fanica unidade. Isso \u00e9 melhor para sistemas pequenos, pois um sistema muito grande pode ser dif\u00edcil de localizar para poss\u00edveis erros de testes falhados. Esta abordagem tamb\u00e9m requer que todos os componentes no sistema em teste estejam conclu\u00eddos, o que pode atrasar o in\u00edcio dos testes. Teste Incremental O teste incremental \u00e9 quando dois ou mais componentes que s\u00e3o logicamente relacionados s\u00e3o testados como uma unidade. Ap\u00f3s o teste da unidade, componentes adicionais s\u00e3o combinados e testados todos juntos. Este processo se repete at\u00e9 que todos os componentes necess\u00e1rios sejam testados. Top Down O teste Top Down \u00e9 quando os componentes de n\u00edvel superior s\u00e3o testados seguindo o fluxo de controle de um sistema de software. Nesse cen\u00e1rio, o que \u00e9 comumente chamado de stubs s\u00e3o usados para emular o comportamento de m\u00f3dulos de n\u00edvel inferior ainda n\u00e3o conclu\u00eddos ou mesclados no teste de integra\u00e7\u00e3o. Bottom Up O teste Bottom Up \u00e9 quando os m\u00f3dulos de n\u00edvel inferior s\u00e3o testados juntos. Nesse cen\u00e1rio, o que \u00e9 comumente chamado de drivers s\u00e3o usados para emular o comportamento de m\u00f3dulos de n\u00edvel superior ainda n\u00e3o conclu\u00eddos ou inclu\u00eddos no teste de integra\u00e7\u00e3o. Uma terceira abordagem conhecida como o modelo sandu\u00edche ou h\u00edbrido combina as abordagens de baixo para cima e de cima para baixo para testar componentes de n\u00edvel inferior e superior ao mesmo tempo. Coisas a Evitar H\u00e1 um trade-off que o desenvolvedor deve fazer entre a cobertura de c\u00f3digo do teste de integra\u00e7\u00e3o e os ciclos de engenharia. Com depend\u00eancias fict\u00edcias, dados de teste e v\u00e1rios ambientes em teste, muitos testes de integra\u00e7\u00e3o s\u00e3o invi\u00e1veis de manter e se tornam cada vez menos significativos. Muita simula\u00e7\u00e3o vai desacelerar o conjunto de testes, tornar o dimensionamento dif\u00edcil e pode ser um sinal de que o desenvolvedor deve considerar outros testes para o cen\u00e1rio, como testes de aceita\u00e7\u00e3o ou E2E. Os testes de integra\u00e7\u00e3o de sistemas complexos requerem alta manuten\u00e7\u00e3o. Evite testar a l\u00f3gica de neg\u00f3cios em testes de integra\u00e7\u00e3o, mantendo os conjuntos de testes separados. N\u00e3o teste al\u00e9m dos crit\u00e9rios de aceita\u00e7\u00e3o da tarefa e certifique-se de limpar quaisquer recursos criados para um determinado teste. Al\u00e9m disso, evite escrever testes em um ambiente de produ\u00e7\u00e3o. Em vez disso, escreva-os em um ambiente de c\u00f3pia reduzida. Frameworks e Ferramentas de Teste de Integra\u00e7\u00e3o Muitas ferramentas e frameworks podem ser usados para escrever tanto testes de unidade quanto de integra\u00e7\u00e3o. As seguintes ferramentas s\u00e3o para automatizar testes de integra\u00e7\u00e3o. JUnit Robot Framework moq Cucumber Selenium Behave (Python) Conclus\u00e3o O teste de integra\u00e7\u00e3o demonstra como um m\u00f3dulo de um sistema, ou sistema externo, se interfaceia com outro. Isso pode ser um teste de dois componentes, um sub-sistema, um sistema inteiro ou uma cole\u00e7\u00e3o de sistemas. Os testes devem ser escritos com frequ\u00eancia e ao longo de todo o ciclo de vida do desenvolvimento, usando uma quantidade apropriada de depend\u00eancias e dados fict\u00edcios. Como os testes de integra\u00e7\u00e3o provam que os m\u00f3dulos desenvolvidos independentemente se interfaceiam conforme tecnicamente projetado, isso aumenta a confian\u00e7a no ciclo de desenvolvimento, fornecendo um caminho para um sistema que \u00e9 implantado e escal\u00e1vel. Recursos Abordagens de teste de integra\u00e7\u00e3o Pr\u00f3s e contras do teste de integra\u00e7\u00e3o Mocks e stubs em testes de integra\u00e7\u00e3o Software Testing: Principles and Practices In\u00edcio r\u00e1pido do teste Behave","title":"Teste de Integra\u00e7\u00e3o"},{"location":"automated-testing/integration-testing/#teste-de-integracao","text":"O teste de integra\u00e7\u00e3o \u00e9 uma metodologia de teste de software usada para determinar o qu\u00e3o bem os componentes ou m\u00f3dulos de um sistema desenvolvidos individualmente se comunicam entre si. Este m\u00e9todo de teste confirma que um agregado de um sistema, ou sub-sistema, funciona corretamente em conjunto ou, caso contr\u00e1rio, exp\u00f5e comportamentos err\u00f4neos entre duas ou mais unidades de c\u00f3digo.","title":"Teste de Integra\u00e7\u00e3o"},{"location":"automated-testing/integration-testing/#por-que-teste-de-integracao","text":"Como um componente de um sistema pode ser desenvolvido de forma independente ou isolada de outro, \u00e9 importante verificar a intera\u00e7\u00e3o de alguns ou todos os componentes. Um sistema complexo pode ser composto por bancos de dados, APIs, interfaces e mais, que interagem entre si ou com sistemas externos adicionais. Os testes de integra\u00e7\u00e3o exp\u00f5em problemas no n\u00edvel do sistema, como esquemas de banco de dados quebrados ou integra\u00e7\u00e3o defeituosa de APIs de terceiros. Ele garante uma maior cobertura de teste e serve como um importante ciclo de feedback ao longo do desenvolvimento.","title":"Por que Teste de Integra\u00e7\u00e3o"},{"location":"automated-testing/integration-testing/#blocos-de-design-de-teste-de-integracao","text":"Considere um aplicativo banc\u00e1rio com tr\u00eas m\u00f3dulos: login, transfer\u00eancias e saldo atual, todos desenvolvidos de forma independente. Um teste de integra\u00e7\u00e3o pode verificar quando um usu\u00e1rio faz login, ele \u00e9 redirecionado para o seu saldo atual com o valor correto para o usu\u00e1rio fict\u00edcio espec\u00edfico. Outro teste de integra\u00e7\u00e3o pode realizar uma transfer\u00eancia de uma quantia espec\u00edfica de dinheiro. O teste pode confirmar que h\u00e1 fundos suficientes na conta para realizar a transfer\u00eancia e, ap\u00f3s a transfer\u00eancia, o saldo atual \u00e9 atualizado adequadamente para o usu\u00e1rio fict\u00edcio. A p\u00e1gina de login pode ser simulada com um usu\u00e1rio de teste e credenciais fict\u00edcias se este m\u00f3dulo n\u00e3o estiver conclu\u00eddo ao testar o m\u00f3dulo de transfer\u00eancias. O teste de integra\u00e7\u00e3o \u00e9 feito pelo desenvolvedor ou pelo testador de QA. No passado, o teste de integra\u00e7\u00e3o sempre acontecia ap\u00f3s o teste de unidade e antes do teste de sistema e E2E. Em compara\u00e7\u00e3o com os testes de unidade, os testes de integra\u00e7\u00e3o s\u00e3o menores em quantidade, geralmente mais lentos e mais caros para configurar e desenvolver. Agora, se uma equipe est\u00e1 seguindo princ\u00edpios \u00e1geis, os testes de integra\u00e7\u00e3o podem ser realizados antes ou depois dos testes de unidade, cedo e frequentemente, pois n\u00e3o h\u00e1 necessidade de esperar por processos sequenciais. Al\u00e9m disso, os testes de integra\u00e7\u00e3o podem utilizar dados fict\u00edcios para simular um sistema completo. H\u00e1 uma abund\u00e2ncia de frameworks de teste espec\u00edficos para cada linguagem que podem ser usados ao longo de todo o ciclo de desenvolvimento. ** \u00c9 importante notar a diferen\u00e7a entre teste de integra\u00e7\u00e3o e teste de aceita\u00e7\u00e3o. O teste de integra\u00e7\u00e3o confirma que um grupo de componentes funciona em conjunto como pretendido do ponto de vista t\u00e9cnico, enquanto o teste de aceita\u00e7\u00e3o confirma que um grupo de componentes funciona em conjunto como pretendido a partir de um cen\u00e1rio de neg\u00f3cios.","title":"Blocos de Design de Teste de Integra\u00e7\u00e3o"},{"location":"automated-testing/integration-testing/#aplicando-teste-de-integracao","text":"Antes de escrever testes de integra\u00e7\u00e3o, os engenheiros devem identificar os diferentes componentes do sistema e seus comportamentos, entradas e sa\u00eddas pretendidos. A arquitetura do projeto deve estar totalmente documentada ou especificada em algum lugar que possa ser prontamente consultado (por exemplo, o diagrama de arquitetura). Existem duas t\u00e9cnicas principais para teste de integra\u00e7\u00e3o.","title":"Aplicando Teste de Integra\u00e7\u00e3o"},{"location":"automated-testing/integration-testing/#big-bang","text":"O teste de integra\u00e7\u00e3o Big Bang \u00e9 quando todos os componentes s\u00e3o testados como uma \u00fanica unidade. Isso \u00e9 melhor para sistemas pequenos, pois um sistema muito grande pode ser dif\u00edcil de localizar para poss\u00edveis erros de testes falhados. Esta abordagem tamb\u00e9m requer que todos os componentes no sistema em teste estejam conclu\u00eddos, o que pode atrasar o in\u00edcio dos testes.","title":"Big Bang"},{"location":"automated-testing/integration-testing/#teste-incremental","text":"O teste incremental \u00e9 quando dois ou mais componentes que s\u00e3o logicamente relacionados s\u00e3o testados como uma unidade. Ap\u00f3s o teste da unidade, componentes adicionais s\u00e3o combinados e testados todos juntos. Este processo se repete at\u00e9 que todos os componentes necess\u00e1rios sejam testados.","title":"Teste Incremental"},{"location":"automated-testing/integration-testing/#top-down","text":"O teste Top Down \u00e9 quando os componentes de n\u00edvel superior s\u00e3o testados seguindo o fluxo de controle de um sistema de software. Nesse cen\u00e1rio, o que \u00e9 comumente chamado de stubs s\u00e3o usados para emular o comportamento de m\u00f3dulos de n\u00edvel inferior ainda n\u00e3o conclu\u00eddos ou mesclados no teste de integra\u00e7\u00e3o.","title":"Top Down"},{"location":"automated-testing/integration-testing/#bottom-up","text":"O teste Bottom Up \u00e9 quando os m\u00f3dulos de n\u00edvel inferior s\u00e3o testados juntos. Nesse cen\u00e1rio, o que \u00e9 comumente chamado de drivers s\u00e3o usados para emular o comportamento de m\u00f3dulos de n\u00edvel superior ainda n\u00e3o conclu\u00eddos ou inclu\u00eddos no teste de integra\u00e7\u00e3o. Uma terceira abordagem conhecida como o modelo sandu\u00edche ou h\u00edbrido combina as abordagens de baixo para cima e de cima para baixo para testar componentes de n\u00edvel inferior e superior ao mesmo tempo.","title":"Bottom Up"},{"location":"automated-testing/integration-testing/#coisas-a-evitar","text":"H\u00e1 um trade-off que o desenvolvedor deve fazer entre a cobertura de c\u00f3digo do teste de integra\u00e7\u00e3o e os ciclos de engenharia. Com depend\u00eancias fict\u00edcias, dados de teste e v\u00e1rios ambientes em teste, muitos testes de integra\u00e7\u00e3o s\u00e3o invi\u00e1veis de manter e se tornam cada vez menos significativos. Muita simula\u00e7\u00e3o vai desacelerar o conjunto de testes, tornar o dimensionamento dif\u00edcil e pode ser um sinal de que o desenvolvedor deve considerar outros testes para o cen\u00e1rio, como testes de aceita\u00e7\u00e3o ou E2E. Os testes de integra\u00e7\u00e3o de sistemas complexos requerem alta manuten\u00e7\u00e3o. Evite testar a l\u00f3gica de neg\u00f3cios em testes de integra\u00e7\u00e3o, mantendo os conjuntos de testes separados. N\u00e3o teste al\u00e9m dos crit\u00e9rios de aceita\u00e7\u00e3o da tarefa e certifique-se de limpar quaisquer recursos criados para um determinado teste. Al\u00e9m disso, evite escrever testes em um ambiente de produ\u00e7\u00e3o. Em vez disso, escreva-os em um ambiente de c\u00f3pia reduzida.","title":"Coisas a Evitar"},{"location":"automated-testing/integration-testing/#frameworks-e-ferramentas-de-teste-de-integracao","text":"Muitas ferramentas e frameworks podem ser usados para escrever tanto testes de unidade quanto de integra\u00e7\u00e3o. As seguintes ferramentas s\u00e3o para automatizar testes de integra\u00e7\u00e3o. JUnit Robot Framework moq Cucumber Selenium Behave (Python)","title":"Frameworks e Ferramentas de Teste de Integra\u00e7\u00e3o"},{"location":"automated-testing/integration-testing/#conclusao","text":"O teste de integra\u00e7\u00e3o demonstra como um m\u00f3dulo de um sistema, ou sistema externo, se interfaceia com outro. Isso pode ser um teste de dois componentes, um sub-sistema, um sistema inteiro ou uma cole\u00e7\u00e3o de sistemas. Os testes devem ser escritos com frequ\u00eancia e ao longo de todo o ciclo de vida do desenvolvimento, usando uma quantidade apropriada de depend\u00eancias e dados fict\u00edcios. Como os testes de integra\u00e7\u00e3o provam que os m\u00f3dulos desenvolvidos independentemente se interfaceiam conforme tecnicamente projetado, isso aumenta a confian\u00e7a no ciclo de desenvolvimento, fornecendo um caminho para um sistema que \u00e9 implantado e escal\u00e1vel.","title":"Conclus\u00e3o"},{"location":"automated-testing/integration-testing/#recursos","text":"Abordagens de teste de integra\u00e7\u00e3o Pr\u00f3s e contras do teste de integra\u00e7\u00e3o Mocks e stubs em testes de integra\u00e7\u00e3o Software Testing: Principles and Practices In\u00edcio r\u00e1pido do teste Behave","title":"Recursos"},{"location":"automated-testing/performance-testing/","text":"Teste de Desempenho O Teste de Desempenho \u00e9 um termo sobrecarregado que \u00e9 usado para se referir a v\u00e1rias subcategorias de testes relacionados ao desempenho, cada uma com um prop\u00f3sito diferente. Uma boa descri\u00e7\u00e3o do teste de desempenho geral \u00e9 a seguinte: O teste de desempenho \u00e9 um tipo de teste destinado a determinar a capacidade de resposta, taxa de transfer\u00eancia, confiabilidade e/ou escalabilidade de um sistema sob uma determinada carga de trabalho. Orienta\u00e7\u00e3o para Teste de Desempenho para Aplica\u00e7\u00f5es Web . Antes de entrar nas diferentes subcategorias de testes de desempenho, vamos entender por que o teste de desempenho \u00e9 normalmente realizado. Por que Teste de Desempenho O teste de desempenho \u00e9 comumente realizado para realizar uma ou mais das seguintes a\u00e7\u00f5es: Ajustar o desempenho do sistema Identificar gargalos e problemas com o sistema em diferentes n\u00edveis de carga. Comparar as caracter\u00edsticas de desempenho do sistema para diferentes configura\u00e7\u00f5es de sistema. Elaborar uma estrat\u00e9gia de escalabilidade para o sistema. Auxiliar no planejamento de capacidade O planejamento de capacidade \u00e9 o processo de determinar que tipo de recursos de hardware e software s\u00e3o necess\u00e1rios para executar uma aplica\u00e7\u00e3o para atender a metas de desempenho predefinidas. O planejamento de capacidade envolve a identifica\u00e7\u00e3o das expectativas de neg\u00f3cios, as flutua\u00e7\u00f5es peri\u00f3dicas do uso da aplica\u00e7\u00e3o, considerando o custo de execu\u00e7\u00e3o da infraestrutura de hardware e software. Avaliar a prontid\u00e3o do sistema para o lan\u00e7amento: Avaliar as caracter\u00edsticas de desempenho do sistema (tempo de resposta, taxa de transfer\u00eancia) em um ambiente semelhante ao de produ\u00e7\u00e3o. O objetivo \u00e9 garantir que as metas de desempenho possam ser alcan\u00e7adas ap\u00f3s o lan\u00e7amento. Avaliar o impacto de desempenho das mudan\u00e7as na aplica\u00e7\u00e3o Comparar as caracter\u00edsticas de desempenho de uma aplica\u00e7\u00e3o ap\u00f3s uma mudan\u00e7a com os valores das caracter\u00edsticas de desempenho durante execu\u00e7\u00f5es anteriores (ou valores de refer\u00eancia), pode fornecer uma indica\u00e7\u00e3o de problemas de desempenho (regress\u00e3o de desempenho) ou melhorias introduzidas devido a uma mudan\u00e7a. Principais Categorias de Teste de Desempenho O teste de desempenho \u00e9 um t\u00f3pico amplo. H\u00e1 muitas \u00e1reas onde voc\u00ea pode realizar testes. De forma geral, voc\u00ea pode realizar testes no backend e na interface do usu\u00e1rio. Voc\u00ea pode testar o desempenho de componentes individuais, bem como testar a funcionalidade de ponta a ponta. Existem v\u00e1rias categorias de testes tamb\u00e9m: Teste de Carga Esta \u00e9 a subcategoria de teste de desempenho que se concentra em validar as caracter\u00edsticas de desempenho de um sistema, quando o sistema enfrenta os volumes de carga que s\u00e3o esperados durante a opera\u00e7\u00e3o de produ\u00e7\u00e3o. Um Teste de Resist\u00eancia ou um Teste de Soak \u00e9 um teste de carga realizado durante um longo per\u00edodo, variando de v\u00e1rias horas a dias. Teste de Estresse Esta \u00e9 a subcategoria de teste de desempenho que se concentra em validar as caracter\u00edsticas de desempenho de um sistema quando o sistema enfrenta carga extrema. O objetivo \u00e9 avaliar como o sistema lida com a press\u00e3o at\u00e9 seus limites, ele se recupera (ou seja, escala) ou simplesmente quebra e falha? Teste de Resist\u00eancia O objetivo do teste de resist\u00eancia \u00e9 garantir que o sistema possa manter um bom desempenho sob per\u00edodos prolongados de carga. Teste de Pico O objetivo do teste de pico \u00e9 validar que um sistema de software pode responder bem a grandes e repentinos picos. Teste de Caos O teste de caos ou engenharia do caos \u00e9 a pr\u00e1tica de experimentar em um sistema para construir confian\u00e7a de que o sistema pode resistir a condi\u00e7\u00f5es turbulentas na produ\u00e7\u00e3o. Seu objetivo \u00e9 identificar fraquezas antes que elas se manifestem em todo o sistema. Desenvolvedores frequentemente implementam procedimentos de conting\u00eancia para falhas de servi\u00e7o. O teste de caos desliga arbitrariamente diferentes partes do sistema para validar que os procedimentos de conting\u00eancia funcionam corretamente. M\u00e9tricas de Monitoramento de Desempenho Ao executar os v\u00e1rios tipos de abordagens de teste, seja estresse, resist\u00eancia, pico ou teste de caos, \u00e9 importante capturar v\u00e1rias m\u00e9tricas para ver como o sistema se comporta. No n\u00edvel b\u00e1sico de hardware, h\u00e1 quatro \u00e1reas a serem consideradas. Disco f\u00edsico Mem\u00f3ria Processador Rede Essas quatro \u00e1reas est\u00e3o inextricavelmente ligadas, o que significa que um desempenho ruim em uma \u00e1rea levar\u00e1 a um desempenho ruim em outra \u00e1rea. Engenheiros preocupados em entender o desempenho da aplica\u00e7\u00e3o devem se concentrar nessas quatro \u00e1reas principais. O exemplo cl\u00e1ssico de como o desempenho em uma \u00e1rea pode afetar o desempenho em outra \u00e9 a press\u00e3o da mem\u00f3ria. Se a mem\u00f3ria dispon\u00edvel de uma aplica\u00e7\u00e3o estiver baixa, o sistema operacional tentar\u00e1 compensar as defici\u00eancias de mem\u00f3ria transferindo p\u00e1ginas de dados da mem\u00f3ria para o disco, liberando assim mem\u00f3ria. Mas esse trabalho requer ajuda da CPU e do disco f\u00edsico. Isso significa que, quando voc\u00ea observa o desempenho quando h\u00e1 baixas quantidades de mem\u00f3ria, tamb\u00e9m notar\u00e1 picos na atividade do disco e da CPU. Disco F\u00edsico Quase todos os sistemas de software dependem do desempenho do disco f\u00edsico. Isso \u00e9 especialmente verdadeiro para o desempenho de bancos de dados. Abordagens mais modernas para o uso de SSDs para armazenamento de disco f\u00edsico podem melhorar dramaticamente o desempenho das aplica\u00e7\u00f5es. Aqui est\u00e3o algumas das m\u00e9tricas que voc\u00ea pode capturar e analisar: Contador Descri\u00e7\u00e3o M\u00e9dia do Comprimento da Fila do Disco Este valor \u00e9 derivado usando os contadores (Transfer\u00eancias de Disco/seg)*(Seg de Disco/Transfer\u00eancia). Esta m\u00e9trica descreve a fila do disco ao longo do tempo, suavizando quaisquer picos r\u00e1pidos. Ter qualquer disco f\u00edsico com um comprimento m\u00e9dio de fila acima de 2 por per\u00edodos prolongados pode ser uma indica\u00e7\u00e3o de que seu disco \u00e9 um gargalo. % de Tempo Ocioso Esta \u00e9 uma medida da porcentagem de tempo que o disco estava ocioso. Ou seja, n\u00e3o h\u00e1 solicita\u00e7\u00f5es de disco pendentes do sistema operacional esperando para serem conclu\u00eddas. Um n\u00famero baixo aqui \u00e9 um sinal positivo de que o disco tem capacidade excedente para atender ou escrever solicita\u00e7\u00f5es do sistema operacional. M\u00e9dia de Seg de Disco/Leitura e M\u00e9dia de Seg de Disco/Escrita Ambos medem a lat\u00eancia dos seus discos. A lat\u00eancia \u00e9 definida como o tempo m\u00e9dio que leva para uma transfer\u00eancia de disco ser conclu\u00edda. Voc\u00ea obviamente quer n\u00fameros t\u00e3o baixos quanto poss\u00edvel, mas precisa ter cuidado para levar em conta as diferen\u00e7as de velocidade inerentes entre SSDs e discos r\u00edgidos tradicionais. Para este contador, \u00e9 importante definir uma linha de base ap\u00f3s a instala\u00e7\u00e3o do hardware. Em seguida, use esse valor daqui para frente para determinar se voc\u00ea est\u00e1 enfrentando problemas de lat\u00eancia relacionados ao hardware. Leituras de Disco/seg e Escritas de Disco/seg Estes contadores medem o n\u00famero total de solicita\u00e7\u00f5es de E/S conclu\u00eddas por segundo. Semelhante aos contadores de lat\u00eancia, valores bons e ruins para esses contadores dependem do seu hardware de disco, mas valores mais altos do que sua linha de base inicial normalmente n\u00e3o apontam para um problema de hardware neste caso. Este contador pode ser \u00fatil para identificar picos na E/S de disco. Processador \u00c9 importante entender a quantidade de tempo gasto no modo kernel ou privilegiado. Em geral, se o c\u00f3digo estiver gastando muito tempo executando chamadas do sistema operacional, isso poder\u00e1 ser uma \u00e1rea de preocupa\u00e7\u00e3o, pois n\u00e3o permitir\u00e1 que voc\u00ea execute suas aplica\u00e7\u00f5es em modo de usu\u00e1rio, como seus bancos de dados, servidores/servi\u00e7os web, etc. A diretriz \u00e9 que a CPU deve gastar apenas cerca de 20% do tempo total do processador executando no modo kernel. Contador Descri\u00e7\u00e3o % de Tempo do Processador Esta \u00e9 a porcentagem do tempo total decorrido que o processador estava ocupado executando. Este contador pode ser muito alto ou muito baixo. Se o tempo do seu processador estiver consistentemente abaixo de 40%, ent\u00e3o h\u00e1 uma quest\u00e3o sobre se voc\u00ea superprovisionou sua CPU. 70% \u00e9 geralmente considerado um bom n\u00famero alvo e, se voc\u00ea come\u00e7ar a ir acima de 70%, pode querer explorar por que h\u00e1 alta press\u00e3o da CPU. % de Tempo Privilegiado (Modo Kernel) Este mede a porcentagem do tempo decorrido que o processador gastou executando no modo kernel. Como este contador leva em conta apenas opera\u00e7\u00f5es de kernel, uma alta porcentagem de tempo privilegiado (maior que 25%) pode indicar um problema de driver ou hardware que deve ser investigado. % de Tempo de Usu\u00e1rio A porcentagem do tempo decorrido que o processador gastou executando no modo de usu\u00e1rio (seu c\u00f3digo de aplica\u00e7\u00e3o). Uma boa diretriz \u00e9 estar consistentemente abaixo de 65%, pois voc\u00ea quer ter alguma folga tanto para as opera\u00e7\u00f5es de kernel mencionadas acima quanto para quaisquer outros picos de CPU exigidos por outras aplica\u00e7\u00f5es. Comprimento da Fila Este \u00e9 o n\u00famero de threads que est\u00e3o prontas para executar, mas esperando que um n\u00facleo fique dispon\u00edvel. Em m\u00e1quinas de n\u00facleo \u00fanico, um valor sustentado maior que 2-3 pode significar que voc\u00ea tem alguma press\u00e3o da CPU. Da mesma forma, para uma m\u00e1quina multicore, divida o comprimento da fila pelo n\u00famero de n\u00facleos e, se isso for continuamente maior que 2-3, pode haver press\u00e3o da CPU. Adaptador de Rede A velocidade da rede \u00e9 frequentemente um culpado oculto de desempenho ruim. Encontrar a causa raiz do mau desempenho da rede \u00e9 frequentemente dif\u00edcil. A fonte de problemas pode se originar de consumidores de largura de banda, como videoconfer\u00eancia, dados de transa\u00e7\u00e3o, backups de rede, v\u00eddeos recreativos. Na verdade, as tr\u00eas raz\u00f5es mais comuns para uma desacelera\u00e7\u00e3o da rede s\u00e3o: Congestionamento Corrup\u00e7\u00e3o de dados Colis\u00f5es Algumas das ferramentas que podem ajudar incluem: ifconfig netstat iperf tcpretrans tcpdump WireShark A solu\u00e7\u00e3o de problemas de desempenho da rede geralmente come\u00e7a com a verifica\u00e7\u00e3o do hardware. Coisas t\u00edpicas a serem exploradas s\u00e3o se h\u00e1 algum fio solto ou verificando que todos os roteadores est\u00e3o ligados. Nem sempre \u00e9 poss\u00edvel fazer isso, mas \u00e0s vezes um simples caso de reciclagem de energia do modem ou roteador pode resolver muitos problemas. Especialistas em rede frequentemente realizam a seguinte sequ\u00eancia de etapas para solucionar problemas: Verificar o hardware Usar IP config Usar ping e tracert Realizar verifica\u00e7\u00e3o de DNS Abordagens mais avan\u00e7adas frequentemente envolvem olhar para alguns dos contadores de desempenho de rede, conforme explicado abaixo. Contadores de Rede A tabela acima oferece alguns pontos de refer\u00eancia para entender melhor o que voc\u00ea pode esperar da sua rede. Aqui est\u00e3o alguns contadores que podem ajud\u00e1-lo a entender onde os gargalos podem existir: Contador Descri\u00e7\u00e3o Bytes Recebidos/seg A taxa na qual bytes s\u00e3o recebidos em cada adaptador de rede. Bytes Enviados/seg A taxa na qual bytes s\u00e3o enviados em cada adaptador de rede. Bytes Total/seg O n\u00famero de bytes enviados e recebidos pela rede. Segmentos Recebidos/seg A taxa na qual segmentos s\u00e3o recebidos para o protocolo. Segmentos Enviados/seg A taxa na qual segmentos s\u00e3o enviados. % de Tempo de Interrup\u00e7\u00e3o A porcentagem de tempo que o processador gasta recebendo e atendendo interrup\u00e7\u00f5es de hardware. Este valor \u00e9 um indicador indireto da atividade de dispositivos que geram interrup\u00e7\u00f5es, como adaptadores de rede. H\u00e1 uma distin\u00e7\u00e3o importante entre lat\u00eancia e vaz\u00e3o . Lat\u00eancia mede o tempo que leva para um pacote ser transferido pela rede, seja em termos de uma transmiss\u00e3o unidirecional ou de ida e volta. Vaz\u00e3o \u00e9 diferente e tenta medir a quantidade de dados sendo enviados e recebidos dentro de uma unidade de tempo. Mem\u00f3ria Contador Descri\u00e7\u00e3o MBs Dispon\u00edveis Este contador representa a quantidade de mem\u00f3ria que est\u00e1 dispon\u00edvel para aplica\u00e7\u00f5es em execu\u00e7\u00e3o. Mem\u00f3ria baixa pode acionar Falhas de P\u00e1gina, onde press\u00e3o adicional \u00e9 colocada na CPU para trocar mem\u00f3ria para dentro e fora do disco. Se a quantidade de mem\u00f3ria dispon\u00edvel cair abaixo de 10%, mais mem\u00f3ria deve ser obtida. P\u00e1ginas/seg Este \u00e9 na verdade a soma dos contadores \"P\u00e1ginas Entradas/seg\" e \"P\u00e1ginas Sa\u00eddas/seg\", que \u00e9 a taxa na qual as p\u00e1ginas est\u00e3o sendo lidas e escritas como resultado de falhas de p\u00e1gina. Pequenos picos com este valor n\u00e3o significam que h\u00e1 um problema, mas valores sustentados acima de 50 podem significar que a mem\u00f3ria do sistema \u00e9 um gargalo. Arquivo de Pagina\u00e7\u00e3o(_Total)\\% de Uso A porcentagem do arquivo de pagina\u00e7\u00e3o do sistema que est\u00e1 atualmente em uso. Isso n\u00e3o est\u00e1 diretamente relacionado ao desempenho, mas voc\u00ea pode enfrentar s\u00e9rios problemas de aplica\u00e7\u00e3o se o arquivo de pagina\u00e7\u00e3o ficar completamente cheio e mem\u00f3ria adicional ainda estiver sendo solicitada por aplica\u00e7\u00f5es. Atividades-chave de Teste de Desempenho As atividades de teste de desempenho variam dependendo da subcategoria de teste de desempenho e dos requisitos e restri\u00e7\u00f5es do sistema. Para orienta\u00e7\u00e3o espec\u00edfica, voc\u00ea pode seguir o link para a subcategoria de testes de desempenho listada acima. As seguintes atividades podem ser inclu\u00eddas dependendo da subcategoria de teste de desempenho: Identificar os Crit\u00e9rios de Aceita\u00e7\u00e3o para os Testes Isso geralmente incluir\u00e1 identificar os objetivos e restri\u00e7\u00f5es para as caracter\u00edsticas de desempenho do sistema. Planejar e Projetar os Testes Em geral, precisamos considerar os seguintes pontos: Definir a carga com a qual a aplica\u00e7\u00e3o deve ser testada Estabelecer as m\u00e9tricas a serem coletadas Estabelecer quais ferramentas ser\u00e3o usadas para os testes Estabelecer a frequ\u00eancia do teste de desempenho: os testes de desempenho ser\u00e3o feitos como parte dos sprints de desenvolvimento de recursos ou apenas antes do lan\u00e7amento para um ambiente importante? Implementa\u00e7\u00e3o Implementar os testes de desempenho de acordo com a abordagem projetada. Instrumentar o sistema e garantir que ele esteja emitindo as m\u00e9tricas de desempenho necess\u00e1rias. Execu\u00e7\u00e3o do Teste Executar os testes e coletar m\u00e9tricas de desempenho. An\u00e1lise de Resultados e Re-teste Analisar os resultados/m\u00e9tricas de desempenho dos testes. Identificar as mudan\u00e7as necess\u00e1rias para ajustar o sistema (ou seja, c\u00f3digo, infraestrutura) para melhor acomodar os objetivos do teste. Em seguida, teste novamente. Este ciclo continua at\u00e9 que o objetivo do teste seja alcan\u00e7ado. O Modelo de Teste de Desempenho Iterativo pode ser usado para capturar detalhes sobre o resultado do teste para cada itera\u00e7\u00e3o. Recursos Padr\u00f5es e Pr\u00e1ticas: Orienta\u00e7\u00e3o para Teste de Desempenho para Aplica\u00e7\u00f5es Web","title":"Teste de Desempenho"},{"location":"automated-testing/performance-testing/#teste-de-desempenho","text":"O Teste de Desempenho \u00e9 um termo sobrecarregado que \u00e9 usado para se referir a v\u00e1rias subcategorias de testes relacionados ao desempenho, cada uma com um prop\u00f3sito diferente. Uma boa descri\u00e7\u00e3o do teste de desempenho geral \u00e9 a seguinte: O teste de desempenho \u00e9 um tipo de teste destinado a determinar a capacidade de resposta, taxa de transfer\u00eancia, confiabilidade e/ou escalabilidade de um sistema sob uma determinada carga de trabalho. Orienta\u00e7\u00e3o para Teste de Desempenho para Aplica\u00e7\u00f5es Web . Antes de entrar nas diferentes subcategorias de testes de desempenho, vamos entender por que o teste de desempenho \u00e9 normalmente realizado.","title":"Teste de Desempenho"},{"location":"automated-testing/performance-testing/#por-que-teste-de-desempenho","text":"O teste de desempenho \u00e9 comumente realizado para realizar uma ou mais das seguintes a\u00e7\u00f5es: Ajustar o desempenho do sistema Identificar gargalos e problemas com o sistema em diferentes n\u00edveis de carga. Comparar as caracter\u00edsticas de desempenho do sistema para diferentes configura\u00e7\u00f5es de sistema. Elaborar uma estrat\u00e9gia de escalabilidade para o sistema. Auxiliar no planejamento de capacidade O planejamento de capacidade \u00e9 o processo de determinar que tipo de recursos de hardware e software s\u00e3o necess\u00e1rios para executar uma aplica\u00e7\u00e3o para atender a metas de desempenho predefinidas. O planejamento de capacidade envolve a identifica\u00e7\u00e3o das expectativas de neg\u00f3cios, as flutua\u00e7\u00f5es peri\u00f3dicas do uso da aplica\u00e7\u00e3o, considerando o custo de execu\u00e7\u00e3o da infraestrutura de hardware e software. Avaliar a prontid\u00e3o do sistema para o lan\u00e7amento: Avaliar as caracter\u00edsticas de desempenho do sistema (tempo de resposta, taxa de transfer\u00eancia) em um ambiente semelhante ao de produ\u00e7\u00e3o. O objetivo \u00e9 garantir que as metas de desempenho possam ser alcan\u00e7adas ap\u00f3s o lan\u00e7amento. Avaliar o impacto de desempenho das mudan\u00e7as na aplica\u00e7\u00e3o Comparar as caracter\u00edsticas de desempenho de uma aplica\u00e7\u00e3o ap\u00f3s uma mudan\u00e7a com os valores das caracter\u00edsticas de desempenho durante execu\u00e7\u00f5es anteriores (ou valores de refer\u00eancia), pode fornecer uma indica\u00e7\u00e3o de problemas de desempenho (regress\u00e3o de desempenho) ou melhorias introduzidas devido a uma mudan\u00e7a.","title":"Por que Teste de Desempenho"},{"location":"automated-testing/performance-testing/#principais-categorias-de-teste-de-desempenho","text":"O teste de desempenho \u00e9 um t\u00f3pico amplo. H\u00e1 muitas \u00e1reas onde voc\u00ea pode realizar testes. De forma geral, voc\u00ea pode realizar testes no backend e na interface do usu\u00e1rio. Voc\u00ea pode testar o desempenho de componentes individuais, bem como testar a funcionalidade de ponta a ponta. Existem v\u00e1rias categorias de testes tamb\u00e9m:","title":"Principais Categorias de Teste de Desempenho"},{"location":"automated-testing/performance-testing/#teste-de-carga","text":"Esta \u00e9 a subcategoria de teste de desempenho que se concentra em validar as caracter\u00edsticas de desempenho de um sistema, quando o sistema enfrenta os volumes de carga que s\u00e3o esperados durante a opera\u00e7\u00e3o de produ\u00e7\u00e3o. Um Teste de Resist\u00eancia ou um Teste de Soak \u00e9 um teste de carga realizado durante um longo per\u00edodo, variando de v\u00e1rias horas a dias.","title":"Teste de Carga"},{"location":"automated-testing/performance-testing/#teste-de-estresse","text":"Esta \u00e9 a subcategoria de teste de desempenho que se concentra em validar as caracter\u00edsticas de desempenho de um sistema quando o sistema enfrenta carga extrema. O objetivo \u00e9 avaliar como o sistema lida com a press\u00e3o at\u00e9 seus limites, ele se recupera (ou seja, escala) ou simplesmente quebra e falha?","title":"Teste de Estresse"},{"location":"automated-testing/performance-testing/#teste-de-resistencia","text":"O objetivo do teste de resist\u00eancia \u00e9 garantir que o sistema possa manter um bom desempenho sob per\u00edodos prolongados de carga.","title":"Teste de Resist\u00eancia"},{"location":"automated-testing/performance-testing/#teste-de-pico","text":"O objetivo do teste de pico \u00e9 validar que um sistema de software pode responder bem a grandes e repentinos picos.","title":"Teste de Pico"},{"location":"automated-testing/performance-testing/#teste-de-caos","text":"O teste de caos ou engenharia do caos \u00e9 a pr\u00e1tica de experimentar em um sistema para construir confian\u00e7a de que o sistema pode resistir a condi\u00e7\u00f5es turbulentas na produ\u00e7\u00e3o. Seu objetivo \u00e9 identificar fraquezas antes que elas se manifestem em todo o sistema. Desenvolvedores frequentemente implementam procedimentos de conting\u00eancia para falhas de servi\u00e7o. O teste de caos desliga arbitrariamente diferentes partes do sistema para validar que os procedimentos de conting\u00eancia funcionam corretamente.","title":"Teste de Caos"},{"location":"automated-testing/performance-testing/#metricas-de-monitoramento-de-desempenho","text":"Ao executar os v\u00e1rios tipos de abordagens de teste, seja estresse, resist\u00eancia, pico ou teste de caos, \u00e9 importante capturar v\u00e1rias m\u00e9tricas para ver como o sistema se comporta. No n\u00edvel b\u00e1sico de hardware, h\u00e1 quatro \u00e1reas a serem consideradas. Disco f\u00edsico Mem\u00f3ria Processador Rede Essas quatro \u00e1reas est\u00e3o inextricavelmente ligadas, o que significa que um desempenho ruim em uma \u00e1rea levar\u00e1 a um desempenho ruim em outra \u00e1rea. Engenheiros preocupados em entender o desempenho da aplica\u00e7\u00e3o devem se concentrar nessas quatro \u00e1reas principais. O exemplo cl\u00e1ssico de como o desempenho em uma \u00e1rea pode afetar o desempenho em outra \u00e9 a press\u00e3o da mem\u00f3ria. Se a mem\u00f3ria dispon\u00edvel de uma aplica\u00e7\u00e3o estiver baixa, o sistema operacional tentar\u00e1 compensar as defici\u00eancias de mem\u00f3ria transferindo p\u00e1ginas de dados da mem\u00f3ria para o disco, liberando assim mem\u00f3ria. Mas esse trabalho requer ajuda da CPU e do disco f\u00edsico. Isso significa que, quando voc\u00ea observa o desempenho quando h\u00e1 baixas quantidades de mem\u00f3ria, tamb\u00e9m notar\u00e1 picos na atividade do disco e da CPU.","title":"M\u00e9tricas de Monitoramento de Desempenho"},{"location":"automated-testing/performance-testing/#disco-fisico","text":"Quase todos os sistemas de software dependem do desempenho do disco f\u00edsico. Isso \u00e9 especialmente verdadeiro para o desempenho de bancos de dados. Abordagens mais modernas para o uso de SSDs para armazenamento de disco f\u00edsico podem melhorar dramaticamente o desempenho das aplica\u00e7\u00f5es. Aqui est\u00e3o algumas das m\u00e9tricas que voc\u00ea pode capturar e analisar: Contador Descri\u00e7\u00e3o M\u00e9dia do Comprimento da Fila do Disco Este valor \u00e9 derivado usando os contadores (Transfer\u00eancias de Disco/seg)*(Seg de Disco/Transfer\u00eancia). Esta m\u00e9trica descreve a fila do disco ao longo do tempo, suavizando quaisquer picos r\u00e1pidos. Ter qualquer disco f\u00edsico com um comprimento m\u00e9dio de fila acima de 2 por per\u00edodos prolongados pode ser uma indica\u00e7\u00e3o de que seu disco \u00e9 um gargalo. % de Tempo Ocioso Esta \u00e9 uma medida da porcentagem de tempo que o disco estava ocioso. Ou seja, n\u00e3o h\u00e1 solicita\u00e7\u00f5es de disco pendentes do sistema operacional esperando para serem conclu\u00eddas. Um n\u00famero baixo aqui \u00e9 um sinal positivo de que o disco tem capacidade excedente para atender ou escrever solicita\u00e7\u00f5es do sistema operacional. M\u00e9dia de Seg de Disco/Leitura e M\u00e9dia de Seg de Disco/Escrita Ambos medem a lat\u00eancia dos seus discos. A lat\u00eancia \u00e9 definida como o tempo m\u00e9dio que leva para uma transfer\u00eancia de disco ser conclu\u00edda. Voc\u00ea obviamente quer n\u00fameros t\u00e3o baixos quanto poss\u00edvel, mas precisa ter cuidado para levar em conta as diferen\u00e7as de velocidade inerentes entre SSDs e discos r\u00edgidos tradicionais. Para este contador, \u00e9 importante definir uma linha de base ap\u00f3s a instala\u00e7\u00e3o do hardware. Em seguida, use esse valor daqui para frente para determinar se voc\u00ea est\u00e1 enfrentando problemas de lat\u00eancia relacionados ao hardware. Leituras de Disco/seg e Escritas de Disco/seg Estes contadores medem o n\u00famero total de solicita\u00e7\u00f5es de E/S conclu\u00eddas por segundo. Semelhante aos contadores de lat\u00eancia, valores bons e ruins para esses contadores dependem do seu hardware de disco, mas valores mais altos do que sua linha de base inicial normalmente n\u00e3o apontam para um problema de hardware neste caso. Este contador pode ser \u00fatil para identificar picos na E/S de disco.","title":"Disco F\u00edsico"},{"location":"automated-testing/performance-testing/#processador","text":"\u00c9 importante entender a quantidade de tempo gasto no modo kernel ou privilegiado. Em geral, se o c\u00f3digo estiver gastando muito tempo executando chamadas do sistema operacional, isso poder\u00e1 ser uma \u00e1rea de preocupa\u00e7\u00e3o, pois n\u00e3o permitir\u00e1 que voc\u00ea execute suas aplica\u00e7\u00f5es em modo de usu\u00e1rio, como seus bancos de dados, servidores/servi\u00e7os web, etc. A diretriz \u00e9 que a CPU deve gastar apenas cerca de 20% do tempo total do processador executando no modo kernel. Contador Descri\u00e7\u00e3o % de Tempo do Processador Esta \u00e9 a porcentagem do tempo total decorrido que o processador estava ocupado executando. Este contador pode ser muito alto ou muito baixo. Se o tempo do seu processador estiver consistentemente abaixo de 40%, ent\u00e3o h\u00e1 uma quest\u00e3o sobre se voc\u00ea superprovisionou sua CPU. 70% \u00e9 geralmente considerado um bom n\u00famero alvo e, se voc\u00ea come\u00e7ar a ir acima de 70%, pode querer explorar por que h\u00e1 alta press\u00e3o da CPU. % de Tempo Privilegiado (Modo Kernel) Este mede a porcentagem do tempo decorrido que o processador gastou executando no modo kernel. Como este contador leva em conta apenas opera\u00e7\u00f5es de kernel, uma alta porcentagem de tempo privilegiado (maior que 25%) pode indicar um problema de driver ou hardware que deve ser investigado. % de Tempo de Usu\u00e1rio A porcentagem do tempo decorrido que o processador gastou executando no modo de usu\u00e1rio (seu c\u00f3digo de aplica\u00e7\u00e3o). Uma boa diretriz \u00e9 estar consistentemente abaixo de 65%, pois voc\u00ea quer ter alguma folga tanto para as opera\u00e7\u00f5es de kernel mencionadas acima quanto para quaisquer outros picos de CPU exigidos por outras aplica\u00e7\u00f5es. Comprimento da Fila Este \u00e9 o n\u00famero de threads que est\u00e3o prontas para executar, mas esperando que um n\u00facleo fique dispon\u00edvel. Em m\u00e1quinas de n\u00facleo \u00fanico, um valor sustentado maior que 2-3 pode significar que voc\u00ea tem alguma press\u00e3o da CPU. Da mesma forma, para uma m\u00e1quina multicore, divida o comprimento da fila pelo n\u00famero de n\u00facleos e, se isso for continuamente maior que 2-3, pode haver press\u00e3o da CPU.","title":"Processador"},{"location":"automated-testing/performance-testing/#adaptador-de-rede","text":"A velocidade da rede \u00e9 frequentemente um culpado oculto de desempenho ruim. Encontrar a causa raiz do mau desempenho da rede \u00e9 frequentemente dif\u00edcil. A fonte de problemas pode se originar de consumidores de largura de banda, como videoconfer\u00eancia, dados de transa\u00e7\u00e3o, backups de rede, v\u00eddeos recreativos. Na verdade, as tr\u00eas raz\u00f5es mais comuns para uma desacelera\u00e7\u00e3o da rede s\u00e3o: Congestionamento Corrup\u00e7\u00e3o de dados Colis\u00f5es Algumas das ferramentas que podem ajudar incluem: ifconfig netstat iperf tcpretrans tcpdump WireShark A solu\u00e7\u00e3o de problemas de desempenho da rede geralmente come\u00e7a com a verifica\u00e7\u00e3o do hardware. Coisas t\u00edpicas a serem exploradas s\u00e3o se h\u00e1 algum fio solto ou verificando que todos os roteadores est\u00e3o ligados. Nem sempre \u00e9 poss\u00edvel fazer isso, mas \u00e0s vezes um simples caso de reciclagem de energia do modem ou roteador pode resolver muitos problemas. Especialistas em rede frequentemente realizam a seguinte sequ\u00eancia de etapas para solucionar problemas: Verificar o hardware Usar IP config Usar ping e tracert Realizar verifica\u00e7\u00e3o de DNS Abordagens mais avan\u00e7adas frequentemente envolvem olhar para alguns dos contadores de desempenho de rede, conforme explicado abaixo.","title":"Adaptador de Rede"},{"location":"automated-testing/performance-testing/#contadores-de-rede","text":"A tabela acima oferece alguns pontos de refer\u00eancia para entender melhor o que voc\u00ea pode esperar da sua rede. Aqui est\u00e3o alguns contadores que podem ajud\u00e1-lo a entender onde os gargalos podem existir: Contador Descri\u00e7\u00e3o Bytes Recebidos/seg A taxa na qual bytes s\u00e3o recebidos em cada adaptador de rede. Bytes Enviados/seg A taxa na qual bytes s\u00e3o enviados em cada adaptador de rede. Bytes Total/seg O n\u00famero de bytes enviados e recebidos pela rede. Segmentos Recebidos/seg A taxa na qual segmentos s\u00e3o recebidos para o protocolo. Segmentos Enviados/seg A taxa na qual segmentos s\u00e3o enviados. % de Tempo de Interrup\u00e7\u00e3o A porcentagem de tempo que o processador gasta recebendo e atendendo interrup\u00e7\u00f5es de hardware. Este valor \u00e9 um indicador indireto da atividade de dispositivos que geram interrup\u00e7\u00f5es, como adaptadores de rede. H\u00e1 uma distin\u00e7\u00e3o importante entre lat\u00eancia e vaz\u00e3o . Lat\u00eancia mede o tempo que leva para um pacote ser transferido pela rede, seja em termos de uma transmiss\u00e3o unidirecional ou de ida e volta. Vaz\u00e3o \u00e9 diferente e tenta medir a quantidade de dados sendo enviados e recebidos dentro de uma unidade de tempo.","title":"Contadores de Rede"},{"location":"automated-testing/performance-testing/#memoria","text":"Contador Descri\u00e7\u00e3o MBs Dispon\u00edveis Este contador representa a quantidade de mem\u00f3ria que est\u00e1 dispon\u00edvel para aplica\u00e7\u00f5es em execu\u00e7\u00e3o. Mem\u00f3ria baixa pode acionar Falhas de P\u00e1gina, onde press\u00e3o adicional \u00e9 colocada na CPU para trocar mem\u00f3ria para dentro e fora do disco. Se a quantidade de mem\u00f3ria dispon\u00edvel cair abaixo de 10%, mais mem\u00f3ria deve ser obtida. P\u00e1ginas/seg Este \u00e9 na verdade a soma dos contadores \"P\u00e1ginas Entradas/seg\" e \"P\u00e1ginas Sa\u00eddas/seg\", que \u00e9 a taxa na qual as p\u00e1ginas est\u00e3o sendo lidas e escritas como resultado de falhas de p\u00e1gina. Pequenos picos com este valor n\u00e3o significam que h\u00e1 um problema, mas valores sustentados acima de 50 podem significar que a mem\u00f3ria do sistema \u00e9 um gargalo. Arquivo de Pagina\u00e7\u00e3o(_Total)\\% de Uso A porcentagem do arquivo de pagina\u00e7\u00e3o do sistema que est\u00e1 atualmente em uso. Isso n\u00e3o est\u00e1 diretamente relacionado ao desempenho, mas voc\u00ea pode enfrentar s\u00e9rios problemas de aplica\u00e7\u00e3o se o arquivo de pagina\u00e7\u00e3o ficar completamente cheio e mem\u00f3ria adicional ainda estiver sendo solicitada por aplica\u00e7\u00f5es.","title":"Mem\u00f3ria"},{"location":"automated-testing/performance-testing/#atividades-chave-de-teste-de-desempenho","text":"As atividades de teste de desempenho variam dependendo da subcategoria de teste de desempenho e dos requisitos e restri\u00e7\u00f5es do sistema. Para orienta\u00e7\u00e3o espec\u00edfica, voc\u00ea pode seguir o link para a subcategoria de testes de desempenho listada acima. As seguintes atividades podem ser inclu\u00eddas dependendo da subcategoria de teste de desempenho:","title":"Atividades-chave de Teste de Desempenho"},{"location":"automated-testing/performance-testing/#identificar-os-criterios-de-aceitacao-para-os-testes","text":"Isso geralmente incluir\u00e1 identificar os objetivos e restri\u00e7\u00f5es para as caracter\u00edsticas de desempenho do sistema.","title":"Identificar os Crit\u00e9rios de Aceita\u00e7\u00e3o para os Testes"},{"location":"automated-testing/performance-testing/#planejar-e-projetar-os-testes","text":"Em geral, precisamos considerar os seguintes pontos: Definir a carga com a qual a aplica\u00e7\u00e3o deve ser testada Estabelecer as m\u00e9tricas a serem coletadas Estabelecer quais ferramentas ser\u00e3o usadas para os testes Estabelecer a frequ\u00eancia do teste de desempenho: os testes de desempenho ser\u00e3o feitos como parte dos sprints de desenvolvimento de recursos ou apenas antes do lan\u00e7amento para um ambiente importante?","title":"Planejar e Projetar os Testes"},{"location":"automated-testing/performance-testing/#implementacao","text":"Implementar os testes de desempenho de acordo com a abordagem projetada. Instrumentar o sistema e garantir que ele esteja emitindo as m\u00e9tricas de desempenho necess\u00e1rias.","title":"Implementa\u00e7\u00e3o"},{"location":"automated-testing/performance-testing/#execucao-do-teste","text":"Executar os testes e coletar m\u00e9tricas de desempenho.","title":"Execu\u00e7\u00e3o do Teste"},{"location":"automated-testing/performance-testing/#analise-de-resultados-e-re-teste","text":"Analisar os resultados/m\u00e9tricas de desempenho dos testes. Identificar as mudan\u00e7as necess\u00e1rias para ajustar o sistema (ou seja, c\u00f3digo, infraestrutura) para melhor acomodar os objetivos do teste. Em seguida, teste novamente. Este ciclo continua at\u00e9 que o objetivo do teste seja alcan\u00e7ado. O Modelo de Teste de Desempenho Iterativo pode ser usado para capturar detalhes sobre o resultado do teste para cada itera\u00e7\u00e3o.","title":"An\u00e1lise de Resultados e Re-teste"},{"location":"automated-testing/performance-testing/#recursos","text":"Padr\u00f5es e Pr\u00e1ticas: Orienta\u00e7\u00e3o para Teste de Desempenho para Aplica\u00e7\u00f5es Web","title":"Recursos"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/","text":"Modelo de Itera\u00e7\u00e3o de Teste de Desempenho Este documento fornece um modelo para capturar os resultados de testes de desempenho. Os testes de desempenho s\u00e3o feitos em itera\u00e7\u00f5es e cada itera\u00e7\u00e3o deve ter um objetivo claro. Os resultados de qualquer itera\u00e7\u00e3o s\u00e3o imut\u00e1veis, independentemente de o objetivo ter sido alcan\u00e7ado ou n\u00e3o. Se a itera\u00e7\u00e3o falhou ou o objetivo n\u00e3o foi alcan\u00e7ado, ent\u00e3o uma nova itera\u00e7\u00e3o de teste \u00e9 realizada com as corre\u00e7\u00f5es apropriadas. \u00c9 recomend\u00e1vel manter o registro das itera\u00e7\u00f5es gravadas para manter uma linha do tempo de como o sistema evoluiu e quais mudan\u00e7as afetaram o desempenho de que maneira. Sinta-se \u00e0 vontade para modificar este modelo conforme necess\u00e1rio. Modelo de Itera\u00e7\u00e3o Objetivo Mencione em t\u00f3picos o objetivo para esta itera\u00e7\u00e3o de teste. O objetivo deve ser pequeno e mensur\u00e1vel dentro desta itera\u00e7\u00e3o. Detalhes do Teste Data : Data e hora em que esta itera\u00e7\u00e3o come\u00e7ou e terminou Dura\u00e7\u00e3o : Tempo que levou para concluir esta itera\u00e7\u00e3o. C\u00f3digo da Aplica\u00e7\u00e3o : ID do commit e link para o commit dos c\u00f3digos que est\u00e3o sendo testados nesta itera\u00e7\u00e3o Configura\u00e7\u00e3o de Refer\u00eancia: Configura\u00e7\u00e3o da Aplica\u00e7\u00e3o : Em t\u00f3picos, mencione a configura\u00e7\u00e3o da aplica\u00e7\u00e3o que deve ser registrada Configura\u00e7\u00e3o do Sistema : Em t\u00f3picos, mencione a configura\u00e7\u00e3o da infraestrutura Registre diferentes tipos de configura\u00e7\u00f5es. Geralmente, as mudan\u00e7as de configura\u00e7\u00e3o espec\u00edficas da aplica\u00e7\u00e3o entre itera\u00e7\u00f5es, enquanto as configura\u00e7\u00f5es do sistema ou infraestrutura raramente mudam. Itens de Trabalho Lista de links para itens de trabalho relevantes (tarefa, hist\u00f3ria, bug) sendo testados nesta itera\u00e7\u00e3o. Resultados Em t\u00f3picos, documente os resultados do teste. - Anexe quaisquer documentos que apoiem os resultados do teste. - Adicione links para o painel de m\u00e9tricas e logs, como Application Insights. - Capture capturas de tela para m\u00e9tricas e inclua-as nos resultados. Um bom candidato para isso \u00e9 o uso de CPU/Mem\u00f3ria/Disco. Observa\u00e7\u00f5es As observa\u00e7\u00f5es s\u00e3o percep\u00e7\u00f5es derivadas dos resultados dos testes. Mantenha as observa\u00e7\u00f5es breves e em forma de t\u00f3picos. Mencione resultados que apoiem o objetivo da itera\u00e7\u00e3o. Se alguma das observa\u00e7\u00f5es resultar em um item de trabalho (tarefa, hist\u00f3ria, bug), adicione o link para o item de trabalho junto com a observa\u00e7\u00e3o.","title":"Modelo de Itera\u00e7\u00e3o de Teste de Desempenho"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#modelo-de-iteracao-de-teste-de-desempenho","text":"Este documento fornece um modelo para capturar os resultados de testes de desempenho. Os testes de desempenho s\u00e3o feitos em itera\u00e7\u00f5es e cada itera\u00e7\u00e3o deve ter um objetivo claro. Os resultados de qualquer itera\u00e7\u00e3o s\u00e3o imut\u00e1veis, independentemente de o objetivo ter sido alcan\u00e7ado ou n\u00e3o. Se a itera\u00e7\u00e3o falhou ou o objetivo n\u00e3o foi alcan\u00e7ado, ent\u00e3o uma nova itera\u00e7\u00e3o de teste \u00e9 realizada com as corre\u00e7\u00f5es apropriadas. \u00c9 recomend\u00e1vel manter o registro das itera\u00e7\u00f5es gravadas para manter uma linha do tempo de como o sistema evoluiu e quais mudan\u00e7as afetaram o desempenho de que maneira. Sinta-se \u00e0 vontade para modificar este modelo conforme necess\u00e1rio.","title":"Modelo de Itera\u00e7\u00e3o de Teste de Desempenho"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#modelo-de-iteracao","text":"","title":"Modelo de Itera\u00e7\u00e3o"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#objetivo","text":"Mencione em t\u00f3picos o objetivo para esta itera\u00e7\u00e3o de teste. O objetivo deve ser pequeno e mensur\u00e1vel dentro desta itera\u00e7\u00e3o.","title":"Objetivo"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#detalhes-do-teste","text":"Data : Data e hora em que esta itera\u00e7\u00e3o come\u00e7ou e terminou Dura\u00e7\u00e3o : Tempo que levou para concluir esta itera\u00e7\u00e3o. C\u00f3digo da Aplica\u00e7\u00e3o : ID do commit e link para o commit dos c\u00f3digos que est\u00e3o sendo testados nesta itera\u00e7\u00e3o Configura\u00e7\u00e3o de Refer\u00eancia: Configura\u00e7\u00e3o da Aplica\u00e7\u00e3o : Em t\u00f3picos, mencione a configura\u00e7\u00e3o da aplica\u00e7\u00e3o que deve ser registrada Configura\u00e7\u00e3o do Sistema : Em t\u00f3picos, mencione a configura\u00e7\u00e3o da infraestrutura Registre diferentes tipos de configura\u00e7\u00f5es. Geralmente, as mudan\u00e7as de configura\u00e7\u00e3o espec\u00edficas da aplica\u00e7\u00e3o entre itera\u00e7\u00f5es, enquanto as configura\u00e7\u00f5es do sistema ou infraestrutura raramente mudam.","title":"Detalhes do Teste"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#itens-de-trabalho","text":"Lista de links para itens de trabalho relevantes (tarefa, hist\u00f3ria, bug) sendo testados nesta itera\u00e7\u00e3o.","title":"Itens de Trabalho"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#resultados","text":"Em t\u00f3picos, documente os resultados do teste. - Anexe quaisquer documentos que apoiem os resultados do teste. - Adicione links para o painel de m\u00e9tricas e logs, como Application Insights. - Capture capturas de tela para m\u00e9tricas e inclua-as nos resultados. Um bom candidato para isso \u00e9 o uso de CPU/Mem\u00f3ria/Disco.","title":"Resultados"},{"location":"automated-testing/performance-testing/iterative-perf-test-template/#observacoes","text":"As observa\u00e7\u00f5es s\u00e3o percep\u00e7\u00f5es derivadas dos resultados dos testes. Mantenha as observa\u00e7\u00f5es breves e em forma de t\u00f3picos. Mencione resultados que apoiem o objetivo da itera\u00e7\u00e3o. Se alguma das observa\u00e7\u00f5es resultar em um item de trabalho (tarefa, hist\u00f3ria, bug), adicione o link para o item de trabalho junto com a observa\u00e7\u00e3o.","title":"Observa\u00e7\u00f5es"},{"location":"automated-testing/performance-testing/load-testing/","text":"Teste de Carga \" O teste de carga \u00e9 realizado para determinar o comportamento de um sistema sob condi\u00e7\u00f5es normais e de pico de carga antecipadas. \" - Teste de carga - Wikipedia Um teste de carga \u00e9 projetado para determinar como um sistema se comporta sob cargas de trabalho normais e de pico esperadas. Especificamente, seu principal objetivo \u00e9 confirmar se um sistema pode lidar com o n\u00edvel de carga esperado. Dependendo do sistema-alvo, isso pode ser usu\u00e1rios simult\u00e2neos, solicita\u00e7\u00f5es por segundo ou tamanho de dados. Por que Teste de Carga O principal objetivo \u00e9 provar que o sistema pode se comportar normalmente sob a carga normal esperada antes de liber\u00e1-lo para produ\u00e7\u00e3o. Os crit\u00e9rios que definem \"comportar-se normalmente\" depender\u00e3o do seu alvo; isso pode ser t\u00e3o simples quanto \"o sistema permanece dispon\u00edvel\", mas tamb\u00e9m pode incluir o cumprimento de um SLA de tempo de resposta ou taxa de erro. Al\u00e9m disso, os resultados de um teste de carga tamb\u00e9m podem ser usados como dados para ajudar no planejamento de capacidade e no c\u00e1lculo da escalabilidade. Blocos de Design do Teste de Carga Existem v\u00e1rios componentes b\u00e1sicos necess\u00e1rios para realizar um teste de carga. Para ter resultados significativos, o sistema precisa ser testado em um ambiente semelhante \u00e0 produ\u00e7\u00e3o, com uma rede e hardware que se assemelhem ao ambiente de implanta\u00e7\u00e3o esperado. O teste de carga consistir\u00e1 em um m\u00f3dulo que simula a atividade do usu\u00e1rio. Claro, a composi\u00e7\u00e3o dessa \"atividade do usu\u00e1rio\" variar\u00e1 com base no tipo de aplica\u00e7\u00e3o que est\u00e1 sendo testada. Por exemplo, um site de com\u00e9rcio eletr\u00f4nico pode simular a navega\u00e7\u00e3o e compra de itens do usu\u00e1rio, mas um pipeline de ingest\u00e3o de dados de IoT simularia um fluxo de leituras de dispositivos. Certifique-se de que a simula\u00e7\u00e3o seja o mais pr\u00f3xima poss\u00edvel da atividade real e considere n\u00e3o apenas o volume, mas tamb\u00e9m os padr\u00f5es e a variabilidade. Por exemplo, se os dados do simulador forem muito uniformes ou previs\u00edveis, as propor\u00e7\u00f5es de acerto/erro do cache podem afetar seus resultados. O teste de carga ser\u00e1 iniciado a partir de um componente externo ao sistema-alvo, que pode controlar a quantidade de carga aplicada. Isso pode ser um \u00fanico agente, mas pode precisar ser dimensionado para v\u00e1rios agentes para alcan\u00e7ar n\u00edveis mais altos de atividade. Embora n\u00e3o seja necess\u00e1rio para executar um teste de carga, \u00e9 aconselh\u00e1vel ter monitoramento e/ou registro em vigor para poder medir o impacto do teste e descobrir gargalos potenciais. Aplicando o Teste de Carga Planejamento Identificar cen\u00e1rios-chave para medir - Re\u00fana esses cen\u00e1rios do Product Owner; eles devem fornecer uma amostra representativa do tr\u00e1fego do mundo real. Determinar carga normal e de pico esperadas para os cen\u00e1rios - Determine um n\u00edvel de carga, como usu\u00e1rios simult\u00e2neos ou solicita\u00e7\u00f5es por segundo, para encontrar o tamanho do teste de carga que voc\u00ea executar\u00e1. Identificar m\u00e9tricas de crit\u00e9rios de sucesso - Essas podem estar no lado do teste, como tempo de resposta e taxa de erro, ou podem estar no lado do sistema, como uso de CPU e mem\u00f3ria. Selecionar a ferramenta certa - Existem muitos frameworks para teste de carga, ent\u00e3o considere se os recursos e limita\u00e7\u00f5es s\u00e3o adequados para suas necessidades. (Algumas ferramentas populares est\u00e3o listadas abaixo). Observabilidade - Determine quais m\u00e9tricas precisam ser coletadas para obter informa\u00e7\u00f5es sobre taxa de transfer\u00eancia, lat\u00eancia, utiliza\u00e7\u00e3o de recursos, etc. Escalabilidade - Determine a quantidade de escala necess\u00e1ria pelo gerador de carga, aplica\u00e7\u00e3o de carga de trabalho, CPU, Mem\u00f3ria e componentes de rede necess\u00e1rios para alcan\u00e7ar os objetivos de teste. O uso de Kubernetes na nuvem pode ser usado para tornar o teste infinitamente escal\u00e1vel. Execu\u00e7\u00e3o \u00c9 recomendado o uso de um framework de teste existente (veja abaixo). Essas ferramentas fornecer\u00e3o um m\u00e9todo para especificar os cen\u00e1rios de atividade do usu\u00e1rio e como execut\u00e1-los sob carga. \u00c9 comum aumentar lentamente a carga desejada para replicar melhor o comportamento do mundo real. Depois de atingir sua carga de trabalho definida, mantenha esse n\u00edvel o tempo suficiente para ver se seu sistema se estabiliza. Para finalizar o teste, voc\u00ea tamb\u00e9m deve aumentar a carga para ver como o sistema desacelera. Voc\u00ea tamb\u00e9m deve considerar a origem do tr\u00e1fego do seu teste de carga. Dependendo do escopo do sistema-alvo, voc\u00ea pode querer iniciar de um local diferente para replicar melhor o tr\u00e1fego do mundo real, como de uma regi\u00e3o diferente. Nota: Antes de come\u00e7ar, esteja ciente de quaisquer restri\u00e7\u00f5es em sua rede, como prote\u00e7\u00e3o DDOS, onde voc\u00ea pode precisar notificar um administrador de rede ou solicitar uma isen\u00e7\u00e3o. Testes Adicionais Ap\u00f3s concluir seu teste de carga, voc\u00ea deve estar preparado para continuar com testes adicionais relacionados, como: Teste de Soak - Tamb\u00e9m conhecido como Teste de Resist\u00eancia . Realizar um teste de carga por um per\u00edodo prolongado para garantir a estabilidade a longo prazo. Teste de Estresse - Aumentar gradualmente a carga para encontrar os limites do sistema e identificar a capacidade m\u00e1xima. Teste de Pico - Introduzir um aumento acentuado de curto prazo nos cen\u00e1rios de carga. Teste de Escalabilidade - Re-teste de um sistema \u00e0 medida que voc\u00ea expande horizontal ou verticalmente para medir como ele escala. Teste Distribu\u00eddo - O teste distribu\u00eddo permite que voc\u00ea aproveite o poder de v\u00e1rias m\u00e1quinas para realizar testes maiores ou mais aprofundados mais rapidamente. \u00c9 necess\u00e1rio quando um n\u00f3 totalmente otimizado n\u00e3o pode produzir a carga exigida pelo seu teste extremamente grande. Frameworks e Ferramentas de Gera\u00e7\u00e3o de Carga de Teste Aqui est\u00e3o alguns frameworks de teste de carga populares que voc\u00ea pode considerar, e as linguagens usadas para definir seus cen\u00e1rios. Azure Load Testing ( https://learn.microsoft.com/en-us/azure/load-testing/ ) - Plataforma gerenciada para executar testes de carga no Azure. Permite executar e monitorar testes automaticamente, obter segredos do KeyVault, gerar tr\u00e1fego em escala e testar endpoints privados do Azure. No caso simples, executa testes de carga com tr\u00e1fego HTTP GET para um determinado endpoint. Para os casos mais complexos, voc\u00ea pode fazer upload de seus pr\u00f3prios cen\u00e1rios JMeter . - JMeter ( https://github.com/apache/jmeter ) - Possui padr\u00f5es integrados para testar sem codifica\u00e7\u00e3o, mas pode ser estendido com Java. - Artillery ( https://artillery.io/ ) - Escreva seus cen\u00e1rios em Javascript, executa uma aplica\u00e7\u00e3o node. - Gatling ( https://gatling.io/ ) - Escreva seus cen\u00e1rios em Scala com seu DSL. - Locust ( https://locust.io/ ) - Escreva seus cen\u00e1rios em Python usando o conceito de atividade de usu\u00e1rio simult\u00e2neo. - K6 ( https://k6.io/ ) - Escreva seus cen\u00e1rios de teste em Javascript, dispon\u00edvel como operador Kubernetes de c\u00f3digo aberto, imagem Docker de c\u00f3digo aberto ou como SaaS. Particularmente \u00fatil para teste de carga distribu\u00eddo. Integra-se facilmente com o Prometheus. - NBomber ( https://nbomber.com/ ) - Escreva seus cen\u00e1rios de teste em C# ou F#, integra\u00e7\u00e3o dispon\u00edvel com test runners (NUnit/xUnit). - WebValidate ( https://github.com/microsoft/webvalidate ) - Ferramenta de valida\u00e7\u00e3o de solicita\u00e7\u00e3o web usada para executar testes de ponta a ponta e testes de desempenho e disponibilidade de longa dura\u00e7\u00e3o. Aplica\u00e7\u00f5es de Carga de Trabalho de Amostra No caso em que uma aplica\u00e7\u00e3o de carga de trabalho espec\u00edfica n\u00e3o est\u00e1 sendo fornecida e o foco est\u00e1, em vez disso, no sistema, aqui est\u00e3o algumas aplica\u00e7\u00f5es de carga de trabalho de amostra populares que voc\u00ea pode considerar. HttpBin ( Python , GoLang ) - Suporta v\u00e1rios tipos de endpoints e implementa\u00e7\u00f5es de linguagem. Pode ecoar dados usados na solicita\u00e7\u00e3o. NGSA ( Java , C# ) - Destinado ao teste de plataforma e monitoramento do Kubernetes. Constru\u00eddo em cima da loja de dados IMDB com muitos endpoints CRUD dispon\u00edveis. N\u00e3o precisa ter uma conex\u00e3o de banco de dados ao vivo. MockBin ( https://github.com/Kong/mockbin ) - Permite que voc\u00ea gere endpoints personalizados para testar, simular e rastrear solicita\u00e7\u00f5es e respostas HTTP entre bibliotecas, sockets e APIs. Conclus\u00e3o Um teste de carga \u00e9 uma etapa cr\u00edtica para entender se um sistema-alvo ser\u00e1 confi\u00e1vel sob o tr\u00e1fego real esperado. Claro, ele s\u00f3 \u00e9 t\u00e3o bom quanto sua capacidade de prever a carga esperada, ent\u00e3o \u00e9 importante seguir com outros testes adicionais para realmente entender como seu sistema se comporta em diferentes situa\u00e7\u00f5es. Recursos Lista de leituras adicionais sobre este tipo de teste para aqueles que gostariam de se aprofundar. Microsoft Azure Well-Architected Framework > Teste de Carga","title":"Teste de Carga"},{"location":"automated-testing/performance-testing/load-testing/#teste-de-carga","text":"\" O teste de carga \u00e9 realizado para determinar o comportamento de um sistema sob condi\u00e7\u00f5es normais e de pico de carga antecipadas. \" - Teste de carga - Wikipedia Um teste de carga \u00e9 projetado para determinar como um sistema se comporta sob cargas de trabalho normais e de pico esperadas. Especificamente, seu principal objetivo \u00e9 confirmar se um sistema pode lidar com o n\u00edvel de carga esperado. Dependendo do sistema-alvo, isso pode ser usu\u00e1rios simult\u00e2neos, solicita\u00e7\u00f5es por segundo ou tamanho de dados.","title":"Teste de Carga"},{"location":"automated-testing/performance-testing/load-testing/#por-que-teste-de-carga","text":"O principal objetivo \u00e9 provar que o sistema pode se comportar normalmente sob a carga normal esperada antes de liber\u00e1-lo para produ\u00e7\u00e3o. Os crit\u00e9rios que definem \"comportar-se normalmente\" depender\u00e3o do seu alvo; isso pode ser t\u00e3o simples quanto \"o sistema permanece dispon\u00edvel\", mas tamb\u00e9m pode incluir o cumprimento de um SLA de tempo de resposta ou taxa de erro. Al\u00e9m disso, os resultados de um teste de carga tamb\u00e9m podem ser usados como dados para ajudar no planejamento de capacidade e no c\u00e1lculo da escalabilidade.","title":"Por que Teste de Carga"},{"location":"automated-testing/performance-testing/load-testing/#blocos-de-design-do-teste-de-carga","text":"Existem v\u00e1rios componentes b\u00e1sicos necess\u00e1rios para realizar um teste de carga. Para ter resultados significativos, o sistema precisa ser testado em um ambiente semelhante \u00e0 produ\u00e7\u00e3o, com uma rede e hardware que se assemelhem ao ambiente de implanta\u00e7\u00e3o esperado. O teste de carga consistir\u00e1 em um m\u00f3dulo que simula a atividade do usu\u00e1rio. Claro, a composi\u00e7\u00e3o dessa \"atividade do usu\u00e1rio\" variar\u00e1 com base no tipo de aplica\u00e7\u00e3o que est\u00e1 sendo testada. Por exemplo, um site de com\u00e9rcio eletr\u00f4nico pode simular a navega\u00e7\u00e3o e compra de itens do usu\u00e1rio, mas um pipeline de ingest\u00e3o de dados de IoT simularia um fluxo de leituras de dispositivos. Certifique-se de que a simula\u00e7\u00e3o seja o mais pr\u00f3xima poss\u00edvel da atividade real e considere n\u00e3o apenas o volume, mas tamb\u00e9m os padr\u00f5es e a variabilidade. Por exemplo, se os dados do simulador forem muito uniformes ou previs\u00edveis, as propor\u00e7\u00f5es de acerto/erro do cache podem afetar seus resultados. O teste de carga ser\u00e1 iniciado a partir de um componente externo ao sistema-alvo, que pode controlar a quantidade de carga aplicada. Isso pode ser um \u00fanico agente, mas pode precisar ser dimensionado para v\u00e1rios agentes para alcan\u00e7ar n\u00edveis mais altos de atividade. Embora n\u00e3o seja necess\u00e1rio para executar um teste de carga, \u00e9 aconselh\u00e1vel ter monitoramento e/ou registro em vigor para poder medir o impacto do teste e descobrir gargalos potenciais.","title":"Blocos de Design do Teste de Carga"},{"location":"automated-testing/performance-testing/load-testing/#aplicando-o-teste-de-carga","text":"","title":"Aplicando o Teste de Carga"},{"location":"automated-testing/performance-testing/load-testing/#planejamento","text":"Identificar cen\u00e1rios-chave para medir - Re\u00fana esses cen\u00e1rios do Product Owner; eles devem fornecer uma amostra representativa do tr\u00e1fego do mundo real. Determinar carga normal e de pico esperadas para os cen\u00e1rios - Determine um n\u00edvel de carga, como usu\u00e1rios simult\u00e2neos ou solicita\u00e7\u00f5es por segundo, para encontrar o tamanho do teste de carga que voc\u00ea executar\u00e1. Identificar m\u00e9tricas de crit\u00e9rios de sucesso - Essas podem estar no lado do teste, como tempo de resposta e taxa de erro, ou podem estar no lado do sistema, como uso de CPU e mem\u00f3ria. Selecionar a ferramenta certa - Existem muitos frameworks para teste de carga, ent\u00e3o considere se os recursos e limita\u00e7\u00f5es s\u00e3o adequados para suas necessidades. (Algumas ferramentas populares est\u00e3o listadas abaixo). Observabilidade - Determine quais m\u00e9tricas precisam ser coletadas para obter informa\u00e7\u00f5es sobre taxa de transfer\u00eancia, lat\u00eancia, utiliza\u00e7\u00e3o de recursos, etc. Escalabilidade - Determine a quantidade de escala necess\u00e1ria pelo gerador de carga, aplica\u00e7\u00e3o de carga de trabalho, CPU, Mem\u00f3ria e componentes de rede necess\u00e1rios para alcan\u00e7ar os objetivos de teste. O uso de Kubernetes na nuvem pode ser usado para tornar o teste infinitamente escal\u00e1vel.","title":"Planejamento"},{"location":"automated-testing/performance-testing/load-testing/#execucao","text":"\u00c9 recomendado o uso de um framework de teste existente (veja abaixo). Essas ferramentas fornecer\u00e3o um m\u00e9todo para especificar os cen\u00e1rios de atividade do usu\u00e1rio e como execut\u00e1-los sob carga. \u00c9 comum aumentar lentamente a carga desejada para replicar melhor o comportamento do mundo real. Depois de atingir sua carga de trabalho definida, mantenha esse n\u00edvel o tempo suficiente para ver se seu sistema se estabiliza. Para finalizar o teste, voc\u00ea tamb\u00e9m deve aumentar a carga para ver como o sistema desacelera. Voc\u00ea tamb\u00e9m deve considerar a origem do tr\u00e1fego do seu teste de carga. Dependendo do escopo do sistema-alvo, voc\u00ea pode querer iniciar de um local diferente para replicar melhor o tr\u00e1fego do mundo real, como de uma regi\u00e3o diferente. Nota: Antes de come\u00e7ar, esteja ciente de quaisquer restri\u00e7\u00f5es em sua rede, como prote\u00e7\u00e3o DDOS, onde voc\u00ea pode precisar notificar um administrador de rede ou solicitar uma isen\u00e7\u00e3o.","title":"Execu\u00e7\u00e3o"},{"location":"automated-testing/performance-testing/load-testing/#testes-adicionais","text":"Ap\u00f3s concluir seu teste de carga, voc\u00ea deve estar preparado para continuar com testes adicionais relacionados, como: Teste de Soak - Tamb\u00e9m conhecido como Teste de Resist\u00eancia . Realizar um teste de carga por um per\u00edodo prolongado para garantir a estabilidade a longo prazo. Teste de Estresse - Aumentar gradualmente a carga para encontrar os limites do sistema e identificar a capacidade m\u00e1xima. Teste de Pico - Introduzir um aumento acentuado de curto prazo nos cen\u00e1rios de carga. Teste de Escalabilidade - Re-teste de um sistema \u00e0 medida que voc\u00ea expande horizontal ou verticalmente para medir como ele escala. Teste Distribu\u00eddo - O teste distribu\u00eddo permite que voc\u00ea aproveite o poder de v\u00e1rias m\u00e1quinas para realizar testes maiores ou mais aprofundados mais rapidamente. \u00c9 necess\u00e1rio quando um n\u00f3 totalmente otimizado n\u00e3o pode produzir a carga exigida pelo seu teste extremamente grande.","title":"Testes Adicionais"},{"location":"automated-testing/performance-testing/load-testing/#frameworks-e-ferramentas-de-geracao-de-carga-de-teste","text":"Aqui est\u00e3o alguns frameworks de teste de carga populares que voc\u00ea pode considerar, e as linguagens usadas para definir seus cen\u00e1rios. Azure Load Testing ( https://learn.microsoft.com/en-us/azure/load-testing/ ) - Plataforma gerenciada para executar testes de carga no Azure. Permite executar e monitorar testes automaticamente, obter segredos do KeyVault, gerar tr\u00e1fego em escala e testar endpoints privados do Azure. No caso simples, executa testes de carga com tr\u00e1fego HTTP GET para um determinado endpoint. Para os casos mais complexos, voc\u00ea pode fazer upload de seus pr\u00f3prios cen\u00e1rios JMeter . - JMeter ( https://github.com/apache/jmeter ) - Possui padr\u00f5es integrados para testar sem codifica\u00e7\u00e3o, mas pode ser estendido com Java. - Artillery ( https://artillery.io/ ) - Escreva seus cen\u00e1rios em Javascript, executa uma aplica\u00e7\u00e3o node. - Gatling ( https://gatling.io/ ) - Escreva seus cen\u00e1rios em Scala com seu DSL. - Locust ( https://locust.io/ ) - Escreva seus cen\u00e1rios em Python usando o conceito de atividade de usu\u00e1rio simult\u00e2neo. - K6 ( https://k6.io/ ) - Escreva seus cen\u00e1rios de teste em Javascript, dispon\u00edvel como operador Kubernetes de c\u00f3digo aberto, imagem Docker de c\u00f3digo aberto ou como SaaS. Particularmente \u00fatil para teste de carga distribu\u00eddo. Integra-se facilmente com o Prometheus. - NBomber ( https://nbomber.com/ ) - Escreva seus cen\u00e1rios de teste em C# ou F#, integra\u00e7\u00e3o dispon\u00edvel com test runners (NUnit/xUnit). - WebValidate ( https://github.com/microsoft/webvalidate ) - Ferramenta de valida\u00e7\u00e3o de solicita\u00e7\u00e3o web usada para executar testes de ponta a ponta e testes de desempenho e disponibilidade de longa dura\u00e7\u00e3o.","title":"Frameworks e Ferramentas de Gera\u00e7\u00e3o de Carga de Teste"},{"location":"automated-testing/performance-testing/load-testing/#aplicacoes-de-carga-de-trabalho-de-amostra","text":"No caso em que uma aplica\u00e7\u00e3o de carga de trabalho espec\u00edfica n\u00e3o est\u00e1 sendo fornecida e o foco est\u00e1, em vez disso, no sistema, aqui est\u00e3o algumas aplica\u00e7\u00f5es de carga de trabalho de amostra populares que voc\u00ea pode considerar. HttpBin ( Python , GoLang ) - Suporta v\u00e1rios tipos de endpoints e implementa\u00e7\u00f5es de linguagem. Pode ecoar dados usados na solicita\u00e7\u00e3o. NGSA ( Java , C# ) - Destinado ao teste de plataforma e monitoramento do Kubernetes. Constru\u00eddo em cima da loja de dados IMDB com muitos endpoints CRUD dispon\u00edveis. N\u00e3o precisa ter uma conex\u00e3o de banco de dados ao vivo. MockBin ( https://github.com/Kong/mockbin ) - Permite que voc\u00ea gere endpoints personalizados para testar, simular e rastrear solicita\u00e7\u00f5es e respostas HTTP entre bibliotecas, sockets e APIs.","title":"Aplica\u00e7\u00f5es de Carga de Trabalho de Amostra"},{"location":"automated-testing/performance-testing/load-testing/#conclusao","text":"Um teste de carga \u00e9 uma etapa cr\u00edtica para entender se um sistema-alvo ser\u00e1 confi\u00e1vel sob o tr\u00e1fego real esperado. Claro, ele s\u00f3 \u00e9 t\u00e3o bom quanto sua capacidade de prever a carga esperada, ent\u00e3o \u00e9 importante seguir com outros testes adicionais para realmente entender como seu sistema se comporta em diferentes situa\u00e7\u00f5es.","title":"Conclus\u00e3o"},{"location":"automated-testing/performance-testing/load-testing/#recursos","text":"Lista de leituras adicionais sobre este tipo de teste para aqueles que gostariam de se aprofundar. Microsoft Azure Well-Architected Framework > Teste de Carga","title":"Recursos"},{"location":"automated-testing/shadow-testing/","text":"Teste de Sombra (Shadow Testing) O Teste de Sombra \u00e9 uma abordagem para reduzir riscos antes de ir para a produ\u00e7\u00e3o. Tamb\u00e9m conhecido como \"Implanta\u00e7\u00e3o Sombra\" ou \"Sombreamento de Tr\u00e1fego\", tem semelhan\u00e7as com o \"Lan\u00e7amento Escuro\" (Dark Launching). Quando Usar O Teste de Sombra reduz riscos quando voc\u00ea considera substituir o ambiente atual (V-Atual) por um ambiente candidato com um novo recurso (V-Pr\u00f3ximo). Essa abordagem envolve monitorar e capturar diferen\u00e7as entre os dois ambientes e, em seguida, compar\u00e1-los para reduzir todos os riscos antes de introduzir um novo recurso/lan\u00e7amento. Aplic\u00e1vel a Implanta\u00e7\u00f5es de Produ\u00e7\u00e3o : O V-Pr\u00f3ximo no Teste de Sombra sempre funciona separadamente e n\u00e3o afeta a produ\u00e7\u00e3o. Os usu\u00e1rios n\u00e3o s\u00e3o afetados por esse teste. Infraestrutura : O Teste de Sombra replica o mesmo tr\u00e1fego, ent\u00e3o no ambiente de teste voc\u00ea pode ter o mesmo tr\u00e1fego que na produ\u00e7\u00e3o. Isso ajuda a produzir cen\u00e1rios de teste da vida real. Manuseio de Escala : Todo o tr\u00e1fego \u00e9 replicado, e voc\u00ea tem a chance de ver como seu sistema est\u00e1 escalando. Frameworks e Ferramentas de Teste de Sombra Existem algumas ferramentas para implementar o teste de sombra. O principal objetivo dessas ferramentas \u00e9 comparar as respostas do V-Atual e do V-Pr\u00f3ximo e encontrar as diferen\u00e7as. Diffy Envoy McRouter Scientist Um dos mais populares \u00e9 o Diffy . Ele foi criado e usado no Twitter. Hoje, o autor original e um ex-funcion\u00e1rio do Twitter mant\u00eam sua pr\u00f3pria vers\u00e3o deste projeto, chamada Opendiffy . Conclus\u00e3o O Teste de Sombra \u00e9 uma abordagem \u00fatil para reduzir riscos quando voc\u00ea considera substituir o ambiente atual com um ambiente candidato usando novos recursos. Algumas vantagens do teste de sombra incluem: Impacto zero no ambiente de produ\u00e7\u00e3o. N\u00e3o \u00e9 necess\u00e1rio gerar cen\u00e1rios de teste e dados de teste. Podemos testar cen\u00e1rios da vida real com dados da vida real. Podemos simular a escala com tr\u00e1fego de produ\u00e7\u00e3o replicado. Refer\u00eancias Martin Fowler - Dark Launching Martin Fowler - Feature Toggle Traffic Shadowing/Mirroring","title":"Teste de Sombra (Shadow Testing)"},{"location":"automated-testing/shadow-testing/#teste-de-sombra-shadow-testing","text":"O Teste de Sombra \u00e9 uma abordagem para reduzir riscos antes de ir para a produ\u00e7\u00e3o. Tamb\u00e9m conhecido como \"Implanta\u00e7\u00e3o Sombra\" ou \"Sombreamento de Tr\u00e1fego\", tem semelhan\u00e7as com o \"Lan\u00e7amento Escuro\" (Dark Launching).","title":"Teste de Sombra (Shadow Testing)"},{"location":"automated-testing/shadow-testing/#quando-usar","text":"O Teste de Sombra reduz riscos quando voc\u00ea considera substituir o ambiente atual (V-Atual) por um ambiente candidato com um novo recurso (V-Pr\u00f3ximo). Essa abordagem envolve monitorar e capturar diferen\u00e7as entre os dois ambientes e, em seguida, compar\u00e1-los para reduzir todos os riscos antes de introduzir um novo recurso/lan\u00e7amento.","title":"Quando Usar"},{"location":"automated-testing/shadow-testing/#aplicavel-a","text":"Implanta\u00e7\u00f5es de Produ\u00e7\u00e3o : O V-Pr\u00f3ximo no Teste de Sombra sempre funciona separadamente e n\u00e3o afeta a produ\u00e7\u00e3o. Os usu\u00e1rios n\u00e3o s\u00e3o afetados por esse teste. Infraestrutura : O Teste de Sombra replica o mesmo tr\u00e1fego, ent\u00e3o no ambiente de teste voc\u00ea pode ter o mesmo tr\u00e1fego que na produ\u00e7\u00e3o. Isso ajuda a produzir cen\u00e1rios de teste da vida real. Manuseio de Escala : Todo o tr\u00e1fego \u00e9 replicado, e voc\u00ea tem a chance de ver como seu sistema est\u00e1 escalando.","title":"Aplic\u00e1vel a"},{"location":"automated-testing/shadow-testing/#frameworks-e-ferramentas-de-teste-de-sombra","text":"Existem algumas ferramentas para implementar o teste de sombra. O principal objetivo dessas ferramentas \u00e9 comparar as respostas do V-Atual e do V-Pr\u00f3ximo e encontrar as diferen\u00e7as. Diffy Envoy McRouter Scientist Um dos mais populares \u00e9 o Diffy . Ele foi criado e usado no Twitter. Hoje, o autor original e um ex-funcion\u00e1rio do Twitter mant\u00eam sua pr\u00f3pria vers\u00e3o deste projeto, chamada Opendiffy .","title":"Frameworks e Ferramentas de Teste de Sombra"},{"location":"automated-testing/shadow-testing/#conclusao","text":"O Teste de Sombra \u00e9 uma abordagem \u00fatil para reduzir riscos quando voc\u00ea considera substituir o ambiente atual com um ambiente candidato usando novos recursos. Algumas vantagens do teste de sombra incluem: Impacto zero no ambiente de produ\u00e7\u00e3o. N\u00e3o \u00e9 necess\u00e1rio gerar cen\u00e1rios de teste e dados de teste. Podemos testar cen\u00e1rios da vida real com dados da vida real. Podemos simular a escala com tr\u00e1fego de produ\u00e7\u00e3o replicado.","title":"Conclus\u00e3o"},{"location":"automated-testing/shadow-testing/#referencias","text":"Martin Fowler - Dark Launching Martin Fowler - Feature Toggle Traffic Shadowing/Mirroring","title":"Refer\u00eancias"},{"location":"automated-testing/smoke-testing/","text":"Teste de Fuma\u00e7a (Smoke Testing) Testes de fuma\u00e7a, \u00e0s vezes chamados de testes de Sanidade , Aceita\u00e7\u00e3o ou Verifica\u00e7\u00e3o de Build/Lan\u00e7amento , s\u00e3o um subtipo de testes de sistema/funcionais geralmente usados como port\u00f5es que verificam a prontid\u00e3o da aplica\u00e7\u00e3o como um passo preliminar. Se uma aplica\u00e7\u00e3o passa nos testes de fuma\u00e7a, ela \u00e9 aceit\u00e1vel ou est\u00e1 em um estado est\u00e1vel o suficiente para as pr\u00f3ximas etapas de teste ou implanta\u00e7\u00e3o. Quando Usar Problema Abordado Os testes de fuma\u00e7a t\u00eam como objetivo descobrir, o mais cedo poss\u00edvel, se uma aplica\u00e7\u00e3o est\u00e1 funcionando ou n\u00e3o. O objetivo dos testes de fuma\u00e7a \u00e9 economizar tempo; se a vers\u00e3o atual da aplica\u00e7\u00e3o n\u00e3o passar nos testes de fuma\u00e7a, ent\u00e3o o resto da cadeia de integra\u00e7\u00e3o ou implanta\u00e7\u00e3o para ela pode ser abandonado. Os testes de fuma\u00e7a n\u00e3o visam fornecer cobertura total de funcionalidade, mas sim focar em algumas invoca\u00e7\u00f5es de aceita\u00e7\u00e3o r\u00e1pidas para as quais a aplica\u00e7\u00e3o deve, em todos os momentos, responder corretamente. Ponto de Inflex\u00e3o do ROI Os testes de fuma\u00e7a cobrem apenas o caminho cr\u00edtico da aplica\u00e7\u00e3o e n\u00e3o devem ser usados para realmente testar o comportamento da aplica\u00e7\u00e3o, mantendo o tempo de execu\u00e7\u00e3o e a complexidade no m\u00ednimo. Os testes podem ser formados por um subconjunto dos testes de integra\u00e7\u00e3o ou e2e da aplica\u00e7\u00e3o, e eles cobrem tanto da funcionalidade com a menor profundidade poss\u00edvel. A regra de ouro de um bom teste de fuma\u00e7a \u00e9 que ele economiza tempo na valida\u00e7\u00e3o de que a aplica\u00e7\u00e3o \u00e9 aceit\u00e1vel para um est\u00e1gio onde testes melhores e mais completos come\u00e7ar\u00e3o. Aplic\u00e1vel a Desktop de desenvolvimento local - Exemplo: Aplica\u00e7\u00e3o de teste de fuma\u00e7a manual para verificar se a aplica\u00e7\u00e3o est\u00e1 OK. Pipelines de Build - Exemplo: Execu\u00e7\u00e3o de um pequeno conjunto da su\u00edte de teste de integra\u00e7\u00e3o antes de executar a cobertura total de testes, que pode levar muito tempo. Implanta\u00e7\u00f5es em ambientes n\u00e3o-produtivos e produtivos - Exemplo: Execu\u00e7\u00e3o de um comando curl para a API do produto e afirmando que a resposta \u00e9 200 antes de executar testes de carga que consomem recursos. Valida\u00e7\u00e3o de PR - Exemplo: Implanta\u00e7\u00e3o do gr\u00e1fico da aplica\u00e7\u00e3o em um namespace de teste e valida\u00e7\u00e3o de que o lan\u00e7amento \u00e9 bem-sucedido e que nenhuma regress\u00e3o imediata \u00e9 mesclada. Conclus\u00e3o O teste de fuma\u00e7a \u00e9 uma etapa de baixo esfor\u00e7o e alto impacto para enviar software mais confi\u00e1vel. Ele deve ser considerado entre as primeiras etapas a serem implementadas ao planejar sistemas continuamente integrados e entregues. Recursos Wikipedia - Teste de Fuma\u00e7a Livro SRE do Google - Testes de Sistema","title":"Teste de Fuma\u00e7a (Smoke Testing)"},{"location":"automated-testing/smoke-testing/#teste-de-fumaca-smoke-testing","text":"Testes de fuma\u00e7a, \u00e0s vezes chamados de testes de Sanidade , Aceita\u00e7\u00e3o ou Verifica\u00e7\u00e3o de Build/Lan\u00e7amento , s\u00e3o um subtipo de testes de sistema/funcionais geralmente usados como port\u00f5es que verificam a prontid\u00e3o da aplica\u00e7\u00e3o como um passo preliminar. Se uma aplica\u00e7\u00e3o passa nos testes de fuma\u00e7a, ela \u00e9 aceit\u00e1vel ou est\u00e1 em um estado est\u00e1vel o suficiente para as pr\u00f3ximas etapas de teste ou implanta\u00e7\u00e3o.","title":"Teste de Fuma\u00e7a (Smoke Testing)"},{"location":"automated-testing/smoke-testing/#quando-usar","text":"","title":"Quando Usar"},{"location":"automated-testing/smoke-testing/#problema-abordado","text":"Os testes de fuma\u00e7a t\u00eam como objetivo descobrir, o mais cedo poss\u00edvel, se uma aplica\u00e7\u00e3o est\u00e1 funcionando ou n\u00e3o. O objetivo dos testes de fuma\u00e7a \u00e9 economizar tempo; se a vers\u00e3o atual da aplica\u00e7\u00e3o n\u00e3o passar nos testes de fuma\u00e7a, ent\u00e3o o resto da cadeia de integra\u00e7\u00e3o ou implanta\u00e7\u00e3o para ela pode ser abandonado. Os testes de fuma\u00e7a n\u00e3o visam fornecer cobertura total de funcionalidade, mas sim focar em algumas invoca\u00e7\u00f5es de aceita\u00e7\u00e3o r\u00e1pidas para as quais a aplica\u00e7\u00e3o deve, em todos os momentos, responder corretamente.","title":"Problema Abordado"},{"location":"automated-testing/smoke-testing/#ponto-de-inflexao-do-roi","text":"Os testes de fuma\u00e7a cobrem apenas o caminho cr\u00edtico da aplica\u00e7\u00e3o e n\u00e3o devem ser usados para realmente testar o comportamento da aplica\u00e7\u00e3o, mantendo o tempo de execu\u00e7\u00e3o e a complexidade no m\u00ednimo. Os testes podem ser formados por um subconjunto dos testes de integra\u00e7\u00e3o ou e2e da aplica\u00e7\u00e3o, e eles cobrem tanto da funcionalidade com a menor profundidade poss\u00edvel. A regra de ouro de um bom teste de fuma\u00e7a \u00e9 que ele economiza tempo na valida\u00e7\u00e3o de que a aplica\u00e7\u00e3o \u00e9 aceit\u00e1vel para um est\u00e1gio onde testes melhores e mais completos come\u00e7ar\u00e3o.","title":"Ponto de Inflex\u00e3o do ROI"},{"location":"automated-testing/smoke-testing/#aplicavel-a","text":"Desktop de desenvolvimento local - Exemplo: Aplica\u00e7\u00e3o de teste de fuma\u00e7a manual para verificar se a aplica\u00e7\u00e3o est\u00e1 OK. Pipelines de Build - Exemplo: Execu\u00e7\u00e3o de um pequeno conjunto da su\u00edte de teste de integra\u00e7\u00e3o antes de executar a cobertura total de testes, que pode levar muito tempo. Implanta\u00e7\u00f5es em ambientes n\u00e3o-produtivos e produtivos - Exemplo: Execu\u00e7\u00e3o de um comando curl para a API do produto e afirmando que a resposta \u00e9 200 antes de executar testes de carga que consomem recursos. Valida\u00e7\u00e3o de PR - Exemplo: Implanta\u00e7\u00e3o do gr\u00e1fico da aplica\u00e7\u00e3o em um namespace de teste e valida\u00e7\u00e3o de que o lan\u00e7amento \u00e9 bem-sucedido e que nenhuma regress\u00e3o imediata \u00e9 mesclada.","title":"Aplic\u00e1vel a"},{"location":"automated-testing/smoke-testing/#conclusao","text":"O teste de fuma\u00e7a \u00e9 uma etapa de baixo esfor\u00e7o e alto impacto para enviar software mais confi\u00e1vel. Ele deve ser considerado entre as primeiras etapas a serem implementadas ao planejar sistemas continuamente integrados e entregues.","title":"Conclus\u00e3o"},{"location":"automated-testing/smoke-testing/#recursos","text":"Wikipedia - Teste de Fuma\u00e7a Livro SRE do Google - Testes de Sistema","title":"Recursos"},{"location":"automated-testing/synthetic-monitoring-tests/","text":"Testes de Monitoramento Sint\u00e9tico Testes de Monitoramento Sint\u00e9tico s\u00e3o um conjunto de testes funcionais que t\u00eam como alvo um sistema ativo em produ\u00e7\u00e3o. O foco desses testes, \u00e0s vezes chamados de \"watchdog\", \"monitoramento ativo\" ou \"transa\u00e7\u00f5es sint\u00e9ticas\", \u00e9 verificar continuamente a sa\u00fade e a resili\u00eancia do produto. Por que Testes de Monitoramento Sint\u00e9tico Tradicionalmente, os provedores de software confiam em testes por meio de etapas de CI/CD na conhecida pir\u00e2mide de testes (unit\u00e1rios, integra\u00e7\u00e3o, e2e) para validar que o produto est\u00e1 saud\u00e1vel e sem regress\u00f5es. No entanto, \u00e0 medida que mais organiza\u00e7\u00f5es hoje fornecem produtos altamente dispon\u00edveis (SLA de 99,9+), elas descobrem que a natureza de aplica\u00e7\u00f5es distribu\u00eddas de longa dura\u00e7\u00e3o, que normalmente dependem de v\u00e1rios componentes de hardware e software, \u00e9 falhar. Para tais sistemas, a ambi\u00e7\u00e3o das equipes de engenharia de servi\u00e7o \u00e9 reduzir ao m\u00ednimo o tempo necess\u00e1rio para corrigir erros, ou o MTTR - Tempo M\u00e9dio para Reparo . \u00c9 um esfor\u00e7o cont\u00ednuo, realizado no sistema ativo/produ\u00e7\u00e3o. Monitores Sint\u00e9ticos podem ser usados para detectar os seguintes problemas: Disponibilidade - Se o sistema ou regi\u00e3o espec\u00edfica est\u00e1 dispon\u00edvel. Transa\u00e7\u00f5es e jornadas do cliente - Requisi\u00e7\u00f5es conhecidas como boas devem funcionar, enquanto requisi\u00e7\u00f5es conhecidas como ruins devem gerar erro. Desempenho - Qu\u00e3o r\u00e1pido s\u00e3o as a\u00e7\u00f5es e se esse desempenho \u00e9 mantido sob cargas elevadas e atrav\u00e9s de lan\u00e7amentos de vers\u00e3o. Componentes de Terceiros - Componentes de nuvem ou software usados pelo sistema podem falhar. Testes Shift-Right Testes de Monitoramento Sint\u00e9tico s\u00e3o um subconjunto de testes que s\u00e3o executados em produ\u00e7\u00e3o, \u00e0s vezes chamados de Test-in-Production ou testes Shift-Right. Com paradigmas de Shift-Left que s\u00e3o t\u00e3o populares, a abordagem \u00e9 realizar testes o mais cedo poss\u00edvel no ciclo de desenvolvimento da aplica\u00e7\u00e3o. Shift-Right complementa e adiciona ao Shift-Left, referindo-se \u00e0 execu\u00e7\u00e3o de testes tarde no ciclo, durante e ap\u00f3s o lan\u00e7amento, quando o produto est\u00e1 atendendo ao tr\u00e1fego de produ\u00e7\u00e3o. Blocos de Design de Testes de Monitoramento Sint\u00e9tico Um teste de monitoramento sint\u00e9tico \u00e9 um teste que usa dados sint\u00e9ticos e contas de teste reais para injetar comportamentos de usu\u00e1rio no sistema e validar seu efeito. Os componentes dos testes de monitoramento sint\u00e9tico incluem Sondas , c\u00f3digo de teste/contas que geram dados, e Ferramentas de Monitoramento colocadas para validar tanto o comportamento do sistema sob teste quanto a sa\u00fade das pr\u00f3prias sondas. Sondas Sondas s\u00e3o a fonte de a\u00e7\u00f5es de usu\u00e1rio sint\u00e9ticas que conduzem os testes. Elas t\u00eam como alvo a interface do usu\u00e1rio do produto ou APIs voltadas para o p\u00fablico e est\u00e3o executando em seu pr\u00f3prio ambiente de produ\u00e7\u00e3o. Um teste de monitoramento sint\u00e9tico est\u00e1, de fato, muito relacionado a testes de caixa-preta e normalmente se concentra em cen\u00e1rios de ponta a ponta do ponto de vista de um usu\u00e1rio. Monitoramento Dado que os testes de monitoramento sint\u00e9tico est\u00e3o sendo executados continuamente, em intervalos, em um ambiente de produ\u00e7\u00e3o, a afirma\u00e7\u00e3o do comportamento do sistema por meio da an\u00e1lise depende dos pilares de monitoramento existentes usados no sistema ativo (Logging, M\u00e9tricas, Rastreamento Distribu\u00eddo). Aplicando Testes de Monitoramento Sint\u00e9tico Afirmando o sistema sob testes Testes de monitoramento sint\u00e9tico s\u00e3o geralmente estat\u00edsticos. As m\u00e9tricas de teste s\u00e3o comparadas com alguma m\u00e9dia hist\u00f3rica ou em execu\u00e7\u00e3o com uma dimens\u00e3o de tempo. Construindo uma Solu\u00e7\u00e3o de Monitoramento Sint\u00e9tico Em um n\u00edvel alto, a constru\u00e7\u00e3o de monitores sint\u00e9ticos geralmente consiste nas seguintes etapas: Determinar a m\u00e9trica a ser validada (resultado funcional, lat\u00eancia, etc.) Construir uma automa\u00e7\u00e3o que me\u00e7a essa m\u00e9trica contra o sistema e colete telemetria na infraestrutura de monitoramento existente do sistema. Configurar alarmes/a\u00e7\u00f5es/respostas de monitoramento que detectem a falha do sistema em atender ao objetivo desejado da m\u00e9trica. Executar a automa\u00e7\u00e3o de casos de teste continuamente em um intervalo apropriado. Monitorando a sa\u00fade dos testes O tempo de execu\u00e7\u00e3o das sondas \u00e9 um ambiente de produ\u00e7\u00e3o por si s\u00f3, e a sa\u00fade dos testes \u00e9 cr\u00edtica. Muitos provedores oferecem sistemas baseados em nuvem que hospedam esses tempos de execu\u00e7\u00e3o, enquanto algumas organiza\u00e7\u00f5es usam ambientes de produ\u00e7\u00e3o existentes para executar esses testes. De qualquer forma, uma estrat\u00e9gia de monitorar o monitor deve ser uma parte essencial dos sistemas de alerta do ambiente de produ\u00e7\u00e3o. Monitoramento Sint\u00e9tico e Monitoramento de Usu\u00e1rios Reais O monitoramento sint\u00e9tico n\u00e3o substitui a necessidade de RUM. Sondas s\u00e3o c\u00f3digos previs\u00edveis que verificam cen\u00e1rios espec\u00edficos, e elas n\u00e3o representam 100% completamente e verdadeiramente como uma sess\u00e3o de usu\u00e1rio \u00e9 tratada. Riscos Testar em produ\u00e7\u00e3o, em geral, tem um fator de risco associado a ele, que n\u00e3o existe em testes executados durante as etapas de CI/CD. Especificamente, em testes de monitoramento sint\u00e9tico, o seguinte pode afetar o ambiente de produ\u00e7\u00e3o: Dados corrompidos ou inv\u00e1lidos - Testes injetam dados de teste que podem ser de alguma forma corrompidos. Vazamento de dados protegidos - Testes s\u00e3o executados em um ambiente de produ\u00e7\u00e3o e emitem logs ou rastreamentos que podem conter dados protegidos. - Sistemas sobrecarregados - Testes sint\u00e9ticos podem causar erros ou sobrecarregar o sistema. Frameworks e Ferramentas de Testes de Monitoramento Sint\u00e9tico A maioria dos principais players de monitoramento/APM tem um produto empresarial que suporta monitoramento sint\u00e9tico integrado aos seus sistemas. No entanto, tais solu\u00e7\u00f5es s\u00e3o tipicamente caras. Algumas organiza\u00e7\u00f5es preferem executar sondas em infraestrutura existente usando ferramentas conhecidas como Postman , Wrk , JMeter , Selenium ou at\u00e9 mesmo c\u00f3digo personalizado para gerar os dados sint\u00e9ticos. Application Insights availability DataDog Synthetics Dynatrace Synthetic Monitoring New Relic Synthetics Checkly Conclus\u00e3o O valor dos testes em produ\u00e7\u00e3o, em geral, e especificamente do monitoramento sint\u00e9tico, s\u00f3 existe para tipos espec\u00edficos de engajamento, e h\u00e1 riscos e custos associados a eles. No entanto, quando aplic\u00e1veis, eles fornecem garantia cont\u00ednua de que n\u00e3o h\u00e1 falhas no sistema do ponto de vista do usu\u00e1rio. Recursos Livro SRE do Google - Testando Confiabilidade Arquiteturas DevOps da Microsoft - Shift Right para Testar em Produ\u00e7\u00e3o Martin Fowler - Monitoramento Sint\u00e9tico","title":"Testes de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#testes-de-monitoramento-sintetico","text":"Testes de Monitoramento Sint\u00e9tico s\u00e3o um conjunto de testes funcionais que t\u00eam como alvo um sistema ativo em produ\u00e7\u00e3o. O foco desses testes, \u00e0s vezes chamados de \"watchdog\", \"monitoramento ativo\" ou \"transa\u00e7\u00f5es sint\u00e9ticas\", \u00e9 verificar continuamente a sa\u00fade e a resili\u00eancia do produto.","title":"Testes de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#por-que-testes-de-monitoramento-sintetico","text":"Tradicionalmente, os provedores de software confiam em testes por meio de etapas de CI/CD na conhecida pir\u00e2mide de testes (unit\u00e1rios, integra\u00e7\u00e3o, e2e) para validar que o produto est\u00e1 saud\u00e1vel e sem regress\u00f5es. No entanto, \u00e0 medida que mais organiza\u00e7\u00f5es hoje fornecem produtos altamente dispon\u00edveis (SLA de 99,9+), elas descobrem que a natureza de aplica\u00e7\u00f5es distribu\u00eddas de longa dura\u00e7\u00e3o, que normalmente dependem de v\u00e1rios componentes de hardware e software, \u00e9 falhar. Para tais sistemas, a ambi\u00e7\u00e3o das equipes de engenharia de servi\u00e7o \u00e9 reduzir ao m\u00ednimo o tempo necess\u00e1rio para corrigir erros, ou o MTTR - Tempo M\u00e9dio para Reparo . \u00c9 um esfor\u00e7o cont\u00ednuo, realizado no sistema ativo/produ\u00e7\u00e3o. Monitores Sint\u00e9ticos podem ser usados para detectar os seguintes problemas: Disponibilidade - Se o sistema ou regi\u00e3o espec\u00edfica est\u00e1 dispon\u00edvel. Transa\u00e7\u00f5es e jornadas do cliente - Requisi\u00e7\u00f5es conhecidas como boas devem funcionar, enquanto requisi\u00e7\u00f5es conhecidas como ruins devem gerar erro. Desempenho - Qu\u00e3o r\u00e1pido s\u00e3o as a\u00e7\u00f5es e se esse desempenho \u00e9 mantido sob cargas elevadas e atrav\u00e9s de lan\u00e7amentos de vers\u00e3o. Componentes de Terceiros - Componentes de nuvem ou software usados pelo sistema podem falhar.","title":"Por que Testes de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#testes-shift-right","text":"Testes de Monitoramento Sint\u00e9tico s\u00e3o um subconjunto de testes que s\u00e3o executados em produ\u00e7\u00e3o, \u00e0s vezes chamados de Test-in-Production ou testes Shift-Right. Com paradigmas de Shift-Left que s\u00e3o t\u00e3o populares, a abordagem \u00e9 realizar testes o mais cedo poss\u00edvel no ciclo de desenvolvimento da aplica\u00e7\u00e3o. Shift-Right complementa e adiciona ao Shift-Left, referindo-se \u00e0 execu\u00e7\u00e3o de testes tarde no ciclo, durante e ap\u00f3s o lan\u00e7amento, quando o produto est\u00e1 atendendo ao tr\u00e1fego de produ\u00e7\u00e3o.","title":"Testes Shift-Right"},{"location":"automated-testing/synthetic-monitoring-tests/#blocos-de-design-de-testes-de-monitoramento-sintetico","text":"Um teste de monitoramento sint\u00e9tico \u00e9 um teste que usa dados sint\u00e9ticos e contas de teste reais para injetar comportamentos de usu\u00e1rio no sistema e validar seu efeito. Os componentes dos testes de monitoramento sint\u00e9tico incluem Sondas , c\u00f3digo de teste/contas que geram dados, e Ferramentas de Monitoramento colocadas para validar tanto o comportamento do sistema sob teste quanto a sa\u00fade das pr\u00f3prias sondas.","title":"Blocos de Design de Testes de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#sondas","text":"Sondas s\u00e3o a fonte de a\u00e7\u00f5es de usu\u00e1rio sint\u00e9ticas que conduzem os testes. Elas t\u00eam como alvo a interface do usu\u00e1rio do produto ou APIs voltadas para o p\u00fablico e est\u00e3o executando em seu pr\u00f3prio ambiente de produ\u00e7\u00e3o. Um teste de monitoramento sint\u00e9tico est\u00e1, de fato, muito relacionado a testes de caixa-preta e normalmente se concentra em cen\u00e1rios de ponta a ponta do ponto de vista de um usu\u00e1rio.","title":"Sondas"},{"location":"automated-testing/synthetic-monitoring-tests/#monitoramento","text":"Dado que os testes de monitoramento sint\u00e9tico est\u00e3o sendo executados continuamente, em intervalos, em um ambiente de produ\u00e7\u00e3o, a afirma\u00e7\u00e3o do comportamento do sistema por meio da an\u00e1lise depende dos pilares de monitoramento existentes usados no sistema ativo (Logging, M\u00e9tricas, Rastreamento Distribu\u00eddo).","title":"Monitoramento"},{"location":"automated-testing/synthetic-monitoring-tests/#aplicando-testes-de-monitoramento-sintetico","text":"","title":"Aplicando Testes de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#afirmando-o-sistema-sob-testes","text":"Testes de monitoramento sint\u00e9tico s\u00e3o geralmente estat\u00edsticos. As m\u00e9tricas de teste s\u00e3o comparadas com alguma m\u00e9dia hist\u00f3rica ou em execu\u00e7\u00e3o com uma dimens\u00e3o de tempo.","title":"Afirmando o sistema sob testes"},{"location":"automated-testing/synthetic-monitoring-tests/#construindo-uma-solucao-de-monitoramento-sintetico","text":"Em um n\u00edvel alto, a constru\u00e7\u00e3o de monitores sint\u00e9ticos geralmente consiste nas seguintes etapas: Determinar a m\u00e9trica a ser validada (resultado funcional, lat\u00eancia, etc.) Construir uma automa\u00e7\u00e3o que me\u00e7a essa m\u00e9trica contra o sistema e colete telemetria na infraestrutura de monitoramento existente do sistema. Configurar alarmes/a\u00e7\u00f5es/respostas de monitoramento que detectem a falha do sistema em atender ao objetivo desejado da m\u00e9trica. Executar a automa\u00e7\u00e3o de casos de teste continuamente em um intervalo apropriado.","title":"Construindo uma Solu\u00e7\u00e3o de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#monitorando-a-saude-dos-testes","text":"O tempo de execu\u00e7\u00e3o das sondas \u00e9 um ambiente de produ\u00e7\u00e3o por si s\u00f3, e a sa\u00fade dos testes \u00e9 cr\u00edtica. Muitos provedores oferecem sistemas baseados em nuvem que hospedam esses tempos de execu\u00e7\u00e3o, enquanto algumas organiza\u00e7\u00f5es usam ambientes de produ\u00e7\u00e3o existentes para executar esses testes. De qualquer forma, uma estrat\u00e9gia de monitorar o monitor deve ser uma parte essencial dos sistemas de alerta do ambiente de produ\u00e7\u00e3o.","title":"Monitorando a sa\u00fade dos testes"},{"location":"automated-testing/synthetic-monitoring-tests/#monitoramento-sintetico-e-monitoramento-de-usuarios-reais","text":"O monitoramento sint\u00e9tico n\u00e3o substitui a necessidade de RUM. Sondas s\u00e3o c\u00f3digos previs\u00edveis que verificam cen\u00e1rios espec\u00edficos, e elas n\u00e3o representam 100% completamente e verdadeiramente como uma sess\u00e3o de usu\u00e1rio \u00e9 tratada.","title":"Monitoramento Sint\u00e9tico e Monitoramento de Usu\u00e1rios Reais"},{"location":"automated-testing/synthetic-monitoring-tests/#riscos","text":"Testar em produ\u00e7\u00e3o, em geral, tem um fator de risco associado a ele, que n\u00e3o existe em testes executados durante as etapas de CI/CD. Especificamente, em testes de monitoramento sint\u00e9tico, o seguinte pode afetar o ambiente de produ\u00e7\u00e3o: Dados corrompidos ou inv\u00e1lidos - Testes injetam dados de teste que podem ser de alguma forma corrompidos. Vazamento de dados protegidos - Testes s\u00e3o executados em um ambiente de produ\u00e7\u00e3o e emitem logs ou rastreamentos que podem conter dados protegidos. - Sistemas sobrecarregados - Testes sint\u00e9ticos podem causar erros ou sobrecarregar o sistema.","title":"Riscos"},{"location":"automated-testing/synthetic-monitoring-tests/#frameworks-e-ferramentas-de-testes-de-monitoramento-sintetico","text":"A maioria dos principais players de monitoramento/APM tem um produto empresarial que suporta monitoramento sint\u00e9tico integrado aos seus sistemas. No entanto, tais solu\u00e7\u00f5es s\u00e3o tipicamente caras. Algumas organiza\u00e7\u00f5es preferem executar sondas em infraestrutura existente usando ferramentas conhecidas como Postman , Wrk , JMeter , Selenium ou at\u00e9 mesmo c\u00f3digo personalizado para gerar os dados sint\u00e9ticos. Application Insights availability DataDog Synthetics Dynatrace Synthetic Monitoring New Relic Synthetics Checkly","title":"Frameworks e Ferramentas de Testes de Monitoramento Sint\u00e9tico"},{"location":"automated-testing/synthetic-monitoring-tests/#conclusao","text":"O valor dos testes em produ\u00e7\u00e3o, em geral, e especificamente do monitoramento sint\u00e9tico, s\u00f3 existe para tipos espec\u00edficos de engajamento, e h\u00e1 riscos e custos associados a eles. No entanto, quando aplic\u00e1veis, eles fornecem garantia cont\u00ednua de que n\u00e3o h\u00e1 falhas no sistema do ponto de vista do usu\u00e1rio.","title":"Conclus\u00e3o"},{"location":"automated-testing/synthetic-monitoring-tests/#recursos","text":"Livro SRE do Google - Testando Confiabilidade Arquiteturas DevOps da Microsoft - Shift Right para Testar em Produ\u00e7\u00e3o Martin Fowler - Monitoramento Sint\u00e9tico","title":"Recursos"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/","text":"Construindo Containers com Azure DevOps usando o Padr\u00e3o DevTest Neste documento, destacamos os aprendizados obtidos ao aplicar o padr\u00e3o DevTest ao desenvolvimento de containers no Azure DevOps por meio de pipelines. O padr\u00e3o nos permitiu construir containers para desenvolvimento, teste e libera\u00e7\u00e3o do container para reutiliza\u00e7\u00e3o posterior (pronto para produ\u00e7\u00e3o). Vamos explorar as ferramentas necess\u00e1rias para construir, testar e enviar um container, nosso ambiente e passar por cada etapa separadamente. Siga este link para aprofundar ou revisitar o padr\u00e3o DevTest . \u00cdndice Construir o Container Testar o Container Enviar Container Refer\u00eancias Construir o Container O primeiro passo no desenvolvimento de containers, ap\u00f3s criar os Dockerfiles e o c\u00f3digo-fonte necess\u00e1rios, \u00e9 construir o container. At\u00e9 mesmo o pr\u00f3prio Dockerfile pode incluir alguns testes b\u00e1sicos. Os testes de c\u00f3digo s\u00e3o realizados ao enviar o c\u00f3digo para o reposit\u00f3rio de origem, onde ele \u00e9 ent\u00e3o usado para construir o container. A primeira etapa em nosso pipeline \u00e9 executar o comando docker build com uma tag tempor\u00e1ria e os argumentos de constru\u00e7\u00e3o necess\u00e1rios: # ... c\u00f3digo omitido para brevidade Essa tarefa inclui os par\u00e2metros buildDirectory , imageName e dockerfileName , que devem ser definidos previamente. Essa tarefa pode, por exemplo, ser usada em um modelo para v\u00e1rios containers para melhorar a reutiliza\u00e7\u00e3o de c\u00f3digo. Tamb\u00e9m \u00e9 poss\u00edvel passar vari\u00e1veis de ambiente diretamente para o Dockerfile por meio da se\u00e7\u00e3o env da tarefa. Se essa tarefa for bem-sucedida, o Dockerfile foi constru\u00eddo sem erros e podemos continuar testando o pr\u00f3prio container. Testar o Container Para testar o container, estamos usando o ambiente tox. Para mais detalhes sobre o tox, visite a se\u00e7\u00e3o tox deste reposit\u00f3rio ou visite a p\u00e1gina oficial de documenta\u00e7\u00e3o do tox . Antes de testarmos o container, estamos verificando se h\u00e1 credenciais expostas no hist\u00f3rico da imagem docker. Se senhas conhecidas, usadas para acessar nossos recursos internos, estiverem expostas aqui, a etapa de constru\u00e7\u00e3o falhar\u00e1: # ... c\u00f3digo omitido para brevidade Ap\u00f3s o teste de credencial, o container \u00e9 testado por meio da extens\u00e3o pytest testinfra . Testinfra \u00e9 uma ferramenta baseada em Python que pode ser usada para iniciar um container, reunir pr\u00e9-requisitos, testar o container e deslig\u00e1-lo novamente, sem nenhum esfor\u00e7o al\u00e9m de escrever os testes. Esses testes podem, por exemplo, incluir: se arquivos existem se vari\u00e1veis de ambiente est\u00e3o configuradas corretamente se certos processos est\u00e3o em execu\u00e7\u00e3o se o ambiente host correto est\u00e1 sendo usado Para uma cole\u00e7\u00e3o completa de capacidades e requisitos, visite o projeto testinfra no GitHub . Alguns m\u00e9todos de um teste de container baseado em Linux podem parecer assim: # ... c\u00f3digo omitido para brevidade Para iniciar o teste, um comando pytest \u00e9 executado por meio do tox. Uma tarefa contendo o comando tox pode parecer assim: # ... c\u00f3digo omitido para brevidade O que poderia acionar o seguinte c\u00f3digo pytest, que est\u00e1 contido no arquivo tox.ini: # ... c\u00f3digo omitido para brevidade Como \u00faltima tarefa deste pipeline para construir e testar o container, definimos uma vari\u00e1vel chamada testsPassed , que \u00e9 apenas true , se as tarefas anteriores tiverem sido bem-sucedidas: # ... c\u00f3digo omitido para brevidade Enviar Container Ap\u00f3s construir e testar, se nosso container funcionar conforme o esperado, queremos liber\u00e1-lo para nosso Azure Container Registry (ACR) para ser usado por nossa aplica\u00e7\u00e3o maior. Antes disso, queremos automatizar o comportamento de envio e definir uma tag significativa. Como desenvolvedor, muitas vezes \u00e9 \u00fatil ter containers enviados para o ACR, mesmo que estejam falhando. Isso pode ser feito verificando a vari\u00e1vel testsPassed que introduzimos no final de nossos testes. Se o teste falhou, queremos adicionar um sufixo de falha no final da tag: # ... c\u00f3digo omitido para brevidade A condi\u00e7\u00e3o verifica se o valor de testsPassed \u00e9 false e tamb\u00e9m se n\u00e3o estamos na main branch , pois n\u00e3o queremos enviar containers falhos da main. Isso nos ajuda a manter nosso ambiente de produ\u00e7\u00e3o limpo. O valor para imageRepository foi definido em outro modelo, junto com o failedSuffix e testsPassed : # ... c\u00f3digo omitido para brevidade A imageTag est\u00e1 aberta para discuss\u00e3o, pois depende muito de como sua equipe deseja usar o container. Optamos por Build.SourceVersion , que \u00e9 o ID do commit da branch em que o container foi desenvolvido. Isso permite que voc\u00ea rastreie facilmente a origem do container e auxilie na depura\u00e7\u00e3o. Um link para as vari\u00e1veis predefinidas do Azure DevOps pode ser encontrado na Documenta\u00e7\u00e3o do Azure sobre Azure DevOps . Ap\u00f3s adicionar uma tag ao container, a imagem deve ser enviada. Isso pode ser feito com a seguinte tarefa: # ... c\u00f3digo omitido para brevidade `` ` Da mesma forma, estas s\u00e3o as etapas para publicar o container no ACR, se os testes forem bem-sucedidos: ```yml # ... c\u00f3digo omitido para brevidade Se voc\u00ea n\u00e3o quiser incluir a tag latest , tamb\u00e9m pode remover as etapas envolvendo latest (SetLatestSuffixTag & pushSuccessfulDockerImageLatest). Refer\u00eancias Padr\u00e3o DevTest Documenta\u00e7\u00e3o do Azure sobre Azure DevOps P\u00e1gina oficial de documenta\u00e7\u00e3o do tox Testinfra Projeto Testinfra no GitHub pytest","title":"Construindo Containers com Azure DevOps usando o Padr\u00e3o DevTest"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/#construindo-containers-com-azure-devops-usando-o-padrao-devtest","text":"Neste documento, destacamos os aprendizados obtidos ao aplicar o padr\u00e3o DevTest ao desenvolvimento de containers no Azure DevOps por meio de pipelines. O padr\u00e3o nos permitiu construir containers para desenvolvimento, teste e libera\u00e7\u00e3o do container para reutiliza\u00e7\u00e3o posterior (pronto para produ\u00e7\u00e3o). Vamos explorar as ferramentas necess\u00e1rias para construir, testar e enviar um container, nosso ambiente e passar por cada etapa separadamente. Siga este link para aprofundar ou revisitar o padr\u00e3o DevTest .","title":"Construindo Containers com Azure DevOps usando o Padr\u00e3o DevTest"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/#indice","text":"Construir o Container Testar o Container Enviar Container Refer\u00eancias","title":"\u00cdndice"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/#construir-o-container","text":"O primeiro passo no desenvolvimento de containers, ap\u00f3s criar os Dockerfiles e o c\u00f3digo-fonte necess\u00e1rios, \u00e9 construir o container. At\u00e9 mesmo o pr\u00f3prio Dockerfile pode incluir alguns testes b\u00e1sicos. Os testes de c\u00f3digo s\u00e3o realizados ao enviar o c\u00f3digo para o reposit\u00f3rio de origem, onde ele \u00e9 ent\u00e3o usado para construir o container. A primeira etapa em nosso pipeline \u00e9 executar o comando docker build com uma tag tempor\u00e1ria e os argumentos de constru\u00e7\u00e3o necess\u00e1rios: # ... c\u00f3digo omitido para brevidade Essa tarefa inclui os par\u00e2metros buildDirectory , imageName e dockerfileName , que devem ser definidos previamente. Essa tarefa pode, por exemplo, ser usada em um modelo para v\u00e1rios containers para melhorar a reutiliza\u00e7\u00e3o de c\u00f3digo. Tamb\u00e9m \u00e9 poss\u00edvel passar vari\u00e1veis de ambiente diretamente para o Dockerfile por meio da se\u00e7\u00e3o env da tarefa. Se essa tarefa for bem-sucedida, o Dockerfile foi constru\u00eddo sem erros e podemos continuar testando o pr\u00f3prio container.","title":"Construir o Container"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/#testar-o-container","text":"Para testar o container, estamos usando o ambiente tox. Para mais detalhes sobre o tox, visite a se\u00e7\u00e3o tox deste reposit\u00f3rio ou visite a p\u00e1gina oficial de documenta\u00e7\u00e3o do tox . Antes de testarmos o container, estamos verificando se h\u00e1 credenciais expostas no hist\u00f3rico da imagem docker. Se senhas conhecidas, usadas para acessar nossos recursos internos, estiverem expostas aqui, a etapa de constru\u00e7\u00e3o falhar\u00e1: # ... c\u00f3digo omitido para brevidade Ap\u00f3s o teste de credencial, o container \u00e9 testado por meio da extens\u00e3o pytest testinfra . Testinfra \u00e9 uma ferramenta baseada em Python que pode ser usada para iniciar um container, reunir pr\u00e9-requisitos, testar o container e deslig\u00e1-lo novamente, sem nenhum esfor\u00e7o al\u00e9m de escrever os testes. Esses testes podem, por exemplo, incluir: se arquivos existem se vari\u00e1veis de ambiente est\u00e3o configuradas corretamente se certos processos est\u00e3o em execu\u00e7\u00e3o se o ambiente host correto est\u00e1 sendo usado Para uma cole\u00e7\u00e3o completa de capacidades e requisitos, visite o projeto testinfra no GitHub . Alguns m\u00e9todos de um teste de container baseado em Linux podem parecer assim: # ... c\u00f3digo omitido para brevidade Para iniciar o teste, um comando pytest \u00e9 executado por meio do tox. Uma tarefa contendo o comando tox pode parecer assim: # ... c\u00f3digo omitido para brevidade O que poderia acionar o seguinte c\u00f3digo pytest, que est\u00e1 contido no arquivo tox.ini: # ... c\u00f3digo omitido para brevidade Como \u00faltima tarefa deste pipeline para construir e testar o container, definimos uma vari\u00e1vel chamada testsPassed , que \u00e9 apenas true , se as tarefas anteriores tiverem sido bem-sucedidas: # ... c\u00f3digo omitido para brevidade","title":"Testar o Container"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/#enviar-container","text":"Ap\u00f3s construir e testar, se nosso container funcionar conforme o esperado, queremos liber\u00e1-lo para nosso Azure Container Registry (ACR) para ser usado por nossa aplica\u00e7\u00e3o maior. Antes disso, queremos automatizar o comportamento de envio e definir uma tag significativa. Como desenvolvedor, muitas vezes \u00e9 \u00fatil ter containers enviados para o ACR, mesmo que estejam falhando. Isso pode ser feito verificando a vari\u00e1vel testsPassed que introduzimos no final de nossos testes. Se o teste falhou, queremos adicionar um sufixo de falha no final da tag: # ... c\u00f3digo omitido para brevidade A condi\u00e7\u00e3o verifica se o valor de testsPassed \u00e9 false e tamb\u00e9m se n\u00e3o estamos na main branch , pois n\u00e3o queremos enviar containers falhos da main. Isso nos ajuda a manter nosso ambiente de produ\u00e7\u00e3o limpo. O valor para imageRepository foi definido em outro modelo, junto com o failedSuffix e testsPassed : # ... c\u00f3digo omitido para brevidade A imageTag est\u00e1 aberta para discuss\u00e3o, pois depende muito de como sua equipe deseja usar o container. Optamos por Build.SourceVersion , que \u00e9 o ID do commit da branch em que o container foi desenvolvido. Isso permite que voc\u00ea rastreie facilmente a origem do container e auxilie na depura\u00e7\u00e3o. Um link para as vari\u00e1veis predefinidas do Azure DevOps pode ser encontrado na Documenta\u00e7\u00e3o do Azure sobre Azure DevOps . Ap\u00f3s adicionar uma tag ao container, a imagem deve ser enviada. Isso pode ser feito com a seguinte tarefa: # ... c\u00f3digo omitido para brevidade `` ` Da mesma forma, estas s\u00e3o as etapas para publicar o container no ACR, se os testes forem bem-sucedidos: ```yml # ... c\u00f3digo omitido para brevidade Se voc\u00ea n\u00e3o quiser incluir a tag latest , tamb\u00e9m pode remover as etapas envolvendo latest (SetLatestSuffixTag & pushSuccessfulDockerImageLatest).","title":"Enviar Container"},{"location":"automated-testing/tech-specific-samples/azdo-container-dev-test-release/#referencias","text":"Padr\u00e3o DevTest Documenta\u00e7\u00e3o do Azure sobre Azure DevOps P\u00e1gina oficial de documenta\u00e7\u00e3o do tox Testinfra Projeto Testinfra no GitHub pytest","title":"Refer\u00eancias"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/","text":"Utilizando Azurite para Executar Testes de Armazenamento Blob em um Pipeline Este documento determina a abordagem para escrever testes automatizados com um ciclo de feedback curto (ou seja, testes unit\u00e1rios) contra considera\u00e7\u00f5es de seguran\u00e7a (endpoints privados) para a funcionalidade do Azure Blob Storage. Uma vez que os endpoints privados s\u00e3o ativados para as contas de armazenamento do Azure, os testes atuais falhar\u00e3o quando executados localmente ou como parte de um pipeline, pois essa conex\u00e3o ser\u00e1 bloqueada. Utilize um emulador de armazenamento Azure - Azurite Para emular um Azure Blob Storage local, podemos usar o Azure Storage Emulator . O Storage Emulator atualmente roda apenas no Windows. Se voc\u00ea precisar de um Storage Emulator para Linux, uma op\u00e7\u00e3o \u00e9 o emulador de armazenamento de c\u00f3digo aberto mantido pela comunidade Azurite . O Azure Storage Emulator n\u00e3o est\u00e1 mais sendo ativamente desenvolvido. Azurite \u00e9 a plataforma de emulador de armazenamento daqui para frente. Azurite substitui o Azure Storage Emulator. Azurite continuar\u00e1 a ser atualizado para suportar as vers\u00f5es mais recentes das APIs de armazenamento Azure. Para mais informa\u00e7\u00f5es, veja Use o emulador Azurite para desenvolvimento local de armazenamento Azure . Existem algumas diferen\u00e7as de funcionalidade entre o Storage Emulator e os servi\u00e7os de armazenamento Azure. Para mais informa\u00e7\u00f5es sobre essas diferen\u00e7as, consulte Diferen\u00e7as entre o Storage Emulator e o armazenamento Azure . H\u00e1 v\u00e1rias maneiras de instalar e executar o Azurite em seu sistema local, conforme listado aqui . Neste documento, abordaremos Instalar e executar o Azurite usando NPM e Instalar e executar a imagem Docker do Azurite . 1. Instalar e executar o Azurite a. Usando NPM Para executar o Azurite V3, voc\u00ea precisa ter o Node.js >= 8.0 instalado em seu sistema. O Azurite funciona de forma multiplataforma no Windows, Linux e OS X. Ap\u00f3s a instala\u00e7\u00e3o do Node.js, voc\u00ea pode instalar o Azurite simplesmente com npm, que \u00e9 a ferramenta de gerenciamento de pacotes Node.js inclu\u00edda em cada instala\u00e7\u00e3o do Node.js. # Instalar o Azurite npm install -g azurite # Criar o diret\u00f3rio azurite mkdir c:/azurite # Iniciar o Azurite para Windows azurite --silent --location c: \\a zurite --debug c: \\a zurite \\d ebug.log A sa\u00edda ser\u00e1: O servi\u00e7o Blob do Azurite est\u00e1 iniciando em http://127.0.0.1:10000 O servi\u00e7o Blob do Azurite est\u00e1 ouvindo com sucesso em http://127.0.0.1:10000 O servi\u00e7o de fila do Azurite est\u00e1 iniciando em http://127.0.0.1:10001 O servi\u00e7o de fila do Azurite est\u00e1 ouvindo com sucesso em http://127.0.0.1:10001 b. Usando uma imagem docker Outra forma de executar o Azurite \u00e9 usando o docker, usando o endpoint HTTP padr\u00e3o. docker run -p 10000 :10000 mcr.microsoft.com/azure-storage/azurite azurite-blob --blobHost 0 .0.0.0 O Docker Compose \u00e9 outra op\u00e7\u00e3o e pode executar a mesma imagem docker usando o arquivo docker-compose.yml abaixo. version : '3.4' services : azurite : image : mcr.microsoft.com/azure-storage/azurite hostname : azurite volumes : - ./cert/azurite:/data command : \"azurite-blob --blobHost 0.0.0.0 -l /data --cert /data/127.0.0.1.pem --key /data/127.0.0.1-key.pem --oauth basic\" ports : - \"10000:10000\" - \"10001:10001\" 2. Executar testes em sua m\u00e1quina local O Python 3.8.7 \u00e9 usado para isso, mas deve funcionar bem em outras vers\u00f5es 3.x tamb\u00e9m. Instale e execute o Azurite para testes locais: Op\u00e7\u00e3o 1: usando npm: # Instalar o Azurite npm install -g azurite # Criar o diret\u00f3rio azurite mkdir c:/azurite # Iniciar o Azurite para Windows azurite --silent --location c: \\a zurite --debug c: \\a zurite \\d ebug.log Op\u00e7\u00e3o 2: usando docker docker run -p 10000 :10000 mcr.microsoft.com/azure-storage/azurite azurite-blob --blobHost 0 .0.0.0 No Azure Storage Explorer, selecione Anexar a um emulador local Forne\u00e7a um nome para exibi\u00e7\u00e3o e n\u00famero da porta, ent\u00e3o sua conex\u00e3o estar\u00e1 pronta, e voc\u00ea poder\u00e1 usar o Storage Explorer para gerenciar seu armazenamento blob local. Para testar e ver como esses endpoints est\u00e3o funcionando, voc\u00ea pode anexar seu armazenamento blob local ao Azure Storage Explorer . Crie um ambiente virtual python python -m venv .venv Nome do cont\u00eainer e inicialize as vari\u00e1veis de ambiente: Use conftest.py para integra\u00e7\u00e3o de teste. ```python from azure.storage.blob import BlobServiceClient import os def pytest_generate_tests(metafunc): os.environ['STORAGE_CONNECTION_STRING'] = 'DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02x NOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;' os.environ['STORAGE_CONTAINER'] = 'test-container' # Criar cont\u00eainer para Azurite na primeira execu\u00e7\u00e3o blob_service_client = BlobServiceClient.from_connection_string(os.environ.get(\"STORAGE_CONNECTION_STRING\")) try: blob_service_client.create_container(os.environ.get(\"STORAGE_CONTAINER\")) except Exception as e: print(e) ``` * Nota: o valor para STORAGE_CONNECTION_STRING \u00e9 o valor padr\u00e3o para o Azurite, n\u00e3o \u00e9 uma chave privada Instale as depend\u00eancias pip install -r requirements_tests.txt Execute os testes: python -m pytest ./tests Ap\u00f3s executar os testes, voc\u00ea pode ver os arquivos em seu armazenamento blob local 3. Executar testes no Azure Pipelines Ap\u00f3s executar os testes localmente, precisamos garantir que esses testes tamb\u00e9m passem no Azure Pipelines. Temos 2 op\u00e7\u00f5es aqui, podemos usar a imagem docker como agente hospedado no Azure ou instalar um pacote npm nas etapas do Pipeline. trigger: - master steps: - task: UsePythonVersion@0 displayName: 'Usar Python 3.7' inputs: versionSpec: 3 .7 - bash: | pip install -r requirements_tests.txt displayName: 'Configurar requisitos para testes' - bash: | sudo npm install -g azurite sudo mkdir azurite sudo azurite --silent --location azurite --debug azurite \\d ebug.log & displayName: 'Instalar e Executar o Azurite' - bash: | python -m pytest --junit-xml = unit_tests_report.xml --cov = tests --cov-report = html --cov-report = xml ./tests displayName: 'Executar Testes' - task: PublishCodeCoverageResults@1 inputs: codeCoverageTool: Cobertura summaryFileLocation: '$(System.DefaultWorkingDirectory)/**/coverage.xml' reportDirectory: '$(System.DefaultWorkingDirectory)/**/htmlcov' - task: PublishTestResults@2 inputs: testResultsFormat: 'JUnit' testResultsFiles: '**/*_tests_report.xml' failTaskOnFailedTests: true Uma vez que configuramos nosso pipeline no Azure Pipelines, o resultado ser\u00e1 como abaixo Refer\u00eancias Azure Storage Emulator Azurite no GitHub Use o emulador Azurite para desenvolvimento local de armazenamento Azure Azure Storage Explorer","title":"Utilizando Azurite para Executar Testes de Armazenamento Blob em um Pipeline"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#utilizando-azurite-para-executar-testes-de-armazenamento-blob-em-um-pipeline","text":"Este documento determina a abordagem para escrever testes automatizados com um ciclo de feedback curto (ou seja, testes unit\u00e1rios) contra considera\u00e7\u00f5es de seguran\u00e7a (endpoints privados) para a funcionalidade do Azure Blob Storage. Uma vez que os endpoints privados s\u00e3o ativados para as contas de armazenamento do Azure, os testes atuais falhar\u00e3o quando executados localmente ou como parte de um pipeline, pois essa conex\u00e3o ser\u00e1 bloqueada.","title":"Utilizando Azurite para Executar Testes de Armazenamento Blob em um Pipeline"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#utilize-um-emulador-de-armazenamento-azure-azurite","text":"Para emular um Azure Blob Storage local, podemos usar o Azure Storage Emulator . O Storage Emulator atualmente roda apenas no Windows. Se voc\u00ea precisar de um Storage Emulator para Linux, uma op\u00e7\u00e3o \u00e9 o emulador de armazenamento de c\u00f3digo aberto mantido pela comunidade Azurite . O Azure Storage Emulator n\u00e3o est\u00e1 mais sendo ativamente desenvolvido. Azurite \u00e9 a plataforma de emulador de armazenamento daqui para frente. Azurite substitui o Azure Storage Emulator. Azurite continuar\u00e1 a ser atualizado para suportar as vers\u00f5es mais recentes das APIs de armazenamento Azure. Para mais informa\u00e7\u00f5es, veja Use o emulador Azurite para desenvolvimento local de armazenamento Azure . Existem algumas diferen\u00e7as de funcionalidade entre o Storage Emulator e os servi\u00e7os de armazenamento Azure. Para mais informa\u00e7\u00f5es sobre essas diferen\u00e7as, consulte Diferen\u00e7as entre o Storage Emulator e o armazenamento Azure . H\u00e1 v\u00e1rias maneiras de instalar e executar o Azurite em seu sistema local, conforme listado aqui . Neste documento, abordaremos Instalar e executar o Azurite usando NPM e Instalar e executar a imagem Docker do Azurite .","title":"Utilize um emulador de armazenamento Azure - Azurite"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#1-instalar-e-executar-o-azurite","text":"","title":"1. Instalar e executar o Azurite"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#a-usando-npm","text":"Para executar o Azurite V3, voc\u00ea precisa ter o Node.js >= 8.0 instalado em seu sistema. O Azurite funciona de forma multiplataforma no Windows, Linux e OS X. Ap\u00f3s a instala\u00e7\u00e3o do Node.js, voc\u00ea pode instalar o Azurite simplesmente com npm, que \u00e9 a ferramenta de gerenciamento de pacotes Node.js inclu\u00edda em cada instala\u00e7\u00e3o do Node.js. # Instalar o Azurite npm install -g azurite # Criar o diret\u00f3rio azurite mkdir c:/azurite # Iniciar o Azurite para Windows azurite --silent --location c: \\a zurite --debug c: \\a zurite \\d ebug.log A sa\u00edda ser\u00e1: O servi\u00e7o Blob do Azurite est\u00e1 iniciando em http://127.0.0.1:10000 O servi\u00e7o Blob do Azurite est\u00e1 ouvindo com sucesso em http://127.0.0.1:10000 O servi\u00e7o de fila do Azurite est\u00e1 iniciando em http://127.0.0.1:10001 O servi\u00e7o de fila do Azurite est\u00e1 ouvindo com sucesso em http://127.0.0.1:10001","title":"a. Usando NPM"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#b-usando-uma-imagem-docker","text":"Outra forma de executar o Azurite \u00e9 usando o docker, usando o endpoint HTTP padr\u00e3o. docker run -p 10000 :10000 mcr.microsoft.com/azure-storage/azurite azurite-blob --blobHost 0 .0.0.0 O Docker Compose \u00e9 outra op\u00e7\u00e3o e pode executar a mesma imagem docker usando o arquivo docker-compose.yml abaixo. version : '3.4' services : azurite : image : mcr.microsoft.com/azure-storage/azurite hostname : azurite volumes : - ./cert/azurite:/data command : \"azurite-blob --blobHost 0.0.0.0 -l /data --cert /data/127.0.0.1.pem --key /data/127.0.0.1-key.pem --oauth basic\" ports : - \"10000:10000\" - \"10001:10001\"","title":"b. Usando uma imagem docker"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#2-executar-testes-em-sua-maquina-local","text":"O Python 3.8.7 \u00e9 usado para isso, mas deve funcionar bem em outras vers\u00f5es 3.x tamb\u00e9m. Instale e execute o Azurite para testes locais: Op\u00e7\u00e3o 1: usando npm: # Instalar o Azurite npm install -g azurite # Criar o diret\u00f3rio azurite mkdir c:/azurite # Iniciar o Azurite para Windows azurite --silent --location c: \\a zurite --debug c: \\a zurite \\d ebug.log Op\u00e7\u00e3o 2: usando docker docker run -p 10000 :10000 mcr.microsoft.com/azure-storage/azurite azurite-blob --blobHost 0 .0.0.0 No Azure Storage Explorer, selecione Anexar a um emulador local Forne\u00e7a um nome para exibi\u00e7\u00e3o e n\u00famero da porta, ent\u00e3o sua conex\u00e3o estar\u00e1 pronta, e voc\u00ea poder\u00e1 usar o Storage Explorer para gerenciar seu armazenamento blob local. Para testar e ver como esses endpoints est\u00e3o funcionando, voc\u00ea pode anexar seu armazenamento blob local ao Azure Storage Explorer . Crie um ambiente virtual python python -m venv .venv Nome do cont\u00eainer e inicialize as vari\u00e1veis de ambiente: Use conftest.py para integra\u00e7\u00e3o de teste. ```python from azure.storage.blob import BlobServiceClient import os def pytest_generate_tests(metafunc): os.environ['STORAGE_CONNECTION_STRING'] = 'DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02x NOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;' os.environ['STORAGE_CONTAINER'] = 'test-container' # Criar cont\u00eainer para Azurite na primeira execu\u00e7\u00e3o blob_service_client = BlobServiceClient.from_connection_string(os.environ.get(\"STORAGE_CONNECTION_STRING\")) try: blob_service_client.create_container(os.environ.get(\"STORAGE_CONTAINER\")) except Exception as e: print(e) ``` * Nota: o valor para STORAGE_CONNECTION_STRING \u00e9 o valor padr\u00e3o para o Azurite, n\u00e3o \u00e9 uma chave privada Instale as depend\u00eancias pip install -r requirements_tests.txt Execute os testes: python -m pytest ./tests Ap\u00f3s executar os testes, voc\u00ea pode ver os arquivos em seu armazenamento blob local","title":"2. Executar testes em sua m\u00e1quina local"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#3-executar-testes-no-azure-pipelines","text":"Ap\u00f3s executar os testes localmente, precisamos garantir que esses testes tamb\u00e9m passem no Azure Pipelines. Temos 2 op\u00e7\u00f5es aqui, podemos usar a imagem docker como agente hospedado no Azure ou instalar um pacote npm nas etapas do Pipeline. trigger: - master steps: - task: UsePythonVersion@0 displayName: 'Usar Python 3.7' inputs: versionSpec: 3 .7 - bash: | pip install -r requirements_tests.txt displayName: 'Configurar requisitos para testes' - bash: | sudo npm install -g azurite sudo mkdir azurite sudo azurite --silent --location azurite --debug azurite \\d ebug.log & displayName: 'Instalar e Executar o Azurite' - bash: | python -m pytest --junit-xml = unit_tests_report.xml --cov = tests --cov-report = html --cov-report = xml ./tests displayName: 'Executar Testes' - task: PublishCodeCoverageResults@1 inputs: codeCoverageTool: Cobertura summaryFileLocation: '$(System.DefaultWorkingDirectory)/**/coverage.xml' reportDirectory: '$(System.DefaultWorkingDirectory)/**/htmlcov' - task: PublishTestResults@2 inputs: testResultsFormat: 'JUnit' testResultsFiles: '**/*_tests_report.xml' failTaskOnFailedTests: true Uma vez que configuramos nosso pipeline no Azure Pipelines, o resultado ser\u00e1 como abaixo","title":"3. Executar testes no Azure Pipelines"},{"location":"automated-testing/tech-specific-samples/blobstorage-unit-tests/#referencias","text":"Azure Storage Emulator Azurite no GitHub Use o emulador Azurite para desenvolvimento local de armazenamento Azure Azure Storage Explorer","title":"Refer\u00eancias"},{"location":"automated-testing/templates/case-study-template/","text":"~Projeto do Cliente~ Estudo de Caso Contexto Descreva o cliente e os requisitos de neg\u00f3cios com a declara\u00e7\u00e3o expl\u00edcita do problema. Sistema Sob Teste (SST) Inclua a arquitetura conceitual do sistema e destaque os componentes da arquitetura que foram inclu\u00eddos nos testes de ponta a ponta (E2E). Problemas e Limita\u00e7\u00f5es Descreva os problemas da solu\u00e7\u00e3o geral do SST que impediram o teste de uma parte espec\u00edfica (ou qualquer parte) da solu\u00e7\u00e3o. Descreva as limita\u00e7\u00f5es das ferramentas e frameworks de teste usados nesta implementa\u00e7\u00e3o. Framework e Ferramentas de Teste E2E Descreva qual framework e/ou ferramentas foram usadas para implementar testes E2E no SST. Casos de Teste Descreva os casos de teste E2E que foram criados para testar o SST. M\u00e9tricas de Teste Descreva qualquer solu\u00e7\u00e3o de arquitetura que foi usada para monitorar, observar e rastrear os v\u00e1rios estados de servi\u00e7o que foram usados como m\u00e9tricas de teste E2E. Al\u00e9m disso, inclua a lista de casos de teste que foram constru\u00eddos para medir o progresso dos testes E2E. Arquitetura de Teste E2E Descreva qualquer arquitetura de teste que foi constru\u00edda para executar testes E2E. Implementa\u00e7\u00e3o de Teste E2E (Exemplos de C\u00f3digo) Inclua exemplos de casos de teste e sua implementa\u00e7\u00e3o na linguagem de programa\u00e7\u00e3o de sua escolha. Inclua quaisquer blocos de implementa\u00e7\u00e3o de c\u00f3digo reutiliz\u00e1vel comuns que possam ser aproveitados em futuras implementa\u00e7\u00f5es de testes E2E do projeto. Relat\u00f3rios e Resultados de Teste E2E Inclua exemplos de relat\u00f3rios e resultados obtidos nas execu\u00e7\u00f5es de testes E2E neste projeto.","title":"~Projeto do Cliente~ Estudo de Caso"},{"location":"automated-testing/templates/case-study-template/#projeto-do-cliente-estudo-de-caso","text":"","title":"~Projeto do Cliente~ Estudo de Caso"},{"location":"automated-testing/templates/case-study-template/#contexto","text":"Descreva o cliente e os requisitos de neg\u00f3cios com a declara\u00e7\u00e3o expl\u00edcita do problema.","title":"Contexto"},{"location":"automated-testing/templates/case-study-template/#sistema-sob-teste-sst","text":"Inclua a arquitetura conceitual do sistema e destaque os componentes da arquitetura que foram inclu\u00eddos nos testes de ponta a ponta (E2E).","title":"Sistema Sob Teste (SST)"},{"location":"automated-testing/templates/case-study-template/#problemas-e-limitacoes","text":"Descreva os problemas da solu\u00e7\u00e3o geral do SST que impediram o teste de uma parte espec\u00edfica (ou qualquer parte) da solu\u00e7\u00e3o. Descreva as limita\u00e7\u00f5es das ferramentas e frameworks de teste usados nesta implementa\u00e7\u00e3o.","title":"Problemas e Limita\u00e7\u00f5es"},{"location":"automated-testing/templates/case-study-template/#framework-e-ferramentas-de-teste-e2e","text":"Descreva qual framework e/ou ferramentas foram usadas para implementar testes E2E no SST.","title":"Framework e Ferramentas de Teste E2E"},{"location":"automated-testing/templates/case-study-template/#casos-de-teste","text":"Descreva os casos de teste E2E que foram criados para testar o SST.","title":"Casos de Teste"},{"location":"automated-testing/templates/case-study-template/#metricas-de-teste","text":"Descreva qualquer solu\u00e7\u00e3o de arquitetura que foi usada para monitorar, observar e rastrear os v\u00e1rios estados de servi\u00e7o que foram usados como m\u00e9tricas de teste E2E. Al\u00e9m disso, inclua a lista de casos de teste que foram constru\u00eddos para medir o progresso dos testes E2E.","title":"M\u00e9tricas de Teste"},{"location":"automated-testing/templates/case-study-template/#arquitetura-de-teste-e2e","text":"Descreva qualquer arquitetura de teste que foi constru\u00edda para executar testes E2E.","title":"Arquitetura de Teste E2E"},{"location":"automated-testing/templates/case-study-template/#implementacao-de-teste-e2e-exemplos-de-codigo","text":"Inclua exemplos de casos de teste e sua implementa\u00e7\u00e3o na linguagem de programa\u00e7\u00e3o de sua escolha. Inclua quaisquer blocos de implementa\u00e7\u00e3o de c\u00f3digo reutiliz\u00e1vel comuns que possam ser aproveitados em futuras implementa\u00e7\u00f5es de testes E2E do projeto.","title":"Implementa\u00e7\u00e3o de Teste E2E (Exemplos de C\u00f3digo)"},{"location":"automated-testing/templates/case-study-template/#relatorios-e-resultados-de-teste-e2e","text":"Inclua exemplos de relat\u00f3rios e resultados obtidos nas execu\u00e7\u00f5es de testes E2E neste projeto.","title":"Relat\u00f3rios e Resultados de Teste E2E"},{"location":"automated-testing/templates/test_type_template/","text":"Nome da T\u00e9cnica de Teste Aqui Insira uma vis\u00e3o geral de 2-3 frases sobre a t\u00e9cnica de teste aqui. Quando Usar Problema Abordado Descrevendo o problema que este tipo de teste aborda, isso deve focar na motiva\u00e7\u00e3o por tr\u00e1s do tipo/t\u00e9cnica de teste para ajudar o leitor a correlacionar esta t\u00e9cnica ao seu problema. Quando Evitar Descreva quando N\u00c3O usar, se aplic\u00e1vel. Ponto de Inflex\u00e3o do ROI Quanto \u00e9 suficiente? Por exemplo, alguns opinam que o ROI do teste unit\u00e1rio cai significativamente com 80% de cobertura de bloco e quando a base de c\u00f3digo \u00e9 bem exercitada por tr\u00e1fego real em produ\u00e7\u00e3o. Aplic\u00e1vel a Desenvolvimento local 'desktop' Pipelines de constru\u00e7\u00e3o Implanta\u00e7\u00f5es n\u00e3o produtivas Implanta\u00e7\u00f5es em produ\u00e7\u00e3o NOTA: Se houver uma \u00f3tima documenta\u00e7\u00e3o (clara, sucinta) para a t\u00e9cnica na web, forne\u00e7a um ponteiro e pule o resto deste modelo. N\u00e3o h\u00e1 necessidade de reescrever o conte\u00fado. Como Usar Arquitetura Descreva os componentes da t\u00e9cnica e como eles interagem entre si e com o assunto da t\u00e9cnica de teste. Adicione um diagrama simples de como as partes da t\u00e9cnica est\u00e3o organizadas, se isso ajudar a ilustrar. Pr\u00e9-requisitos Alguma coisa \u00e9 necess\u00e1ria antecipadamente? Passo a Passo de Alto N\u00edvel 1. 1. 1. Melhores Pr\u00e1ticas e Conselhos Descreva como \u00e9 um bom teste para esta t\u00e9cnica, melhores pr\u00e1ticas, armadilhas. Antipadr\u00f5es Por exemplo, testes unit\u00e1rios nunca devem exigir depend\u00eancias fora da caixa ou mesmo fora do processo. Existem coisas semelhantes a evitar ao aplicar esta t\u00e9cnica? Frameworks, Ferramentas, Modelos Descreva frameworks, ferramentas e modelos conhecidos como bons (ou seja, realmente usados e conhecidos por fornecer bons resultados), seus pr\u00f3s e contras, com links. Recursos Forne\u00e7a links para leituras adicionais sobre esta t\u00e9cnica para aprofundar o conhecimento.","title":"Nome da T\u00e9cnica de Teste Aqui"},{"location":"automated-testing/templates/test_type_template/#nome-da-tecnica-de-teste-aqui","text":"Insira uma vis\u00e3o geral de 2-3 frases sobre a t\u00e9cnica de teste aqui.","title":"Nome da T\u00e9cnica de Teste Aqui"},{"location":"automated-testing/templates/test_type_template/#quando-usar","text":"","title":"Quando Usar"},{"location":"automated-testing/templates/test_type_template/#problema-abordado","text":"Descrevendo o problema que este tipo de teste aborda, isso deve focar na motiva\u00e7\u00e3o por tr\u00e1s do tipo/t\u00e9cnica de teste para ajudar o leitor a correlacionar esta t\u00e9cnica ao seu problema.","title":"Problema Abordado"},{"location":"automated-testing/templates/test_type_template/#quando-evitar","text":"Descreva quando N\u00c3O usar, se aplic\u00e1vel.","title":"Quando Evitar"},{"location":"automated-testing/templates/test_type_template/#ponto-de-inflexao-do-roi","text":"Quanto \u00e9 suficiente? Por exemplo, alguns opinam que o ROI do teste unit\u00e1rio cai significativamente com 80% de cobertura de bloco e quando a base de c\u00f3digo \u00e9 bem exercitada por tr\u00e1fego real em produ\u00e7\u00e3o.","title":"Ponto de Inflex\u00e3o do ROI"},{"location":"automated-testing/templates/test_type_template/#aplicavel-a","text":"Desenvolvimento local 'desktop' Pipelines de constru\u00e7\u00e3o Implanta\u00e7\u00f5es n\u00e3o produtivas Implanta\u00e7\u00f5es em produ\u00e7\u00e3o","title":"Aplic\u00e1vel a"},{"location":"automated-testing/templates/test_type_template/#nota-se-houver-uma-otima-documentacao-clara-sucinta-para-a-tecnica-na-web-forneca-um-ponteiro-e-pule-o-resto-deste-modelo-nao-ha-necessidade-de-reescrever-o-conteudo","text":"","title":"NOTA: Se houver uma \u00f3tima documenta\u00e7\u00e3o (clara, sucinta) para a t\u00e9cnica na web, forne\u00e7a um ponteiro e pule o resto deste modelo. N\u00e3o h\u00e1 necessidade de reescrever o conte\u00fado."},{"location":"automated-testing/templates/test_type_template/#como-usar","text":"","title":"Como Usar"},{"location":"automated-testing/templates/test_type_template/#arquitetura","text":"Descreva os componentes da t\u00e9cnica e como eles interagem entre si e com o assunto da t\u00e9cnica de teste. Adicione um diagrama simples de como as partes da t\u00e9cnica est\u00e3o organizadas, se isso ajudar a ilustrar.","title":"Arquitetura"},{"location":"automated-testing/templates/test_type_template/#pre-requisitos","text":"Alguma coisa \u00e9 necess\u00e1ria antecipadamente?","title":"Pr\u00e9-requisitos"},{"location":"automated-testing/templates/test_type_template/#passo-a-passo-de-alto-nivel","text":"1. 1. 1.","title":"Passo a Passo de Alto N\u00edvel"},{"location":"automated-testing/templates/test_type_template/#melhores-praticas-e-conselhos","text":"Descreva como \u00e9 um bom teste para esta t\u00e9cnica, melhores pr\u00e1ticas, armadilhas.","title":"Melhores Pr\u00e1ticas e Conselhos"},{"location":"automated-testing/templates/test_type_template/#antipadroes","text":"Por exemplo, testes unit\u00e1rios nunca devem exigir depend\u00eancias fora da caixa ou mesmo fora do processo. Existem coisas semelhantes a evitar ao aplicar esta t\u00e9cnica?","title":"Antipadr\u00f5es"},{"location":"automated-testing/templates/test_type_template/#frameworks-ferramentas-modelos","text":"Descreva frameworks, ferramentas e modelos conhecidos como bons (ou seja, realmente usados e conhecidos por fornecer bons resultados), seus pr\u00f3s e contras, com links.","title":"Frameworks, Ferramentas, Modelos"},{"location":"automated-testing/templates/test_type_template/#recursos","text":"Forne\u00e7a links para leituras adicionais sobre esta t\u00e9cnica para aprofundar o conhecimento.","title":"Recursos"},{"location":"automated-testing/ui-testing/","text":"Teste de Interface do Usu\u00e1rio (UI) Esta se\u00e7\u00e3o \u00e9 voltada principalmente para UIs baseadas na web, mas as orienta\u00e7\u00f5es s\u00e3o semelhantes para aplicativos m\u00f3veis e baseados em sistemas operacionais. Aplicabilidade O teste de UI nem sempre ser\u00e1 aplic\u00e1vel, por exemplo, em aplica\u00e7\u00f5es sem uma UI ou partes de uma aplica\u00e7\u00e3o que n\u00e3o requerem intera\u00e7\u00e3o humana. Nesses casos, os testes unit\u00e1rios, funcionais e de integra\u00e7\u00e3o/e2e seriam os principais meios. O teste de UI ser\u00e1 principalmente aplic\u00e1vel ao lidar com uma UI voltada para o p\u00fablico que \u00e9 usada em um ambiente diversificado ou em uma UI cr\u00edtica que requer maior fidelidade. Com algo como uma UI de administra\u00e7\u00e3o que \u00e9 usada por apenas algumas pessoas, o teste de UI ainda \u00e9 valioso, mas n\u00e3o t\u00e3o priorit\u00e1rio. Objetivos O teste de UI fornece a capacidade de garantir que os usu\u00e1rios tenham uma experi\u00eancia visual consistente em uma variedade de meios de acesso e que a intera\u00e7\u00e3o do usu\u00e1rio seja consistente com os requisitos funcionais. Garantir que a apar\u00eancia e intera\u00e7\u00e3o da UI satisfa\u00e7am os requisitos funcionais e n\u00e3o funcionais Detectar mudan\u00e7as na UI tanto entre dispositivos e plataformas de entrega quanto entre mudan\u00e7as de c\u00f3digo Dar confian\u00e7a a designers e desenvolvedores de que a experi\u00eancia do usu\u00e1rio \u00e9 consistente Apoiar a r\u00e1pida evolu\u00e7\u00e3o do c\u00f3digo e refatora\u00e7\u00e3o, reduzindo o risco de regress\u00f5es Evid\u00eancias e Medidas Integrar testes de UI no seu CI/CD \u00e9 necess\u00e1rio, mas mais desafiador do que testes unit\u00e1rios. O desafio aumentado \u00e9 que os testes de UI precisam ser executados em modo headless com algo como Puppeteer ou precisa haver uma orquestra\u00e7\u00e3o mais extensa com Azure DevOps ou GitHub que cuidaria da integra\u00e7\u00e3o completa de testes para voc\u00ea, como BrowserStack . Integra\u00e7\u00f5es como BrowserStack s\u00e3o interessantes, pois fornecem relat\u00f3rios do Azure DevOps como parte da execu\u00e7\u00e3o do teste. Dito isso, o Azure DevOps suporta uma variedade de adaptadores de teste, ent\u00e3o voc\u00ea pode usar qualquer framework de teste de UI que suporte a sa\u00edda dos resultados do teste para um dos formatos de sa\u00edda listados em Publish Test Results task . Se voc\u00ea estiver usando um pipeline do Azure DevOps para executar testes de UI, considere usar um agente auto-hospedado para gerenciar as vers\u00f5es do framework e evitar atualiza\u00e7\u00f5es inesperadas. Orienta\u00e7\u00e3o Geral O escopo do teste de UI deve ser estrat\u00e9gico. Os testes de UI podem levar uma quantidade significativa de tempo tanto para implementar quanto para executar, e \u00e9 desafiador testar todos os tipos de intera\u00e7\u00e3o do usu\u00e1rio em um aplicativo de produ\u00e7\u00e3o devido ao grande n\u00famero de intera\u00e7\u00f5es poss\u00edveis. Projetar os testes de UI em torno dos testes funcionais faz sentido. Por exemplo, dado um formul\u00e1rio de entrada, um teste de UI garantiria que a representa\u00e7\u00e3o visual seja consistente entre dispositivos, seja acess\u00edvel e f\u00e1cil de interagir, e seja consistente entre mudan\u00e7as de c\u00f3digo. Os testes de UI pegar\u00e3o bugs de 'tempo de execu\u00e7\u00e3o' que os testes unit\u00e1rios e funcionais n\u00e3o pegar\u00e3o. Por exemplo, se o bot\u00e3o de envio de um formul\u00e1rio de entrada for renderizado, mas n\u00e3o for clic\u00e1vel devido a um bug de posicionamento na UI, ent\u00e3o isso poderia ser considerado um bug de tempo de execu\u00e7\u00e3o que n\u00e3o teria sido pego por testes unit\u00e1rios ou funcionais. Os testes de UI podem ser executados em dados fict\u00edcios ou em instant\u00e2neos de dados de produ\u00e7\u00e3o, como em QA ou staging. Escrevendo Testes Bons testes de UI seguem alguns princ\u00edpios gerais: Escolha um framework de teste de UI que permita um feedback r\u00e1pido e seja f\u00e1cil de usar Projete a UI para ser facilmente test\u00e1vel. Por exemplo, adicione seletores CSS ou defina o id em elementos de uma p\u00e1gina da web para permitir uma sele\u00e7\u00e3o mais f\u00e1cil. Teste em todos os dispositivos prim\u00e1rios que o usu\u00e1rio usa, n\u00e3o teste apenas em um \u00fanico dispositivo ou sistema operacional. Quando um teste altera dados, garanta que os dados sejam criados sob demanda e limpos posteriormente. A consequ\u00eancia de n\u00e3o fazer isso seria testes inconsistentes. Problemas Comuns O teste de UI pode se tornar muito desafiador no n\u00edvel mais baixo, especialmente com um framework de teste como o Selenium. Se voc\u00ea optar por seguir esse caminho, provavelmente encontrar\u00e1 timeouts, elementos ausentes e ter\u00e1 atrito significativo com o pr\u00f3prio framework de teste. Devido a muitos problemas com o teste de UI, surgiram v\u00e1rias solu\u00e7\u00f5es gratuitas e pagas que ajudam a aliviar certos problemas com frameworks como o Selenium. \u00c9 por isso que voc\u00ea encontrar\u00e1 o Cypress nos frameworks recomendados, pois ele resolve muitos dos problemas conhecidos com o Selenium. Este \u00e9 um ponto importante. Dependendo do framework de teste de UI que voc\u00ea escolher, o resultado ser\u00e1 uma experi\u00eancia de cria\u00e7\u00e3o de teste mais suave ou uma muito frustrante e demorada. Se voc\u00ea optar apenas pelo Selenium, os custos de desenvolvimento e os custos de tempo provavelmente ser\u00e3o muito altos. \u00c9 melhor usar um framework constru\u00eddo em cima do Selenium ou um que tente resolver muitos dos problemas com algo como o Selenium. Note que h\u00e1 outras considera\u00e7\u00f5es, como quando executado em modo headless, a UI pode renderizar de forma diferente do que voc\u00ea pode ver na sua m\u00e1quina de desenvolvimento, particularmente com aplica\u00e7\u00f5es web. Al\u00e9m disso, note que ao renderizar em diferentes dimens\u00f5es de p\u00e1gina, elementos podem desaparecer na p\u00e1gina devido a regras de CSS, portanto, n\u00e3o seriam selecion\u00e1veis por certos frameworks com op\u00e7\u00f5es padr\u00e3o fora da caixa. Todos esses problemas podem ser resolvidos e contornados, mas a renderiza\u00e7\u00e3o demonstra outro desafio particular do teste de UI. Orienta\u00e7\u00e3o Espec\u00edfica Frameworks de teste recomendados: Web BrowserStack Cypress Jest Selenium OS/Aplica\u00e7\u00f5es M\u00f3veis Coded UI tests (CUITs) Xamarin.UITest Note que o framework listado acima que \u00e9 pago \u00e9 o BrowserStack, ele est\u00e1 listado porque \u00e9 um padr\u00e3o da ind\u00fastria, o resto s\u00e3o de c\u00f3digo aberto e gratuitos.","title":"Teste de Interface do Usu\u00e1rio (UI)"},{"location":"automated-testing/ui-testing/#teste-de-interface-do-usuario-ui","text":"Esta se\u00e7\u00e3o \u00e9 voltada principalmente para UIs baseadas na web, mas as orienta\u00e7\u00f5es s\u00e3o semelhantes para aplicativos m\u00f3veis e baseados em sistemas operacionais.","title":"Teste de Interface do Usu\u00e1rio (UI)"},{"location":"automated-testing/ui-testing/#aplicabilidade","text":"O teste de UI nem sempre ser\u00e1 aplic\u00e1vel, por exemplo, em aplica\u00e7\u00f5es sem uma UI ou partes de uma aplica\u00e7\u00e3o que n\u00e3o requerem intera\u00e7\u00e3o humana. Nesses casos, os testes unit\u00e1rios, funcionais e de integra\u00e7\u00e3o/e2e seriam os principais meios. O teste de UI ser\u00e1 principalmente aplic\u00e1vel ao lidar com uma UI voltada para o p\u00fablico que \u00e9 usada em um ambiente diversificado ou em uma UI cr\u00edtica que requer maior fidelidade. Com algo como uma UI de administra\u00e7\u00e3o que \u00e9 usada por apenas algumas pessoas, o teste de UI ainda \u00e9 valioso, mas n\u00e3o t\u00e3o priorit\u00e1rio.","title":"Aplicabilidade"},{"location":"automated-testing/ui-testing/#objetivos","text":"O teste de UI fornece a capacidade de garantir que os usu\u00e1rios tenham uma experi\u00eancia visual consistente em uma variedade de meios de acesso e que a intera\u00e7\u00e3o do usu\u00e1rio seja consistente com os requisitos funcionais. Garantir que a apar\u00eancia e intera\u00e7\u00e3o da UI satisfa\u00e7am os requisitos funcionais e n\u00e3o funcionais Detectar mudan\u00e7as na UI tanto entre dispositivos e plataformas de entrega quanto entre mudan\u00e7as de c\u00f3digo Dar confian\u00e7a a designers e desenvolvedores de que a experi\u00eancia do usu\u00e1rio \u00e9 consistente Apoiar a r\u00e1pida evolu\u00e7\u00e3o do c\u00f3digo e refatora\u00e7\u00e3o, reduzindo o risco de regress\u00f5es","title":"Objetivos"},{"location":"automated-testing/ui-testing/#evidencias-e-medidas","text":"Integrar testes de UI no seu CI/CD \u00e9 necess\u00e1rio, mas mais desafiador do que testes unit\u00e1rios. O desafio aumentado \u00e9 que os testes de UI precisam ser executados em modo headless com algo como Puppeteer ou precisa haver uma orquestra\u00e7\u00e3o mais extensa com Azure DevOps ou GitHub que cuidaria da integra\u00e7\u00e3o completa de testes para voc\u00ea, como BrowserStack . Integra\u00e7\u00f5es como BrowserStack s\u00e3o interessantes, pois fornecem relat\u00f3rios do Azure DevOps como parte da execu\u00e7\u00e3o do teste. Dito isso, o Azure DevOps suporta uma variedade de adaptadores de teste, ent\u00e3o voc\u00ea pode usar qualquer framework de teste de UI que suporte a sa\u00edda dos resultados do teste para um dos formatos de sa\u00edda listados em Publish Test Results task . Se voc\u00ea estiver usando um pipeline do Azure DevOps para executar testes de UI, considere usar um agente auto-hospedado para gerenciar as vers\u00f5es do framework e evitar atualiza\u00e7\u00f5es inesperadas.","title":"Evid\u00eancias e Medidas"},{"location":"automated-testing/ui-testing/#orientacao-geral","text":"O escopo do teste de UI deve ser estrat\u00e9gico. Os testes de UI podem levar uma quantidade significativa de tempo tanto para implementar quanto para executar, e \u00e9 desafiador testar todos os tipos de intera\u00e7\u00e3o do usu\u00e1rio em um aplicativo de produ\u00e7\u00e3o devido ao grande n\u00famero de intera\u00e7\u00f5es poss\u00edveis. Projetar os testes de UI em torno dos testes funcionais faz sentido. Por exemplo, dado um formul\u00e1rio de entrada, um teste de UI garantiria que a representa\u00e7\u00e3o visual seja consistente entre dispositivos, seja acess\u00edvel e f\u00e1cil de interagir, e seja consistente entre mudan\u00e7as de c\u00f3digo. Os testes de UI pegar\u00e3o bugs de 'tempo de execu\u00e7\u00e3o' que os testes unit\u00e1rios e funcionais n\u00e3o pegar\u00e3o. Por exemplo, se o bot\u00e3o de envio de um formul\u00e1rio de entrada for renderizado, mas n\u00e3o for clic\u00e1vel devido a um bug de posicionamento na UI, ent\u00e3o isso poderia ser considerado um bug de tempo de execu\u00e7\u00e3o que n\u00e3o teria sido pego por testes unit\u00e1rios ou funcionais. Os testes de UI podem ser executados em dados fict\u00edcios ou em instant\u00e2neos de dados de produ\u00e7\u00e3o, como em QA ou staging.","title":"Orienta\u00e7\u00e3o Geral"},{"location":"automated-testing/ui-testing/#escrevendo-testes","text":"Bons testes de UI seguem alguns princ\u00edpios gerais: Escolha um framework de teste de UI que permita um feedback r\u00e1pido e seja f\u00e1cil de usar Projete a UI para ser facilmente test\u00e1vel. Por exemplo, adicione seletores CSS ou defina o id em elementos de uma p\u00e1gina da web para permitir uma sele\u00e7\u00e3o mais f\u00e1cil. Teste em todos os dispositivos prim\u00e1rios que o usu\u00e1rio usa, n\u00e3o teste apenas em um \u00fanico dispositivo ou sistema operacional. Quando um teste altera dados, garanta que os dados sejam criados sob demanda e limpos posteriormente. A consequ\u00eancia de n\u00e3o fazer isso seria testes inconsistentes.","title":"Escrevendo Testes"},{"location":"automated-testing/ui-testing/#problemas-comuns","text":"O teste de UI pode se tornar muito desafiador no n\u00edvel mais baixo, especialmente com um framework de teste como o Selenium. Se voc\u00ea optar por seguir esse caminho, provavelmente encontrar\u00e1 timeouts, elementos ausentes e ter\u00e1 atrito significativo com o pr\u00f3prio framework de teste. Devido a muitos problemas com o teste de UI, surgiram v\u00e1rias solu\u00e7\u00f5es gratuitas e pagas que ajudam a aliviar certos problemas com frameworks como o Selenium. \u00c9 por isso que voc\u00ea encontrar\u00e1 o Cypress nos frameworks recomendados, pois ele resolve muitos dos problemas conhecidos com o Selenium. Este \u00e9 um ponto importante. Dependendo do framework de teste de UI que voc\u00ea escolher, o resultado ser\u00e1 uma experi\u00eancia de cria\u00e7\u00e3o de teste mais suave ou uma muito frustrante e demorada. Se voc\u00ea optar apenas pelo Selenium, os custos de desenvolvimento e os custos de tempo provavelmente ser\u00e3o muito altos. \u00c9 melhor usar um framework constru\u00eddo em cima do Selenium ou um que tente resolver muitos dos problemas com algo como o Selenium. Note que h\u00e1 outras considera\u00e7\u00f5es, como quando executado em modo headless, a UI pode renderizar de forma diferente do que voc\u00ea pode ver na sua m\u00e1quina de desenvolvimento, particularmente com aplica\u00e7\u00f5es web. Al\u00e9m disso, note que ao renderizar em diferentes dimens\u00f5es de p\u00e1gina, elementos podem desaparecer na p\u00e1gina devido a regras de CSS, portanto, n\u00e3o seriam selecion\u00e1veis por certos frameworks com op\u00e7\u00f5es padr\u00e3o fora da caixa. Todos esses problemas podem ser resolvidos e contornados, mas a renderiza\u00e7\u00e3o demonstra outro desafio particular do teste de UI.","title":"Problemas Comuns"},{"location":"automated-testing/ui-testing/#orientacao-especifica","text":"Frameworks de teste recomendados: Web BrowserStack Cypress Jest Selenium OS/Aplica\u00e7\u00f5es M\u00f3veis Coded UI tests (CUITs) Xamarin.UITest Note que o framework listado acima que \u00e9 pago \u00e9 o BrowserStack, ele est\u00e1 listado porque \u00e9 um padr\u00e3o da ind\u00fastria, o resto s\u00e3o de c\u00f3digo aberto e gratuitos.","title":"Orienta\u00e7\u00e3o Espec\u00edfica"},{"location":"automated-testing/unit-testing/","text":"Teste de Unidade O teste de unidade \u00e9 uma ferramenta fundamental no conjunto de ferramentas de todo desenvolvedor. Testes de unidade n\u00e3o apenas nos ajudam a testar nosso c\u00f3digo, mas tamb\u00e9m incentivam boas pr\u00e1ticas de design, reduzem as chances de bugs chegarem \u00e0 produ\u00e7\u00e3o e podem at\u00e9 servir como exemplos ou documenta\u00e7\u00e3o sobre como o c\u00f3digo funciona. Testes de unidade bem escritos tamb\u00e9m podem melhorar a efici\u00eancia do desenvolvedor. O teste de unidade tamb\u00e9m \u00e9 uma das formas mais comumente mal compreendidas de teste. Teste de unidade se refere a um tipo muito espec\u00edfico de teste; um teste de unidade deve ser: Comprovadamente confi\u00e1vel - deve ser 100% confi\u00e1vel para que falhas indiquem um bug no c\u00f3digo R\u00e1pido - deve ser executado em milissegundos, uma su\u00edte completa de teste de unidade n\u00e3o deve demorar mais do que alguns segundos Isolado - remover todas as depend\u00eancias externas garante confiabilidade e velocidade Por que Teste de Unidade N\u00e3o \u00e9 segredo que escrever testes de unidade \u00e9 dif\u00edcil e ainda mais dif\u00edcil escrev\u00ea-los bem. Escrever testes de unidade tamb\u00e9m aumenta o tempo de desenvolvimento para cada funcionalidade. Ent\u00e3o, por que devemos escrev\u00ea-los? Testes de unidade: reduzem custos ao detectar bugs mais cedo e evitar regress\u00f5es aumentam a confian\u00e7a do desenvolvedor nas mudan\u00e7as aceleram o ciclo interno do desenvolvedor atuam como documenta\u00e7\u00e3o como c\u00f3digo Para mais detalhes, veja todas as descri\u00e7\u00f5es detalhadas dos pontos acima . Blocos de Design de Teste de Unidade O teste de unidade \u00e9 o n\u00edvel mais baixo de teste e, como tal, geralmente tem poucos componentes e depend\u00eancias. O sistema sob teste (abreviado como SUT) \u00e9 a \"unidade\" que estamos testando. Geralmente, s\u00e3o m\u00e9todos ou fun\u00e7\u00f5es, mas dependendo da linguagem, esses podem ser diferentes. Em geral, voc\u00ea quer que a unidade seja o menor poss\u00edvel. A maioria das linguagens tamb\u00e9m possui uma ampla su\u00edte de frameworks de teste de unidade e executores de teste. Esses frameworks de teste t\u00eam uma ampla gama de funcionalidades, mas a funcionalidade b\u00e1sica deve ser uma forma de organizar seus testes e execut\u00e1-los rapidamente. Finalmente, h\u00e1 o seu c\u00f3digo de teste de unidade ; o c\u00f3digo de teste de unidade geralmente \u00e9 curto e simples, preferindo repeti\u00e7\u00e3o a adicionar camadas e complexidade ao c\u00f3digo. Aplicando o Teste de Unidade Come\u00e7ar a escrever um teste de unidade \u00e9 muito mais f\u00e1cil do que alguns outros tipos de teste, j\u00e1 que deve exigir quase nenhuma configura\u00e7\u00e3o e \u00e9 apenas c\u00f3digo. Cada framework de teste \u00e9 diferente na forma como voc\u00ea organiza e escreve seus testes, mas as t\u00e9cnicas gerais e melhores pr\u00e1ticas de escrita de um teste de unidade s\u00e3o universais. T\u00e9cnicas Essas s\u00e3o algumas t\u00e9cnicas comumente usadas que ajudar\u00e3o na autoria de testes de unidade. Para alguns exemplos, veja as p\u00e1ginas sobre o uso de abstra\u00e7\u00e3o e inje\u00e7\u00e3o de depend\u00eancia para criar um teste de unidade ou como fazer desenvolvimento orientado por testes . Observe que algumas dessas t\u00e9cnicas s\u00e3o mais espec\u00edficas para linguagens fortemente tipadas e orientadas a objetos. Linguagens funcionais e linguagens de script t\u00eam t\u00e9cnicas semelhantes que podem parecer diferentes, mas esses termos s\u00e3o comumente usados em todos os exemplos de teste de unidade. Abstra\u00e7\u00e3o A abstra\u00e7\u00e3o \u00e9 quando pegamos um detalhe de implementa\u00e7\u00e3o exato e o generalizamos em um conceito. Essa t\u00e9cnica pode ser usada na cria\u00e7\u00e3o de design test\u00e1vel e \u00e9 usada com frequ\u00eancia, especialmente em linguagens orientadas a objetos. Para testes de unidade, a abstra\u00e7\u00e3o \u00e9 comumente usada para quebrar uma depend\u00eancia r\u00edgida e substitu\u00ed-la por uma abstra\u00e7\u00e3o. Essa abstra\u00e7\u00e3o permite ent\u00e3o maior flexibilidade no c\u00f3digo e permite que um mock ou simulador seja usado em seu lugar. Um dos efeitos colaterais da abstra\u00e7\u00e3o de depend\u00eancias \u00e9 que voc\u00ea pode ter uma abstra\u00e7\u00e3o que n\u00e3o tem cobertura de teste. Este \u00e9 um caso em que o teste de unidade n\u00e3o \u00e9 bem adequado, voc\u00ea n\u00e3o pode esperar testar tudo em unidade, coisas como depend\u00eancias sempre ser\u00e3o um caso n\u00e3o coberto. \u00c9 por isso que mesmo se voc\u00ea tiver uma su\u00edte robusta de teste de unidade, teste de integra\u00e7\u00e3o ou teste funcional ainda deve ser usado - sem isso, uma mudan\u00e7a na forma como a depend\u00eancia funciona nunca seria detectada. Ao criar wrappers em torno de depend\u00eancias de terceiros, \u00e9 melhor manter as implementa\u00e7\u00f5es com o m\u00ednimo de l\u00f3gica poss\u00edvel, usando uma fachada muito simples que chama a depend\u00eancia. Um exemplo de uso de abstra\u00e7\u00e3o pode ser encontrado aqui . Inje\u00e7\u00e3o de Depend\u00eancia A inje\u00e7\u00e3o de depend\u00eancia \u00e9 uma t\u00e9cnica que nos permite extrair depend\u00eancias do nosso c\u00f3digo. Em um caso de uso normal de uma classe dependente, a depend\u00eancia \u00e9 constru\u00edda e usada dentro do sistema sob teste. Isso cria uma depend\u00eancia r\u00edgida entre as duas classes, o que pode torn\u00e1-la particularmente dif\u00edcil de testar isoladamente. Depend\u00eancias podem ser coisas como classes que envolvem uma API REST ou at\u00e9 mesmo algo t\u00e3o simples quanto o acesso a arquivos. Ao injetar as depend\u00eancias em nosso sistema em vez de constru\u00ed-las, \"invertemos o controle\" da depend\u00eancia. Voc\u00ea pode ver \"Invers\u00e3o de Controle\" e \"Inje\u00e7\u00e3o de Depend\u00eancia\" usados como termos separados, mas \u00e9 muito dif\u00edcil ter um e n\u00e3o o outro, com alguns argumentando que Inje\u00e7\u00e3o de Depend\u00eancia \u00e9 uma forma mais espec\u00edfica de dizer invers\u00e3o de controle . Em certas linguagens como C#, n\u00e3o usar inje\u00e7\u00e3o de depend\u00eancia pode levar a um c\u00f3digo que n\u00e3o \u00e9 test\u00e1vel em unidade, j\u00e1 que n\u00e3o h\u00e1 como injetar objetos simulados. Manter a testabilidade em mente desde o in\u00edcio e avaliar o uso da inje\u00e7\u00e3o de depend\u00eancia pode poupar voc\u00ea de um refatoramento demorado mais tarde. Uma das desvantagens da inje\u00e7\u00e3o de depend\u00eancia \u00e9 que ela pode facilmente sair do controle. Embora n\u00e3o haja mais depend\u00eancias r\u00edgidas, ainda h\u00e1 acoplamento entre as interfaces, e passar todas as implementa\u00e7\u00f5es de interface para todas as classes apresenta tantas desvantagens quanto n\u00e3o usar Inje\u00e7\u00e3o de Depend\u00eancia. Ser intencional com quais depend\u00eancias s\u00e3o injetadas em quais classes \u00e9 a chave para desenvolver um sistema sustent\u00e1vel. Muitas linguagens incluem frameworks especiais de Inje\u00e7\u00e3o de Depend\u00eancia que cuidam do c\u00f3digo de inicializa\u00e7\u00e3o e constru\u00e7\u00e3o dos objetos. Exemplos disso s\u00e3o Spring em Java ou embutido em ASP.NET Core . Um exemplo de uso de inje\u00e7\u00e3o de depend\u00eancia pode ser encontrado aqui . Desenvolvimento Orientado por Testes O Desenvolvimento Orientado por Testes (TDD) \u00e9 menos uma t\u00e9cnica em como seu c\u00f3digo \u00e9 projetado, mas uma t\u00e9cnica para escrever seu c\u00f3digo que o levar\u00e1 a um design test\u00e1vel desde o in\u00edcio. A premissa b\u00e1sica do desenvolvimento orientado por testes \u00e9 que voc\u00ea escreve seu c\u00f3digo de teste primeiro e depois escreve o sistema sob teste para corresponder ao teste que voc\u00ea acabou de escrever. Dessa forma, todo o design do teste \u00e9 feito antecipadamente e, quando voc\u00ea termina de escrever seu c\u00f3digo do sistema, j\u00e1 est\u00e1 com 100% de taxa de aprova\u00e7\u00e3o e cobertura de teste. Tamb\u00e9m garante que o design test\u00e1vel seja incorporado ao sistema, j\u00e1 que o teste foi escrito primeiro! Para mais informa\u00e7\u00f5es sobre TDD e um exemplo, veja a p\u00e1gina sobre Desenvolvimento Orientado por Testes . Melhores Pr\u00e1ticas Organizar/Agir/Afirmar Uma forma comum de organizar seu c\u00f3digo de teste de unidade \u00e9 chamada de Organizar/Agir/Afirmar. Isso divide seu teste de unidade em 3 se\u00e7\u00f5es diferentes e discretas: Organizar - Configure todas as vari\u00e1veis, mocks, interfaces e estados de que voc\u00ea precisar\u00e1 para executar o teste Agir - Execute o sistema sob teste, passando qualquer um dos objetos acima que foram criados Afirmar - Verifique que, com o estado dado, o sistema agiu adequadamente. Usar esse padr\u00e3o para escrever testes torna-os muito leg\u00edveis e tamb\u00e9m familiares para futuros desenvolvedores que precisariam ler seus testes de unidade. Exemplo Vamos supor que temos uma classe MeuObjeto com um m\u00e9todo TentarAlgo que interage com uma matriz de strings, mas se a matriz n\u00e3o tiver elementos, ele retornar\u00e1 falso. Queremos escrever um teste que verifica o caso em que a matriz n\u00e3o tem elementos: [Fact] public void TentarAlgo_SemElementos_RetornaFalso () { // Organizar var elementos = Array . Empty < string > (); var meuObjeto = new MeuObjeto (); // Agir var meuRetorno = meuObjeto . TentarAlgo ( elementos ); // Afirmar Assert . False ( meuRetorno ); } Mantenha os testes pequenos e teste apenas uma coisa Os testes de unidade devem ser curtos e testar apenas uma coisa. Isso facilita o diagn\u00f3stico quando houve uma falha sem precisar de algo como o n\u00famero da linha em que o teste falhou. Ao usar Organizar/Agir/Afirmar , pense nisso como testar apenas uma coisa na fase \"Agir\". H\u00e1 algum desacordo sobre se testar uma coisa significa \"afirmar uma coisa\" ou \"testar um estado, com v\u00e1rias afirma\u00e7\u00f5es, se necess\u00e1rio\". Ambos t\u00eam suas vantagens e desvantagens, mas como na maioria dos desacordos t\u00e9cnicos, n\u00e3o h\u00e1 uma \"resposta certa\". A consist\u00eancia ao escrever seus testes de uma forma ou de outra \u00e9 mais importante! Usando uma conven\u00e7\u00e3o de nomenclatura padr\u00e3o para todos os testes de unidade Sem ter uma conven\u00e7\u00e3o padr\u00e3o estabelecida para os nomes dos testes de unidade, os nomes dos testes de unidade acabam sendo ou n\u00e3o descritivos o suficiente ou duplicados em v\u00e1rias classes de teste diferentes. Estabelecer um padr\u00e3o n\u00e3o \u00e9 apenas importante para manter seu c\u00f3digo consistente, mas um bom padr\u00e3o tamb\u00e9m melhora a legibilidade e a capacidade de depura\u00e7\u00e3o de um teste. Neste artigo, a conven\u00e7\u00e3o usada para todos os testes de unidade foi NomeDaUnidade_EstadoSobTeste_ResultadoEsperado , mas h\u00e1 muitas outras conven\u00e7\u00f5es poss\u00edveis tamb\u00e9m, o importante \u00e9 ser consistente e descritivo. Ter nomes descritivos como o acima torna trivial encontrar o teste quando h\u00e1 uma falha e tamb\u00e9m j\u00e1 explica qual era a expectativa do teste e qual estado fez com que ele falhasse. Isso pode ser especialmente \u00fatil ao olhar para falhas em um sistema de CI/CD onde tudo o que voc\u00ea sabe \u00e9 o nome do teste que falhou - em vez disso, agora voc\u00ea sabe o nome do teste e exatamente por que ele falhou (especialmente acoplado com um framework de teste que registra sa\u00eddas \u00fateis em falhas). Coisas a Evitar Alguns problemas comuns ao escrever um teste de unidade que s\u00e3o importantes de evitar: Sleeps - Um sleep pode ser um indicador de que talvez algo esteja fazendo uma solicita\u00e7\u00e3o a uma depend\u00eancia que n\u00e3o deveria. Em geral, se seu c\u00f3digo \u00e9 inst\u00e1vel sem o sleep, considere por que ele est\u00e1 falhando e se voc\u00ea pode remover a instabilidade introduzindo uma forma mais confi\u00e1vel de comunicar poss\u00edveis mudan\u00e7as de estado. Adicionar sleeps aos seus testes de unidade tamb\u00e9m quebra um dos nossos princ\u00edpios originais de teste de unidade: os testes devem ser r\u00e1pidos, na ordem de milissegundos. Se os testes est\u00e3o demorando na ordem de segundos, eles se tornam mais dif\u00edceis de executar. Leitura do disco - Pode ser realmente tentador colocar o valor esperado de um retorno de fun\u00e7\u00e3o em um arquivo e ler esse arquivo para comparar os resultados. Isso cria uma depend\u00eancia com o sistema de arquivos e quebra nosso princ\u00edpio de manter nossos testes de unidade isolados e 100% confi\u00e1veis . Qualquer depend\u00eancia externa, como acesso ao sistema de arquivos, pode potencialmente causar falhas intermitentes. Al\u00e9m disso, isso pode ser um sinal de que talvez o teste ou a unidade sob teste seja muito complexa e deva ser simplificada. - Chamadas de APIs de terceiros - Quando voc\u00ea n\u00e3o controla uma biblioteca de terceiros que est\u00e1 chamando, \u00e9 imposs\u00edvel saber com certeza o que ela est\u00e1 fazendo, e \u00e9 melhor abstrai-la. Caso contr\u00e1rio, voc\u00ea pode estar fazendo chamadas REST ou outras \u00e1reas potenciais de falha sem escrever diretamente o c\u00f3digo para isso. Isso tamb\u00e9m \u00e9 geralmente um sinal de que o design do sistema n\u00e3o \u00e9 totalmente test\u00e1vel. \u00c9 melhor envolver chamadas de API de terceiros em interfaces ou outras estruturas para que elas n\u00e3o sejam invocadas em testes de unidade. Para mais informa\u00e7\u00f5es, consulte a p\u00e1gina sobre mocking . Frameworks e Ferramentas de Teste de Unidade Frameworks de Teste Os frameworks de teste de unidade est\u00e3o em constante mudan\u00e7a. Para uma lista completa de todos os frameworks de teste de unidade veja a p\u00e1gina na Wikipedia . Os frameworks t\u00eam muitos recursos e devem ser escolhidos com base em qual conjunto de recursos se encaixa melhor para o projeto em particular. Frameworks de Mock Muitos projetos come\u00e7am com um framework de teste de unidade e tamb\u00e9m adicionam um framework de mock. Embora os frameworks de mock tenham seus usos e \u00e0s vezes possam ser um requisito, n\u00e3o deve ser algo que \u00e9 adicionado sem considerar as implica\u00e7\u00f5es e riscos mais amplos associados ao uso pesado de mocks. Para ver se o uso de mocks \u00e9 adequado para o seu projeto, ou se uma abordagem sem mocks \u00e9 mais apropriada, consulte a p\u00e1gina sobre mocking . Ferramentas Essas ferramentas permitem a execu\u00e7\u00e3o constante de seus testes de unidade com cobertura de c\u00f3digo em linha, tornando o ciclo interno de desenvolvimento extremamente r\u00e1pido e permitindo um f\u00e1cil TDD: Visual Studio Live Unit Testing Wallaby.js Infinitest para Java PyCrunch para Python Coisas a Considerar Transferindo a responsabilidade para testes de integra\u00e7\u00e3o Em algumas situa\u00e7\u00f5es, vale a pena considerar incluir os testes de integra\u00e7\u00e3o no ciclo interno de desenvolvimento para fornecer uma cobertura de c\u00f3digo suficiente para garantir que o sistema est\u00e1 funcionando corretamente. O pr\u00e9-requisito para que essa abordagem seja bem-sucedida \u00e9 ter testes de integra\u00e7\u00e3o capazes de serem executados a uma velocidade compar\u00e1vel \u00e0 dos testes de unidade, tanto localmente quanto em um ambiente de CI. Frameworks de aplica\u00e7\u00e3o modernos como .NET ou Spring Boot, combinados com a abordagem de mocking ou stubbing correta para depend\u00eancias externas, oferecem excelentes capacidades para habilitar tais cen\u00e1rios para testes. Normalmente, os testes de integra\u00e7\u00e3o apenas provam que os m\u00f3dulos desenvolvidos independentemente se conectam conforme projetado. A cobertura de teste dos testes de integra\u00e7\u00e3o pode ser estendida para verificar o comportamento correto do sistema tamb\u00e9m. A responsabilidade de fornecer uma cobertura de c\u00f3digo de ramo e linha suficiente pode ser transferida dos testes de unidade para os testes de integra\u00e7\u00e3o. Em vez de v\u00e1rios testes de unidade necess\u00e1rios para testar um caso espec\u00edfico de funcionalidade do sistema, um cen\u00e1rio de integra\u00e7\u00e3o \u00e9 criado que cobre todo o fluxo. Por exemplo, no caso de uma API, as respostas HTTP recebidas e seu conte\u00fado s\u00e3o verificados para cada solicita\u00e7\u00e3o no teste. Isso cobre tanto a integra\u00e7\u00e3o entre os componentes da API quanto a corre\u00e7\u00e3o de sua l\u00f3gica de neg\u00f3cios. Com essa abordagem, testes de integra\u00e7\u00e3o eficientes podem ser tratados como uma extens\u00e3o do teste de unidade, assumindo a responsabilidade de validar cen\u00e1rios de caminho feliz/falha. Ele tem a vantagem de testar o sistema como uma caixa preta, sem qualquer conhecimento de seus componentes internos. A refatora\u00e7\u00e3o de c\u00f3digo n\u00e3o tem impacto nos testes. T\u00e9cnicas comuns de teste como TDD podem ser aplicadas em um n\u00edvel mais alto, resultando em um processo de desenvolvimento orientado por testes de aceita\u00e7\u00e3o. Dependendo das especificidades do projeto, os testes de unidade ainda desempenham um papel importante. Eles podem ser usados para ajudar a ditar um design test\u00e1vel em um n\u00edvel mais baixo ou para testar l\u00f3gica de neg\u00f3cios complexa e casos extremos, se necess\u00e1rio. Conclus\u00e3o O teste de unidade \u00e9 extremamente importante, mas tamb\u00e9m n\u00e3o \u00e9 a bala de prata; ter testes de unidade adequados \u00e9 apenas uma parte de um sistema bem testado. No entanto, escrever testes de unidade adequados ajudar\u00e1 no design do seu sistema, bem como ajudar\u00e1 a capturar regress\u00f5es, bugs e aumentar a velocidade do desenvolvedor. Recursos Melhores Pr\u00e1ticas de Teste de Unidade","title":"Teste de Unidade"},{"location":"automated-testing/unit-testing/#teste-de-unidade","text":"O teste de unidade \u00e9 uma ferramenta fundamental no conjunto de ferramentas de todo desenvolvedor. Testes de unidade n\u00e3o apenas nos ajudam a testar nosso c\u00f3digo, mas tamb\u00e9m incentivam boas pr\u00e1ticas de design, reduzem as chances de bugs chegarem \u00e0 produ\u00e7\u00e3o e podem at\u00e9 servir como exemplos ou documenta\u00e7\u00e3o sobre como o c\u00f3digo funciona. Testes de unidade bem escritos tamb\u00e9m podem melhorar a efici\u00eancia do desenvolvedor. O teste de unidade tamb\u00e9m \u00e9 uma das formas mais comumente mal compreendidas de teste. Teste de unidade se refere a um tipo muito espec\u00edfico de teste; um teste de unidade deve ser: Comprovadamente confi\u00e1vel - deve ser 100% confi\u00e1vel para que falhas indiquem um bug no c\u00f3digo R\u00e1pido - deve ser executado em milissegundos, uma su\u00edte completa de teste de unidade n\u00e3o deve demorar mais do que alguns segundos Isolado - remover todas as depend\u00eancias externas garante confiabilidade e velocidade","title":"Teste de Unidade"},{"location":"automated-testing/unit-testing/#por-que-teste-de-unidade","text":"N\u00e3o \u00e9 segredo que escrever testes de unidade \u00e9 dif\u00edcil e ainda mais dif\u00edcil escrev\u00ea-los bem. Escrever testes de unidade tamb\u00e9m aumenta o tempo de desenvolvimento para cada funcionalidade. Ent\u00e3o, por que devemos escrev\u00ea-los? Testes de unidade: reduzem custos ao detectar bugs mais cedo e evitar regress\u00f5es aumentam a confian\u00e7a do desenvolvedor nas mudan\u00e7as aceleram o ciclo interno do desenvolvedor atuam como documenta\u00e7\u00e3o como c\u00f3digo Para mais detalhes, veja todas as descri\u00e7\u00f5es detalhadas dos pontos acima .","title":"Por que Teste de Unidade"},{"location":"automated-testing/unit-testing/#blocos-de-design-de-teste-de-unidade","text":"O teste de unidade \u00e9 o n\u00edvel mais baixo de teste e, como tal, geralmente tem poucos componentes e depend\u00eancias. O sistema sob teste (abreviado como SUT) \u00e9 a \"unidade\" que estamos testando. Geralmente, s\u00e3o m\u00e9todos ou fun\u00e7\u00f5es, mas dependendo da linguagem, esses podem ser diferentes. Em geral, voc\u00ea quer que a unidade seja o menor poss\u00edvel. A maioria das linguagens tamb\u00e9m possui uma ampla su\u00edte de frameworks de teste de unidade e executores de teste. Esses frameworks de teste t\u00eam uma ampla gama de funcionalidades, mas a funcionalidade b\u00e1sica deve ser uma forma de organizar seus testes e execut\u00e1-los rapidamente. Finalmente, h\u00e1 o seu c\u00f3digo de teste de unidade ; o c\u00f3digo de teste de unidade geralmente \u00e9 curto e simples, preferindo repeti\u00e7\u00e3o a adicionar camadas e complexidade ao c\u00f3digo.","title":"Blocos de Design de Teste de Unidade"},{"location":"automated-testing/unit-testing/#aplicando-o-teste-de-unidade","text":"Come\u00e7ar a escrever um teste de unidade \u00e9 muito mais f\u00e1cil do que alguns outros tipos de teste, j\u00e1 que deve exigir quase nenhuma configura\u00e7\u00e3o e \u00e9 apenas c\u00f3digo. Cada framework de teste \u00e9 diferente na forma como voc\u00ea organiza e escreve seus testes, mas as t\u00e9cnicas gerais e melhores pr\u00e1ticas de escrita de um teste de unidade s\u00e3o universais.","title":"Aplicando o Teste de Unidade"},{"location":"automated-testing/unit-testing/#tecnicas","text":"Essas s\u00e3o algumas t\u00e9cnicas comumente usadas que ajudar\u00e3o na autoria de testes de unidade. Para alguns exemplos, veja as p\u00e1ginas sobre o uso de abstra\u00e7\u00e3o e inje\u00e7\u00e3o de depend\u00eancia para criar um teste de unidade ou como fazer desenvolvimento orientado por testes . Observe que algumas dessas t\u00e9cnicas s\u00e3o mais espec\u00edficas para linguagens fortemente tipadas e orientadas a objetos. Linguagens funcionais e linguagens de script t\u00eam t\u00e9cnicas semelhantes que podem parecer diferentes, mas esses termos s\u00e3o comumente usados em todos os exemplos de teste de unidade.","title":"T\u00e9cnicas"},{"location":"automated-testing/unit-testing/#abstracao","text":"A abstra\u00e7\u00e3o \u00e9 quando pegamos um detalhe de implementa\u00e7\u00e3o exato e o generalizamos em um conceito. Essa t\u00e9cnica pode ser usada na cria\u00e7\u00e3o de design test\u00e1vel e \u00e9 usada com frequ\u00eancia, especialmente em linguagens orientadas a objetos. Para testes de unidade, a abstra\u00e7\u00e3o \u00e9 comumente usada para quebrar uma depend\u00eancia r\u00edgida e substitu\u00ed-la por uma abstra\u00e7\u00e3o. Essa abstra\u00e7\u00e3o permite ent\u00e3o maior flexibilidade no c\u00f3digo e permite que um mock ou simulador seja usado em seu lugar. Um dos efeitos colaterais da abstra\u00e7\u00e3o de depend\u00eancias \u00e9 que voc\u00ea pode ter uma abstra\u00e7\u00e3o que n\u00e3o tem cobertura de teste. Este \u00e9 um caso em que o teste de unidade n\u00e3o \u00e9 bem adequado, voc\u00ea n\u00e3o pode esperar testar tudo em unidade, coisas como depend\u00eancias sempre ser\u00e3o um caso n\u00e3o coberto. \u00c9 por isso que mesmo se voc\u00ea tiver uma su\u00edte robusta de teste de unidade, teste de integra\u00e7\u00e3o ou teste funcional ainda deve ser usado - sem isso, uma mudan\u00e7a na forma como a depend\u00eancia funciona nunca seria detectada. Ao criar wrappers em torno de depend\u00eancias de terceiros, \u00e9 melhor manter as implementa\u00e7\u00f5es com o m\u00ednimo de l\u00f3gica poss\u00edvel, usando uma fachada muito simples que chama a depend\u00eancia. Um exemplo de uso de abstra\u00e7\u00e3o pode ser encontrado aqui .","title":"Abstra\u00e7\u00e3o"},{"location":"automated-testing/unit-testing/#injecao-de-dependencia","text":"A inje\u00e7\u00e3o de depend\u00eancia \u00e9 uma t\u00e9cnica que nos permite extrair depend\u00eancias do nosso c\u00f3digo. Em um caso de uso normal de uma classe dependente, a depend\u00eancia \u00e9 constru\u00edda e usada dentro do sistema sob teste. Isso cria uma depend\u00eancia r\u00edgida entre as duas classes, o que pode torn\u00e1-la particularmente dif\u00edcil de testar isoladamente. Depend\u00eancias podem ser coisas como classes que envolvem uma API REST ou at\u00e9 mesmo algo t\u00e3o simples quanto o acesso a arquivos. Ao injetar as depend\u00eancias em nosso sistema em vez de constru\u00ed-las, \"invertemos o controle\" da depend\u00eancia. Voc\u00ea pode ver \"Invers\u00e3o de Controle\" e \"Inje\u00e7\u00e3o de Depend\u00eancia\" usados como termos separados, mas \u00e9 muito dif\u00edcil ter um e n\u00e3o o outro, com alguns argumentando que Inje\u00e7\u00e3o de Depend\u00eancia \u00e9 uma forma mais espec\u00edfica de dizer invers\u00e3o de controle . Em certas linguagens como C#, n\u00e3o usar inje\u00e7\u00e3o de depend\u00eancia pode levar a um c\u00f3digo que n\u00e3o \u00e9 test\u00e1vel em unidade, j\u00e1 que n\u00e3o h\u00e1 como injetar objetos simulados. Manter a testabilidade em mente desde o in\u00edcio e avaliar o uso da inje\u00e7\u00e3o de depend\u00eancia pode poupar voc\u00ea de um refatoramento demorado mais tarde. Uma das desvantagens da inje\u00e7\u00e3o de depend\u00eancia \u00e9 que ela pode facilmente sair do controle. Embora n\u00e3o haja mais depend\u00eancias r\u00edgidas, ainda h\u00e1 acoplamento entre as interfaces, e passar todas as implementa\u00e7\u00f5es de interface para todas as classes apresenta tantas desvantagens quanto n\u00e3o usar Inje\u00e7\u00e3o de Depend\u00eancia. Ser intencional com quais depend\u00eancias s\u00e3o injetadas em quais classes \u00e9 a chave para desenvolver um sistema sustent\u00e1vel. Muitas linguagens incluem frameworks especiais de Inje\u00e7\u00e3o de Depend\u00eancia que cuidam do c\u00f3digo de inicializa\u00e7\u00e3o e constru\u00e7\u00e3o dos objetos. Exemplos disso s\u00e3o Spring em Java ou embutido em ASP.NET Core . Um exemplo de uso de inje\u00e7\u00e3o de depend\u00eancia pode ser encontrado aqui .","title":"Inje\u00e7\u00e3o de Depend\u00eancia"},{"location":"automated-testing/unit-testing/#desenvolvimento-orientado-por-testes","text":"O Desenvolvimento Orientado por Testes (TDD) \u00e9 menos uma t\u00e9cnica em como seu c\u00f3digo \u00e9 projetado, mas uma t\u00e9cnica para escrever seu c\u00f3digo que o levar\u00e1 a um design test\u00e1vel desde o in\u00edcio. A premissa b\u00e1sica do desenvolvimento orientado por testes \u00e9 que voc\u00ea escreve seu c\u00f3digo de teste primeiro e depois escreve o sistema sob teste para corresponder ao teste que voc\u00ea acabou de escrever. Dessa forma, todo o design do teste \u00e9 feito antecipadamente e, quando voc\u00ea termina de escrever seu c\u00f3digo do sistema, j\u00e1 est\u00e1 com 100% de taxa de aprova\u00e7\u00e3o e cobertura de teste. Tamb\u00e9m garante que o design test\u00e1vel seja incorporado ao sistema, j\u00e1 que o teste foi escrito primeiro! Para mais informa\u00e7\u00f5es sobre TDD e um exemplo, veja a p\u00e1gina sobre Desenvolvimento Orientado por Testes .","title":"Desenvolvimento Orientado por Testes"},{"location":"automated-testing/unit-testing/#melhores-praticas","text":"","title":"Melhores Pr\u00e1ticas"},{"location":"automated-testing/unit-testing/#organizaragirafirmar","text":"Uma forma comum de organizar seu c\u00f3digo de teste de unidade \u00e9 chamada de Organizar/Agir/Afirmar. Isso divide seu teste de unidade em 3 se\u00e7\u00f5es diferentes e discretas: Organizar - Configure todas as vari\u00e1veis, mocks, interfaces e estados de que voc\u00ea precisar\u00e1 para executar o teste Agir - Execute o sistema sob teste, passando qualquer um dos objetos acima que foram criados Afirmar - Verifique que, com o estado dado, o sistema agiu adequadamente. Usar esse padr\u00e3o para escrever testes torna-os muito leg\u00edveis e tamb\u00e9m familiares para futuros desenvolvedores que precisariam ler seus testes de unidade.","title":"Organizar/Agir/Afirmar"},{"location":"automated-testing/unit-testing/#exemplo","text":"Vamos supor que temos uma classe MeuObjeto com um m\u00e9todo TentarAlgo que interage com uma matriz de strings, mas se a matriz n\u00e3o tiver elementos, ele retornar\u00e1 falso. Queremos escrever um teste que verifica o caso em que a matriz n\u00e3o tem elementos: [Fact] public void TentarAlgo_SemElementos_RetornaFalso () { // Organizar var elementos = Array . Empty < string > (); var meuObjeto = new MeuObjeto (); // Agir var meuRetorno = meuObjeto . TentarAlgo ( elementos ); // Afirmar Assert . False ( meuRetorno ); }","title":"Exemplo"},{"location":"automated-testing/unit-testing/#mantenha-os-testes-pequenos-e-teste-apenas-uma-coisa","text":"Os testes de unidade devem ser curtos e testar apenas uma coisa. Isso facilita o diagn\u00f3stico quando houve uma falha sem precisar de algo como o n\u00famero da linha em que o teste falhou. Ao usar Organizar/Agir/Afirmar , pense nisso como testar apenas uma coisa na fase \"Agir\". H\u00e1 algum desacordo sobre se testar uma coisa significa \"afirmar uma coisa\" ou \"testar um estado, com v\u00e1rias afirma\u00e7\u00f5es, se necess\u00e1rio\". Ambos t\u00eam suas vantagens e desvantagens, mas como na maioria dos desacordos t\u00e9cnicos, n\u00e3o h\u00e1 uma \"resposta certa\". A consist\u00eancia ao escrever seus testes de uma forma ou de outra \u00e9 mais importante!","title":"Mantenha os testes pequenos e teste apenas uma coisa"},{"location":"automated-testing/unit-testing/#usando-uma-convencao-de-nomenclatura-padrao-para-todos-os-testes-de-unidade","text":"Sem ter uma conven\u00e7\u00e3o padr\u00e3o estabelecida para os nomes dos testes de unidade, os nomes dos testes de unidade acabam sendo ou n\u00e3o descritivos o suficiente ou duplicados em v\u00e1rias classes de teste diferentes. Estabelecer um padr\u00e3o n\u00e3o \u00e9 apenas importante para manter seu c\u00f3digo consistente, mas um bom padr\u00e3o tamb\u00e9m melhora a legibilidade e a capacidade de depura\u00e7\u00e3o de um teste. Neste artigo, a conven\u00e7\u00e3o usada para todos os testes de unidade foi NomeDaUnidade_EstadoSobTeste_ResultadoEsperado , mas h\u00e1 muitas outras conven\u00e7\u00f5es poss\u00edveis tamb\u00e9m, o importante \u00e9 ser consistente e descritivo. Ter nomes descritivos como o acima torna trivial encontrar o teste quando h\u00e1 uma falha e tamb\u00e9m j\u00e1 explica qual era a expectativa do teste e qual estado fez com que ele falhasse. Isso pode ser especialmente \u00fatil ao olhar para falhas em um sistema de CI/CD onde tudo o que voc\u00ea sabe \u00e9 o nome do teste que falhou - em vez disso, agora voc\u00ea sabe o nome do teste e exatamente por que ele falhou (especialmente acoplado com um framework de teste que registra sa\u00eddas \u00fateis em falhas).","title":"Usando uma conven\u00e7\u00e3o de nomenclatura padr\u00e3o para todos os testes de unidade"},{"location":"automated-testing/unit-testing/#coisas-a-evitar","text":"Alguns problemas comuns ao escrever um teste de unidade que s\u00e3o importantes de evitar: Sleeps - Um sleep pode ser um indicador de que talvez algo esteja fazendo uma solicita\u00e7\u00e3o a uma depend\u00eancia que n\u00e3o deveria. Em geral, se seu c\u00f3digo \u00e9 inst\u00e1vel sem o sleep, considere por que ele est\u00e1 falhando e se voc\u00ea pode remover a instabilidade introduzindo uma forma mais confi\u00e1vel de comunicar poss\u00edveis mudan\u00e7as de estado. Adicionar sleeps aos seus testes de unidade tamb\u00e9m quebra um dos nossos princ\u00edpios originais de teste de unidade: os testes devem ser r\u00e1pidos, na ordem de milissegundos. Se os testes est\u00e3o demorando na ordem de segundos, eles se tornam mais dif\u00edceis de executar. Leitura do disco - Pode ser realmente tentador colocar o valor esperado de um retorno de fun\u00e7\u00e3o em um arquivo e ler esse arquivo para comparar os resultados. Isso cria uma depend\u00eancia com o sistema de arquivos e quebra nosso princ\u00edpio de manter nossos testes de unidade isolados e 100% confi\u00e1veis . Qualquer depend\u00eancia externa, como acesso ao sistema de arquivos, pode potencialmente causar falhas intermitentes. Al\u00e9m disso, isso pode ser um sinal de que talvez o teste ou a unidade sob teste seja muito complexa e deva ser simplificada. - Chamadas de APIs de terceiros - Quando voc\u00ea n\u00e3o controla uma biblioteca de terceiros que est\u00e1 chamando, \u00e9 imposs\u00edvel saber com certeza o que ela est\u00e1 fazendo, e \u00e9 melhor abstrai-la. Caso contr\u00e1rio, voc\u00ea pode estar fazendo chamadas REST ou outras \u00e1reas potenciais de falha sem escrever diretamente o c\u00f3digo para isso. Isso tamb\u00e9m \u00e9 geralmente um sinal de que o design do sistema n\u00e3o \u00e9 totalmente test\u00e1vel. \u00c9 melhor envolver chamadas de API de terceiros em interfaces ou outras estruturas para que elas n\u00e3o sejam invocadas em testes de unidade. Para mais informa\u00e7\u00f5es, consulte a p\u00e1gina sobre mocking .","title":"Coisas a Evitar"},{"location":"automated-testing/unit-testing/#frameworks-e-ferramentas-de-teste-de-unidade","text":"","title":"Frameworks e Ferramentas de Teste de Unidade"},{"location":"automated-testing/unit-testing/#frameworks-de-teste","text":"Os frameworks de teste de unidade est\u00e3o em constante mudan\u00e7a. Para uma lista completa de todos os frameworks de teste de unidade veja a p\u00e1gina na Wikipedia . Os frameworks t\u00eam muitos recursos e devem ser escolhidos com base em qual conjunto de recursos se encaixa melhor para o projeto em particular.","title":"Frameworks de Teste"},{"location":"automated-testing/unit-testing/#frameworks-de-mock","text":"Muitos projetos come\u00e7am com um framework de teste de unidade e tamb\u00e9m adicionam um framework de mock. Embora os frameworks de mock tenham seus usos e \u00e0s vezes possam ser um requisito, n\u00e3o deve ser algo que \u00e9 adicionado sem considerar as implica\u00e7\u00f5es e riscos mais amplos associados ao uso pesado de mocks. Para ver se o uso de mocks \u00e9 adequado para o seu projeto, ou se uma abordagem sem mocks \u00e9 mais apropriada, consulte a p\u00e1gina sobre mocking .","title":"Frameworks de Mock"},{"location":"automated-testing/unit-testing/#ferramentas","text":"Essas ferramentas permitem a execu\u00e7\u00e3o constante de seus testes de unidade com cobertura de c\u00f3digo em linha, tornando o ciclo interno de desenvolvimento extremamente r\u00e1pido e permitindo um f\u00e1cil TDD: Visual Studio Live Unit Testing Wallaby.js Infinitest para Java PyCrunch para Python","title":"Ferramentas"},{"location":"automated-testing/unit-testing/#coisas-a-considerar","text":"","title":"Coisas a Considerar"},{"location":"automated-testing/unit-testing/#transferindo-a-responsabilidade-para-testes-de-integracao","text":"Em algumas situa\u00e7\u00f5es, vale a pena considerar incluir os testes de integra\u00e7\u00e3o no ciclo interno de desenvolvimento para fornecer uma cobertura de c\u00f3digo suficiente para garantir que o sistema est\u00e1 funcionando corretamente. O pr\u00e9-requisito para que essa abordagem seja bem-sucedida \u00e9 ter testes de integra\u00e7\u00e3o capazes de serem executados a uma velocidade compar\u00e1vel \u00e0 dos testes de unidade, tanto localmente quanto em um ambiente de CI. Frameworks de aplica\u00e7\u00e3o modernos como .NET ou Spring Boot, combinados com a abordagem de mocking ou stubbing correta para depend\u00eancias externas, oferecem excelentes capacidades para habilitar tais cen\u00e1rios para testes. Normalmente, os testes de integra\u00e7\u00e3o apenas provam que os m\u00f3dulos desenvolvidos independentemente se conectam conforme projetado. A cobertura de teste dos testes de integra\u00e7\u00e3o pode ser estendida para verificar o comportamento correto do sistema tamb\u00e9m. A responsabilidade de fornecer uma cobertura de c\u00f3digo de ramo e linha suficiente pode ser transferida dos testes de unidade para os testes de integra\u00e7\u00e3o. Em vez de v\u00e1rios testes de unidade necess\u00e1rios para testar um caso espec\u00edfico de funcionalidade do sistema, um cen\u00e1rio de integra\u00e7\u00e3o \u00e9 criado que cobre todo o fluxo. Por exemplo, no caso de uma API, as respostas HTTP recebidas e seu conte\u00fado s\u00e3o verificados para cada solicita\u00e7\u00e3o no teste. Isso cobre tanto a integra\u00e7\u00e3o entre os componentes da API quanto a corre\u00e7\u00e3o de sua l\u00f3gica de neg\u00f3cios. Com essa abordagem, testes de integra\u00e7\u00e3o eficientes podem ser tratados como uma extens\u00e3o do teste de unidade, assumindo a responsabilidade de validar cen\u00e1rios de caminho feliz/falha. Ele tem a vantagem de testar o sistema como uma caixa preta, sem qualquer conhecimento de seus componentes internos. A refatora\u00e7\u00e3o de c\u00f3digo n\u00e3o tem impacto nos testes. T\u00e9cnicas comuns de teste como TDD podem ser aplicadas em um n\u00edvel mais alto, resultando em um processo de desenvolvimento orientado por testes de aceita\u00e7\u00e3o. Dependendo das especificidades do projeto, os testes de unidade ainda desempenham um papel importante. Eles podem ser usados para ajudar a ditar um design test\u00e1vel em um n\u00edvel mais baixo ou para testar l\u00f3gica de neg\u00f3cios complexa e casos extremos, se necess\u00e1rio.","title":"Transferindo a responsabilidade para testes de integra\u00e7\u00e3o"},{"location":"automated-testing/unit-testing/#conclusao","text":"O teste de unidade \u00e9 extremamente importante, mas tamb\u00e9m n\u00e3o \u00e9 a bala de prata; ter testes de unidade adequados \u00e9 apenas uma parte de um sistema bem testado. No entanto, escrever testes de unidade adequados ajudar\u00e1 no design do seu sistema, bem como ajudar\u00e1 a capturar regress\u00f5es, bugs e aumentar a velocidade do desenvolvedor.","title":"Conclus\u00e3o"},{"location":"automated-testing/unit-testing/#recursos","text":"Melhores Pr\u00e1ticas de Teste de Unidade","title":"Recursos"},{"location":"automated-testing/unit-testing/authoring_example/","text":"Exemplo: Criando um teste de unidade Para ilustrar algumas t\u00e9cnicas de teste de unidade para uma linguagem orientada a objetos, vamos come\u00e7ar com um exemplo de algum c\u00f3digo para o qual desejamos adicionar testes de unidade. Neste exemplo, temos uma classe de configura\u00e7\u00e3o que cont\u00e9m todas as op\u00e7\u00f5es de inicializa\u00e7\u00e3o para um aplicativo que estamos desenvolvendo. Normalmente, ela l\u00ea de um arquivo .config , mas estamos enfrentando tr\u00eas problemas com a implementa\u00e7\u00e3o atual: H\u00e1 um erro na classe Configuration, e n\u00e3o temos testes de unidade, pois ela depende da leitura de um arquivo de configura\u00e7\u00e3o. N\u00e3o podemos testar nenhuma parte do c\u00f3digo que depende da classe Configuration lendo um arquivo de configura\u00e7\u00e3o. No futuro, queremos permitir que a configura\u00e7\u00e3o seja salva na nuvem e acessada via API REST. O erro que estamos tentando corrigir \u00e9 que, se houver v\u00e1rias linhas vazias no arquivo de configura\u00e7\u00e3o, uma exce\u00e7\u00e3o IndexOutOfRangeException \u00e9 lan\u00e7ada. Nossa classe atualmente se parece com isto: using System.IO ; using System.Linq ; public class Configuration { // Propriedades p\u00fablicas de getter do objeto de configura\u00e7\u00e3o public string MyProperty { get ; private set ; } public void Initialize () { var configContents = File . ReadAllLines ( \".config\" ); // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Select ( l => l . Split ( '=' )) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } } Abstra\u00e7\u00e3o Em nosso exemplo, temos uma \u00fanica depend\u00eancia: o sistema de arquivos. Em vez de apenas abstrair completamente o sistema de arquivos, vamos pensar sobre por que precisamos do sistema de arquivos e abstrair o conceito em vez da implementa\u00e7\u00e3o. Neste caso, estamos usando a classe File para ler o arquivo de configura\u00e7\u00e3o e o conte\u00fado da configura\u00e7\u00e3o. O conceito de abstra\u00e7\u00e3o aqui \u00e9 alguma forma de leitor de configura\u00e7\u00e3o que retorna cada linha da configura\u00e7\u00e3o em uma matriz de strings. Poder\u00edamos cham\u00e1-lo de ConfigurationReader , e ele tem um \u00fanico m\u00e9todo, Read , que retorna o conte\u00fado. Ao criar abstra\u00e7\u00f5es, pode ser uma boa pr\u00e1tica criar uma interface para essa abstra\u00e7\u00e3o, em linguagens que a suportam. No exemplo com C#, podemos criar uma interface IConfigurationReader , e em vez de apenas termos uma classe ConfigurationReader , podemos ser mais espec\u00edficos e nome\u00e1-la FileConfigurationReader para indicar que ela l\u00ea do sistema de arquivos: // IConfigurationReader.cs public interface IConfigurationReader { string [] Read (); } // FileConfigurationReader.cs public class FileConfigurationReader : IConfigurationReader { public string [] Read () { return File . ReadAllLines ( \".config\" ); } } Agora que a depend\u00eancia do arquivo foi abstra\u00edda, precisamos atualizar o m\u00e9todo Initialize da nossa classe Configuration para usar a nova abstra\u00e7\u00e3o em vez de chamar File.ReadAllLines diretamente: public void Initialize () { var configContents = new FileConfigurationReader (). Read (); // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Select ( l => l . Split ( '=' )) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } Como voc\u00ea pode ver, ainda temos uma depend\u00eancia no sistema de arquivos, mas essa depend\u00eancia foi abstra\u00edda. Precisaremos usar outras t\u00e9cnicas para quebrar completamente a depend\u00eancia. Inje\u00e7\u00e3o de Depend\u00eancia Na se\u00e7\u00e3o anterior, abstra\u00edmos o acesso ao arquivo em um FileConfigurationReader , mas ainda t\u00ednhamos uma depend\u00eancia no sistema de arquivos em nossa fun\u00e7\u00e3o. Podemos usar a inje\u00e7\u00e3o de depend\u00eancia para injetar o leitor certo em nossa classe Configuration : using System.IO ; using System.Linq ; public class Configuration { private readonly IConfigurationReader configReader ; // Propriedades p\u00fablicas de getter do objeto de configura\u00e7\u00e3o public string MyProperty { get ; private set ; } public Configuration ( IConfigurationReader reader ) { this . configReader = reader ; } public void Initialize () { var configContents = configReader . Read (); // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Select ( l => l . Split ( '=' )) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } } Acima, foi usada uma t\u00e9cnica chamada Inje\u00e7\u00e3o de Construtor . Isso usa o construtor do objeto para definir quais ser\u00e3o nossas depend\u00eancias, o que significa que qualquer objeto que cria o objeto Configuration controlar\u00e1 qual leitor precisa ser passado. Este \u00e9 um exemplo de \"invers\u00e3o de controle\", anteriormente o objeto Configuration controlava a depend\u00eancia, mas em vez disso, empurramos o controle para qualquer componente que cria este objeto. Note que injetamos a interface IConfigurationReader e n\u00e3o a classe concreta. Isso \u00e9 o que nos permite quebrar a depend\u00eancia; enquanto originalmente t\u00ednhamos uma depend\u00eancia codificada na classe File , agora dependemos apenas de um objeto que implementa IConfigurationReader . Escrevendo nossos primeiros testes de unidade Come\u00e7amos essa aventura porque temos um erro na classe Configuration que n\u00e3o foi detectado porque n\u00e3o temos testes de unidade. Vamos escrever alguns testes de unidade que nos d\u00e3o cobertura total da classe Configuration , incluindo um teste que testa o cen\u00e1rio descrito pelo erro (se houver v\u00e1rias linhas vazias no arquivo de configura\u00e7\u00e3o, uma exce\u00e7\u00e3o IndexOutOfRangeException est\u00e1 sendo lan\u00e7ada). No entanto, ainda temos um problema, temos apenas uma \u00fanica implementa\u00e7\u00e3o de IConfigurationReader , e ela usa o sistema de arquivos, o que significa que qualquer teste de unidade que escrevermos ainda ter\u00e1 uma depend\u00eancia no sistema de arquivos! Felizmente, como usamos a inje\u00e7\u00e3o de depend\u00eancia, tudo o que precisamos fazer \u00e9 criar uma implementa\u00e7\u00e3o de IConfigurationReader que n\u00e3o dependa do sistema de arquivos. Poder\u00edamos criar um mock aqui, mas em vez disso, vamos criar uma implementa\u00e7\u00e3o concreta da interface que simplesmente retorna a matriz de strings passada podemos cham\u00e1-la de PassThroughConfigurationReader (para mais detalhes sobre por que essa abordagem pode ser melhor do que a cria\u00e7\u00e3o de mocks, consulte a p\u00e1gina sobre mocking ) public class PassThroughConfigurationReader : IConfigurationReader { private readonly string [] contents ; public PassThroughConfigurationReader ( string [] contents ) { this . contents = contents ; } public string [] Read () { return this . contents ; } } Esta simples classe ser\u00e1 usada em nossos testes de unidade, para que possamos criar diferentes estados sem exigir muito acesso ao arquivo. Agora que temos isso no lugar, podemos prosseguir e escrever nossos testes de unidade, come\u00e7ando com os testes que descrevem o comportamento atual: public class ConfigurationTests { [Fact] public void Initialize_EmptyConfig_Throws () { var reader = new PassThroughConfigurationReader ( Array . Empty < string > ()); var config = new Configuration ( reader ); Assert . Throws < KeyNotFoundException > (() => config . Initialize ()); } [Fact] public void Initialize_CorrectFormat_SetsProperty () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myvalue\" }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myvalue\" , config . MyProperty ); } } Corrigindo o erro Todos os nossos testes atuais passam e nos d\u00e3o 100% de cobertura, no entanto, como evidenciado pelo erro, devemos n\u00e3o estar cobrindo todas as entradas e sa\u00eddas poss\u00edveis. No caso do erro, v\u00e1rias linhas vazias causariam um problema. Al\u00e9m disso, KeyNotFoundException n\u00e3o \u00e9 uma exce\u00e7\u00e3o muito amig\u00e1vel e \u00e9 um detalhe de implementa\u00e7\u00e3o, n\u00e3o algo que faz sentido ao projetar a API de Configura\u00e7\u00e3o. Vamos adicionar mais alguns testes e alinhar os testes com o que pensamos que a classe Configuration deve se comportar: public class ConfigurationTests { [Fact] public void Initialize_EmptyConfig_Throws () { var reader = new PassThroughConfigurationReader ( Array . Empty < string > ()); var config = new Configuration ( reader ); Assert . Throws < InvalidOperationException > (() => config . Initialize ()); } [Fact] public void Initialize_MalformedLine_Throws () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty\" , }); var config = new Configuration ( reader ); Assert . Throws < InvalidOperationException > (() => config . Initialize ()); } [Fact] public void Initialize_MultipleEqualSigns_PropertyContainsNoEquals () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myval1=myval2\" , }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myval1=myval2\" , config . MyProperty ); } [Fact] public void Initialize_WithBlankLines_Ignores () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myvalue\" , string . Empty , }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myvalue\" , config . MyProperty ); } [Fact] public void Initialize_CorrectFormat_SetsProperty () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myvalue\" }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myvalue\" , config . MyProperty ); } } Agora temos 4 testes falhando e 1 teste passando, mas estabelecemos firmemente atrav\u00e9s do uso desses testes como esperamos que os chamadores usem a classe Configuration e o que \u00e9 e n\u00e3o \u00e9 permitido como entradas. Agora s\u00f3 precisamos corrigir a classe Configuration para que nossos testes passem: public void Initialize () { var configContents = configReader . Read (); if ( configContents . Length == 0 ) { throw new InvalidOperationException ( \"Configura\u00e7\u00e3o vazia\" ); } // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Where ( l => ! string . IsNullOrWhiteSpace ( l )) . Select ( l => { var splitLine = l . Split ( '=' , 2 ); if ( splitLine . Length < 2 ) { throw new InvalidOperationException ( \"Linha malformada\" ); } return splitLine ; }) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } Agora todos os nossos testes passam! Corrigimos nosso erro, adicionamos testes de unidade \u00e0 classe Configuration e temos muito mais confian\u00e7a em mudan\u00e7as futuras. C\u00f3digo N\u00e3o Test\u00e1vel Como descrito na se\u00e7\u00e3o de abstra\u00e7\u00e3o , nem todo c\u00f3digo pode ser devidamente testado por unidade. Em nosso caso, temos uma \u00fanica classe que tem 0% de cobertura de teste: FileConfigurationReader . Isso \u00e9 esperado; neste caso, mantivemos o FileConfigurationReader o mais leve poss\u00edvel, sem l\u00f3gica adicional al\u00e9m de chamar a depend\u00eancia de terceiros. FileConfigurationReader \u00e9 um exemplo do padr\u00e3o de design de fachada . Design Test\u00e1vel e Melhorias Futuras Um dos nossos problemas originais descritos neste exemplo \u00e9 que, no futuro, esperamos carregar a configura\u00e7\u00e3o a partir de uma API web. Ao fazer todo o trabalho de abstrair a forma como carregamos o texto de configura\u00e7\u00e3o e quebrar a depend\u00eancia no sistema de arquivos, j\u00e1 fizemos todo o trabalho \u00e1rduo para habilitar esse cen\u00e1rio futuro! Tudo o que precisa ser feito a seguir \u00e9 criar uma implementa\u00e7\u00e3o WebApiConfigurationReader e us\u00e1-la para construir o objeto Configuration , e ele deve funcionar. Esse \u00e9 um dos benef\u00edcios do design test\u00e1vel, no processo de escrever nossos testes de forma segura, um efeito colateral disso \u00e9 que j\u00e1 temos nossas depend\u00eancias que podem mudar abstra\u00eddas e exigir\u00e3o mudan\u00e7as m\u00ednimas para implementar. Outro benef\u00edcio adicional \u00e9 que temos v\u00e1rias possibilidades abertas por esse design test\u00e1vel. Por exemplo, agora podemos ter uma configura\u00e7\u00e3o em cascata usando todas as 3 implementa\u00e7\u00f5es IConfigurationReader , incluindo a que escrevemos apenas para nossos testes! Podemos primeiro verificar se o acesso \u00e0 Internet est\u00e1 dispon\u00edvel e, se estiver, usar WebApiConfigurationReader . Se n\u00e3o houver internet dispon\u00edvel, podemos recorrer ao arquivo de configura\u00e7\u00e3o local no sistema atual usando FileConfigurationReader . Se por algum motivo o arquivo de configura\u00e7\u00e3o n\u00e3o existir, podemos usar o `PassThrough ConfigurationReader` para fornecer um conjunto de configura\u00e7\u00f5es padr\u00e3o. Conclus\u00e3o Espero que este exemplo tenha demonstrado como o design test\u00e1vel pode ser ben\u00e9fico para o desenvolvimento de software. N\u00e3o apenas nos d\u00e1 a capacidade de escrever testes de unidade, mas tamb\u00e9m nos d\u00e1 a capacidade de escrever c\u00f3digo mais modular e flex\u00edvel.","title":"Authoring example"},{"location":"automated-testing/unit-testing/authoring_example/#exemplo-criando-um-teste-de-unidade","text":"Para ilustrar algumas t\u00e9cnicas de teste de unidade para uma linguagem orientada a objetos, vamos come\u00e7ar com um exemplo de algum c\u00f3digo para o qual desejamos adicionar testes de unidade. Neste exemplo, temos uma classe de configura\u00e7\u00e3o que cont\u00e9m todas as op\u00e7\u00f5es de inicializa\u00e7\u00e3o para um aplicativo que estamos desenvolvendo. Normalmente, ela l\u00ea de um arquivo .config , mas estamos enfrentando tr\u00eas problemas com a implementa\u00e7\u00e3o atual: H\u00e1 um erro na classe Configuration, e n\u00e3o temos testes de unidade, pois ela depende da leitura de um arquivo de configura\u00e7\u00e3o. N\u00e3o podemos testar nenhuma parte do c\u00f3digo que depende da classe Configuration lendo um arquivo de configura\u00e7\u00e3o. No futuro, queremos permitir que a configura\u00e7\u00e3o seja salva na nuvem e acessada via API REST. O erro que estamos tentando corrigir \u00e9 que, se houver v\u00e1rias linhas vazias no arquivo de configura\u00e7\u00e3o, uma exce\u00e7\u00e3o IndexOutOfRangeException \u00e9 lan\u00e7ada. Nossa classe atualmente se parece com isto: using System.IO ; using System.Linq ; public class Configuration { // Propriedades p\u00fablicas de getter do objeto de configura\u00e7\u00e3o public string MyProperty { get ; private set ; } public void Initialize () { var configContents = File . ReadAllLines ( \".config\" ); // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Select ( l => l . Split ( '=' )) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } }","title":"Exemplo: Criando um teste de unidade"},{"location":"automated-testing/unit-testing/authoring_example/#abstracao","text":"Em nosso exemplo, temos uma \u00fanica depend\u00eancia: o sistema de arquivos. Em vez de apenas abstrair completamente o sistema de arquivos, vamos pensar sobre por que precisamos do sistema de arquivos e abstrair o conceito em vez da implementa\u00e7\u00e3o. Neste caso, estamos usando a classe File para ler o arquivo de configura\u00e7\u00e3o e o conte\u00fado da configura\u00e7\u00e3o. O conceito de abstra\u00e7\u00e3o aqui \u00e9 alguma forma de leitor de configura\u00e7\u00e3o que retorna cada linha da configura\u00e7\u00e3o em uma matriz de strings. Poder\u00edamos cham\u00e1-lo de ConfigurationReader , e ele tem um \u00fanico m\u00e9todo, Read , que retorna o conte\u00fado. Ao criar abstra\u00e7\u00f5es, pode ser uma boa pr\u00e1tica criar uma interface para essa abstra\u00e7\u00e3o, em linguagens que a suportam. No exemplo com C#, podemos criar uma interface IConfigurationReader , e em vez de apenas termos uma classe ConfigurationReader , podemos ser mais espec\u00edficos e nome\u00e1-la FileConfigurationReader para indicar que ela l\u00ea do sistema de arquivos: // IConfigurationReader.cs public interface IConfigurationReader { string [] Read (); } // FileConfigurationReader.cs public class FileConfigurationReader : IConfigurationReader { public string [] Read () { return File . ReadAllLines ( \".config\" ); } } Agora que a depend\u00eancia do arquivo foi abstra\u00edda, precisamos atualizar o m\u00e9todo Initialize da nossa classe Configuration para usar a nova abstra\u00e7\u00e3o em vez de chamar File.ReadAllLines diretamente: public void Initialize () { var configContents = new FileConfigurationReader (). Read (); // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Select ( l => l . Split ( '=' )) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } Como voc\u00ea pode ver, ainda temos uma depend\u00eancia no sistema de arquivos, mas essa depend\u00eancia foi abstra\u00edda. Precisaremos usar outras t\u00e9cnicas para quebrar completamente a depend\u00eancia.","title":"Abstra\u00e7\u00e3o"},{"location":"automated-testing/unit-testing/authoring_example/#injecao-de-dependencia","text":"Na se\u00e7\u00e3o anterior, abstra\u00edmos o acesso ao arquivo em um FileConfigurationReader , mas ainda t\u00ednhamos uma depend\u00eancia no sistema de arquivos em nossa fun\u00e7\u00e3o. Podemos usar a inje\u00e7\u00e3o de depend\u00eancia para injetar o leitor certo em nossa classe Configuration : using System.IO ; using System.Linq ; public class Configuration { private readonly IConfigurationReader configReader ; // Propriedades p\u00fablicas de getter do objeto de configura\u00e7\u00e3o public string MyProperty { get ; private set ; } public Configuration ( IConfigurationReader reader ) { this . configReader = reader ; } public void Initialize () { var configContents = configReader . Read (); // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Select ( l => l . Split ( '=' )) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } } Acima, foi usada uma t\u00e9cnica chamada Inje\u00e7\u00e3o de Construtor . Isso usa o construtor do objeto para definir quais ser\u00e3o nossas depend\u00eancias, o que significa que qualquer objeto que cria o objeto Configuration controlar\u00e1 qual leitor precisa ser passado. Este \u00e9 um exemplo de \"invers\u00e3o de controle\", anteriormente o objeto Configuration controlava a depend\u00eancia, mas em vez disso, empurramos o controle para qualquer componente que cria este objeto. Note que injetamos a interface IConfigurationReader e n\u00e3o a classe concreta. Isso \u00e9 o que nos permite quebrar a depend\u00eancia; enquanto originalmente t\u00ednhamos uma depend\u00eancia codificada na classe File , agora dependemos apenas de um objeto que implementa IConfigurationReader .","title":"Inje\u00e7\u00e3o de Depend\u00eancia"},{"location":"automated-testing/unit-testing/authoring_example/#escrevendo-nossos-primeiros-testes-de-unidade","text":"Come\u00e7amos essa aventura porque temos um erro na classe Configuration que n\u00e3o foi detectado porque n\u00e3o temos testes de unidade. Vamos escrever alguns testes de unidade que nos d\u00e3o cobertura total da classe Configuration , incluindo um teste que testa o cen\u00e1rio descrito pelo erro (se houver v\u00e1rias linhas vazias no arquivo de configura\u00e7\u00e3o, uma exce\u00e7\u00e3o IndexOutOfRangeException est\u00e1 sendo lan\u00e7ada). No entanto, ainda temos um problema, temos apenas uma \u00fanica implementa\u00e7\u00e3o de IConfigurationReader , e ela usa o sistema de arquivos, o que significa que qualquer teste de unidade que escrevermos ainda ter\u00e1 uma depend\u00eancia no sistema de arquivos! Felizmente, como usamos a inje\u00e7\u00e3o de depend\u00eancia, tudo o que precisamos fazer \u00e9 criar uma implementa\u00e7\u00e3o de IConfigurationReader que n\u00e3o dependa do sistema de arquivos. Poder\u00edamos criar um mock aqui, mas em vez disso, vamos criar uma implementa\u00e7\u00e3o concreta da interface que simplesmente retorna a matriz de strings passada podemos cham\u00e1-la de PassThroughConfigurationReader (para mais detalhes sobre por que essa abordagem pode ser melhor do que a cria\u00e7\u00e3o de mocks, consulte a p\u00e1gina sobre mocking ) public class PassThroughConfigurationReader : IConfigurationReader { private readonly string [] contents ; public PassThroughConfigurationReader ( string [] contents ) { this . contents = contents ; } public string [] Read () { return this . contents ; } } Esta simples classe ser\u00e1 usada em nossos testes de unidade, para que possamos criar diferentes estados sem exigir muito acesso ao arquivo. Agora que temos isso no lugar, podemos prosseguir e escrever nossos testes de unidade, come\u00e7ando com os testes que descrevem o comportamento atual: public class ConfigurationTests { [Fact] public void Initialize_EmptyConfig_Throws () { var reader = new PassThroughConfigurationReader ( Array . Empty < string > ()); var config = new Configuration ( reader ); Assert . Throws < KeyNotFoundException > (() => config . Initialize ()); } [Fact] public void Initialize_CorrectFormat_SetsProperty () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myvalue\" }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myvalue\" , config . MyProperty ); } }","title":"Escrevendo nossos primeiros testes de unidade"},{"location":"automated-testing/unit-testing/authoring_example/#corrigindo-o-erro","text":"Todos os nossos testes atuais passam e nos d\u00e3o 100% de cobertura, no entanto, como evidenciado pelo erro, devemos n\u00e3o estar cobrindo todas as entradas e sa\u00eddas poss\u00edveis. No caso do erro, v\u00e1rias linhas vazias causariam um problema. Al\u00e9m disso, KeyNotFoundException n\u00e3o \u00e9 uma exce\u00e7\u00e3o muito amig\u00e1vel e \u00e9 um detalhe de implementa\u00e7\u00e3o, n\u00e3o algo que faz sentido ao projetar a API de Configura\u00e7\u00e3o. Vamos adicionar mais alguns testes e alinhar os testes com o que pensamos que a classe Configuration deve se comportar: public class ConfigurationTests { [Fact] public void Initialize_EmptyConfig_Throws () { var reader = new PassThroughConfigurationReader ( Array . Empty < string > ()); var config = new Configuration ( reader ); Assert . Throws < InvalidOperationException > (() => config . Initialize ()); } [Fact] public void Initialize_MalformedLine_Throws () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty\" , }); var config = new Configuration ( reader ); Assert . Throws < InvalidOperationException > (() => config . Initialize ()); } [Fact] public void Initialize_MultipleEqualSigns_PropertyContainsNoEquals () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myval1=myval2\" , }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myval1=myval2\" , config . MyProperty ); } [Fact] public void Initialize_WithBlankLines_Ignores () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myvalue\" , string . Empty , }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myvalue\" , config . MyProperty ); } [Fact] public void Initialize_CorrectFormat_SetsProperty () { var reader = new PassThroughConfigurationReader ( new [] { \"myproperty=myvalue\" }); var config = new Configuration ( reader ); config . Initialize (); Assert . Equal ( \"myvalue\" , config . MyProperty ); } } Agora temos 4 testes falhando e 1 teste passando, mas estabelecemos firmemente atrav\u00e9s do uso desses testes como esperamos que os chamadores usem a classe Configuration e o que \u00e9 e n\u00e3o \u00e9 permitido como entradas. Agora s\u00f3 precisamos corrigir a classe Configuration para que nossos testes passem: public void Initialize () { var configContents = configReader . Read (); if ( configContents . Length == 0 ) { throw new InvalidOperationException ( \"Configura\u00e7\u00e3o vazia\" ); } // A configura\u00e7\u00e3o est\u00e1 no formato: chave=valor var config = configContents . Where ( l => ! string . IsNullOrWhiteSpace ( l )) . Select ( l => { var splitLine = l . Split ( '=' , 2 ); if ( splitLine . Length < 2 ) { throw new InvalidOperationException ( \"Linha malformada\" ); } return splitLine ; }) . ToDictionary ( kv => kv [ 0 ], kv => kv [ 1 ]); // Atribuir todas as propriedades aqui this . MyProperty = config [ \"myproperty\" ]; } Agora todos os nossos testes passam! Corrigimos nosso erro, adicionamos testes de unidade \u00e0 classe Configuration e temos muito mais confian\u00e7a em mudan\u00e7as futuras.","title":"Corrigindo o erro"},{"location":"automated-testing/unit-testing/authoring_example/#codigo-nao-testavel","text":"Como descrito na se\u00e7\u00e3o de abstra\u00e7\u00e3o , nem todo c\u00f3digo pode ser devidamente testado por unidade. Em nosso caso, temos uma \u00fanica classe que tem 0% de cobertura de teste: FileConfigurationReader . Isso \u00e9 esperado; neste caso, mantivemos o FileConfigurationReader o mais leve poss\u00edvel, sem l\u00f3gica adicional al\u00e9m de chamar a depend\u00eancia de terceiros. FileConfigurationReader \u00e9 um exemplo do padr\u00e3o de design de fachada .","title":"C\u00f3digo N\u00e3o Test\u00e1vel"},{"location":"automated-testing/unit-testing/authoring_example/#design-testavel-e-melhorias-futuras","text":"Um dos nossos problemas originais descritos neste exemplo \u00e9 que, no futuro, esperamos carregar a configura\u00e7\u00e3o a partir de uma API web. Ao fazer todo o trabalho de abstrair a forma como carregamos o texto de configura\u00e7\u00e3o e quebrar a depend\u00eancia no sistema de arquivos, j\u00e1 fizemos todo o trabalho \u00e1rduo para habilitar esse cen\u00e1rio futuro! Tudo o que precisa ser feito a seguir \u00e9 criar uma implementa\u00e7\u00e3o WebApiConfigurationReader e us\u00e1-la para construir o objeto Configuration , e ele deve funcionar. Esse \u00e9 um dos benef\u00edcios do design test\u00e1vel, no processo de escrever nossos testes de forma segura, um efeito colateral disso \u00e9 que j\u00e1 temos nossas depend\u00eancias que podem mudar abstra\u00eddas e exigir\u00e3o mudan\u00e7as m\u00ednimas para implementar. Outro benef\u00edcio adicional \u00e9 que temos v\u00e1rias possibilidades abertas por esse design test\u00e1vel. Por exemplo, agora podemos ter uma configura\u00e7\u00e3o em cascata usando todas as 3 implementa\u00e7\u00f5es IConfigurationReader , incluindo a que escrevemos apenas para nossos testes! Podemos primeiro verificar se o acesso \u00e0 Internet est\u00e1 dispon\u00edvel e, se estiver, usar WebApiConfigurationReader . Se n\u00e3o houver internet dispon\u00edvel, podemos recorrer ao arquivo de configura\u00e7\u00e3o local no sistema atual usando FileConfigurationReader . Se por algum motivo o arquivo de configura\u00e7\u00e3o n\u00e3o existir, podemos usar o `PassThrough ConfigurationReader` para fornecer um conjunto de configura\u00e7\u00f5es padr\u00e3o.","title":"Design Test\u00e1vel e Melhorias Futuras"},{"location":"automated-testing/unit-testing/authoring_example/#conclusao","text":"Espero que este exemplo tenha demonstrado como o design test\u00e1vel pode ser ben\u00e9fico para o desenvolvimento de software. N\u00e3o apenas nos d\u00e1 a capacidade de escrever testes de unidade, mas tamb\u00e9m nos d\u00e1 a capacidade de escrever c\u00f3digo mais modular e flex\u00edvel.","title":"Conclus\u00e3o"},{"location":"automated-testing/unit-testing/custom-connector/","text":"Teste de Conector Personalizado Ao desenvolver Conectores Personalizados para inserir dados na Power Platform, existem algumas estrat\u00e9gias que voc\u00ea pode seguir: Teste de Unidade H\u00e1 v\u00e1rias verifica\u00e7\u00f5es que podem ser feitas durante o desenvolvimento de conectores personalizados para ter certeza de que o c\u00f3digo est\u00e1 funcionando corretamente. Existem duas principais: Validar o esquema OpenAPI no qual o conector \u00e9 definido. Validar se o esquema tamb\u00e9m possui todas as informa\u00e7\u00f5es necess\u00e1rias para o processo de conector certificado. (o \u00faltimo \u00e9 opcional, mas necess\u00e1rio caso voc\u00ea queira public\u00e1-lo como um conector certificado). Existem v\u00e1rias ferramentas para ajudar a validar o esquema OpenAPI, uma lista delas est\u00e1 dispon\u00edvel neste link . Uma ferramenta sugerida seria o swagger-cli . Por outro lado, para validar se o conector personalizado que voc\u00ea est\u00e1 construindo est\u00e1 correto para se tornar um conector certificado, use o paconn-cli , uma vez que ele possui um comando de valida\u00e7\u00e3o que mostra informa\u00e7\u00f5es ausentes na defini\u00e7\u00e3o do conector personalizado.","title":"Teste de Conector Personalizado"},{"location":"automated-testing/unit-testing/custom-connector/#teste-de-conector-personalizado","text":"Ao desenvolver Conectores Personalizados para inserir dados na Power Platform, existem algumas estrat\u00e9gias que voc\u00ea pode seguir:","title":"Teste de Conector Personalizado"},{"location":"automated-testing/unit-testing/custom-connector/#teste-de-unidade","text":"H\u00e1 v\u00e1rias verifica\u00e7\u00f5es que podem ser feitas durante o desenvolvimento de conectores personalizados para ter certeza de que o c\u00f3digo est\u00e1 funcionando corretamente. Existem duas principais: Validar o esquema OpenAPI no qual o conector \u00e9 definido. Validar se o esquema tamb\u00e9m possui todas as informa\u00e7\u00f5es necess\u00e1rias para o processo de conector certificado. (o \u00faltimo \u00e9 opcional, mas necess\u00e1rio caso voc\u00ea queira public\u00e1-lo como um conector certificado). Existem v\u00e1rias ferramentas para ajudar a validar o esquema OpenAPI, uma lista delas est\u00e1 dispon\u00edvel neste link . Uma ferramenta sugerida seria o swagger-cli . Por outro lado, para validar se o conector personalizado que voc\u00ea est\u00e1 construindo est\u00e1 correto para se tornar um conector certificado, use o paconn-cli , uma vez que ele possui um comando de valida\u00e7\u00e3o que mostra informa\u00e7\u00f5es ausentes na defini\u00e7\u00e3o do conector personalizado.","title":"Teste de Unidade"},{"location":"automated-testing/unit-testing/mocking/","text":"Simula\u00e7\u00e3o em Testes de Unidade Um dos componentes-chave para escrever testes de unidade \u00e9 remover as depend\u00eancias que seu sistema possui e substitu\u00ed-las por uma implementa\u00e7\u00e3o que voc\u00ea controla. O m\u00e9todo mais comum que as pessoas usam como substituto para a depend\u00eancia \u00e9 um mock, e existem frameworks de simula\u00e7\u00e3o para tornar esse processo mais f\u00e1cil. Muitos frameworks e artigos usam diferentes significados para as diferen\u00e7as entre test doubles. Um test double \u00e9 um termo gen\u00e9rico para qualquer objeto \"fingido\" usado no lugar de um real. Este termo, bem como outros usados nesta p\u00e1gina, s\u00e3o as defini\u00e7\u00f5es fornecidas por Martin Fowler . A forma mais comumente usada de test double s\u00e3o os Mocks, mas h\u00e1 muitos casos em que Mocks talvez n\u00e3o sejam a melhor escolha e Fakes devem ser considerados em vez disso. Stubs Stub permite que voc\u00ea tenha um comportamento predeterminado que substitui o comportamento real. A depend\u00eancia (classe abstrata ou interface) \u00e9 implementada como um stub com uma l\u00f3gica conforme esperado pelo cliente. Stubs podem ser \u00fateis quando os clientes dos stubs esperam o mesmo conjunto de respostas, por exemplo, voc\u00ea usa um servi\u00e7o de terceiros. O conceito-chave aqui \u00e9 que os stubs nunca devem falhar em um teste de unidade ou integra\u00e7\u00e3o onde um mock pode falhar. Stubs n\u00e3o requerem nenhum tipo de framework para serem executados, mas geralmente s\u00e3o suportados por frameworks de simula\u00e7\u00e3o para construir rapidamente os stubs. Stubs s\u00e3o comumente usados em combina\u00e7\u00e3o com frameworks ou bibliotecas de inje\u00e7\u00e3o de depend\u00eancia, onde o objeto real \u00e9 substitu\u00eddo por uma implementa\u00e7\u00e3o de stub. Stubs podem ser especialmente \u00fateis durante o desenvolvimento inicial de um sistema, mas como quase todo teste requer seus pr\u00f3prios stubs (para testar os diferentes estados), isso rapidamente se torna repetitivo e envolve muito c\u00f3digo boilerplate. Raramente voc\u00ea encontrar\u00e1 um c\u00f3digo-fonte que usa apenas stubs para simula\u00e7\u00e3o, eles geralmente s\u00e3o emparelhados com outros test doubles. Vantagens N\u00e3o requerem nenhum framework, f\u00e1cil de configurar. Desvantagens Pode envolver a reescrita do mesmo c\u00f3digo muitas vezes, muito c\u00f3digo boilerplate. Mocks Fowler descreve mocks como objetos pr\u00e9-programados com expectativas que formam uma especifica\u00e7\u00e3o das chamadas que se espera receber. Em outras palavras, mocks s\u00e3o um objeto de substitui\u00e7\u00e3o para a depend\u00eancia que tem certas expectativas que s\u00e3o colocadas nele; essas expectativas podem ser coisas como validar que um subm\u00e9todo foi chamado um determinado n\u00famero de vezes ou que argumentos s\u00e3o passados de uma determinada maneira. Frameworks de simula\u00e7\u00e3o s\u00e3o abundantes para cada linguagem, com algumas linguagens tendo mocks incorporados nos pacotes de teste de unidade. Eles tornam a escrita de testes de unidade f\u00e1cil e ainda incentivam boas pr\u00e1ticas de teste de unidade. A principal diferen\u00e7a entre um mock e a maioria dos outros test doubles \u00e9 que mocks fazem verifica\u00e7\u00e3o comportamental , enquanto outros test doubles fazem verifica\u00e7\u00e3o de estado . Com a verifica\u00e7\u00e3o comportamental, voc\u00ea acaba testando que a implementa\u00e7\u00e3o do sistema sob teste \u00e9 como voc\u00ea espera, enquanto com a verifica\u00e7\u00e3o de estado a implementa\u00e7\u00e3o n\u00e3o \u00e9 testada, apenas as entradas e sa\u00eddas para o sistema s\u00e3o validadas. A maior desvantagem da verifica\u00e7\u00e3o comportamental \u00e9 que ela est\u00e1 atrelada \u00e0 implementa\u00e7\u00e3o. Uma das maiores vantagens de escrever testes de unidade \u00e9 que, quando voc\u00ea faz altera\u00e7\u00f5es no c\u00f3digo, tem confian\u00e7a de que, se seus testes de unidade continuarem a passar, voc\u00ea est\u00e1 fazendo uma mudan\u00e7a relativamente segura. Se os testes precisam ser atualizados toda vez porque o comportamento do m\u00e9todo mudou, ent\u00e3o voc\u00ea perde essa confian\u00e7a porque bugs tamb\u00e9m podem ser introduzidos no c\u00f3digo do teste. Isso tamb\u00e9m aumenta o tempo de desenvolvimento e pode ser uma fonte de frustra\u00e7\u00e3o. Vantagens da Simula\u00e7\u00e3o F\u00e1cil de escrever. Incentiva o design test\u00e1vel. Desvantagens da Simula\u00e7\u00e3o Testes comportamentais podem apresentar problemas com a manutenibilidade no c\u00f3digo do teste de unidade. Geralmente requer um framework para ser instalado (ou, se nenhum framework, muito c\u00f3digo boilerplate) Fakes Objetos Fake realmente t\u00eam implementa\u00e7\u00f5es funcionais, mas geralmente usam algum atalho que pode torn\u00e1-los inadequados para produ\u00e7\u00e3o. Um dos exemplos comuns de uso de um Fake \u00e9 um banco de dados em mem\u00f3ria - normalmente voc\u00ea quer que seu banco de dados seja capaz de salvar dados em algum lugar entre as execu\u00e7\u00f5es do aplicativo, mas ao escrever testes de unidade, se voc\u00ea tem uma implementa\u00e7\u00e3o fake de suas APIs de banco de dados que armazenam todos os dados na mem\u00f3ria, voc\u00ea pode usar esses para testes de unidade e n\u00e3o quebrar a abstra\u00e7\u00e3o, bem como ainda manter seus testes r\u00e1pidos. Escrever um fake leva mais tempo do que outros test doubles, porque eles s\u00e3o implementa\u00e7\u00f5es completas e podem ter seu pr\u00f3prio conjunto de testes de unidade. Nesse sentido, por\u00e9m, eles aumentam a confian\u00e7a em seu c\u00f3digo ainda mais porque seu test double foi minuciosamente testado para bugs antes de voc\u00ea mesmo us\u00e1-lo como uma depend\u00eancia downstream. Vantagens dos Fakes Nenhum framework necess\u00e1rio, \u00e9 como qualquer outra implementa\u00e7\u00e3o. Incentiva o design test\u00e1vel. O c\u00f3digo pode ser \"promovido\" para o c\u00f3digo do produto, ent\u00e3o n\u00e3o \u00e9 um esfor\u00e7o desperdi\u00e7ado. Desvantagens dos Fakes Leva mais tempo para implementar. Melhores Pr\u00e1ticas Para manter sua simula\u00e7\u00e3o eficiente, considere essas melhores pr\u00e1ticas para tornar seu c\u00f3digo test\u00e1vel, economizar tempo e tornar suas asser\u00e7\u00f5es de teste mais significativas. Inje\u00e7\u00e3o de Depend\u00eancia Se voc\u00ea n\u00e3o mantiver a testabilidade em mente desde o in\u00edcio, uma vez que voc\u00ea come\u00e7ar a escrever seus testes, poder\u00e1 perceber que precisa fazer uma refatora\u00e7\u00e3o demorada para tornar o c\u00f3digo test\u00e1vel em unidade. Um problema comum que pode levar a c\u00f3digo n\u00e3o test\u00e1vel em certas linguagens, como C#, \u00e9 n\u00e3o usar inje\u00e7\u00e3o de depend\u00eancia. Considere usar inje\u00e7\u00e3o de depend\u00eancia para que um mock possa ser facilmente injetado em seu Subject Under Test (SUT) durante um teste de unidade. Conclus\u00e3o Usar test doubles em testes de unidade \u00e9 uma parte essencial de ter um conjunto de testes saud\u00e1vel. Ao olhar para frameworks de simula\u00e7\u00e3o e usar test doubles, \u00e9 importante considerar as implica\u00e7\u00f5es futuras de integrar com um framework de simula\u00e7\u00e3o desde o in\u00edcio. \u00c0s vezes, certos recursos de frameworks de simula\u00e7\u00e3o parecem essenciais, mas geralmente isso \u00e9 um sinal de que o c\u00f3digo em si n\u00e3o \u00e9 abstrato o suficiente se requer um framework. Se poss\u00edvel, come\u00e7ar sem um framework de simula\u00e7\u00e3o e tentar criar implementa\u00e7\u00f5es fake levar\u00e1 a uma base de c\u00f3digo mais saud\u00e1vel, mas quando isso n\u00e3o for poss\u00edvel, a responsabilidade est\u00e1 nos l\u00edderes t\u00e9cnicos da equipe para encontrar casos em que mocks podem ser excessivamente usados, depender muito de detalhes de implementa\u00e7\u00e3o ou acabar n\u00e3o testando as coisas certas.","title":"Simula\u00e7\u00e3o em Testes de Unidade"},{"location":"automated-testing/unit-testing/mocking/#simulacao-em-testes-de-unidade","text":"Um dos componentes-chave para escrever testes de unidade \u00e9 remover as depend\u00eancias que seu sistema possui e substitu\u00ed-las por uma implementa\u00e7\u00e3o que voc\u00ea controla. O m\u00e9todo mais comum que as pessoas usam como substituto para a depend\u00eancia \u00e9 um mock, e existem frameworks de simula\u00e7\u00e3o para tornar esse processo mais f\u00e1cil. Muitos frameworks e artigos usam diferentes significados para as diferen\u00e7as entre test doubles. Um test double \u00e9 um termo gen\u00e9rico para qualquer objeto \"fingido\" usado no lugar de um real. Este termo, bem como outros usados nesta p\u00e1gina, s\u00e3o as defini\u00e7\u00f5es fornecidas por Martin Fowler . A forma mais comumente usada de test double s\u00e3o os Mocks, mas h\u00e1 muitos casos em que Mocks talvez n\u00e3o sejam a melhor escolha e Fakes devem ser considerados em vez disso.","title":"Simula\u00e7\u00e3o em Testes de Unidade"},{"location":"automated-testing/unit-testing/mocking/#stubs","text":"Stub permite que voc\u00ea tenha um comportamento predeterminado que substitui o comportamento real. A depend\u00eancia (classe abstrata ou interface) \u00e9 implementada como um stub com uma l\u00f3gica conforme esperado pelo cliente. Stubs podem ser \u00fateis quando os clientes dos stubs esperam o mesmo conjunto de respostas, por exemplo, voc\u00ea usa um servi\u00e7o de terceiros. O conceito-chave aqui \u00e9 que os stubs nunca devem falhar em um teste de unidade ou integra\u00e7\u00e3o onde um mock pode falhar. Stubs n\u00e3o requerem nenhum tipo de framework para serem executados, mas geralmente s\u00e3o suportados por frameworks de simula\u00e7\u00e3o para construir rapidamente os stubs. Stubs s\u00e3o comumente usados em combina\u00e7\u00e3o com frameworks ou bibliotecas de inje\u00e7\u00e3o de depend\u00eancia, onde o objeto real \u00e9 substitu\u00eddo por uma implementa\u00e7\u00e3o de stub. Stubs podem ser especialmente \u00fateis durante o desenvolvimento inicial de um sistema, mas como quase todo teste requer seus pr\u00f3prios stubs (para testar os diferentes estados), isso rapidamente se torna repetitivo e envolve muito c\u00f3digo boilerplate. Raramente voc\u00ea encontrar\u00e1 um c\u00f3digo-fonte que usa apenas stubs para simula\u00e7\u00e3o, eles geralmente s\u00e3o emparelhados com outros test doubles.","title":"Stubs"},{"location":"automated-testing/unit-testing/mocking/#vantagens","text":"N\u00e3o requerem nenhum framework, f\u00e1cil de configurar.","title":"Vantagens"},{"location":"automated-testing/unit-testing/mocking/#desvantagens","text":"Pode envolver a reescrita do mesmo c\u00f3digo muitas vezes, muito c\u00f3digo boilerplate.","title":"Desvantagens"},{"location":"automated-testing/unit-testing/mocking/#mocks","text":"Fowler descreve mocks como objetos pr\u00e9-programados com expectativas que formam uma especifica\u00e7\u00e3o das chamadas que se espera receber. Em outras palavras, mocks s\u00e3o um objeto de substitui\u00e7\u00e3o para a depend\u00eancia que tem certas expectativas que s\u00e3o colocadas nele; essas expectativas podem ser coisas como validar que um subm\u00e9todo foi chamado um determinado n\u00famero de vezes ou que argumentos s\u00e3o passados de uma determinada maneira. Frameworks de simula\u00e7\u00e3o s\u00e3o abundantes para cada linguagem, com algumas linguagens tendo mocks incorporados nos pacotes de teste de unidade. Eles tornam a escrita de testes de unidade f\u00e1cil e ainda incentivam boas pr\u00e1ticas de teste de unidade. A principal diferen\u00e7a entre um mock e a maioria dos outros test doubles \u00e9 que mocks fazem verifica\u00e7\u00e3o comportamental , enquanto outros test doubles fazem verifica\u00e7\u00e3o de estado . Com a verifica\u00e7\u00e3o comportamental, voc\u00ea acaba testando que a implementa\u00e7\u00e3o do sistema sob teste \u00e9 como voc\u00ea espera, enquanto com a verifica\u00e7\u00e3o de estado a implementa\u00e7\u00e3o n\u00e3o \u00e9 testada, apenas as entradas e sa\u00eddas para o sistema s\u00e3o validadas. A maior desvantagem da verifica\u00e7\u00e3o comportamental \u00e9 que ela est\u00e1 atrelada \u00e0 implementa\u00e7\u00e3o. Uma das maiores vantagens de escrever testes de unidade \u00e9 que, quando voc\u00ea faz altera\u00e7\u00f5es no c\u00f3digo, tem confian\u00e7a de que, se seus testes de unidade continuarem a passar, voc\u00ea est\u00e1 fazendo uma mudan\u00e7a relativamente segura. Se os testes precisam ser atualizados toda vez porque o comportamento do m\u00e9todo mudou, ent\u00e3o voc\u00ea perde essa confian\u00e7a porque bugs tamb\u00e9m podem ser introduzidos no c\u00f3digo do teste. Isso tamb\u00e9m aumenta o tempo de desenvolvimento e pode ser uma fonte de frustra\u00e7\u00e3o.","title":"Mocks"},{"location":"automated-testing/unit-testing/mocking/#vantagens-da-simulacao","text":"F\u00e1cil de escrever. Incentiva o design test\u00e1vel.","title":"Vantagens da Simula\u00e7\u00e3o"},{"location":"automated-testing/unit-testing/mocking/#desvantagens-da-simulacao","text":"Testes comportamentais podem apresentar problemas com a manutenibilidade no c\u00f3digo do teste de unidade. Geralmente requer um framework para ser instalado (ou, se nenhum framework, muito c\u00f3digo boilerplate)","title":"Desvantagens da Simula\u00e7\u00e3o"},{"location":"automated-testing/unit-testing/mocking/#fakes","text":"Objetos Fake realmente t\u00eam implementa\u00e7\u00f5es funcionais, mas geralmente usam algum atalho que pode torn\u00e1-los inadequados para produ\u00e7\u00e3o. Um dos exemplos comuns de uso de um Fake \u00e9 um banco de dados em mem\u00f3ria - normalmente voc\u00ea quer que seu banco de dados seja capaz de salvar dados em algum lugar entre as execu\u00e7\u00f5es do aplicativo, mas ao escrever testes de unidade, se voc\u00ea tem uma implementa\u00e7\u00e3o fake de suas APIs de banco de dados que armazenam todos os dados na mem\u00f3ria, voc\u00ea pode usar esses para testes de unidade e n\u00e3o quebrar a abstra\u00e7\u00e3o, bem como ainda manter seus testes r\u00e1pidos. Escrever um fake leva mais tempo do que outros test doubles, porque eles s\u00e3o implementa\u00e7\u00f5es completas e podem ter seu pr\u00f3prio conjunto de testes de unidade. Nesse sentido, por\u00e9m, eles aumentam a confian\u00e7a em seu c\u00f3digo ainda mais porque seu test double foi minuciosamente testado para bugs antes de voc\u00ea mesmo us\u00e1-lo como uma depend\u00eancia downstream.","title":"Fakes"},{"location":"automated-testing/unit-testing/mocking/#vantagens-dos-fakes","text":"Nenhum framework necess\u00e1rio, \u00e9 como qualquer outra implementa\u00e7\u00e3o. Incentiva o design test\u00e1vel. O c\u00f3digo pode ser \"promovido\" para o c\u00f3digo do produto, ent\u00e3o n\u00e3o \u00e9 um esfor\u00e7o desperdi\u00e7ado.","title":"Vantagens dos Fakes"},{"location":"automated-testing/unit-testing/mocking/#desvantagens-dos-fakes","text":"Leva mais tempo para implementar.","title":"Desvantagens dos Fakes"},{"location":"automated-testing/unit-testing/mocking/#melhores-praticas","text":"Para manter sua simula\u00e7\u00e3o eficiente, considere essas melhores pr\u00e1ticas para tornar seu c\u00f3digo test\u00e1vel, economizar tempo e tornar suas asser\u00e7\u00f5es de teste mais significativas.","title":"Melhores Pr\u00e1ticas"},{"location":"automated-testing/unit-testing/mocking/#injecao-de-dependencia","text":"Se voc\u00ea n\u00e3o mantiver a testabilidade em mente desde o in\u00edcio, uma vez que voc\u00ea come\u00e7ar a escrever seus testes, poder\u00e1 perceber que precisa fazer uma refatora\u00e7\u00e3o demorada para tornar o c\u00f3digo test\u00e1vel em unidade. Um problema comum que pode levar a c\u00f3digo n\u00e3o test\u00e1vel em certas linguagens, como C#, \u00e9 n\u00e3o usar inje\u00e7\u00e3o de depend\u00eancia. Considere usar inje\u00e7\u00e3o de depend\u00eancia para que um mock possa ser facilmente injetado em seu Subject Under Test (SUT) durante um teste de unidade.","title":"Inje\u00e7\u00e3o de Depend\u00eancia"},{"location":"automated-testing/unit-testing/mocking/#conclusao","text":"Usar test doubles em testes de unidade \u00e9 uma parte essencial de ter um conjunto de testes saud\u00e1vel. Ao olhar para frameworks de simula\u00e7\u00e3o e usar test doubles, \u00e9 importante considerar as implica\u00e7\u00f5es futuras de integrar com um framework de simula\u00e7\u00e3o desde o in\u00edcio. \u00c0s vezes, certos recursos de frameworks de simula\u00e7\u00e3o parecem essenciais, mas geralmente isso \u00e9 um sinal de que o c\u00f3digo em si n\u00e3o \u00e9 abstrato o suficiente se requer um framework. Se poss\u00edvel, come\u00e7ar sem um framework de simula\u00e7\u00e3o e tentar criar implementa\u00e7\u00f5es fake levar\u00e1 a uma base de c\u00f3digo mais saud\u00e1vel, mas quando isso n\u00e3o for poss\u00edvel, a responsabilidade est\u00e1 nos l\u00edderes t\u00e9cnicos da equipe para encontrar casos em que mocks podem ser excessivamente usados, depender muito de detalhes de implementa\u00e7\u00e3o ou acabar n\u00e3o testando as coisas certas.","title":"Conclus\u00e3o"},{"location":"automated-testing/unit-testing/tdd_example/","text":"Exemplo de Desenvolvimento Orientado por Testes (TDD) Com este m\u00e9todo, em vez de escrever todos os seus testes de uma vez, voc\u00ea escreve um teste de cada vez e, em seguida, muda para escrever o c\u00f3digo do sistema que faria esse teste passar. \u00c9 importante escrever o m\u00ednimo de c\u00f3digo necess\u00e1rio, mesmo que ele n\u00e3o seja tecnicamente \"correto\". Uma vez que o teste passa, voc\u00ea pode refatorar o c\u00f3digo para talvez torn\u00e1-lo mais sensato, mas novamente a l\u00f3gica deve ser simples. \u00c0 medida que voc\u00ea escreve mais testes, a l\u00f3gica fica cada vez mais complexa, mas voc\u00ea pode continuar a fazer as mudan\u00e7as m\u00ednimas no c\u00f3digo do sistema com confian\u00e7a, porque todo o c\u00f3digo que foi escrito est\u00e1 coberto. Como exemplo, vamos supor que estamos tentando escrever uma nova fun\u00e7\u00e3o que valida se uma string \u00e9 um formato de senha v\u00e1lido. O formato da senha deve ser uma string maior que 8 caracteres contendo pelo menos um n\u00famero. Come\u00e7amos com o teste mais simples poss\u00edvel; uma das maneiras mais f\u00e1ceis de fazer isso \u00e9 escrever primeiro testes que validem as entradas na fun\u00e7\u00e3o: // Tests.cs public class Tests { [Fact] public void ValidatePassword_NullInput_Throws () { var s = new MyClass (); Assert . Throws < ArgumentNullException > (() => s . ValidatePassword ( null )); } } // MyClass.cs public class MyClass { public bool ValidatePassword ( string input ) { return false ; } } Se executarmos este c\u00f3digo, o teste falhar\u00e1, pois nenhuma exce\u00e7\u00e3o foi lan\u00e7ada, j\u00e1 que nosso c\u00f3digo em ValidateString \u00e9 apenas um stub. Isso est\u00e1 ok! Esta \u00e9 a parte \"Vermelha\" do ciclo Vermelho-Verde-Refatorar. Agora queremos passar para a parte \"Verde\" - fazer a mudan\u00e7a m\u00ednima necess\u00e1ria para fazer este teste passar: // MyClass.cs public class MyClass { public bool ValidatePassword ( string input ) { throw new ArgumentNullException ( nameof ( input )); } } Nossos testes passam, mas esta fun\u00e7\u00e3o realmente n\u00e3o funciona, ela sempre lan\u00e7ar\u00e1 a exce\u00e7\u00e3o. Tudo bem! \u00c0 medida que continuamos a escrever testes, vamos adicionando lentamente a l\u00f3gica para esta fun\u00e7\u00e3o, e ela se construir\u00e1 sobre si mesma, garantindo que nossos testes continuem a passar. Vamos pular a etapa \"Refatorar\" neste momento porque n\u00e3o h\u00e1 nada para refatorar. Em seguida, vamos adicionar um teste que verifica se a fun\u00e7\u00e3o retorna falso se a senha tiver menos de 8 caracteres: [Fact] public void ValidatePassword_SmallSize_ReturnsFalse () { var s = new MyClass (); Assert . False ( s . ValidatePassword ( \"abc\" )); } Este teste passar\u00e1, pois ainda s\u00f3 lan\u00e7a uma ArgumentNullException , mas novamente, isso \u00e9 uma falha esperada. Corrigindo nossa fun\u00e7\u00e3o, ela dever\u00e1 passar: public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } return false ; } Finalmente, algum c\u00f3digo que parece real! Note como n\u00e3o foi o teste que verificou o valor nulo que nos fez adicionar a instru\u00e7\u00e3o if para a verifica\u00e7\u00e3o de nulo, mas sim o teste subsequente que desbloqueou um novo ramo. Ao adicionar essa instru\u00e7\u00e3o if , fizemos a mudan\u00e7a m\u00ednima necess\u00e1ria para fazer ambos os testes passarem, mas ainda temos trabalho a fazer. Em geral, trabalhar na ordem de adicionar um teste negativo primeiro antes de adicionar um teste positivo garantir\u00e1 que ambos os casos sejam cobertos pelo c\u00f3digo de uma forma que possa ser testada. O ciclo Vermelho-Verde-Refatorar torna esse processo super f\u00e1cil, exigindo a mudan\u00e7a m\u00ednima - j\u00e1 que s\u00f3 queremos fazer as mudan\u00e7as m\u00ednimas, simplesmente retornamos falso aqui, sabendo muito bem que estaremos adicionando l\u00f3gica mais tarde que se expandir\u00e1 sobre isso. Falando nisso, vamos adicionar o teste positivo agora: [Fact] public void ValidatePassword_RightSize_ReturnsTrue () { var s = new MyClass (); Assert . True ( s . ValidatePassword ( \"abcdefgh1\" )); } Novamente, este teste falhar\u00e1 no in\u00edcio. Uma coisa a notar aqui \u00e9 que \u00e9 importante tentarmos tornar nossos testes resilientes a mudan\u00e7as futuras. Quando escrevemos o c\u00f3digo sob teste, agimos de forma muito ing\u00eanua, apenas tentando fazer os testes atuais que temos passar; quando voc\u00ea escreve testes, voc\u00ea quer garantir que tudo o que est\u00e1 fazendo \u00e9 um caso v\u00e1lido no futuro. Neste caso, poder\u00edamos ter escrito a string de entrada como abcdefgh e, quando eventualmente escrev\u00eassemos a fun\u00e7\u00e3o, ela passaria, mas mais tarde, quando adicion\u00e1ssemos testes que validassem que a fun\u00e7\u00e3o tem o resto das entradas adequadas, ela falharia incorretamente. De qualquer forma, a pr\u00f3xima mudan\u00e7a de c\u00f3digo \u00e9: public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if ( input . Length > 8 ) { return true ; } return false ; } Aqui agora temos um teste que passa! No entanto, a l\u00f3gica realmente n\u00e3o faz muito sentido. Fizemos a mudan\u00e7a m\u00ednima, que foi adicionar uma nova condi\u00e7\u00e3o que passou para strings mais longas, mas pensando para frente, sabemos que isso n\u00e3o funcionar\u00e1 assim que adicionarmos valida\u00e7\u00f5es adicionais. Ent\u00e3o, vamos usar nosso primeiro passo de \"Refatorar\" no fluxo Vermelho-Verde-Refatorar! public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if ( input . Length < 8 ) { return false ; } return true ; } Isso parece melhor. Note como, do ponto de vista funcional, inverter a instru\u00e7\u00e3o if n\u00e3o muda o que a fun\u00e7\u00e3o retorna. Esta \u00e9 uma parte importante do fluxo de refatora\u00e7\u00e3o, mantendo a l\u00f3gica fazendo refatora\u00e7\u00f5es comprovadamente seguras, geralmente atrav\u00e9s do uso de ferramentas e refatora\u00e7\u00f5es automatizadas do seu IDE. Finalmente, temos um \u00faltimo requisito para o nosso m\u00e9todo ValidatePassword e \u00e9 que ele precisa verificar se h\u00e1 um n\u00famero na senha. Vamos come\u00e7ar novamente com o teste negativo e validar que, com uma string com o comprimento v\u00e1lido, a fun\u00e7\u00e3o retorna false se n\u00e3o passarmos um n\u00famero: [Fact] public void ValidatePassword_ValidLength_ReturnsFalse () { var s = new MyClass (); Assert . False ( s . ValidatePassword ( \"abcdefghij\" )); } Claro que o teste falha, pois ele est\u00e1 apenas verificando os requisitos de comprimento. Vamos corrigir o m\u00e9todo para verificar os n\u00fameros: public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if ( input . Length < 8 ) { return false ; } if ( ! input . Any ( char . IsDigit )) { return false ; } return true ; } Aqui usamos um m\u00e9todo LINQ \u00fatil para verificar se algum dos char s na string \u00e9 um d\u00edgito, e se n\u00e3o for, retornamos falso. Os testes agora passam, e podemos refatorar. Para melhorar a legibilidade, por que n\u00e3o combinar as instru\u00e7\u00f5es if : public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if (( input . Length < 8 ) || ( ! input . Any ( char . IsDigit ))) { return false ; } return true ; } Ao refatorar esse c\u00f3digo, nos sentimos 100% confiantes nas mudan\u00e7as que fizemos, pois temos 100% de cobertura de testes que testam tanto cen\u00e1rios positivos quanto negativos. Neste caso, j\u00e1 temos um m\u00e9todo que testa o caso positivo, ent\u00e3o nossa fun\u00e7\u00e3o est\u00e1 pronta! Agora que nosso c\u00f3digo est\u00e1 completamente testado, podemos fazer todo tipo de mudan\u00e7as e ainda ter confian\u00e7a de que ele funciona. Por exemplo, se quis\u00e9ssemos mudar a implementa\u00e7\u00e3o do m\u00e9todo para usar regex, todos os nossos testes ainda passariam e ainda seriam v\u00e1lidos. \u00c9 isso a\u00ed! Terminamos de escrever nossa fun\u00e7\u00e3o, temos 100% de cobertura de testes e, se tiv\u00e9ssemos feito algo um pouco mais complexo, ter\u00edamos a garantia de que o que projetamos j\u00e1 \u00e9 test\u00e1vel, pois os testes foram escritos primeiro!","title":"Exemplo de Desenvolvimento Orientado por Testes (TDD)"},{"location":"automated-testing/unit-testing/tdd_example/#exemplo-de-desenvolvimento-orientado-por-testes-tdd","text":"Com este m\u00e9todo, em vez de escrever todos os seus testes de uma vez, voc\u00ea escreve um teste de cada vez e, em seguida, muda para escrever o c\u00f3digo do sistema que faria esse teste passar. \u00c9 importante escrever o m\u00ednimo de c\u00f3digo necess\u00e1rio, mesmo que ele n\u00e3o seja tecnicamente \"correto\". Uma vez que o teste passa, voc\u00ea pode refatorar o c\u00f3digo para talvez torn\u00e1-lo mais sensato, mas novamente a l\u00f3gica deve ser simples. \u00c0 medida que voc\u00ea escreve mais testes, a l\u00f3gica fica cada vez mais complexa, mas voc\u00ea pode continuar a fazer as mudan\u00e7as m\u00ednimas no c\u00f3digo do sistema com confian\u00e7a, porque todo o c\u00f3digo que foi escrito est\u00e1 coberto. Como exemplo, vamos supor que estamos tentando escrever uma nova fun\u00e7\u00e3o que valida se uma string \u00e9 um formato de senha v\u00e1lido. O formato da senha deve ser uma string maior que 8 caracteres contendo pelo menos um n\u00famero. Come\u00e7amos com o teste mais simples poss\u00edvel; uma das maneiras mais f\u00e1ceis de fazer isso \u00e9 escrever primeiro testes que validem as entradas na fun\u00e7\u00e3o: // Tests.cs public class Tests { [Fact] public void ValidatePassword_NullInput_Throws () { var s = new MyClass (); Assert . Throws < ArgumentNullException > (() => s . ValidatePassword ( null )); } } // MyClass.cs public class MyClass { public bool ValidatePassword ( string input ) { return false ; } } Se executarmos este c\u00f3digo, o teste falhar\u00e1, pois nenhuma exce\u00e7\u00e3o foi lan\u00e7ada, j\u00e1 que nosso c\u00f3digo em ValidateString \u00e9 apenas um stub. Isso est\u00e1 ok! Esta \u00e9 a parte \"Vermelha\" do ciclo Vermelho-Verde-Refatorar. Agora queremos passar para a parte \"Verde\" - fazer a mudan\u00e7a m\u00ednima necess\u00e1ria para fazer este teste passar: // MyClass.cs public class MyClass { public bool ValidatePassword ( string input ) { throw new ArgumentNullException ( nameof ( input )); } } Nossos testes passam, mas esta fun\u00e7\u00e3o realmente n\u00e3o funciona, ela sempre lan\u00e7ar\u00e1 a exce\u00e7\u00e3o. Tudo bem! \u00c0 medida que continuamos a escrever testes, vamos adicionando lentamente a l\u00f3gica para esta fun\u00e7\u00e3o, e ela se construir\u00e1 sobre si mesma, garantindo que nossos testes continuem a passar. Vamos pular a etapa \"Refatorar\" neste momento porque n\u00e3o h\u00e1 nada para refatorar. Em seguida, vamos adicionar um teste que verifica se a fun\u00e7\u00e3o retorna falso se a senha tiver menos de 8 caracteres: [Fact] public void ValidatePassword_SmallSize_ReturnsFalse () { var s = new MyClass (); Assert . False ( s . ValidatePassword ( \"abc\" )); } Este teste passar\u00e1, pois ainda s\u00f3 lan\u00e7a uma ArgumentNullException , mas novamente, isso \u00e9 uma falha esperada. Corrigindo nossa fun\u00e7\u00e3o, ela dever\u00e1 passar: public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } return false ; } Finalmente, algum c\u00f3digo que parece real! Note como n\u00e3o foi o teste que verificou o valor nulo que nos fez adicionar a instru\u00e7\u00e3o if para a verifica\u00e7\u00e3o de nulo, mas sim o teste subsequente que desbloqueou um novo ramo. Ao adicionar essa instru\u00e7\u00e3o if , fizemos a mudan\u00e7a m\u00ednima necess\u00e1ria para fazer ambos os testes passarem, mas ainda temos trabalho a fazer. Em geral, trabalhar na ordem de adicionar um teste negativo primeiro antes de adicionar um teste positivo garantir\u00e1 que ambos os casos sejam cobertos pelo c\u00f3digo de uma forma que possa ser testada. O ciclo Vermelho-Verde-Refatorar torna esse processo super f\u00e1cil, exigindo a mudan\u00e7a m\u00ednima - j\u00e1 que s\u00f3 queremos fazer as mudan\u00e7as m\u00ednimas, simplesmente retornamos falso aqui, sabendo muito bem que estaremos adicionando l\u00f3gica mais tarde que se expandir\u00e1 sobre isso. Falando nisso, vamos adicionar o teste positivo agora: [Fact] public void ValidatePassword_RightSize_ReturnsTrue () { var s = new MyClass (); Assert . True ( s . ValidatePassword ( \"abcdefgh1\" )); } Novamente, este teste falhar\u00e1 no in\u00edcio. Uma coisa a notar aqui \u00e9 que \u00e9 importante tentarmos tornar nossos testes resilientes a mudan\u00e7as futuras. Quando escrevemos o c\u00f3digo sob teste, agimos de forma muito ing\u00eanua, apenas tentando fazer os testes atuais que temos passar; quando voc\u00ea escreve testes, voc\u00ea quer garantir que tudo o que est\u00e1 fazendo \u00e9 um caso v\u00e1lido no futuro. Neste caso, poder\u00edamos ter escrito a string de entrada como abcdefgh e, quando eventualmente escrev\u00eassemos a fun\u00e7\u00e3o, ela passaria, mas mais tarde, quando adicion\u00e1ssemos testes que validassem que a fun\u00e7\u00e3o tem o resto das entradas adequadas, ela falharia incorretamente. De qualquer forma, a pr\u00f3xima mudan\u00e7a de c\u00f3digo \u00e9: public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if ( input . Length > 8 ) { return true ; } return false ; } Aqui agora temos um teste que passa! No entanto, a l\u00f3gica realmente n\u00e3o faz muito sentido. Fizemos a mudan\u00e7a m\u00ednima, que foi adicionar uma nova condi\u00e7\u00e3o que passou para strings mais longas, mas pensando para frente, sabemos que isso n\u00e3o funcionar\u00e1 assim que adicionarmos valida\u00e7\u00f5es adicionais. Ent\u00e3o, vamos usar nosso primeiro passo de \"Refatorar\" no fluxo Vermelho-Verde-Refatorar! public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if ( input . Length < 8 ) { return false ; } return true ; } Isso parece melhor. Note como, do ponto de vista funcional, inverter a instru\u00e7\u00e3o if n\u00e3o muda o que a fun\u00e7\u00e3o retorna. Esta \u00e9 uma parte importante do fluxo de refatora\u00e7\u00e3o, mantendo a l\u00f3gica fazendo refatora\u00e7\u00f5es comprovadamente seguras, geralmente atrav\u00e9s do uso de ferramentas e refatora\u00e7\u00f5es automatizadas do seu IDE. Finalmente, temos um \u00faltimo requisito para o nosso m\u00e9todo ValidatePassword e \u00e9 que ele precisa verificar se h\u00e1 um n\u00famero na senha. Vamos come\u00e7ar novamente com o teste negativo e validar que, com uma string com o comprimento v\u00e1lido, a fun\u00e7\u00e3o retorna false se n\u00e3o passarmos um n\u00famero: [Fact] public void ValidatePassword_ValidLength_ReturnsFalse () { var s = new MyClass (); Assert . False ( s . ValidatePassword ( \"abcdefghij\" )); } Claro que o teste falha, pois ele est\u00e1 apenas verificando os requisitos de comprimento. Vamos corrigir o m\u00e9todo para verificar os n\u00fameros: public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if ( input . Length < 8 ) { return false ; } if ( ! input . Any ( char . IsDigit )) { return false ; } return true ; } Aqui usamos um m\u00e9todo LINQ \u00fatil para verificar se algum dos char s na string \u00e9 um d\u00edgito, e se n\u00e3o for, retornamos falso. Os testes agora passam, e podemos refatorar. Para melhorar a legibilidade, por que n\u00e3o combinar as instru\u00e7\u00f5es if : public bool ValidatePassword ( string input ) { if ( input == null ) { throw new ArgumentNullException ( nameof ( input )); } if (( input . Length < 8 ) || ( ! input . Any ( char . IsDigit ))) { return false ; } return true ; } Ao refatorar esse c\u00f3digo, nos sentimos 100% confiantes nas mudan\u00e7as que fizemos, pois temos 100% de cobertura de testes que testam tanto cen\u00e1rios positivos quanto negativos. Neste caso, j\u00e1 temos um m\u00e9todo que testa o caso positivo, ent\u00e3o nossa fun\u00e7\u00e3o est\u00e1 pronta! Agora que nosso c\u00f3digo est\u00e1 completamente testado, podemos fazer todo tipo de mudan\u00e7as e ainda ter confian\u00e7a de que ele funciona. Por exemplo, se quis\u00e9ssemos mudar a implementa\u00e7\u00e3o do m\u00e9todo para usar regex, todos os nossos testes ainda passariam e ainda seriam v\u00e1lidos. \u00c9 isso a\u00ed! Terminamos de escrever nossa fun\u00e7\u00e3o, temos 100% de cobertura de testes e, se tiv\u00e9ssemos feito algo um pouco mais complexo, ter\u00edamos a garantia de que o que projetamos j\u00e1 \u00e9 test\u00e1vel, pois os testes foram escritos primeiro!","title":"Exemplo de Desenvolvimento Orientado por Testes (TDD)"},{"location":"automated-testing/unit-testing/why-unit-tests/","text":"Por que Testes Unit\u00e1rios N\u00e3o \u00e9 segredo que escrever testes unit\u00e1rios \u00e9 dif\u00edcil e ainda mais dif\u00edcil escrev\u00ea-los bem. Escrever testes unit\u00e1rios tamb\u00e9m aumenta o tempo de desenvolvimento para cada funcionalidade. Ent\u00e3o, por que dever\u00edamos nos dar ao trabalho de escrev\u00ea-los? Reduzir Custos N\u00e3o h\u00e1 d\u00favida de que quanto mais tarde um bug \u00e9 encontrado, mais caro \u00e9 para corrigi-lo; especialmente se o bug chegar \u00e0 produ\u00e7\u00e3o. Um estudo de pesquisa de 2008 da IBM estima que um bug capturado em produ\u00e7\u00e3o pode custar 6 vezes mais do que se fosse capturado durante a implementa\u00e7\u00e3o. Aumentar a Confian\u00e7a do Desenvolvedor Muitas mudan\u00e7as que os desenvolvedores fazem n\u00e3o s\u00e3o grandes funcionalidades ou algo que requer uma su\u00edte de testes inteira. Uma su\u00edte de testes unit\u00e1rios robusta ajuda a aumentar a confian\u00e7a do desenvolvedor de que sua mudan\u00e7a n\u00e3o causar\u00e1 bugs a jusante. Ter testes unit\u00e1rios tamb\u00e9m ajuda a fazer refatora\u00e7\u00f5es seguras e mec\u00e2nicas que s\u00e3o comprovadamente seguras; usando coisas como ferramentas de refatora\u00e7\u00e3o para fazer refatora\u00e7\u00e3o mec\u00e2nica e executar testes unit\u00e1rios que cobrem o c\u00f3digo refatorado deve ser suficiente para aumentar a confian\u00e7a no commit. Acelerar o Desenvolvimento Testes unit\u00e1rios levam tempo para escrever, mas tamb\u00e9m aceleram o desenvolvimento? Embora isso possa parecer um paradoxo, \u00e9 uma das for\u00e7as de uma su\u00edte de testes unit\u00e1rios - com o tempo ela continua a crescer e evoluir at\u00e9 que os testes se tornem uma parte essencial do fluxo de trabalho do desenvolvedor. Se o \u00fanico teste dispon\u00edvel para um desenvolvedor \u00e9 um teste de sistema de longa dura\u00e7\u00e3o, testes de integra\u00e7\u00e3o que requerem uma implanta\u00e7\u00e3o ou testes manuais, isso aumentar\u00e1 a quantidade de tempo necess\u00e1ria para escrever uma funcionalidade. Esses tipos de testes devem fazer parte do \"Loop Externo\"; testes que podem levar algum tempo para serem executados e validar mais do que apenas o c\u00f3digo que voc\u00ea est\u00e1 escrevendo. Geralmente, esses tipos de testes de loop externo s\u00e3o executados na etapa de PR ou at\u00e9 mesmo mais tarde durante as mesclagens em branches. O Loop Interno do Desenvolvedor \u00e9 o processo pelo qual os desenvolvedores passam enquanto est\u00e3o escrevendo c\u00f3digo. Isso varia de desenvolvedor para desenvolvedor e de linguagem para linguagem, mas normalmente \u00e9 algo como c\u00f3digo -> construir -> executar -> repetir. Quando testes unit\u00e1rios s\u00e3o inseridos no loop interno, os desenvolvedores podem obter feedback e resultados antecipados do c\u00f3digo que est\u00e3o escrevendo. Como os testes unit\u00e1rios s\u00e3o executados muito rapidamente, executar testes n\u00e3o deve ser visto como uma barreira de entrada para este loop. Ferramentas como Visual Studio Live Unit Testing tamb\u00e9m ajudam a encurtar ainda mais o loop interno. Documenta\u00e7\u00e3o como C\u00f3digo Escrever testes unit\u00e1rios \u00e9 uma \u00f3tima maneira de mostrar como as unidades de c\u00f3digo que voc\u00ea est\u00e1 escrevendo devem ser usadas. De certa forma, os testes unit\u00e1rios s\u00e3o melhores do que qualquer documenta\u00e7\u00e3o ou amostras porque eles s\u00e3o (ou pelo menos deveriam ser) executados a cada constru\u00e7\u00e3o, ent\u00e3o h\u00e1 confian\u00e7a de que eles n\u00e3o est\u00e3o desatualizados. Testes unit\u00e1rios tamb\u00e9m devem ser t\u00e3o simples que sejam f\u00e1ceis de seguir.","title":"Por que Testes Unit\u00e1rios"},{"location":"automated-testing/unit-testing/why-unit-tests/#por-que-testes-unitarios","text":"N\u00e3o \u00e9 segredo que escrever testes unit\u00e1rios \u00e9 dif\u00edcil e ainda mais dif\u00edcil escrev\u00ea-los bem. Escrever testes unit\u00e1rios tamb\u00e9m aumenta o tempo de desenvolvimento para cada funcionalidade. Ent\u00e3o, por que dever\u00edamos nos dar ao trabalho de escrev\u00ea-los?","title":"Por que Testes Unit\u00e1rios"},{"location":"automated-testing/unit-testing/why-unit-tests/#reduzir-custos","text":"N\u00e3o h\u00e1 d\u00favida de que quanto mais tarde um bug \u00e9 encontrado, mais caro \u00e9 para corrigi-lo; especialmente se o bug chegar \u00e0 produ\u00e7\u00e3o. Um estudo de pesquisa de 2008 da IBM estima que um bug capturado em produ\u00e7\u00e3o pode custar 6 vezes mais do que se fosse capturado durante a implementa\u00e7\u00e3o.","title":"Reduzir Custos"},{"location":"automated-testing/unit-testing/why-unit-tests/#aumentar-a-confianca-do-desenvolvedor","text":"Muitas mudan\u00e7as que os desenvolvedores fazem n\u00e3o s\u00e3o grandes funcionalidades ou algo que requer uma su\u00edte de testes inteira. Uma su\u00edte de testes unit\u00e1rios robusta ajuda a aumentar a confian\u00e7a do desenvolvedor de que sua mudan\u00e7a n\u00e3o causar\u00e1 bugs a jusante. Ter testes unit\u00e1rios tamb\u00e9m ajuda a fazer refatora\u00e7\u00f5es seguras e mec\u00e2nicas que s\u00e3o comprovadamente seguras; usando coisas como ferramentas de refatora\u00e7\u00e3o para fazer refatora\u00e7\u00e3o mec\u00e2nica e executar testes unit\u00e1rios que cobrem o c\u00f3digo refatorado deve ser suficiente para aumentar a confian\u00e7a no commit.","title":"Aumentar a Confian\u00e7a do Desenvolvedor"},{"location":"automated-testing/unit-testing/why-unit-tests/#acelerar-o-desenvolvimento","text":"Testes unit\u00e1rios levam tempo para escrever, mas tamb\u00e9m aceleram o desenvolvimento? Embora isso possa parecer um paradoxo, \u00e9 uma das for\u00e7as de uma su\u00edte de testes unit\u00e1rios - com o tempo ela continua a crescer e evoluir at\u00e9 que os testes se tornem uma parte essencial do fluxo de trabalho do desenvolvedor. Se o \u00fanico teste dispon\u00edvel para um desenvolvedor \u00e9 um teste de sistema de longa dura\u00e7\u00e3o, testes de integra\u00e7\u00e3o que requerem uma implanta\u00e7\u00e3o ou testes manuais, isso aumentar\u00e1 a quantidade de tempo necess\u00e1ria para escrever uma funcionalidade. Esses tipos de testes devem fazer parte do \"Loop Externo\"; testes que podem levar algum tempo para serem executados e validar mais do que apenas o c\u00f3digo que voc\u00ea est\u00e1 escrevendo. Geralmente, esses tipos de testes de loop externo s\u00e3o executados na etapa de PR ou at\u00e9 mesmo mais tarde durante as mesclagens em branches. O Loop Interno do Desenvolvedor \u00e9 o processo pelo qual os desenvolvedores passam enquanto est\u00e3o escrevendo c\u00f3digo. Isso varia de desenvolvedor para desenvolvedor e de linguagem para linguagem, mas normalmente \u00e9 algo como c\u00f3digo -> construir -> executar -> repetir. Quando testes unit\u00e1rios s\u00e3o inseridos no loop interno, os desenvolvedores podem obter feedback e resultados antecipados do c\u00f3digo que est\u00e3o escrevendo. Como os testes unit\u00e1rios s\u00e3o executados muito rapidamente, executar testes n\u00e3o deve ser visto como uma barreira de entrada para este loop. Ferramentas como Visual Studio Live Unit Testing tamb\u00e9m ajudam a encurtar ainda mais o loop interno.","title":"Acelerar o Desenvolvimento"},{"location":"automated-testing/unit-testing/why-unit-tests/#documentacao-como-codigo","text":"Escrever testes unit\u00e1rios \u00e9 uma \u00f3tima maneira de mostrar como as unidades de c\u00f3digo que voc\u00ea est\u00e1 escrevendo devem ser usadas. De certa forma, os testes unit\u00e1rios s\u00e3o melhores do que qualquer documenta\u00e7\u00e3o ou amostras porque eles s\u00e3o (ou pelo menos deveriam ser) executados a cada constru\u00e7\u00e3o, ent\u00e3o h\u00e1 confian\u00e7a de que eles n\u00e3o est\u00e3o desatualizados. Testes unit\u00e1rios tamb\u00e9m devem ser t\u00e3o simples que sejam f\u00e1ceis de seguir.","title":"Documenta\u00e7\u00e3o como C\u00f3digo"},{"location":"code-reviews/","text":"Revis\u00f5es de C\u00f3digo Desenvolvedores trabalhando em projetos devem realizar revis\u00f5es de c\u00f3digo entre pares em cada pull request (ou check-in em um branch compartilhado). Objetivos A revis\u00e3o de c\u00f3digo \u00e9 uma forma de ter uma conversa sobre o c\u00f3digo onde os participantes ir\u00e3o: Melhorar a qualidade do c\u00f3digo identificando e removendo defeitos antes que eles possam ser introduzidos em branches de c\u00f3digo compartilhados. Aprender e crescer ao ter outras pessoas revisando o c\u00f3digo, somos expostos a padr\u00f5es de design ou linguagens desconhecidas, entre outros t\u00f3picos, e at\u00e9 mesmo quebramos alguns maus h\u00e1bitos. Entendimento compartilhado entre os desenvolvedores sobre o c\u00f3digo do projeto. Recursos Ferramentas de revis\u00e3o de c\u00f3digo Documenta\u00e7\u00e3o de Pr\u00e1ticas de Engenharia do Google: Como fazer uma revis\u00e3o de c\u00f3digo Segredos Melhor Guardados da Revis\u00e3o de C\u00f3digo entre Pares","title":"Revis\u00f5es de C\u00f3digo"},{"location":"code-reviews/#revisoes-de-codigo","text":"Desenvolvedores trabalhando em projetos devem realizar revis\u00f5es de c\u00f3digo entre pares em cada pull request (ou check-in em um branch compartilhado).","title":"Revis\u00f5es de C\u00f3digo"},{"location":"code-reviews/#objetivos","text":"A revis\u00e3o de c\u00f3digo \u00e9 uma forma de ter uma conversa sobre o c\u00f3digo onde os participantes ir\u00e3o: Melhorar a qualidade do c\u00f3digo identificando e removendo defeitos antes que eles possam ser introduzidos em branches de c\u00f3digo compartilhados. Aprender e crescer ao ter outras pessoas revisando o c\u00f3digo, somos expostos a padr\u00f5es de design ou linguagens desconhecidas, entre outros t\u00f3picos, e at\u00e9 mesmo quebramos alguns maus h\u00e1bitos. Entendimento compartilhado entre os desenvolvedores sobre o c\u00f3digo do projeto.","title":"Objetivos"},{"location":"code-reviews/#recursos","text":"Ferramentas de revis\u00e3o de c\u00f3digo Documenta\u00e7\u00e3o de Pr\u00e1ticas de Engenharia do Google: Como fazer uma revis\u00e3o de c\u00f3digo Segredos Melhor Guardados da Revis\u00e3o de C\u00f3digo entre Pares","title":"Recursos"},{"location":"code-reviews/faq/","text":"Perguntas Frequentes (FAQ) Esta \u00e9 uma lista de perguntas / problemas frequentemente encontrados ao trabalhar com revis\u00f5es de c\u00f3digo e respostas sobre como voc\u00ea pode possivelmente abord\u00e1-los. O que torna uma revis\u00e3o de c\u00f3digo diferente de um PR? Um pull request (PR) \u00e9 uma forma de notificar que uma tarefa est\u00e1 conclu\u00edda e pronta para ser mesclada no branch principal de trabalho (fonte da verdade). Uma revis\u00e3o de c\u00f3digo \u00e9 ter algu\u00e9m examinando o c\u00f3digo em um PR e validando-o antes de ser mesclado, mas, em geral, revis\u00f5es de c\u00f3digo tamb\u00e9m podem ocorrer fora dos PRs. Revis\u00e3o de C\u00f3digo Pull Request Focado no c\u00f3digo-fonte Destinado a aprimorar e habilitar revis\u00f5es de c\u00f3digo. Inclui tanto o c\u00f3digo-fonte quanto pode ter um escopo mais amplo (por exemplo, documenta\u00e7\u00e3o, testes de integra\u00e7\u00e3o, compila\u00e7\u00f5es) Destinado para feedback antecipado antes de enviar um PR N\u00e3o destinado para feedback antecipado . Criado quando o autor est\u00e1 pronto para mesclar Geralmente uma revis\u00e3o s\u00edncrona com ciclos de feedback mais r\u00e1pidos (PRs em rascunho como exce\u00e7\u00e3o). Exemplos: reuni\u00f5es agendadas, revis\u00e3o presencial, programa\u00e7\u00e3o em pares Geralmente uma revis\u00e3o ass\u00edncrona auxiliada por ferramentas, mas pode ser elevada para uma reuni\u00e3o s\u00edncrona quando necess\u00e1rio Por que precisamos de revis\u00f5es de c\u00f3digo? Nossas revis\u00f5es de c\u00f3digo entre pares s\u00e3o estruturadas em torno das melhores pr\u00e1ticas, para encontrar tipos espec\u00edficos de erros. Assim como voc\u00ea ainda executaria um linter em c\u00f3digo mobado, voc\u00ea ainda pediria a algu\u00e9m para fazer a \u00faltima verifica\u00e7\u00e3o para garantir que o c\u00f3digo esteja em conformidade com os padr\u00f5es esperados e evite armadilhas comuns. Os PRs s\u00e3o muito grandes, como podemos corrigir isso? Certifique-se de dimensionar os itens de trabalho em peda\u00e7os pequenos e claros, para que a pessoa revisora possa entender o c\u00f3digo por conta pr\u00f3pria. A equipe \u00e9 instru\u00edda a fazer commits antecipadamente, antes que o item completo do backlog do produto / hist\u00f3ria do usu\u00e1rio esteja completo, mas sim quando um item individual est\u00e1 conclu\u00eddo. Se o trabalho resultaria em um recurso incompleto, certifique-se de que ele possa ser desativado at\u00e9 que o recurso completo seja entregue. Mais informa\u00e7\u00f5es podem ser encontradas em Pull Requests - Orienta\u00e7\u00f5es de Tamanho . Como podemos acelerar as revis\u00f5es de c\u00f3digo? Revis\u00f5es de c\u00f3digo lentas podem causar atrasos na entrega de recursos e causar frustra\u00e7\u00e3o entre os membros da equipe. A\u00e7\u00f5es poss\u00edveis que voc\u00ea pode tomar Adicione uma regra para o tempo de resposta do PR ao seu acordo de trabalho. Reserve um espa\u00e7o ap\u00f3s o standup para analisar os PRs pendentes e atribuir aqueles que est\u00e3o inativos. Dedique um gerente de revis\u00e3o de PR que ser\u00e1 respons\u00e1vel por manter as coisas fluindo, atribuindo ou notificando pessoas quando o PR ficou obsoleto. Use ferramentas para indicar melhor revis\u00f5es obsoletas - Personalizar ADO - Quadros de Tarefas . Quais ferramentas posso usar para revisar um PR complexo? Consulte a se\u00e7\u00e3o Ferramentas para obter ajuda sobre como realizar revis\u00f5es fora do Visual Studio ou Visual Studio Code. Como podemos impor pol\u00edticas de revis\u00e3o de c\u00f3digo? Ao configurar Pol\u00edticas de Branch , voc\u00ea pode facilmente impor regras de revis\u00f5es de c\u00f3digo. N\u00f3s fazemos programa\u00e7\u00e3o em pares ou em grupo. Como isso deve se refletir em nossas revis\u00f5es de c\u00f3digo? Existem duas formas de realizar uma revis\u00e3o de c\u00f3digo: Par - Algu\u00e9m de fora do par deve realizar a revis\u00e3o de c\u00f3digo. Um dos outros grandes benef\u00edcios das revis\u00f5es de c\u00f3digo \u00e9 disseminar o conhecimento sobre a base de c\u00f3digo para outros membros da equipe que normalmente n\u00e3o trabalham na parte da base de c\u00f3digo em revis\u00e3o. Grupo - Um membro do grupo que passou menos (ou nenhum) tempo no teclado deve realizar a revis\u00e3o de c\u00f3digo.","title":"Perguntas Frequentes (FAQ)"},{"location":"code-reviews/faq/#perguntas-frequentes-faq","text":"Esta \u00e9 uma lista de perguntas / problemas frequentemente encontrados ao trabalhar com revis\u00f5es de c\u00f3digo e respostas sobre como voc\u00ea pode possivelmente abord\u00e1-los.","title":"Perguntas Frequentes (FAQ)"},{"location":"code-reviews/faq/#o-que-torna-uma-revisao-de-codigo-diferente-de-um-pr","text":"Um pull request (PR) \u00e9 uma forma de notificar que uma tarefa est\u00e1 conclu\u00edda e pronta para ser mesclada no branch principal de trabalho (fonte da verdade). Uma revis\u00e3o de c\u00f3digo \u00e9 ter algu\u00e9m examinando o c\u00f3digo em um PR e validando-o antes de ser mesclado, mas, em geral, revis\u00f5es de c\u00f3digo tamb\u00e9m podem ocorrer fora dos PRs. Revis\u00e3o de C\u00f3digo Pull Request Focado no c\u00f3digo-fonte Destinado a aprimorar e habilitar revis\u00f5es de c\u00f3digo. Inclui tanto o c\u00f3digo-fonte quanto pode ter um escopo mais amplo (por exemplo, documenta\u00e7\u00e3o, testes de integra\u00e7\u00e3o, compila\u00e7\u00f5es) Destinado para feedback antecipado antes de enviar um PR N\u00e3o destinado para feedback antecipado . Criado quando o autor est\u00e1 pronto para mesclar Geralmente uma revis\u00e3o s\u00edncrona com ciclos de feedback mais r\u00e1pidos (PRs em rascunho como exce\u00e7\u00e3o). Exemplos: reuni\u00f5es agendadas, revis\u00e3o presencial, programa\u00e7\u00e3o em pares Geralmente uma revis\u00e3o ass\u00edncrona auxiliada por ferramentas, mas pode ser elevada para uma reuni\u00e3o s\u00edncrona quando necess\u00e1rio","title":"O que torna uma revis\u00e3o de c\u00f3digo diferente de um PR?"},{"location":"code-reviews/faq/#por-que-precisamos-de-revisoes-de-codigo","text":"Nossas revis\u00f5es de c\u00f3digo entre pares s\u00e3o estruturadas em torno das melhores pr\u00e1ticas, para encontrar tipos espec\u00edficos de erros. Assim como voc\u00ea ainda executaria um linter em c\u00f3digo mobado, voc\u00ea ainda pediria a algu\u00e9m para fazer a \u00faltima verifica\u00e7\u00e3o para garantir que o c\u00f3digo esteja em conformidade com os padr\u00f5es esperados e evite armadilhas comuns.","title":"Por que precisamos de revis\u00f5es de c\u00f3digo?"},{"location":"code-reviews/faq/#os-prs-sao-muito-grandes-como-podemos-corrigir-isso","text":"Certifique-se de dimensionar os itens de trabalho em peda\u00e7os pequenos e claros, para que a pessoa revisora possa entender o c\u00f3digo por conta pr\u00f3pria. A equipe \u00e9 instru\u00edda a fazer commits antecipadamente, antes que o item completo do backlog do produto / hist\u00f3ria do usu\u00e1rio esteja completo, mas sim quando um item individual est\u00e1 conclu\u00eddo. Se o trabalho resultaria em um recurso incompleto, certifique-se de que ele possa ser desativado at\u00e9 que o recurso completo seja entregue. Mais informa\u00e7\u00f5es podem ser encontradas em Pull Requests - Orienta\u00e7\u00f5es de Tamanho .","title":"Os PRs s\u00e3o muito grandes, como podemos corrigir isso?"},{"location":"code-reviews/faq/#como-podemos-acelerar-as-revisoes-de-codigo","text":"Revis\u00f5es de c\u00f3digo lentas podem causar atrasos na entrega de recursos e causar frustra\u00e7\u00e3o entre os membros da equipe.","title":"Como podemos acelerar as revis\u00f5es de c\u00f3digo?"},{"location":"code-reviews/faq/#acoes-possiveis-que-voce-pode-tomar","text":"Adicione uma regra para o tempo de resposta do PR ao seu acordo de trabalho. Reserve um espa\u00e7o ap\u00f3s o standup para analisar os PRs pendentes e atribuir aqueles que est\u00e3o inativos. Dedique um gerente de revis\u00e3o de PR que ser\u00e1 respons\u00e1vel por manter as coisas fluindo, atribuindo ou notificando pessoas quando o PR ficou obsoleto. Use ferramentas para indicar melhor revis\u00f5es obsoletas - Personalizar ADO - Quadros de Tarefas .","title":"A\u00e7\u00f5es poss\u00edveis que voc\u00ea pode tomar"},{"location":"code-reviews/faq/#quais-ferramentas-posso-usar-para-revisar-um-pr-complexo","text":"Consulte a se\u00e7\u00e3o Ferramentas para obter ajuda sobre como realizar revis\u00f5es fora do Visual Studio ou Visual Studio Code.","title":"Quais ferramentas posso usar para revisar um PR complexo?"},{"location":"code-reviews/faq/#como-podemos-impor-politicas-de-revisao-de-codigo","text":"Ao configurar Pol\u00edticas de Branch , voc\u00ea pode facilmente impor regras de revis\u00f5es de c\u00f3digo.","title":"Como podemos impor pol\u00edticas de revis\u00e3o de c\u00f3digo?"},{"location":"code-reviews/faq/#nos-fazemos-programacao-em-pares-ou-em-grupo-como-isso-deve-se-refletir-em-nossas-revisoes-de-codigo","text":"Existem duas formas de realizar uma revis\u00e3o de c\u00f3digo: Par - Algu\u00e9m de fora do par deve realizar a revis\u00e3o de c\u00f3digo. Um dos outros grandes benef\u00edcios das revis\u00f5es de c\u00f3digo \u00e9 disseminar o conhecimento sobre a base de c\u00f3digo para outros membros da equipe que normalmente n\u00e3o trabalham na parte da base de c\u00f3digo em revis\u00e3o. Grupo - Um membro do grupo que passou menos (ou nenhum) tempo no teclado deve realizar a revis\u00e3o de c\u00f3digo.","title":"N\u00f3s fazemos programa\u00e7\u00e3o em pares ou em grupo. Como isso deve se refletir em nossas revis\u00f5es de c\u00f3digo?"},{"location":"code-reviews/inclusion-in-code-review/","text":"Inclus\u00e3o na Revis\u00e3o de C\u00f3digo A seguir est\u00e3o alguns pontos que enfatizam por que a inclusividade nas revis\u00f5es de c\u00f3digo \u00e9 importante: Revis\u00f5es de c\u00f3digo s\u00e3o uma parte importante do nosso trabalho como profissionais de software. Na ISE, trabalhamos com equipes interculturais de todo o mundo. Como nos comunicamos afeta o moral da equipe. Revis\u00f5es de c\u00f3digo inclusivas acolhem novos desenvolvedores e os tornam confort\u00e1veis com a equipe. Ataques rudes ou pessoais durante revis\u00f5es de c\u00f3digo alienam - as pessoas podem, sem saber, fazer coment\u00e1rios rudes ao revisar pull requests (PRs). Tipos e Exemplos de Comportamento N\u00e3o Inclusivo na Revis\u00e3o de C\u00f3digo Atribui\u00e7\u00f5es de revis\u00e3o injustas. Exemplo: Atribuir a maioria das revis\u00f5es a poucas pessoas e desconsiderar alguns membros da equipe. Intera\u00e7\u00f5es interpessoais negativas. Exemplo: Longas discuss\u00f5es sobre t\u00f3picos subjetivos, como estilo de c\u00f3digo. Tomada de decis\u00e3o tendenciosa. Exemplo: Coment\u00e1rios sobre o desenvolvedor e n\u00e3o sobre o c\u00f3digo. Supor que o c\u00f3digo do desenvolvedor X sempre ser\u00e1 bom e, portanto, n\u00e3o revis\u00e1-lo adequadamente e vice-versa. Exemplos de Revis\u00f5es de C\u00f3digo Inclusivas Qualquer pessoa da equipe deve ser designada para revisar PRs. O revisor deve ser claro sobre o que \u00e9 uma opini\u00e3o, prefer\u00eancia pessoal, melhor pr\u00e1tica ou um fato. Discuss\u00f5es sobre prefer\u00eancias pessoais e opini\u00f5es s\u00e3o na maioria das vezes evit\u00e1veis. Usar linguagem e tom inclusivos nos coment\u00e1rios da revis\u00e3o de c\u00f3digo. Por exemplo, ser sugestivo em vez de prescritivo nos coment\u00e1rios da revis\u00e3o \u00e9 uma boa maneira de passar o ponto de vista. \u00c9 uma boa pr\u00e1tica para o autor de um PR agradecer ao revisor pela revis\u00e3o, quando eles contribu\u00edram para melhorar o c\u00f3digo ou voc\u00ea aprendeu algo novo. Usar o m\u00e9todo sandu\u00edche para recomendar uma mudan\u00e7a de c\u00f3digo para um novo desenvolvedor ou um novo cliente: coloque a sugest\u00e3o entre dois elogios. Por exemplo: \"\u00d3timo trabalho at\u00e9 agora, mas eu recomendaria algumas mudan\u00e7as aqui. A prop\u00f3sito, adorei o uso de XYZ aqui, bom trabalho!\" Diretrizes para o Autor O objetivo \u00e9 escrever um c\u00f3digo que seja f\u00e1cil de ler, revisar e manter. \u00c9 importante garantir que quem estiver olhando para o c\u00f3digo, seja o revisor ou um futuro engenheiro, possa entender as motiva\u00e7\u00f5es e como seu c\u00f3digo atinge seus objetivos. Pedir proativamente ajuda ou feedback direcionado. Responder claramente \u00e0s perguntas feitas pelos revisores. Evitar commits grandes, enviando mudan\u00e7as incrementais. Commits grandes e que cont\u00eam mudan\u00e7as em v\u00e1rios arquivos levar\u00e3o a uma revis\u00e3o injusta do c\u00f3digo. O comportamento tendencioso dos revisores pode surgir ao revisar tais PRs. Por exemplo, um commit grande de um desenvolvedor s\u00eanior pode ser aprovado sem uma revis\u00e3o completa, enquanto um commit grande de um desenvolvedor j\u00fanior pode nunca ser revisado e aprovado. Diretrizes para o Revisor Presuma inten\u00e7\u00f5es positivas do autor. Escreva coment\u00e1rios claros e elaborados. Identifique subjetividade, escolha de codifica\u00e7\u00e3o e melhores pr\u00e1ticas. \u00c9 bom discutir estilo de codifica\u00e7\u00e3o e escolhas de codifica\u00e7\u00e3o subjetivas em algum outro f\u00f3rum e n\u00e3o no PR. Um PR n\u00e3o deve se tornar um terreno para discutir escolhas de codifica\u00e7\u00e3o subjetivas e ter longas discuss\u00f5es sobre isso. Se voc\u00ea n\u00e3o entender o c\u00f3digo adequadamente, evite comentar, por exemplo, \"Este c\u00f3digo \u00e9 incompreens\u00edvel\". \u00c9 melhor ter uma liga\u00e7\u00e3o com o autor e obter um entendimento b\u00e1sico do trabalho deles. Seja sugestivo e n\u00e3o prescritivo. Um revisor deve sugerir mudan\u00e7as e n\u00e3o prescrever mudan\u00e7as, deixe o autor decidir se realmente deseja aceitar as mudan\u00e7as propostas. Cultura e Revis\u00f5es de C\u00f3digo N\u00f3s, na ISE, podemos nos deparar com situa\u00e7\u00f5es em que as revis\u00f5es de c\u00f3digo n\u00e3o s\u00e3o ideais e frequentemente observamos comportamentos de revis\u00e3o de c\u00f3digo n\u00e3o inclusivos. \u00c9 importante estar ciente do fato de que a cultura e o estilo de comunica\u00e7\u00e3o de uma geografia espec\u00edfica tamb\u00e9m influenciam como as pessoas interagem em pull requests. Nesses casos, presumir a inten\u00e7\u00e3o positiva do autor e do revisor \u00e9 um bom ponto de partida para come\u00e7ar a analisar a qualidade das revis\u00f5es de c\u00f3digo. Lidando com o Fen\u00f4meno do Impostor O fen\u00f4meno do impostor \u00e9 um padr\u00e3o psicol\u00f3gico em que um indiv\u00edduo duvida de suas habilidades, talentos ou realiza\u00e7\u00f5es e tem um medo interno persistente de ser exposto como uma \"fraude\" - Wikipedia . Algu\u00e9m que experimenta o fen\u00f4meno do impostor pode achar particularmente estressante enviar c\u00f3digo para revis\u00e3o. \u00c9 importante perceber que todos podem ter contribui\u00e7\u00f5es significativas e n\u00e3o deixar que as fraquezas percebidas impe\u00e7am as contribui\u00e7\u00f5es. Algumas dicas para superar o fen\u00f4meno do impostor para autores: Revise as diretrizes destacadas acima e certifique-se de que sua mudan\u00e7a de c\u00f3digo esteja em conformidade com elas. Pe\u00e7a ajuda a um colega - programe em par com um colega experiente de quem voc\u00ea possa aprender. Algumas dicas para superar o fen\u00f4meno do impostor para revisores: Qualquer pessoa pode ter percep\u00e7\u00f5es valiosas. Um novo par de olhos \u00e9 sempre bem-vindo. Estude a revis\u00e3o at\u00e9 que voc\u00ea a tenha entendido claramente, verifique os casos extremos e procure maneiras de melhor\u00e1-la. Se algo n\u00e3o estiver claro, uma pergunta espec\u00edfica simples deve ser feita. Se voc\u00ea aprendeu algo, sempre pode elogiar o autor. Se poss\u00edvel, fa\u00e7a parceria com algu\u00e9m para revisar o c\u00f3digo, para que voc\u00ea possa estabelecer uma conex\u00e3o pessoal e ter uma discuss\u00e3o mais profunda sobre o c\u00f3digo. Ferramentas A seguir est\u00e3o algumas ferramentas que podem ajudar a estabelecer uma cultura de revis\u00e3o de c\u00f3digo inclusiva dentro de nossas equipes. Anonymous GitHub Blind Code Reviews Gitmask inclusivelint","title":"Inclus\u00e3o na Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/inclusion-in-code-review/#inclusao-na-revisao-de-codigo","text":"A seguir est\u00e3o alguns pontos que enfatizam por que a inclusividade nas revis\u00f5es de c\u00f3digo \u00e9 importante: Revis\u00f5es de c\u00f3digo s\u00e3o uma parte importante do nosso trabalho como profissionais de software. Na ISE, trabalhamos com equipes interculturais de todo o mundo. Como nos comunicamos afeta o moral da equipe. Revis\u00f5es de c\u00f3digo inclusivas acolhem novos desenvolvedores e os tornam confort\u00e1veis com a equipe. Ataques rudes ou pessoais durante revis\u00f5es de c\u00f3digo alienam - as pessoas podem, sem saber, fazer coment\u00e1rios rudes ao revisar pull requests (PRs).","title":"Inclus\u00e3o na Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/inclusion-in-code-review/#tipos-e-exemplos-de-comportamento-nao-inclusivo-na-revisao-de-codigo","text":"Atribui\u00e7\u00f5es de revis\u00e3o injustas. Exemplo: Atribuir a maioria das revis\u00f5es a poucas pessoas e desconsiderar alguns membros da equipe. Intera\u00e7\u00f5es interpessoais negativas. Exemplo: Longas discuss\u00f5es sobre t\u00f3picos subjetivos, como estilo de c\u00f3digo. Tomada de decis\u00e3o tendenciosa. Exemplo: Coment\u00e1rios sobre o desenvolvedor e n\u00e3o sobre o c\u00f3digo. Supor que o c\u00f3digo do desenvolvedor X sempre ser\u00e1 bom e, portanto, n\u00e3o revis\u00e1-lo adequadamente e vice-versa.","title":"Tipos e Exemplos de Comportamento N\u00e3o Inclusivo na Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/inclusion-in-code-review/#exemplos-de-revisoes-de-codigo-inclusivas","text":"Qualquer pessoa da equipe deve ser designada para revisar PRs. O revisor deve ser claro sobre o que \u00e9 uma opini\u00e3o, prefer\u00eancia pessoal, melhor pr\u00e1tica ou um fato. Discuss\u00f5es sobre prefer\u00eancias pessoais e opini\u00f5es s\u00e3o na maioria das vezes evit\u00e1veis. Usar linguagem e tom inclusivos nos coment\u00e1rios da revis\u00e3o de c\u00f3digo. Por exemplo, ser sugestivo em vez de prescritivo nos coment\u00e1rios da revis\u00e3o \u00e9 uma boa maneira de passar o ponto de vista. \u00c9 uma boa pr\u00e1tica para o autor de um PR agradecer ao revisor pela revis\u00e3o, quando eles contribu\u00edram para melhorar o c\u00f3digo ou voc\u00ea aprendeu algo novo. Usar o m\u00e9todo sandu\u00edche para recomendar uma mudan\u00e7a de c\u00f3digo para um novo desenvolvedor ou um novo cliente: coloque a sugest\u00e3o entre dois elogios. Por exemplo: \"\u00d3timo trabalho at\u00e9 agora, mas eu recomendaria algumas mudan\u00e7as aqui. A prop\u00f3sito, adorei o uso de XYZ aqui, bom trabalho!\"","title":"Exemplos de Revis\u00f5es de C\u00f3digo Inclusivas"},{"location":"code-reviews/inclusion-in-code-review/#diretrizes-para-o-autor","text":"O objetivo \u00e9 escrever um c\u00f3digo que seja f\u00e1cil de ler, revisar e manter. \u00c9 importante garantir que quem estiver olhando para o c\u00f3digo, seja o revisor ou um futuro engenheiro, possa entender as motiva\u00e7\u00f5es e como seu c\u00f3digo atinge seus objetivos. Pedir proativamente ajuda ou feedback direcionado. Responder claramente \u00e0s perguntas feitas pelos revisores. Evitar commits grandes, enviando mudan\u00e7as incrementais. Commits grandes e que cont\u00eam mudan\u00e7as em v\u00e1rios arquivos levar\u00e3o a uma revis\u00e3o injusta do c\u00f3digo. O comportamento tendencioso dos revisores pode surgir ao revisar tais PRs. Por exemplo, um commit grande de um desenvolvedor s\u00eanior pode ser aprovado sem uma revis\u00e3o completa, enquanto um commit grande de um desenvolvedor j\u00fanior pode nunca ser revisado e aprovado.","title":"Diretrizes para o Autor"},{"location":"code-reviews/inclusion-in-code-review/#diretrizes-para-o-revisor","text":"Presuma inten\u00e7\u00f5es positivas do autor. Escreva coment\u00e1rios claros e elaborados. Identifique subjetividade, escolha de codifica\u00e7\u00e3o e melhores pr\u00e1ticas. \u00c9 bom discutir estilo de codifica\u00e7\u00e3o e escolhas de codifica\u00e7\u00e3o subjetivas em algum outro f\u00f3rum e n\u00e3o no PR. Um PR n\u00e3o deve se tornar um terreno para discutir escolhas de codifica\u00e7\u00e3o subjetivas e ter longas discuss\u00f5es sobre isso. Se voc\u00ea n\u00e3o entender o c\u00f3digo adequadamente, evite comentar, por exemplo, \"Este c\u00f3digo \u00e9 incompreens\u00edvel\". \u00c9 melhor ter uma liga\u00e7\u00e3o com o autor e obter um entendimento b\u00e1sico do trabalho deles. Seja sugestivo e n\u00e3o prescritivo. Um revisor deve sugerir mudan\u00e7as e n\u00e3o prescrever mudan\u00e7as, deixe o autor decidir se realmente deseja aceitar as mudan\u00e7as propostas.","title":"Diretrizes para o Revisor"},{"location":"code-reviews/inclusion-in-code-review/#cultura-e-revisoes-de-codigo","text":"N\u00f3s, na ISE, podemos nos deparar com situa\u00e7\u00f5es em que as revis\u00f5es de c\u00f3digo n\u00e3o s\u00e3o ideais e frequentemente observamos comportamentos de revis\u00e3o de c\u00f3digo n\u00e3o inclusivos. \u00c9 importante estar ciente do fato de que a cultura e o estilo de comunica\u00e7\u00e3o de uma geografia espec\u00edfica tamb\u00e9m influenciam como as pessoas interagem em pull requests. Nesses casos, presumir a inten\u00e7\u00e3o positiva do autor e do revisor \u00e9 um bom ponto de partida para come\u00e7ar a analisar a qualidade das revis\u00f5es de c\u00f3digo.","title":"Cultura e Revis\u00f5es de C\u00f3digo"},{"location":"code-reviews/inclusion-in-code-review/#lidando-com-o-fenomeno-do-impostor","text":"O fen\u00f4meno do impostor \u00e9 um padr\u00e3o psicol\u00f3gico em que um indiv\u00edduo duvida de suas habilidades, talentos ou realiza\u00e7\u00f5es e tem um medo interno persistente de ser exposto como uma \"fraude\" - Wikipedia . Algu\u00e9m que experimenta o fen\u00f4meno do impostor pode achar particularmente estressante enviar c\u00f3digo para revis\u00e3o. \u00c9 importante perceber que todos podem ter contribui\u00e7\u00f5es significativas e n\u00e3o deixar que as fraquezas percebidas impe\u00e7am as contribui\u00e7\u00f5es. Algumas dicas para superar o fen\u00f4meno do impostor para autores: Revise as diretrizes destacadas acima e certifique-se de que sua mudan\u00e7a de c\u00f3digo esteja em conformidade com elas. Pe\u00e7a ajuda a um colega - programe em par com um colega experiente de quem voc\u00ea possa aprender. Algumas dicas para superar o fen\u00f4meno do impostor para revisores: Qualquer pessoa pode ter percep\u00e7\u00f5es valiosas. Um novo par de olhos \u00e9 sempre bem-vindo. Estude a revis\u00e3o at\u00e9 que voc\u00ea a tenha entendido claramente, verifique os casos extremos e procure maneiras de melhor\u00e1-la. Se algo n\u00e3o estiver claro, uma pergunta espec\u00edfica simples deve ser feita. Se voc\u00ea aprendeu algo, sempre pode elogiar o autor. Se poss\u00edvel, fa\u00e7a parceria com algu\u00e9m para revisar o c\u00f3digo, para que voc\u00ea possa estabelecer uma conex\u00e3o pessoal e ter uma discuss\u00e3o mais profunda sobre o c\u00f3digo.","title":"Lidando com o Fen\u00f4meno do Impostor"},{"location":"code-reviews/inclusion-in-code-review/#ferramentas","text":"A seguir est\u00e3o algumas ferramentas que podem ajudar a estabelecer uma cultura de revis\u00e3o de c\u00f3digo inclusiva dentro de nossas equipes. Anonymous GitHub Blind Code Reviews Gitmask inclusivelint","title":"Ferramentas"},{"location":"code-reviews/pull-requests/","text":"Pull Requests As altera\u00e7\u00f5es em qualquer c\u00f3digo principal - como o ramo principal em um reposit\u00f3rio Git, por exemplo - devem ser feitas usando pull requests (PR). As pull requests possibilitam: Inspe\u00e7\u00e3o de c\u00f3digo - veja Revis\u00f5es de C\u00f3digo Execu\u00e7\u00e3o de qualifica\u00e7\u00e3o automatizada do c\u00f3digo Linters (verificadores de c\u00f3digo) Compila\u00e7\u00e3o Testes unit\u00e1rios Testes de integra\u00e7\u00e3o, etc. Os requisitos das pull requests podem e devem ser aplicados por pol\u00edticas, que podem ser configuradas nos sistemas mais modernos de controle de vers\u00e3o e rastreamento de itens de trabalho. Consulte a se\u00e7\u00e3o Evid\u00eancia e Medidas para mais informa\u00e7\u00f5es. Processo Geral Implemente as altera\u00e7\u00f5es com base na descri\u00e7\u00e3o bem definida e nos crit\u00e9rios de aceita\u00e7\u00e3o da tarefa em quest\u00e3o. Em seguida, antes de criar uma nova pull request: * Certifique-se de que o c\u00f3digo esteja em conformidade com as conven\u00e7\u00f5es de codifica\u00e7\u00e3o acordadas * Isso pode ser parcialmente automatizado usando linters (verificadores de c\u00f3digo) * Garanta que o c\u00f3digo compile e execute sem erros ou avisos * Escreva e/ou atualize os testes para abranger as altera\u00e7\u00f5es e certifique-se de que todos os testes novos e existentes passem * Escreva e/ou atualize a documenta\u00e7\u00e3o para corresponder \u00e0s altera\u00e7\u00f5es Uma vez convencido de que os crit\u00e9rios acima est\u00e3o atendidos, crie e envie uma nova pull request seguindo o modelo de pull request Siga o processo de revis\u00e3o de c\u00f3digo para mesclar as altera\u00e7\u00f5es no c\u00f3digo principal O diagrama a seguir ilustra essa abordagem. sequenceDiagram New branch->>+Pull request: Cria\u00e7\u00e3o de nova PR Pull request->>+Code review: Processo de revis\u00e3o Code review->>+Pull request: Atualiza\u00e7\u00f5es de c\u00f3digo Pull request->>+New branch: Mesclar Pull Request Pull request-->>-New branch: Excluir ramo Pull request ->>+ Main branch: Mesclar ap\u00f3s a conclus\u00e3o New branch->>+Main branch: Objetivo da Pull request Orienta\u00e7\u00e3o de Tamanho Devemos sempre procurar manter as pull requests pequenas. PRs pequenas t\u00eam v\u00e1rias vantagens: S\u00e3o mais f\u00e1ceis de revisar; um benef\u00edcio claro para os revisores. S\u00e3o mais f\u00e1ceis de implantar; isso est\u00e1 alinhado com a estrat\u00e9gia de lan\u00e7ar r\u00e1pido e lan\u00e7ar com frequ\u00eancia. Minimiza poss\u00edveis conflitos e PRs n\u00e3o atualizadas. No entanto, devemos manter as PRs focadas - por exemplo, em torno de uma funcionalidade funcional, otimiza\u00e7\u00e3o ou legibilidade de c\u00f3digo, e evitar PRs que incluam c\u00f3digo sem contexto ou frouxamente acoplado. N\u00e3o h\u00e1 um tamanho certo, mas tenha em mente que uma revis\u00e3o de c\u00f3digo \u00e9 um processo colaborativo, e PRs grandes podem ser dif\u00edceis e, portanto, mais lentas de revisar. Devemos sempre nos esfor\u00e7ar para ter PRs o mais pequenas poss\u00edvel que ainda agreguem valor. Melhores Pr\u00e1ticas Al\u00e9m do tamanho, lembre-se de que toda PR deve: ser consistente, n\u00e3o quebrar a compila\u00e7\u00e3o e incluir testes relacionados como parte da PR. Ser consistente significa que todas as altera\u00e7\u00f5es inclu\u00eddas na PR devem visar resolver um objetivo (por exemplo, uma hist\u00f3ria de usu\u00e1rio) e estar intrinsecamente relacionadas. Pense nisso como o princ\u00edpio de \u00fanica responsabilidade em termos do projeto como um todo, a PR deve ter apenas uma raz\u00e3o para alterar o projeto. Comece pequeno, \u00e9 mais f\u00e1cil criar uma PR pequena desde o in\u00edcio do que dividir uma maior. Aqui est\u00e3o algumas estrat\u00e9gias para manter as PRs pequenas, dependendo da \"causa\" da inevitabilidade: voc\u00ea pode dividir a PR em altera\u00e7\u00f5es autocontidas que ainda agreguem valor, lan\u00e7ar recursos ocultos (consulte feature flag, feature toggling ou lan\u00e7amentos can\u00e1rios) ou dividir a PR em diferentes camadas (por exemplo, usando padr\u00f5es de design como MVC ou Observer/Subject). N\u00e3o importa a estrat\u00e9gia. Descri\u00e7\u00e3o da Pull Request Descri\u00e7\u00f5es de PR bem escritas ajudam a manter um hist\u00f3rico de altera\u00e7\u00f5es limpo e bem estruturado. Embora cada equipe n\u00e3o precise aderir \u00e0 mesma especifica\u00e7\u00e3o, \u00e9 importante que a conven\u00e7\u00e3o seja acordada no in\u00edcio do projeto. Uma especifica\u00e7\u00e3o popular para projetos de c\u00f3digo aberto e outros \u00e9 a Conventional Commits specification , que \u00e9 estruturada como: <tipo>[escopo opcional]: <descri\u00e7\u00e3o> [corpo opcional] [rodap\u00e9 opcional] O <tipo> nesta mensagem pode ser selecionado em uma lista de tipos definidos pela equipe, mas muitos projetos usam a lista de tipos de commit do projeto open-source Angular . Deve ficar claro que os elementos escopo , corpo e rodap\u00e9 s\u00e3o opcionais , mas ter um tipo obrigat\u00f3rio e uma breve descri\u00e7\u00e3o permite as funcionalidades mencionadas acima. Veja tamb\u00e9m Modelo de Pull Request Recursos Escrevendo uma \u00f3tima descri\u00e7\u00e3o de pull request Revisando c\u00f3digo com pull requests (Azure DevOps) Colabora\u00e7\u00e3o com problemas e pull requests (GitHub) Abordagem do Google para o tamanho de PR Feature Flags Abordagem do Facebook para recursos ocultos Abordagem da Azure para lan\u00e7amentos can\u00e1rios [Especifica\u00e7\u00e3o Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0-beta.2/) * Tipos de Commit do Angular","title":"Pull Requests"},{"location":"code-reviews/pull-requests/#pull-requests","text":"As altera\u00e7\u00f5es em qualquer c\u00f3digo principal - como o ramo principal em um reposit\u00f3rio Git, por exemplo - devem ser feitas usando pull requests (PR). As pull requests possibilitam: Inspe\u00e7\u00e3o de c\u00f3digo - veja Revis\u00f5es de C\u00f3digo Execu\u00e7\u00e3o de qualifica\u00e7\u00e3o automatizada do c\u00f3digo Linters (verificadores de c\u00f3digo) Compila\u00e7\u00e3o Testes unit\u00e1rios Testes de integra\u00e7\u00e3o, etc. Os requisitos das pull requests podem e devem ser aplicados por pol\u00edticas, que podem ser configuradas nos sistemas mais modernos de controle de vers\u00e3o e rastreamento de itens de trabalho. Consulte a se\u00e7\u00e3o Evid\u00eancia e Medidas para mais informa\u00e7\u00f5es.","title":"Pull Requests"},{"location":"code-reviews/pull-requests/#processo-geral","text":"Implemente as altera\u00e7\u00f5es com base na descri\u00e7\u00e3o bem definida e nos crit\u00e9rios de aceita\u00e7\u00e3o da tarefa em quest\u00e3o. Em seguida, antes de criar uma nova pull request: * Certifique-se de que o c\u00f3digo esteja em conformidade com as conven\u00e7\u00f5es de codifica\u00e7\u00e3o acordadas * Isso pode ser parcialmente automatizado usando linters (verificadores de c\u00f3digo) * Garanta que o c\u00f3digo compile e execute sem erros ou avisos * Escreva e/ou atualize os testes para abranger as altera\u00e7\u00f5es e certifique-se de que todos os testes novos e existentes passem * Escreva e/ou atualize a documenta\u00e7\u00e3o para corresponder \u00e0s altera\u00e7\u00f5es Uma vez convencido de que os crit\u00e9rios acima est\u00e3o atendidos, crie e envie uma nova pull request seguindo o modelo de pull request Siga o processo de revis\u00e3o de c\u00f3digo para mesclar as altera\u00e7\u00f5es no c\u00f3digo principal O diagrama a seguir ilustra essa abordagem. sequenceDiagram New branch->>+Pull request: Cria\u00e7\u00e3o de nova PR Pull request->>+Code review: Processo de revis\u00e3o Code review->>+Pull request: Atualiza\u00e7\u00f5es de c\u00f3digo Pull request->>+New branch: Mesclar Pull Request Pull request-->>-New branch: Excluir ramo Pull request ->>+ Main branch: Mesclar ap\u00f3s a conclus\u00e3o New branch->>+Main branch: Objetivo da Pull request","title":"Processo Geral"},{"location":"code-reviews/pull-requests/#orientacao-de-tamanho","text":"Devemos sempre procurar manter as pull requests pequenas. PRs pequenas t\u00eam v\u00e1rias vantagens: S\u00e3o mais f\u00e1ceis de revisar; um benef\u00edcio claro para os revisores. S\u00e3o mais f\u00e1ceis de implantar; isso est\u00e1 alinhado com a estrat\u00e9gia de lan\u00e7ar r\u00e1pido e lan\u00e7ar com frequ\u00eancia. Minimiza poss\u00edveis conflitos e PRs n\u00e3o atualizadas. No entanto, devemos manter as PRs focadas - por exemplo, em torno de uma funcionalidade funcional, otimiza\u00e7\u00e3o ou legibilidade de c\u00f3digo, e evitar PRs que incluam c\u00f3digo sem contexto ou frouxamente acoplado. N\u00e3o h\u00e1 um tamanho certo, mas tenha em mente que uma revis\u00e3o de c\u00f3digo \u00e9 um processo colaborativo, e PRs grandes podem ser dif\u00edceis e, portanto, mais lentas de revisar. Devemos sempre nos esfor\u00e7ar para ter PRs o mais pequenas poss\u00edvel que ainda agreguem valor.","title":"Orienta\u00e7\u00e3o de Tamanho"},{"location":"code-reviews/pull-requests/#melhores-praticas","text":"Al\u00e9m do tamanho, lembre-se de que toda PR deve: ser consistente, n\u00e3o quebrar a compila\u00e7\u00e3o e incluir testes relacionados como parte da PR. Ser consistente significa que todas as altera\u00e7\u00f5es inclu\u00eddas na PR devem visar resolver um objetivo (por exemplo, uma hist\u00f3ria de usu\u00e1rio) e estar intrinsecamente relacionadas. Pense nisso como o princ\u00edpio de \u00fanica responsabilidade em termos do projeto como um todo, a PR deve ter apenas uma raz\u00e3o para alterar o projeto. Comece pequeno, \u00e9 mais f\u00e1cil criar uma PR pequena desde o in\u00edcio do que dividir uma maior. Aqui est\u00e3o algumas estrat\u00e9gias para manter as PRs pequenas, dependendo da \"causa\" da inevitabilidade: voc\u00ea pode dividir a PR em altera\u00e7\u00f5es autocontidas que ainda agreguem valor, lan\u00e7ar recursos ocultos (consulte feature flag, feature toggling ou lan\u00e7amentos can\u00e1rios) ou dividir a PR em diferentes camadas (por exemplo, usando padr\u00f5es de design como MVC ou Observer/Subject). N\u00e3o importa a estrat\u00e9gia.","title":"Melhores Pr\u00e1ticas"},{"location":"code-reviews/pull-requests/#descricao-da-pull-request","text":"Descri\u00e7\u00f5es de PR bem escritas ajudam a manter um hist\u00f3rico de altera\u00e7\u00f5es limpo e bem estruturado. Embora cada equipe n\u00e3o precise aderir \u00e0 mesma especifica\u00e7\u00e3o, \u00e9 importante que a conven\u00e7\u00e3o seja acordada no in\u00edcio do projeto. Uma especifica\u00e7\u00e3o popular para projetos de c\u00f3digo aberto e outros \u00e9 a Conventional Commits specification , que \u00e9 estruturada como: <tipo>[escopo opcional]: <descri\u00e7\u00e3o> [corpo opcional] [rodap\u00e9 opcional] O <tipo> nesta mensagem pode ser selecionado em uma lista de tipos definidos pela equipe, mas muitos projetos usam a lista de tipos de commit do projeto open-source Angular . Deve ficar claro que os elementos escopo , corpo e rodap\u00e9 s\u00e3o opcionais , mas ter um tipo obrigat\u00f3rio e uma breve descri\u00e7\u00e3o permite as funcionalidades mencionadas acima. Veja tamb\u00e9m Modelo de Pull Request","title":"Descri\u00e7\u00e3o da Pull Request"},{"location":"code-reviews/pull-requests/#recursos","text":"Escrevendo uma \u00f3tima descri\u00e7\u00e3o de pull request Revisando c\u00f3digo com pull requests (Azure DevOps) Colabora\u00e7\u00e3o com problemas e pull requests (GitHub) Abordagem do Google para o tamanho de PR Feature Flags Abordagem do Facebook para recursos ocultos Abordagem da Azure para lan\u00e7amentos can\u00e1rios [Especifica\u00e7\u00e3o Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0-beta.2/) * Tipos de Commit do Angular","title":"Recursos"},{"location":"code-reviews/tools/","text":"Ferramentas de Revis\u00e3o de C\u00f3digo Personalizar o ADO (Azure DevOps) Quadros de Tarefas AzDO: Personalizar cart\u00f5es AzDO: Adicionar colunas no quadro de tarefas Pol\u00edticas de Revisor Configurar um grupo de revisores obrigat\u00f3rios no AzDO - Incluir automaticamente revisores de c\u00f3digo Configurando Pol\u00edticas de Ramifica\u00e7\u00e3o AzDO: Configurar pol\u00edticas de ramifica\u00e7\u00e3o AzDO: Configurar pol\u00edticas de ramifica\u00e7\u00e3o com a ferramenta CLI: Criar um arquivo de configura\u00e7\u00e3o de pol\u00edtica Pol\u00edtica de contagem de aprova\u00e7\u00e3o GitHub: Configurando ramifica\u00e7\u00f5es protegidas Visual Studio Code GitHub: GitHub Pull Requests Suporta o processamento de pull requests do GitHub dentro do VS Code. Abra o plugin na Barra de Atividades Selecione Atribu\u00eddo a Mim Selecione um PR Sob Descri\u00e7\u00e3o , voc\u00ea pode escolher Fazer Check-out do ramo e entrar no Modo de Revis\u00e3o para obter uma experi\u00eancia mais integrada Azure DevOps: Azure DevOps Pull Requests Suporta o processamento de pull requests do Azure DevOps dentro do VS Code. Abra o plugin na Barra de Atividades Selecione Atribu\u00eddo a Mim Selecione um PR Sob Descri\u00e7\u00e3o , voc\u00ea pode escolher Fazer Check-out do ramo e entrar no Modo de Revis\u00e3o para obter uma experi\u00eancia mais integrada Visual Studio As seguintes extens\u00f5es podem ser usadas para criar uma experi\u00eancia integrada de revis\u00e3o de c\u00f3digo no Visual Studio, trabalhando com GitHub ou Azure DevOps. GitHub: GitHub Extension para Visual Studio Fornece funcionalidades estendidas para trabalhar com pull requests no GitHub diretamente no Visual Studio. View -> Other Windows -> GitHub Clique no \u00edcone de Pull Requests na barra de tarefas Clique duas vezes em um pull request pendente Azure DevOps: Pull Requests para Visual Studio Trabalhe com pull requests no Azure DevOps diretamente no Visual Studio. Abra o Team Explorer Clique em Pull Requests Clique duas vezes em um pull request - os Detalhes do Pull Request ser\u00e3o abertos Clique em Checkout se voc\u00ea quiser ter a mudan\u00e7a completa localmente e ter uma experi\u00eancia mais integrada Revise as mudan\u00e7as e fa\u00e7a coment\u00e1rios Web Reviewable: Revis\u00f5es de C\u00f3digo GitHub multi-round sem interrup\u00e7\u00f5es Suporta revis\u00f5es de c\u00f3digo GitHub multi-round, com atalhos de teclado e muito mais. A extens\u00e3o para o VS Code est\u00e1 em andamento. Visite o Painel de Revis\u00f5es para ver revis\u00f5es aguardando sua a\u00e7\u00e3o, que t\u00eam novos coment\u00e1rios para voc\u00ea e muito mais. Selecione um Pull Request dessa lista. Abra qualquer arquivo no seu navegador, no Visual Studio Code ou em qualquer editor que voc\u00ea tenha configurado, clicando na sua foto de perfil no canto superior direito. Selecione um editor em \"Modelo de link externo\". O VS Code \u00e9 uma op\u00e7\u00e3o, mas tamb\u00e9m qualquer editor que suporte URI. Revise a diferen\u00e7a globalmente ou por arquivo, deixando coment\u00e1rios, sugest\u00f5es de c\u00f3digo e muito mais.","title":"Ferramentas de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/tools/#ferramentas-de-revisao-de-codigo","text":"","title":"Ferramentas de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/tools/#personalizar-o-ado-azure-devops","text":"","title":"Personalizar o ADO (Azure DevOps)"},{"location":"code-reviews/tools/#quadros-de-tarefas","text":"AzDO: Personalizar cart\u00f5es AzDO: Adicionar colunas no quadro de tarefas","title":"Quadros de Tarefas"},{"location":"code-reviews/tools/#politicas-de-revisor","text":"Configurar um grupo de revisores obrigat\u00f3rios no AzDO - Incluir automaticamente revisores de c\u00f3digo","title":"Pol\u00edticas de Revisor"},{"location":"code-reviews/tools/#configurando-politicas-de-ramificacao","text":"AzDO: Configurar pol\u00edticas de ramifica\u00e7\u00e3o AzDO: Configurar pol\u00edticas de ramifica\u00e7\u00e3o com a ferramenta CLI: Criar um arquivo de configura\u00e7\u00e3o de pol\u00edtica Pol\u00edtica de contagem de aprova\u00e7\u00e3o GitHub: Configurando ramifica\u00e7\u00f5es protegidas","title":"Configurando Pol\u00edticas de Ramifica\u00e7\u00e3o"},{"location":"code-reviews/tools/#visual-studio-code","text":"","title":"Visual Studio Code"},{"location":"code-reviews/tools/#github-github-pull-requests","text":"Suporta o processamento de pull requests do GitHub dentro do VS Code. Abra o plugin na Barra de Atividades Selecione Atribu\u00eddo a Mim Selecione um PR Sob Descri\u00e7\u00e3o , voc\u00ea pode escolher Fazer Check-out do ramo e entrar no Modo de Revis\u00e3o para obter uma experi\u00eancia mais integrada","title":"GitHub: GitHub Pull Requests"},{"location":"code-reviews/tools/#azure-devops-azure-devops-pull-requests","text":"Suporta o processamento de pull requests do Azure DevOps dentro do VS Code. Abra o plugin na Barra de Atividades Selecione Atribu\u00eddo a Mim Selecione um PR Sob Descri\u00e7\u00e3o , voc\u00ea pode escolher Fazer Check-out do ramo e entrar no Modo de Revis\u00e3o para obter uma experi\u00eancia mais integrada","title":"Azure DevOps: Azure DevOps Pull Requests"},{"location":"code-reviews/tools/#visual-studio","text":"As seguintes extens\u00f5es podem ser usadas para criar uma experi\u00eancia integrada de revis\u00e3o de c\u00f3digo no Visual Studio, trabalhando com GitHub ou Azure DevOps.","title":"Visual Studio"},{"location":"code-reviews/tools/#github-github-extension-para-visual-studio","text":"Fornece funcionalidades estendidas para trabalhar com pull requests no GitHub diretamente no Visual Studio. View -> Other Windows -> GitHub Clique no \u00edcone de Pull Requests na barra de tarefas Clique duas vezes em um pull request pendente","title":"GitHub: GitHub Extension para Visual Studio"},{"location":"code-reviews/tools/#azure-devops-pull-requests-para-visual-studio","text":"Trabalhe com pull requests no Azure DevOps diretamente no Visual Studio. Abra o Team Explorer Clique em Pull Requests Clique duas vezes em um pull request - os Detalhes do Pull Request ser\u00e3o abertos Clique em Checkout se voc\u00ea quiser ter a mudan\u00e7a completa localmente e ter uma experi\u00eancia mais integrada Revise as mudan\u00e7as e fa\u00e7a coment\u00e1rios","title":"Azure DevOps: Pull Requests para Visual Studio"},{"location":"code-reviews/tools/#web","text":"","title":"Web"},{"location":"code-reviews/tools/#reviewable-revisoes-de-codigo-github-multi-round-sem-interrupcoes","text":"Suporta revis\u00f5es de c\u00f3digo GitHub multi-round, com atalhos de teclado e muito mais. A extens\u00e3o para o VS Code est\u00e1 em andamento. Visite o Painel de Revis\u00f5es para ver revis\u00f5es aguardando sua a\u00e7\u00e3o, que t\u00eam novos coment\u00e1rios para voc\u00ea e muito mais. Selecione um Pull Request dessa lista. Abra qualquer arquivo no seu navegador, no Visual Studio Code ou em qualquer editor que voc\u00ea tenha configurado, clicando na sua foto de perfil no canto superior direito. Selecione um editor em \"Modelo de link externo\". O VS Code \u00e9 uma op\u00e7\u00e3o, mas tamb\u00e9m qualquer editor que suporte URI. Revise a diferen\u00e7a globalmente ou por arquivo, deixando coment\u00e1rios, sugest\u00f5es de c\u00f3digo e muito mais.","title":"Reviewable: Revis\u00f5es de C\u00f3digo GitHub multi-round sem interrup\u00e7\u00f5es"},{"location":"code-reviews/evidence-and-measures/","text":"Evid\u00eancias e Medidas Evid\u00eancias Muitos dos itens de garantia de qualidade de c\u00f3digo podem ser automatizados ou aplicados por meio de pol\u00edticas em sistemas modernos de controle de vers\u00e3o e rastreamento de itens de trabalho. A verifica\u00e7\u00e3o das pol\u00edticas na branch principal no Azure DevOps (AzDO) ou no GitHub , por exemplo, pode ser evid\u00eancia suficiente de que uma equipe de projeto est\u00e1 conduzindo revis\u00f5es de c\u00f3digo. Todas as branches principais em todos os reposit\u00f3rios t\u00eam pol\u00edticas de branch. - Configurar pol\u00edticas de branch Todas as compila\u00e7\u00f5es geradas a partir dos reposit\u00f3rios do projeto incluem linters apropriados e executam testes unit\u00e1rios. Cada item de trabalho de corre\u00e7\u00e3o de bug deve incluir um link para o pull request que o introduziu, assim que o erro for diagnosticado. Isso ajuda na aprendizagem. Cada item de trabalho de corre\u00e7\u00e3o de bug deve incluir uma observa\u00e7\u00e3o sobre como o bug poderia (ou n\u00e3o) ter sido detectado em uma revis\u00e3o de c\u00f3digo. A equipe do projeto atualiza regularmente suas listas de verifica\u00e7\u00e3o de revis\u00e3o de c\u00f3digo para refletir problemas comuns que eles encontraram. Os l\u00edderes de desenvolvimento devem revisar uma amostra de pull requests e/ou ser co-revisores com outros desenvolvedores para ajudar todos a melhorar suas habilidades como revisores de c\u00f3digo. Medidas A equipe pode coletar m\u00e9tricas de revis\u00f5es de c\u00f3digo para medir sua efici\u00eancia. Algumas m\u00e9tricas \u00fateis incluem: Efici\u00eancia na Remo\u00e7\u00e3o de Defeitos (DRE) - uma medida da capacidade da equipe de desenvolvimento de remover defeitos antes do lan\u00e7amento. M\u00e9tricas de tempo: Tempo gasto preparando-se para sess\u00f5es de inspe\u00e7\u00e3o de c\u00f3digo. Tempo gasto em sess\u00f5es de revis\u00e3o. Linhas de c\u00f3digo (LOC) inspecionadas por unidade de tempo/reuni\u00e3o. \u00c9 uma solu\u00e7\u00e3o perfeitamente razo\u00e1vel rastrear essas m\u00e9tricas manualmente, por exemplo, em uma planilha do Excel. Tamb\u00e9m \u00e9 poss\u00edvel utilizar os recursos de plataformas de gerenciamento de projetos - por exemplo, o AzDO permite pain\u00e9is de m\u00e9tricas, incluindo rastreamento de bugs . Voc\u00ea pode encontrar plugins prontos para v\u00e1rias plataformas - consulte o GitHub Marketplace , por exemplo - ou optar por implementar esses recursos por conta pr\u00f3pria. Lembre-se de que, uma vez que defeitos removidos gra\u00e7as a revis\u00f5es s\u00e3o muito menos custosos em compara\u00e7\u00e3o com a detec\u00e7\u00e3o deles em produ\u00e7\u00e3o, o custo das revis\u00f5es de c\u00f3digo \u00e9, na verdade, negativo! Para obter mais informa\u00e7\u00f5es, consulte os links na se\u00e7\u00e3o de recursos . Recursos Um Guia para Inspe\u00e7\u00f5es de C\u00f3digo","title":"Evid\u00eancias e Medidas"},{"location":"code-reviews/evidence-and-measures/#evidencias-e-medidas","text":"","title":"Evid\u00eancias e Medidas"},{"location":"code-reviews/evidence-and-measures/#evidencias","text":"Muitos dos itens de garantia de qualidade de c\u00f3digo podem ser automatizados ou aplicados por meio de pol\u00edticas em sistemas modernos de controle de vers\u00e3o e rastreamento de itens de trabalho. A verifica\u00e7\u00e3o das pol\u00edticas na branch principal no Azure DevOps (AzDO) ou no GitHub , por exemplo, pode ser evid\u00eancia suficiente de que uma equipe de projeto est\u00e1 conduzindo revis\u00f5es de c\u00f3digo. Todas as branches principais em todos os reposit\u00f3rios t\u00eam pol\u00edticas de branch. - Configurar pol\u00edticas de branch Todas as compila\u00e7\u00f5es geradas a partir dos reposit\u00f3rios do projeto incluem linters apropriados e executam testes unit\u00e1rios. Cada item de trabalho de corre\u00e7\u00e3o de bug deve incluir um link para o pull request que o introduziu, assim que o erro for diagnosticado. Isso ajuda na aprendizagem. Cada item de trabalho de corre\u00e7\u00e3o de bug deve incluir uma observa\u00e7\u00e3o sobre como o bug poderia (ou n\u00e3o) ter sido detectado em uma revis\u00e3o de c\u00f3digo. A equipe do projeto atualiza regularmente suas listas de verifica\u00e7\u00e3o de revis\u00e3o de c\u00f3digo para refletir problemas comuns que eles encontraram. Os l\u00edderes de desenvolvimento devem revisar uma amostra de pull requests e/ou ser co-revisores com outros desenvolvedores para ajudar todos a melhorar suas habilidades como revisores de c\u00f3digo.","title":"Evid\u00eancias"},{"location":"code-reviews/evidence-and-measures/#medidas","text":"A equipe pode coletar m\u00e9tricas de revis\u00f5es de c\u00f3digo para medir sua efici\u00eancia. Algumas m\u00e9tricas \u00fateis incluem: Efici\u00eancia na Remo\u00e7\u00e3o de Defeitos (DRE) - uma medida da capacidade da equipe de desenvolvimento de remover defeitos antes do lan\u00e7amento. M\u00e9tricas de tempo: Tempo gasto preparando-se para sess\u00f5es de inspe\u00e7\u00e3o de c\u00f3digo. Tempo gasto em sess\u00f5es de revis\u00e3o. Linhas de c\u00f3digo (LOC) inspecionadas por unidade de tempo/reuni\u00e3o. \u00c9 uma solu\u00e7\u00e3o perfeitamente razo\u00e1vel rastrear essas m\u00e9tricas manualmente, por exemplo, em uma planilha do Excel. Tamb\u00e9m \u00e9 poss\u00edvel utilizar os recursos de plataformas de gerenciamento de projetos - por exemplo, o AzDO permite pain\u00e9is de m\u00e9tricas, incluindo rastreamento de bugs . Voc\u00ea pode encontrar plugins prontos para v\u00e1rias plataformas - consulte o GitHub Marketplace , por exemplo - ou optar por implementar esses recursos por conta pr\u00f3pria. Lembre-se de que, uma vez que defeitos removidos gra\u00e7as a revis\u00f5es s\u00e3o muito menos custosos em compara\u00e7\u00e3o com a detec\u00e7\u00e3o deles em produ\u00e7\u00e3o, o custo das revis\u00f5es de c\u00f3digo \u00e9, na verdade, negativo! Para obter mais informa\u00e7\u00f5es, consulte os links na se\u00e7\u00e3o de recursos .","title":"Medidas"},{"location":"code-reviews/evidence-and-measures/#recursos","text":"Um Guia para Inspe\u00e7\u00f5es de C\u00f3digo","title":"Recursos"},{"location":"code-reviews/process-guidance/","text":"Orienta\u00e7\u00e3o do Processo Orienta\u00e7\u00f5es Gerais As revis\u00f5es de c\u00f3digo devem fazer parte do processo da equipe de engenharia de software, independentemente do modelo de desenvolvimento. Al\u00e9m disso, a equipe deve aprender a realizar revis\u00f5es de forma oportuna. Pull requests (PRs) deixados pendentes podem causar problemas adicionais de mesclagem e ficarem desatualizados, resultando em trabalho perdido. PRs qualificados devem refletir tarefas bem definidas e concisas, sendo, portanto, compactos em conte\u00fado. A revis\u00e3o de uma \u00fanica tarefa deve levar relativamente pouco tempo para ser conclu\u00edda. Para garantir que o processo de revis\u00e3o de c\u00f3digo seja saud\u00e1vel, inclusivo e atenda aos objetivos mencionados acima, considere seguir estas diretrizes: Estabele\u00e7a um acordo de n\u00edvel de servi\u00e7o (SLA) para revis\u00f5es de c\u00f3digo e inclua-o no acordo de trabalho de sua equipe. Embora os ambientes modernos de DevOps incorporem ferramentas para gerenciar PRs, pode ser \u00fatil rotular tarefas pendentes de revis\u00e3o ou ter um local dedicado para elas no quadro de tarefas - Personalize os quadros de tarefas do AzDO Na reuni\u00e3o di\u00e1ria de standup, verifique as tarefas pendentes de revis\u00e3o e certifique-se de que possuam revisores atribu\u00eddos. Equipes juniores e equipes novas no processo podem considerar criar tarefas separadas para revis\u00f5es junto com as pr\u00f3prias tarefas. Utilize ferramentas para simplificar o processo de revis\u00e3o - Ferramentas de revis\u00e3o de c\u00f3digo Promova revis\u00f5es de c\u00f3digo inclusivas - Inclus\u00e3o na Revis\u00e3o de C\u00f3digo Medindo o Processo de Revis\u00e3o de C\u00f3digo Se a equipe perceber que as revis\u00f5es de c\u00f3digo est\u00e3o demorando muito para serem mescladas e est\u00e3o se tornando um obst\u00e1culo, considere as seguintes recomenda\u00e7\u00f5es adicionais: Me\u00e7a o tempo m\u00e9dio necess\u00e1rio para mesclar um PR por ciclo de sprint. Revise durante a retrospectiva como o tempo para mesclar pode ser melhorado e priorizado. Avalie o tempo para mesclar ao longo dos sprints para ver se o processo est\u00e1 melhorando. Lembre os aprovadores necess\u00e1rios diretamente como lembrete. As revis\u00f5es de c\u00f3digo n\u00e3o devem incluir muito c\u00f3digo \u00c9 f\u00e1cil dizer que um desenvolvedor pode revisar algumas centenas de linhas de c\u00f3digo, mas quando o c\u00f3digo ultrapassa uma certa quantidade de linhas, a efic\u00e1cia na descoberta de defeitos diminuir\u00e1, e h\u00e1 menos chances de fazer uma boa revis\u00e3o. N\u00e3o se trata de estabelecer um limite de linhas de c\u00f3digo, mas sim de usar o bom senso. Quanto mais c\u00f3digo houver para revisar, maiores s\u00e3o as chances de deixar um erro passar despercebido. Consulte Orienta\u00e7\u00e3o de Tamanho de PR . Automatize sempre que for razo\u00e1vel Use automa\u00e7\u00e3o (linting, an\u00e1lise de c\u00f3digo etc.) para evitar a necessidade de \" nits \" e permita que o revisor se concentre mais nos aspectos funcionais do PR. Configurando compila\u00e7\u00f5es automatizadas, testes e verifica\u00e7\u00f5es (algo alcan\u00e7\u00e1vel no processo de CI ), as equipes podem economizar tempo dos revisores humanos e permitir que eles se concentrem em \u00e1reas como design e funcionalidade para uma avalia\u00e7\u00e3o adequada. Isso garantir\u00e1 maiores chances de sucesso, pois a equipe est\u00e1 se concentrando no que realmente importa. Orienta\u00e7\u00f5es Espec\u00edficas por Fun\u00e7\u00e3o Orienta\u00e7\u00f5es para o Autor Orienta\u00e7\u00f5es para o Revisor","title":"Orienta\u00e7\u00e3o do Processo"},{"location":"code-reviews/process-guidance/#orientacao-do-processo","text":"","title":"Orienta\u00e7\u00e3o do Processo"},{"location":"code-reviews/process-guidance/#orientacoes-gerais","text":"As revis\u00f5es de c\u00f3digo devem fazer parte do processo da equipe de engenharia de software, independentemente do modelo de desenvolvimento. Al\u00e9m disso, a equipe deve aprender a realizar revis\u00f5es de forma oportuna. Pull requests (PRs) deixados pendentes podem causar problemas adicionais de mesclagem e ficarem desatualizados, resultando em trabalho perdido. PRs qualificados devem refletir tarefas bem definidas e concisas, sendo, portanto, compactos em conte\u00fado. A revis\u00e3o de uma \u00fanica tarefa deve levar relativamente pouco tempo para ser conclu\u00edda. Para garantir que o processo de revis\u00e3o de c\u00f3digo seja saud\u00e1vel, inclusivo e atenda aos objetivos mencionados acima, considere seguir estas diretrizes: Estabele\u00e7a um acordo de n\u00edvel de servi\u00e7o (SLA) para revis\u00f5es de c\u00f3digo e inclua-o no acordo de trabalho de sua equipe. Embora os ambientes modernos de DevOps incorporem ferramentas para gerenciar PRs, pode ser \u00fatil rotular tarefas pendentes de revis\u00e3o ou ter um local dedicado para elas no quadro de tarefas - Personalize os quadros de tarefas do AzDO Na reuni\u00e3o di\u00e1ria de standup, verifique as tarefas pendentes de revis\u00e3o e certifique-se de que possuam revisores atribu\u00eddos. Equipes juniores e equipes novas no processo podem considerar criar tarefas separadas para revis\u00f5es junto com as pr\u00f3prias tarefas. Utilize ferramentas para simplificar o processo de revis\u00e3o - Ferramentas de revis\u00e3o de c\u00f3digo Promova revis\u00f5es de c\u00f3digo inclusivas - Inclus\u00e3o na Revis\u00e3o de C\u00f3digo","title":"Orienta\u00e7\u00f5es Gerais"},{"location":"code-reviews/process-guidance/#medindo-o-processo-de-revisao-de-codigo","text":"Se a equipe perceber que as revis\u00f5es de c\u00f3digo est\u00e3o demorando muito para serem mescladas e est\u00e3o se tornando um obst\u00e1culo, considere as seguintes recomenda\u00e7\u00f5es adicionais: Me\u00e7a o tempo m\u00e9dio necess\u00e1rio para mesclar um PR por ciclo de sprint. Revise durante a retrospectiva como o tempo para mesclar pode ser melhorado e priorizado. Avalie o tempo para mesclar ao longo dos sprints para ver se o processo est\u00e1 melhorando. Lembre os aprovadores necess\u00e1rios diretamente como lembrete.","title":"Medindo o Processo de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/process-guidance/#as-revisoes-de-codigo-nao-devem-incluir-muito-codigo","text":"\u00c9 f\u00e1cil dizer que um desenvolvedor pode revisar algumas centenas de linhas de c\u00f3digo, mas quando o c\u00f3digo ultrapassa uma certa quantidade de linhas, a efic\u00e1cia na descoberta de defeitos diminuir\u00e1, e h\u00e1 menos chances de fazer uma boa revis\u00e3o. N\u00e3o se trata de estabelecer um limite de linhas de c\u00f3digo, mas sim de usar o bom senso. Quanto mais c\u00f3digo houver para revisar, maiores s\u00e3o as chances de deixar um erro passar despercebido. Consulte Orienta\u00e7\u00e3o de Tamanho de PR .","title":"As revis\u00f5es de c\u00f3digo n\u00e3o devem incluir muito c\u00f3digo"},{"location":"code-reviews/process-guidance/#automatize-sempre-que-for-razoavel","text":"Use automa\u00e7\u00e3o (linting, an\u00e1lise de c\u00f3digo etc.) para evitar a necessidade de \" nits \" e permita que o revisor se concentre mais nos aspectos funcionais do PR. Configurando compila\u00e7\u00f5es automatizadas, testes e verifica\u00e7\u00f5es (algo alcan\u00e7\u00e1vel no processo de CI ), as equipes podem economizar tempo dos revisores humanos e permitir que eles se concentrem em \u00e1reas como design e funcionalidade para uma avalia\u00e7\u00e3o adequada. Isso garantir\u00e1 maiores chances de sucesso, pois a equipe est\u00e1 se concentrando no que realmente importa.","title":"Automatize sempre que for razo\u00e1vel"},{"location":"code-reviews/process-guidance/#orientacoes-especificas-por-funcao","text":"Orienta\u00e7\u00f5es para o Autor Orienta\u00e7\u00f5es para o Revisor","title":"Orienta\u00e7\u00f5es Espec\u00edficas por Fun\u00e7\u00e3o"},{"location":"code-reviews/process-guidance/author-guidance/","text":"Orienta\u00e7\u00f5es para o Autor Descreva adequadamente o seu pull request (PR) D\u00ea ao PR um t\u00edtulo descritivo, para que outros membros possam entender facilmente (em uma frase curta) sobre o que se trata o PR. Todo PR deve ter uma descri\u00e7\u00e3o adequada que mostre ao revisor o que foi alterado e por qu\u00ea. Adicione revisores relevantes Adicione um ou mais revisores (dependendo das diretrizes do seu projeto) ao PR. Idealmente, voc\u00ea adicionaria pelo menos algu\u00e9m que tenha expertise e esteja familiarizado com o projeto ou a linguagem utilizada. Adicionar algu\u00e9m menos familiarizado com o projeto ou a linguagem pode ajudar a verificar se as altera\u00e7\u00f5es s\u00e3o compreens\u00edveis, f\u00e1ceis de ler e aumenta a expertise dentro da equipe. Nos projetos code-with da ISE com uma equipe de cliente, \u00e9 importante incluir revisores de ambas as organiza\u00e7\u00f5es para transfer\u00eancia de conhecimento - Personalize a Pol\u00edtica de Revisores Esteja aberto para receber feedback Discuta o design/l\u00f3gica do c\u00f3digo e aborde todos os coment\u00e1rios da seguinte forma: Resolva um coment\u00e1rio se a altera\u00e7\u00e3o solicitada foi feita. Marque o coment\u00e1rio como \"n\u00e3o vou corrigir\" se voc\u00ea n\u00e3o pretende fazer as altera\u00e7\u00f5es solicitadas e forne\u00e7a um racioc\u00ednio claro. Se a altera\u00e7\u00e3o solicitada estiver dentro do escopo da tarefa, \"farei mais tarde\" n\u00e3o \u00e9 uma raz\u00e3o aceit\u00e1vel! Se a altera\u00e7\u00e3o solicitada estiver fora do escopo, crie um novo item de trabalho (tarefa ou bug) para ela. Se voc\u00ea n\u00e3o entender um coment\u00e1rio, fa\u00e7a perguntas na pr\u00f3pria revis\u00e3o em vez de iniciar um chat privado. Se uma discuss\u00e3o se estender sem uma conclus\u00e3o, agende uma reuni\u00e3o com o revisor (ligue para eles ou bata \u00e0 porta). Use listas de verifica\u00e7\u00e3o Ao criar um PR, \u00e9 uma boa ideia adicionar uma lista de verifica\u00e7\u00e3o dos objetivos do PR na descri\u00e7\u00e3o. Isso ajuda os revisores a se concentrarem nas \u00e1reas-chave das altera\u00e7\u00f5es de c\u00f3digo. Vincule uma tarefa ao seu PR Vincule os itens de trabalho/tarefas correspondentes ao PR. N\u00e3o \u00e9 necess\u00e1rio duplicar informa\u00e7\u00f5es entre o item de trabalho e o PR, mas se alguns detalhes estiverem faltando em um deles, juntos eles fornecem mais contexto ao revisor. O c\u00f3digo deve ter anota\u00e7\u00f5es antes da revis\u00e3o Se voc\u00ea n\u00e3o puder evitar PRs grandes, inclua explica\u00e7\u00f5es das altera\u00e7\u00f5es para facilitar a revis\u00e3o do c\u00f3digo. Com coment\u00e1rios claros, o revisor pode identificar o objetivo de cada bloco de c\u00f3digo.","title":"Orienta\u00e7\u00f5es para o Autor"},{"location":"code-reviews/process-guidance/author-guidance/#orientacoes-para-o-autor","text":"","title":"Orienta\u00e7\u00f5es para o Autor"},{"location":"code-reviews/process-guidance/author-guidance/#descreva-adequadamente-o-seu-pull-request-pr","text":"D\u00ea ao PR um t\u00edtulo descritivo, para que outros membros possam entender facilmente (em uma frase curta) sobre o que se trata o PR. Todo PR deve ter uma descri\u00e7\u00e3o adequada que mostre ao revisor o que foi alterado e por qu\u00ea.","title":"Descreva adequadamente o seu pull request (PR)"},{"location":"code-reviews/process-guidance/author-guidance/#adicione-revisores-relevantes","text":"Adicione um ou mais revisores (dependendo das diretrizes do seu projeto) ao PR. Idealmente, voc\u00ea adicionaria pelo menos algu\u00e9m que tenha expertise e esteja familiarizado com o projeto ou a linguagem utilizada. Adicionar algu\u00e9m menos familiarizado com o projeto ou a linguagem pode ajudar a verificar se as altera\u00e7\u00f5es s\u00e3o compreens\u00edveis, f\u00e1ceis de ler e aumenta a expertise dentro da equipe. Nos projetos code-with da ISE com uma equipe de cliente, \u00e9 importante incluir revisores de ambas as organiza\u00e7\u00f5es para transfer\u00eancia de conhecimento - Personalize a Pol\u00edtica de Revisores","title":"Adicione revisores relevantes"},{"location":"code-reviews/process-guidance/author-guidance/#esteja-aberto-para-receber-feedback","text":"Discuta o design/l\u00f3gica do c\u00f3digo e aborde todos os coment\u00e1rios da seguinte forma: Resolva um coment\u00e1rio se a altera\u00e7\u00e3o solicitada foi feita. Marque o coment\u00e1rio como \"n\u00e3o vou corrigir\" se voc\u00ea n\u00e3o pretende fazer as altera\u00e7\u00f5es solicitadas e forne\u00e7a um racioc\u00ednio claro. Se a altera\u00e7\u00e3o solicitada estiver dentro do escopo da tarefa, \"farei mais tarde\" n\u00e3o \u00e9 uma raz\u00e3o aceit\u00e1vel! Se a altera\u00e7\u00e3o solicitada estiver fora do escopo, crie um novo item de trabalho (tarefa ou bug) para ela. Se voc\u00ea n\u00e3o entender um coment\u00e1rio, fa\u00e7a perguntas na pr\u00f3pria revis\u00e3o em vez de iniciar um chat privado. Se uma discuss\u00e3o se estender sem uma conclus\u00e3o, agende uma reuni\u00e3o com o revisor (ligue para eles ou bata \u00e0 porta).","title":"Esteja aberto para receber feedback"},{"location":"code-reviews/process-guidance/author-guidance/#use-listas-de-verificacao","text":"Ao criar um PR, \u00e9 uma boa ideia adicionar uma lista de verifica\u00e7\u00e3o dos objetivos do PR na descri\u00e7\u00e3o. Isso ajuda os revisores a se concentrarem nas \u00e1reas-chave das altera\u00e7\u00f5es de c\u00f3digo.","title":"Use listas de verifica\u00e7\u00e3o"},{"location":"code-reviews/process-guidance/author-guidance/#vincule-uma-tarefa-ao-seu-pr","text":"Vincule os itens de trabalho/tarefas correspondentes ao PR. N\u00e3o \u00e9 necess\u00e1rio duplicar informa\u00e7\u00f5es entre o item de trabalho e o PR, mas se alguns detalhes estiverem faltando em um deles, juntos eles fornecem mais contexto ao revisor.","title":"Vincule uma tarefa ao seu PR"},{"location":"code-reviews/process-guidance/author-guidance/#o-codigo-deve-ter-anotacoes-antes-da-revisao","text":"Se voc\u00ea n\u00e3o puder evitar PRs grandes, inclua explica\u00e7\u00f5es das altera\u00e7\u00f5es para facilitar a revis\u00e3o do c\u00f3digo. Com coment\u00e1rios claros, o revisor pode identificar o objetivo de cada bloco de c\u00f3digo.","title":"O c\u00f3digo deve ter anota\u00e7\u00f5es antes da revis\u00e3o"},{"location":"code-reviews/process-guidance/reviewer-guidance/","text":"Orienta\u00e7\u00f5es para o Revisor Uma vez que partes das revis\u00f5es podem ser automatizadas por meio de linters e similares, os revisores humanos podem se concentrar na corre\u00e7\u00e3o arquitetural e funcional. Os revisores humanos devem se concentrar em: A corre\u00e7\u00e3o da l\u00f3gica de neg\u00f3cios incorporada no c\u00f3digo. A corre\u00e7\u00e3o de novos testes ou testes alterados. A \"legibilidade\" e manutenibilidade das decis\u00f5es gerais de design refletidas no c\u00f3digo. A lista de verifica\u00e7\u00e3o de erros comuns mantida pela equipe para cada linguagem de programa\u00e7\u00e3o. As revis\u00f5es de c\u00f3digo devem seguir as orienta\u00e7\u00f5es e listas de verifica\u00e7\u00e3o abaixo para garantir revis\u00f5es de c\u00f3digo positivas e eficazes. Orienta\u00e7\u00f5es gerais Compreenda o c\u00f3digo que voc\u00ea est\u00e1 revisando Leia cada linha alterada. Se tivermos uma revis\u00e3o do interessado, n\u00e3o \u00e9 necess\u00e1rio executar o PR, a menos que isso ajude a entender o c\u00f3digo. O AzDO ordena os arquivos para voc\u00ea, mas voc\u00ea deve ler o c\u00f3digo em alguma sequ\u00eancia l\u00f3gica para facilitar o entendimento. Se voc\u00ea n\u00e3o entender completamente uma altera\u00e7\u00e3o em um arquivo por falta de contexto, clique para visualizar o arquivo completo e leia o c\u00f3digo circundante ou verifique as altera\u00e7\u00f5es e visualize-as no IDE. Pe\u00e7a ao autor para esclarecer. Leve seu tempo e mantenha o foco no escopo Voc\u00ea n\u00e3o deve revisar o c\u00f3digo apressadamente, mas tamb\u00e9m n\u00e3o deve demorar muito em uma \u00fanica sess\u00e3o. Se voc\u00ea tiver muitos pull requests (PRs) para revisar ou se a complexidade do c\u00f3digo for alta, a recomenda\u00e7\u00e3o \u00e9 fazer pausas entre as revis\u00f5es para se recuperar e se concentrar naqueles com os quais voc\u00ea tem mais experi\u00eancia. Lembre-se sempre de que o objetivo de uma revis\u00e3o de c\u00f3digo \u00e9 verificar se os objetivos da tarefa correspondente foram alcan\u00e7ados. Se voc\u00ea tiver preocupa\u00e7\u00f5es com o c\u00f3digo relacionado ou adjacente que n\u00e3o est\u00e1 no escopo do PR, aborde essas preocupa\u00e7\u00f5es como tarefas separadas (por exemplo, bugs ou d\u00edvidas t\u00e9cnicas). N\u00e3o bloqueie o PR atual devido a problemas que est\u00e3o fora do escopo. Fomente uma cultura de revis\u00e3o de c\u00f3digo positiva As revis\u00f5es de c\u00f3digo desempenham um papel cr\u00edtico na qualidade do produto e n\u00e3o devem representar um local para discuss\u00f5es longas ou, pior ainda, uma batalha de egos. O que importa \u00e9 encontrar um erro, n\u00e3o quem o cometeu, n\u00e3o quem o encontrou, n\u00e3o quem o corrigiu. A \u00fanica coisa que importa \u00e9 ter o melhor produto poss\u00edvel. Seja considerado Seja positivo - incentive e aprecie as boas pr\u00e1ticas. Prefira prefixar um \"ponto de polimento\" com \"Ajuste:\". Evite linguagem que aponte o dedo, como \"voc\u00ea\", e use preferencialmente \"n\u00f3s\" ou \"esta linha\" - as revis\u00f5es de c\u00f3digo n\u00e3o s\u00e3o pessoais e a linguagem importa. Prefira fazer perguntas em vez de fazer afirma\u00e7\u00f5es. Pode haver uma boa raz\u00e3o para o autor fazer algo. Se voc\u00ea fizer um coment\u00e1rio direto, explique por que o c\u00f3digo precisa ser alterado, de prefer\u00eancia com um exemplo. Falando em mudan\u00e7as, voc\u00ea pode sugerir altera\u00e7\u00f5es a um PR usando o recurso de sugest\u00e3o (dispon\u00edvel no GitHub e no Azure DevOps) ou criando um PR para o branch do autor. Se alguns coment\u00e1rios de ida e volta n\u00e3o resolverem uma discord\u00e2ncia, conversem rapidamente entre si (pessoalmente ou por telefone) ou crie uma discuss\u00e3o em grupo, o que pode levar a uma s\u00e9rie de melhorias para os pr\u00f3ximos PRs. N\u00e3o se esque\u00e7a de atualizar o PR com o que voc\u00eas concordaram e por qu\u00ea. Primeira an\u00e1lise de design Vis\u00e3o geral do Pull Request A descri\u00e7\u00e3o do PR faz sentido? Todas as altera\u00e7\u00f5es se encaixam logicamente neste PR ou existem altera\u00e7\u00f5es n\u00e3o relacionadas? Se necess\u00e1rio, as altera\u00e7\u00f5es feitas est\u00e3o refletidas nas atualiza\u00e7\u00f5es do README ou em outros documentos? Especialmente se as altera\u00e7\u00f5es afetarem como o usu\u00e1rio compila o c\u00f3digo. Altera\u00e7\u00f5es vis\u00edveis pelo usu\u00e1rio Se o c\u00f3digo envolver uma altera\u00e7\u00e3o vis\u00edvel pelo usu\u00e1rio, h\u00e1 um GIF/foto que explique a funcionalidade? Se n\u00e3o houver, pode ser crucial validar o PR para garantir que a altera\u00e7\u00e3o fa\u00e7a o que \u00e9 esperado. Certifique-se de que as altera\u00e7\u00f5es de interface do usu\u00e1rio pare\u00e7am boas sem comportamentos inesperados. Design As intera\u00e7\u00f5es das v\u00e1rias partes de c\u00f3digo no PR fazem sentido? O c\u00f3digo reconhece e incorpora arquiteturas e padr\u00f5es de codifica\u00e7\u00e3o? An\u00e1lise de Qualidade de C\u00f3digo Complexidade As fun\u00e7\u00f5es s\u00e3o muito complexas? O princ\u00edpio da responsabilidade \u00fanica \u00e9 seguido? Uma fun\u00e7\u00e3o ou classe deve fazer apenas uma 'coisa'. Uma fun\u00e7\u00e3o deve ser dividida em v\u00e1rias fun\u00e7\u00f5es? Se um m\u00e9todo tem mais de 3 argumentos, ele \u00e9 potencialmente excessivamente complexo. O c\u00f3digo adiciona funcionalidade que n\u00e3o \u00e9 necess\u00e1ria? O c\u00f3digo pode ser facilmente compreendido pelos leitores de c\u00f3digo? Nomea\u00e7\u00e3o/legibilidade O desenvolvedor escolheu bons nomes para fun\u00e7\u00f5es, vari\u00e1veis, etc.? Tratamento de Erros Os erros s\u00e3o tratados com eleg\u00e2ncia e de forma expl\u00edcita quando necess\u00e1rio? Funcionalidade H\u00e1 programa\u00e7\u00e3o paralela neste PR que pode causar condi\u00e7\u00f5es de corrida? Leia atentamente essa l\u00f3gica. O c\u00f3digo pode ser otimizado? Por exemplo: existem mais chamadas ao banco de dados do que o necess\u00e1rio? Como a funcionalidade se encaixa na imagem maior? Pode ter efeitos negativos no sistema como um todo? Existem falhas de seguran\u00e7a? O nome de uma vari\u00e1vel revela alguma informa\u00e7\u00e3o espec\u00edfica do cliente? PII (Informa\u00e7\u00f5es Pessoais Identific\u00e1veis) e EUII (Informa\u00e7\u00f5es Empresariais Identific\u00e1veis) s\u00e3o tratados corretamente? Estamos registrando informa\u00e7\u00f5es PII? Estilo Existem coment\u00e1rios desnecess\u00e1rios? Se o c\u00f3digo n\u00e3o for claro o suficiente para se explicar, ent\u00e3o o c\u00f3digo deve ser simplificado. Os coment\u00e1rios podem estar l\u00e1 para explicar por que algum c\u00f3digo existe. O c\u00f3digo segue o guia de estilo/conven\u00e7\u00f5es que acordamos? Usamos formata\u00e7\u00e3o autom\u00e1tica como black e prettier. Testes Os testes sempre devem ser inclu\u00eddos no mesmo PR que o c\u00f3digo em si (\"Vou adicionar testes depois\" n\u00e3o \u00e9 aceit\u00e1vel). Certifique-se de que os testes sejam sensatos e que sejam feitas suposi\u00e7\u00f5es v\u00e1lidas. Certifique-se de que os casos limite sejam tratados tamb\u00e9m. Os testes podem ser uma \u00f3tima fonte para entender as altera\u00e7\u00f5es. Pode ser uma estrat\u00e9gia olhar primeiro os testes para ajudar a entender melhor as altera\u00e7\u00f5es.","title":"Orienta\u00e7\u00f5es para o Revisor"},{"location":"code-reviews/process-guidance/reviewer-guidance/#orientacoes-para-o-revisor","text":"Uma vez que partes das revis\u00f5es podem ser automatizadas por meio de linters e similares, os revisores humanos podem se concentrar na corre\u00e7\u00e3o arquitetural e funcional. Os revisores humanos devem se concentrar em: A corre\u00e7\u00e3o da l\u00f3gica de neg\u00f3cios incorporada no c\u00f3digo. A corre\u00e7\u00e3o de novos testes ou testes alterados. A \"legibilidade\" e manutenibilidade das decis\u00f5es gerais de design refletidas no c\u00f3digo. A lista de verifica\u00e7\u00e3o de erros comuns mantida pela equipe para cada linguagem de programa\u00e7\u00e3o. As revis\u00f5es de c\u00f3digo devem seguir as orienta\u00e7\u00f5es e listas de verifica\u00e7\u00e3o abaixo para garantir revis\u00f5es de c\u00f3digo positivas e eficazes.","title":"Orienta\u00e7\u00f5es para o Revisor"},{"location":"code-reviews/process-guidance/reviewer-guidance/#orientacoes-gerais","text":"","title":"Orienta\u00e7\u00f5es gerais"},{"location":"code-reviews/process-guidance/reviewer-guidance/#compreenda-o-codigo-que-voce-esta-revisando","text":"Leia cada linha alterada. Se tivermos uma revis\u00e3o do interessado, n\u00e3o \u00e9 necess\u00e1rio executar o PR, a menos que isso ajude a entender o c\u00f3digo. O AzDO ordena os arquivos para voc\u00ea, mas voc\u00ea deve ler o c\u00f3digo em alguma sequ\u00eancia l\u00f3gica para facilitar o entendimento. Se voc\u00ea n\u00e3o entender completamente uma altera\u00e7\u00e3o em um arquivo por falta de contexto, clique para visualizar o arquivo completo e leia o c\u00f3digo circundante ou verifique as altera\u00e7\u00f5es e visualize-as no IDE. Pe\u00e7a ao autor para esclarecer.","title":"Compreenda o c\u00f3digo que voc\u00ea est\u00e1 revisando"},{"location":"code-reviews/process-guidance/reviewer-guidance/#leve-seu-tempo-e-mantenha-o-foco-no-escopo","text":"Voc\u00ea n\u00e3o deve revisar o c\u00f3digo apressadamente, mas tamb\u00e9m n\u00e3o deve demorar muito em uma \u00fanica sess\u00e3o. Se voc\u00ea tiver muitos pull requests (PRs) para revisar ou se a complexidade do c\u00f3digo for alta, a recomenda\u00e7\u00e3o \u00e9 fazer pausas entre as revis\u00f5es para se recuperar e se concentrar naqueles com os quais voc\u00ea tem mais experi\u00eancia. Lembre-se sempre de que o objetivo de uma revis\u00e3o de c\u00f3digo \u00e9 verificar se os objetivos da tarefa correspondente foram alcan\u00e7ados. Se voc\u00ea tiver preocupa\u00e7\u00f5es com o c\u00f3digo relacionado ou adjacente que n\u00e3o est\u00e1 no escopo do PR, aborde essas preocupa\u00e7\u00f5es como tarefas separadas (por exemplo, bugs ou d\u00edvidas t\u00e9cnicas). N\u00e3o bloqueie o PR atual devido a problemas que est\u00e3o fora do escopo.","title":"Leve seu tempo e mantenha o foco no escopo"},{"location":"code-reviews/process-guidance/reviewer-guidance/#fomente-uma-cultura-de-revisao-de-codigo-positiva","text":"As revis\u00f5es de c\u00f3digo desempenham um papel cr\u00edtico na qualidade do produto e n\u00e3o devem representar um local para discuss\u00f5es longas ou, pior ainda, uma batalha de egos. O que importa \u00e9 encontrar um erro, n\u00e3o quem o cometeu, n\u00e3o quem o encontrou, n\u00e3o quem o corrigiu. A \u00fanica coisa que importa \u00e9 ter o melhor produto poss\u00edvel.","title":"Fomente uma cultura de revis\u00e3o de c\u00f3digo positiva"},{"location":"code-reviews/process-guidance/reviewer-guidance/#seja-considerado","text":"Seja positivo - incentive e aprecie as boas pr\u00e1ticas. Prefira prefixar um \"ponto de polimento\" com \"Ajuste:\". Evite linguagem que aponte o dedo, como \"voc\u00ea\", e use preferencialmente \"n\u00f3s\" ou \"esta linha\" - as revis\u00f5es de c\u00f3digo n\u00e3o s\u00e3o pessoais e a linguagem importa. Prefira fazer perguntas em vez de fazer afirma\u00e7\u00f5es. Pode haver uma boa raz\u00e3o para o autor fazer algo. Se voc\u00ea fizer um coment\u00e1rio direto, explique por que o c\u00f3digo precisa ser alterado, de prefer\u00eancia com um exemplo. Falando em mudan\u00e7as, voc\u00ea pode sugerir altera\u00e7\u00f5es a um PR usando o recurso de sugest\u00e3o (dispon\u00edvel no GitHub e no Azure DevOps) ou criando um PR para o branch do autor. Se alguns coment\u00e1rios de ida e volta n\u00e3o resolverem uma discord\u00e2ncia, conversem rapidamente entre si (pessoalmente ou por telefone) ou crie uma discuss\u00e3o em grupo, o que pode levar a uma s\u00e9rie de melhorias para os pr\u00f3ximos PRs. N\u00e3o se esque\u00e7a de atualizar o PR com o que voc\u00eas concordaram e por qu\u00ea.","title":"Seja considerado"},{"location":"code-reviews/process-guidance/reviewer-guidance/#primeira-analise-de-design","text":"","title":"Primeira an\u00e1lise de design"},{"location":"code-reviews/process-guidance/reviewer-guidance/#visao-geral-do-pull-request","text":"A descri\u00e7\u00e3o do PR faz sentido? Todas as altera\u00e7\u00f5es se encaixam logicamente neste PR ou existem altera\u00e7\u00f5es n\u00e3o relacionadas? Se necess\u00e1rio, as altera\u00e7\u00f5es feitas est\u00e3o refletidas nas atualiza\u00e7\u00f5es do README ou em outros documentos? Especialmente se as altera\u00e7\u00f5es afetarem como o usu\u00e1rio compila o c\u00f3digo.","title":"Vis\u00e3o geral do Pull Request"},{"location":"code-reviews/process-guidance/reviewer-guidance/#alteracoes-visiveis-pelo-usuario","text":"Se o c\u00f3digo envolver uma altera\u00e7\u00e3o vis\u00edvel pelo usu\u00e1rio, h\u00e1 um GIF/foto que explique a funcionalidade? Se n\u00e3o houver, pode ser crucial validar o PR para garantir que a altera\u00e7\u00e3o fa\u00e7a o que \u00e9 esperado. Certifique-se de que as altera\u00e7\u00f5es de interface do usu\u00e1rio pare\u00e7am boas sem comportamentos inesperados.","title":"Altera\u00e7\u00f5es vis\u00edveis pelo usu\u00e1rio"},{"location":"code-reviews/process-guidance/reviewer-guidance/#design","text":"As intera\u00e7\u00f5es das v\u00e1rias partes de c\u00f3digo no PR fazem sentido? O c\u00f3digo reconhece e incorpora arquiteturas e padr\u00f5es de codifica\u00e7\u00e3o?","title":"Design"},{"location":"code-reviews/process-guidance/reviewer-guidance/#analise-de-qualidade-de-codigo","text":"","title":"An\u00e1lise de Qualidade de C\u00f3digo"},{"location":"code-reviews/process-guidance/reviewer-guidance/#complexidade","text":"As fun\u00e7\u00f5es s\u00e3o muito complexas? O princ\u00edpio da responsabilidade \u00fanica \u00e9 seguido? Uma fun\u00e7\u00e3o ou classe deve fazer apenas uma 'coisa'. Uma fun\u00e7\u00e3o deve ser dividida em v\u00e1rias fun\u00e7\u00f5es? Se um m\u00e9todo tem mais de 3 argumentos, ele \u00e9 potencialmente excessivamente complexo. O c\u00f3digo adiciona funcionalidade que n\u00e3o \u00e9 necess\u00e1ria? O c\u00f3digo pode ser facilmente compreendido pelos leitores de c\u00f3digo?","title":"Complexidade"},{"location":"code-reviews/process-guidance/reviewer-guidance/#nomeacaolegibilidade","text":"O desenvolvedor escolheu bons nomes para fun\u00e7\u00f5es, vari\u00e1veis, etc.?","title":"Nomea\u00e7\u00e3o/legibilidade"},{"location":"code-reviews/process-guidance/reviewer-guidance/#tratamento-de-erros","text":"Os erros s\u00e3o tratados com eleg\u00e2ncia e de forma expl\u00edcita quando necess\u00e1rio?","title":"Tratamento de Erros"},{"location":"code-reviews/process-guidance/reviewer-guidance/#funcionalidade","text":"H\u00e1 programa\u00e7\u00e3o paralela neste PR que pode causar condi\u00e7\u00f5es de corrida? Leia atentamente essa l\u00f3gica. O c\u00f3digo pode ser otimizado? Por exemplo: existem mais chamadas ao banco de dados do que o necess\u00e1rio? Como a funcionalidade se encaixa na imagem maior? Pode ter efeitos negativos no sistema como um todo? Existem falhas de seguran\u00e7a? O nome de uma vari\u00e1vel revela alguma informa\u00e7\u00e3o espec\u00edfica do cliente? PII (Informa\u00e7\u00f5es Pessoais Identific\u00e1veis) e EUII (Informa\u00e7\u00f5es Empresariais Identific\u00e1veis) s\u00e3o tratados corretamente? Estamos registrando informa\u00e7\u00f5es PII?","title":"Funcionalidade"},{"location":"code-reviews/process-guidance/reviewer-guidance/#estilo","text":"Existem coment\u00e1rios desnecess\u00e1rios? Se o c\u00f3digo n\u00e3o for claro o suficiente para se explicar, ent\u00e3o o c\u00f3digo deve ser simplificado. Os coment\u00e1rios podem estar l\u00e1 para explicar por que algum c\u00f3digo existe. O c\u00f3digo segue o guia de estilo/conven\u00e7\u00f5es que acordamos? Usamos formata\u00e7\u00e3o autom\u00e1tica como black e prettier.","title":"Estilo"},{"location":"code-reviews/process-guidance/reviewer-guidance/#testes","text":"Os testes sempre devem ser inclu\u00eddos no mesmo PR que o c\u00f3digo em si (\"Vou adicionar testes depois\" n\u00e3o \u00e9 aceit\u00e1vel). Certifique-se de que os testes sejam sensatos e que sejam feitas suposi\u00e7\u00f5es v\u00e1lidas. Certifique-se de que os casos limite sejam tratados tamb\u00e9m. Os testes podem ser uma \u00f3tima fonte para entender as altera\u00e7\u00f5es. Pode ser uma estrat\u00e9gia olhar primeiro os testes para ajudar a entender melhor as altera\u00e7\u00f5es.","title":"Testes"},{"location":"code-reviews/pull-request-template/pull-request-template/","text":"Nro do Ticket do Jira Para obter mais informa\u00e7\u00f5es sobre como contribuir para este reposit\u00f3rio, visite esta p\u00e1gina . Descri\u00e7\u00e3o Deve incluir uma descri\u00e7\u00e3o concisa das altera\u00e7\u00f5es (bug ou recurso), seu impacto, juntamente com um resumo da solu\u00e7\u00e3o. Passos para Reproduzir o Bug e Validar a Solu\u00e7\u00e3o Somente aplic\u00e1vel se o trabalho for para corrigir um bug. Por favor, remova esta se\u00e7\u00e3o se o trabalho for para um recurso ou hist\u00f3ria. Forne\u00e7a detalhes sobre o ambiente em que o bug foi encontrado e os passos detalhados para reproduzir o bug. Isso deve ser detalhado o suficiente para que um membro da equipe possa confirmar que o bug n\u00e3o ocorre mais. Lista de Verifica\u00e7\u00e3o do PR Use a lista de verifica\u00e7\u00e3o abaixo para garantir que seu branch esteja pronto para PR. Se o item n\u00e3o se aplicar, deixe-o em branco. Atualizei a documenta\u00e7\u00e3o de acordo. Adicionei testes para cobrir minhas altera\u00e7\u00f5es. Todos os testes novos e existentes passaram. Meu c\u00f3digo segue o estilo de c\u00f3digo deste projeto. Executei as verifica\u00e7\u00f5es de lint que n\u00e3o produziram novos erros nem avisos para minhas altera\u00e7\u00f5es. Verifiquei se n\u00e3o h\u00e1 outros Pull Requests abertos para a mesma atualiza\u00e7\u00e3o/altera\u00e7\u00e3o. Isso introduz uma altera\u00e7\u00e3o que quebra a compatibilidade? Sim N\u00e3o Se isso introduzir uma altera\u00e7\u00e3o que quebra a compatibilidade, descreva o impacto e o caminho de migra\u00e7\u00e3o para aplicativos existentes abaixo. Testes Instru\u00e7\u00f5es para teste e valida\u00e7\u00e3o do seu c\u00f3digo: Qual sistema operacional foi usado para testar. Quais conjuntos de testes foram usados. Descri\u00e7\u00e3o dos cen\u00e1rios de teste que voc\u00ea experimentou. Registros ou sa\u00eddas relevantes Use esta se\u00e7\u00e3o para anexar imagens que demonstrem seu c\u00f3digo funcionando/funcionando corretamente. Se voc\u00ea estiver imprimindo algo, mostre uma captura de tela. Quando quiser compartilhar registros longos, fa\u00e7a o upload para: (ContaDeArmazenamento)/pr-support/anexos/(N\u00fameroDoPR)/(seusArquivos) usando o Azure Storage Explorer ou portal.azure.com e insira o link aqui. Outras informa\u00e7\u00f5es ou depend\u00eancias conhecidas Qualquer outra informa\u00e7\u00e3o ou depend\u00eancias conhecidas que sejam importantes para este PR. Tarefas a fazer ap\u00f3s este PR.","title":"[Nro do Ticket do Jira](./link-para-o-item-de-trabalho)"},{"location":"code-reviews/pull-request-template/pull-request-template/#nro-do-ticket-do-jira","text":"Para obter mais informa\u00e7\u00f5es sobre como contribuir para este reposit\u00f3rio, visite esta p\u00e1gina .","title":"Nro do Ticket do Jira"},{"location":"code-reviews/pull-request-template/pull-request-template/#descricao","text":"Deve incluir uma descri\u00e7\u00e3o concisa das altera\u00e7\u00f5es (bug ou recurso), seu impacto, juntamente com um resumo da solu\u00e7\u00e3o.","title":"Descri\u00e7\u00e3o"},{"location":"code-reviews/pull-request-template/pull-request-template/#passos-para-reproduzir-o-bug-e-validar-a-solucao","text":"Somente aplic\u00e1vel se o trabalho for para corrigir um bug. Por favor, remova esta se\u00e7\u00e3o se o trabalho for para um recurso ou hist\u00f3ria. Forne\u00e7a detalhes sobre o ambiente em que o bug foi encontrado e os passos detalhados para reproduzir o bug. Isso deve ser detalhado o suficiente para que um membro da equipe possa confirmar que o bug n\u00e3o ocorre mais.","title":"Passos para Reproduzir o Bug e Validar a Solu\u00e7\u00e3o"},{"location":"code-reviews/pull-request-template/pull-request-template/#lista-de-verificacao-do-pr","text":"Use a lista de verifica\u00e7\u00e3o abaixo para garantir que seu branch esteja pronto para PR. Se o item n\u00e3o se aplicar, deixe-o em branco. Atualizei a documenta\u00e7\u00e3o de acordo. Adicionei testes para cobrir minhas altera\u00e7\u00f5es. Todos os testes novos e existentes passaram. Meu c\u00f3digo segue o estilo de c\u00f3digo deste projeto. Executei as verifica\u00e7\u00f5es de lint que n\u00e3o produziram novos erros nem avisos para minhas altera\u00e7\u00f5es. Verifiquei se n\u00e3o h\u00e1 outros Pull Requests abertos para a mesma atualiza\u00e7\u00e3o/altera\u00e7\u00e3o.","title":"Lista de Verifica\u00e7\u00e3o do PR"},{"location":"code-reviews/pull-request-template/pull-request-template/#isso-introduz-uma-alteracao-que-quebra-a-compatibilidade","text":"Sim N\u00e3o Se isso introduzir uma altera\u00e7\u00e3o que quebra a compatibilidade, descreva o impacto e o caminho de migra\u00e7\u00e3o para aplicativos existentes abaixo.","title":"Isso introduz uma altera\u00e7\u00e3o que quebra a compatibilidade?"},{"location":"code-reviews/pull-request-template/pull-request-template/#testes","text":"Instru\u00e7\u00f5es para teste e valida\u00e7\u00e3o do seu c\u00f3digo: Qual sistema operacional foi usado para testar. Quais conjuntos de testes foram usados. Descri\u00e7\u00e3o dos cen\u00e1rios de teste que voc\u00ea experimentou.","title":"Testes"},{"location":"code-reviews/pull-request-template/pull-request-template/#registros-ou-saidas-relevantes","text":"Use esta se\u00e7\u00e3o para anexar imagens que demonstrem seu c\u00f3digo funcionando/funcionando corretamente. Se voc\u00ea estiver imprimindo algo, mostre uma captura de tela. Quando quiser compartilhar registros longos, fa\u00e7a o upload para: (ContaDeArmazenamento)/pr-support/anexos/(N\u00fameroDoPR)/(seusArquivos) usando o Azure Storage Explorer ou portal.azure.com e insira o link aqui.","title":"Registros ou sa\u00eddas relevantes"},{"location":"code-reviews/pull-request-template/pull-request-template/#outras-informacoes-ou-dependencias-conhecidas","text":"Qualquer outra informa\u00e7\u00e3o ou depend\u00eancias conhecidas que sejam importantes para este PR. Tarefas a fazer ap\u00f3s este PR.","title":"Outras informa\u00e7\u00f5es ou depend\u00eancias conhecidas"},{"location":"code-reviews/recipes/","text":"Orienta\u00e7\u00f5es Espec\u00edficas da Linguagem Bash C# Go Java JavaScript e TypeScript Markdown Python Terraform YAML (Azure Pipelines)","title":"Orienta\u00e7\u00f5es Espec\u00edficas da Linguagem"},{"location":"code-reviews/recipes/#orientacoes-especificas-da-linguagem","text":"Bash C# Go Java JavaScript e TypeScript Markdown Python Terraform YAML (Azure Pipelines)","title":"Orienta\u00e7\u00f5es Espec\u00edficas da Linguagem"},{"location":"code-reviews/recipes/azure-pipelines-yaml/","text":"Revis\u00e3o de C\u00f3digo YAML (Azure Pipelines) Guia de Estilo Os desenvolvedores devem seguir a refer\u00eancia do esquema YAML . An\u00e1lise de C\u00f3digo / Linting O linter YAML mais popular \u00e9 a extens\u00e3o YAML . Esta extens\u00e3o fornece valida\u00e7\u00e3o YAML, destaque de documentos, auto-completar, suporte de hover e recursos de formata\u00e7\u00e3o. Extens\u00f5es do VS Code Existe uma extens\u00e3o Azure Pipelines para o VS Code para adicionar realce de sintaxe e autocompletar para o YAML das Pipelines do Azure no VS Code. Ele tamb\u00e9m ajuda a configurar compila\u00e7\u00e3o e implanta\u00e7\u00e3o cont\u00ednuas para aplicativos da Web do Azure sem sair do VS Code. Vis\u00e3o Geral do YAML nas Pipelines do Azure Quando a pipeline \u00e9 acionada, antes de executar a pipeline, existem algumas fases, como Tempo de Fila, Tempo de Compila\u00e7\u00e3o e Tempo de Execu\u00e7\u00e3o , onde as vari\u00e1veis s\u00e3o interpretadas pelo sintaxe de express\u00e3o em tempo de execu\u00e7\u00e3o . Quando a pipeline \u00e9 acionada, todos os arquivos YAML aninhados s\u00e3o expandidos para serem executados nas Pipelines do Azure. Esta lista de verifica\u00e7\u00e3o cont\u00e9m algumas dicas para revisar todos os arquivos YAML aninhados. Estes documentos podem ser \u00fateis ao revisar os arquivos YAML: Documenta\u00e7\u00e3o YAML das Pipelines do Azure . Sequ\u00eancia de execu\u00e7\u00e3o da pipeline Principais conceitos para as novas Pipelines do Azure Vis\u00e3o geral dos principais conceitos das Pipelines do Azure Um acionador diz a uma Pipeline para ser executada. Uma pipeline \u00e9 composta por um ou mais est\u00e1gios. Uma pipeline pode ser implantada em um ou mais ambientes. Um est\u00e1gio \u00e9 uma maneira de organizar trabalhos em uma pipeline e cada est\u00e1gio pode ter um ou mais trabalhos. Cada trabalho \u00e9 executado em um agente. Um trabalho tamb\u00e9m pode ser sem agente. Cada agente executa um trabalho que cont\u00e9m uma ou mais etapas. Uma etapa pode ser uma tarefa ou um script e \u00e9 a menor unidade de constru\u00e7\u00e3o de uma pipeline. Uma tarefa \u00e9 um script pr\u00e9-empacotado que realiza uma a\u00e7\u00e3o, como invocar uma API REST ou publicar um artefato de compila\u00e7\u00e3o. Um artefato \u00e9 uma cole\u00e7\u00e3o de arquivos ou pacotes publicados por uma execu\u00e7\u00e3o. Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo Al\u00e9m da Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos da revis\u00e3o de c\u00f3digo YAML das Pipelines do Azure. Estrutura da Pipeline Os passos s\u00e3o bem compreendidos e os componentes s\u00e3o facilmente identific\u00e1veis. Certifique-se de que h\u00e1 uma descri\u00e7\u00e3o adequada displayName: para cada etapa na pipeline. Etapas/est\u00e1gios da pipeline s\u00e3o verificados nas Pipelines do Azure para ter uma compreens\u00e3o maior dos componentes. No caso de ter arquivos YAML aninhados complexos, a pipeline nas Pipelines do Azure \u00e9 editada para encontrar o arquivo raiz do acionador. Todas as refer\u00eancias de arquivos de modelo s\u00e3o visitadas para garantir que uma pequena altera\u00e7\u00e3o n\u00e3o cause altera\u00e7\u00f5es quebradas, alterar um arquivo pode afetar v\u00e1rias pipelines Scripts longos incorporados no arquivo YAML s\u00e3o movidos para arquivos de script Estrutura YAML Componentes reutiliz\u00e1veis s\u00e3o divididos em modelos YAML separados. Vari\u00e1veis s\u00e3o separadas por ambiente armazenadas em modelos ou grupos de vari\u00e1veis. Mudan\u00e7as de valor de vari\u00e1vel em Tempo de Fila , Tempo de Compila\u00e7\u00e3o e Tempo de Execu\u00e7\u00e3o s\u00e3o consideradas. Valores de sintaxe de vari\u00e1vel usados com Sintaxe de Macro , Sintaxe de Express\u00e3o de Modelo e Sintaxe de Express\u00e3o em Tempo de Execu\u00e7\u00e3o s\u00e3o considerados. Vari\u00e1veis n\u00e3o utilizadas/par\u00e2metros s\u00e3o removidos na pipeline. A pipeline atende aos crit\u00e9rios de Condi\u00e7\u00f5es do est\u00e1gio/trabalho? Verifica\u00e7\u00e3o de Permiss\u00e3o e Seguran\u00e7a Valores secretos n\u00e3o devem ser impressos na pipeline, issecret \u00e9 usado para imprimir segredos para depura\u00e7\u00e3o. Se a pipeline estiver usando grupos de vari\u00e1veis na Biblioteca, verifique se a pipeline tem acesso aos grupos de vari\u00e1veis criados. Se a pipeline tiver uma tarefa remota em outro reposit\u00f3rio/organiza\u00e7\u00e3o, ela tem acesso? Se a pipeline estiver tentando acessar um arquivo seguro, ela tem permiss\u00e3o? Se a pipeline exigir aprova\u00e7\u00e3o para implanta\u00e7\u00f5es em ambientes, quem \u00e9 o aprovador? \u00c9 necess\u00e1rio manter segredos e gerenci\u00e1-los, voc\u00ea considerou o uso do Azure KeyVault? Dicas de Solu\u00e7\u00e3o de Problemas Considere a Sintaxe de Vari\u00e1vel com Express\u00f5es em Tempo de Execu\u00e7\u00e3o na pipeline. Aqui est\u00e1 um bom exemplo para entender a Expans\u00e3o de vari\u00e1veis . Quando atribu\u00edmos uma vari\u00e1vel como abaixo, ela n\u00e3o ser\u00e1 definida durante o tempo de inicializa\u00e7\u00e3o, ser\u00e1 atribu\u00edda durante a execu\u00e7\u00e3o, e ent\u00e3o podemos recuperar alguns er ros com base no momento em que o modelo \u00e9 executado. - task : AzureWebApp@1 displayName : 'Implantar Azure Web App : $(webAppName)' inputs : azureSubscription : '$(azureServiceConnectionId)' appName : '$(webAppName)' package : $(Pipeline.Workspace)/drop/Application$(Build.BuildId).zip startUpCommand : 'gunicorn --bind=0.0.0.0 --workers=4 app:app' Erro: Ap\u00f3s passar essas vari\u00e1veis como par\u00e2metro, ela carrega os valores corretamente. - template : steps-deployment.yaml parameters : azureServiceConnectionId : ${{ variables.azureServiceConnectionId }} webAppName : ${{ variables.webAppName }} - task : AzureWebApp@1 displayName : 'Implantar Azure Web App :${{ parameters.webAppName }}' inputs : azureSubscription : '${{ parameters.azureServiceConnectionId }}' appName : '${{ parameters.webAppName }}' package : $(Pipeline.Workspace)/drop/Application$(Build.BuildId).zip startUpCommand : 'gunicorn --bind=0.0.0.0 --workers=4 app:app' Use issecret para imprimir segredos para depura\u00e7\u00e3o echo \"##vso[task.setvariable variable=token;issecret=true] ${ token } \"","title":"Revis\u00e3o de C\u00f3digo YAML (Azure Pipelines)"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#revisao-de-codigo-yaml-azure-pipelines","text":"","title":"Revis\u00e3o de C\u00f3digo YAML (Azure Pipelines)"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#guia-de-estilo","text":"Os desenvolvedores devem seguir a refer\u00eancia do esquema YAML .","title":"Guia de Estilo"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#analise-de-codigo-linting","text":"O linter YAML mais popular \u00e9 a extens\u00e3o YAML . Esta extens\u00e3o fornece valida\u00e7\u00e3o YAML, destaque de documentos, auto-completar, suporte de hover e recursos de formata\u00e7\u00e3o.","title":"An\u00e1lise de C\u00f3digo / Linting"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#extensoes-do-vs-code","text":"Existe uma extens\u00e3o Azure Pipelines para o VS Code para adicionar realce de sintaxe e autocompletar para o YAML das Pipelines do Azure no VS Code. Ele tamb\u00e9m ajuda a configurar compila\u00e7\u00e3o e implanta\u00e7\u00e3o cont\u00ednuas para aplicativos da Web do Azure sem sair do VS Code.","title":"Extens\u00f5es do VS Code"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#visao-geral-do-yaml-nas-pipelines-do-azure","text":"Quando a pipeline \u00e9 acionada, antes de executar a pipeline, existem algumas fases, como Tempo de Fila, Tempo de Compila\u00e7\u00e3o e Tempo de Execu\u00e7\u00e3o , onde as vari\u00e1veis s\u00e3o interpretadas pelo sintaxe de express\u00e3o em tempo de execu\u00e7\u00e3o . Quando a pipeline \u00e9 acionada, todos os arquivos YAML aninhados s\u00e3o expandidos para serem executados nas Pipelines do Azure. Esta lista de verifica\u00e7\u00e3o cont\u00e9m algumas dicas para revisar todos os arquivos YAML aninhados. Estes documentos podem ser \u00fateis ao revisar os arquivos YAML: Documenta\u00e7\u00e3o YAML das Pipelines do Azure . Sequ\u00eancia de execu\u00e7\u00e3o da pipeline Principais conceitos para as novas Pipelines do Azure Vis\u00e3o geral dos principais conceitos das Pipelines do Azure Um acionador diz a uma Pipeline para ser executada. Uma pipeline \u00e9 composta por um ou mais est\u00e1gios. Uma pipeline pode ser implantada em um ou mais ambientes. Um est\u00e1gio \u00e9 uma maneira de organizar trabalhos em uma pipeline e cada est\u00e1gio pode ter um ou mais trabalhos. Cada trabalho \u00e9 executado em um agente. Um trabalho tamb\u00e9m pode ser sem agente. Cada agente executa um trabalho que cont\u00e9m uma ou mais etapas. Uma etapa pode ser uma tarefa ou um script e \u00e9 a menor unidade de constru\u00e7\u00e3o de uma pipeline. Uma tarefa \u00e9 um script pr\u00e9-empacotado que realiza uma a\u00e7\u00e3o, como invocar uma API REST ou publicar um artefato de compila\u00e7\u00e3o. Um artefato \u00e9 uma cole\u00e7\u00e3o de arquivos ou pacotes publicados por uma execu\u00e7\u00e3o.","title":"Vis\u00e3o Geral do YAML nas Pipelines do Azure"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#lista-de-verificacao-de-revisao-de-codigo","text":"Al\u00e9m da Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos da revis\u00e3o de c\u00f3digo YAML das Pipelines do Azure.","title":"Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#estrutura-da-pipeline","text":"Os passos s\u00e3o bem compreendidos e os componentes s\u00e3o facilmente identific\u00e1veis. Certifique-se de que h\u00e1 uma descri\u00e7\u00e3o adequada displayName: para cada etapa na pipeline. Etapas/est\u00e1gios da pipeline s\u00e3o verificados nas Pipelines do Azure para ter uma compreens\u00e3o maior dos componentes. No caso de ter arquivos YAML aninhados complexos, a pipeline nas Pipelines do Azure \u00e9 editada para encontrar o arquivo raiz do acionador. Todas as refer\u00eancias de arquivos de modelo s\u00e3o visitadas para garantir que uma pequena altera\u00e7\u00e3o n\u00e3o cause altera\u00e7\u00f5es quebradas, alterar um arquivo pode afetar v\u00e1rias pipelines Scripts longos incorporados no arquivo YAML s\u00e3o movidos para arquivos de script","title":"Estrutura da Pipeline"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#estrutura-yaml","text":"Componentes reutiliz\u00e1veis s\u00e3o divididos em modelos YAML separados. Vari\u00e1veis s\u00e3o separadas por ambiente armazenadas em modelos ou grupos de vari\u00e1veis. Mudan\u00e7as de valor de vari\u00e1vel em Tempo de Fila , Tempo de Compila\u00e7\u00e3o e Tempo de Execu\u00e7\u00e3o s\u00e3o consideradas. Valores de sintaxe de vari\u00e1vel usados com Sintaxe de Macro , Sintaxe de Express\u00e3o de Modelo e Sintaxe de Express\u00e3o em Tempo de Execu\u00e7\u00e3o s\u00e3o considerados. Vari\u00e1veis n\u00e3o utilizadas/par\u00e2metros s\u00e3o removidos na pipeline. A pipeline atende aos crit\u00e9rios de Condi\u00e7\u00f5es do est\u00e1gio/trabalho?","title":"Estrutura YAML"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#verificacao-de-permissao-e-seguranca","text":"Valores secretos n\u00e3o devem ser impressos na pipeline, issecret \u00e9 usado para imprimir segredos para depura\u00e7\u00e3o. Se a pipeline estiver usando grupos de vari\u00e1veis na Biblioteca, verifique se a pipeline tem acesso aos grupos de vari\u00e1veis criados. Se a pipeline tiver uma tarefa remota em outro reposit\u00f3rio/organiza\u00e7\u00e3o, ela tem acesso? Se a pipeline estiver tentando acessar um arquivo seguro, ela tem permiss\u00e3o? Se a pipeline exigir aprova\u00e7\u00e3o para implanta\u00e7\u00f5es em ambientes, quem \u00e9 o aprovador? \u00c9 necess\u00e1rio manter segredos e gerenci\u00e1-los, voc\u00ea considerou o uso do Azure KeyVault?","title":"Verifica\u00e7\u00e3o de Permiss\u00e3o e Seguran\u00e7a"},{"location":"code-reviews/recipes/azure-pipelines-yaml/#dicas-de-solucao-de-problemas","text":"Considere a Sintaxe de Vari\u00e1vel com Express\u00f5es em Tempo de Execu\u00e7\u00e3o na pipeline. Aqui est\u00e1 um bom exemplo para entender a Expans\u00e3o de vari\u00e1veis . Quando atribu\u00edmos uma vari\u00e1vel como abaixo, ela n\u00e3o ser\u00e1 definida durante o tempo de inicializa\u00e7\u00e3o, ser\u00e1 atribu\u00edda durante a execu\u00e7\u00e3o, e ent\u00e3o podemos recuperar alguns er ros com base no momento em que o modelo \u00e9 executado. - task : AzureWebApp@1 displayName : 'Implantar Azure Web App : $(webAppName)' inputs : azureSubscription : '$(azureServiceConnectionId)' appName : '$(webAppName)' package : $(Pipeline.Workspace)/drop/Application$(Build.BuildId).zip startUpCommand : 'gunicorn --bind=0.0.0.0 --workers=4 app:app' Erro: Ap\u00f3s passar essas vari\u00e1veis como par\u00e2metro, ela carrega os valores corretamente. - template : steps-deployment.yaml parameters : azureServiceConnectionId : ${{ variables.azureServiceConnectionId }} webAppName : ${{ variables.webAppName }} - task : AzureWebApp@1 displayName : 'Implantar Azure Web App :${{ parameters.webAppName }}' inputs : azureSubscription : '${{ parameters.azureServiceConnectionId }}' appName : '${{ parameters.webAppName }}' package : $(Pipeline.Workspace)/drop/Application$(Build.BuildId).zip startUpCommand : 'gunicorn --bind=0.0.0.0 --workers=4 app:app' Use issecret para imprimir segredos para depura\u00e7\u00e3o echo \"##vso[task.setvariable variable=token;issecret=true] ${ token } \"","title":"Dicas de Solu\u00e7\u00e3o de Problemas"},{"location":"code-reviews/recipes/bash/","text":"Revis\u00e3o de C\u00f3digo em Bash Guia de Estilo Os desenvolvedores devem seguir o Guia de Estilo Bash do Google . An\u00e1lise de C\u00f3digo / Linting Projetos devem verificar o c\u00f3digo Bash com o shellcheck como parte do processo de CI . Al\u00e9m do linting, shfmt pode ser usado para formatar automaticamente scripts shell. Existem algumas extens\u00f5es de c\u00f3digo do vscode baseadas no shfmt, como shell-format, que podem ser usadas para formatar automaticamente scripts shell. Configura\u00e7\u00e3o do Projeto vscode-shellcheck A extens\u00e3o Shellcheck deve ser usada no VS Code, ela fornece capacidades de an\u00e1lise de c\u00f3digo est\u00e1tico e corre\u00e7\u00e3o autom\u00e1tica de problemas de linting. Para usar o vscode-shellcheck no VS Code, fa\u00e7a o seguinte: Instale o shellcheck em sua m\u00e1quina Para macOS brew install shellcheck Para Ubuntu: apt-get install shellcheck Instale o shellcheck no vscode Encontre a extens\u00e3o vscode-shellcheck no vscode e instale-a. Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo shell-format A extens\u00e3o shell-format faz a formata\u00e7\u00e3o autom\u00e1tica de seus scripts bash, arquivos Docker e v\u00e1rios arquivos de configura\u00e7\u00e3o. Ela depende do shfmt, que pode aplicar verifica\u00e7\u00f5es do guia de estilo do Google para bash. Para usar o shell-format no vscode, siga os passos abaixo: Instale o shfmt (requer Go 1.13 ou posterior) em sua m\u00e1quina GO111MODULE = on go get mvdan.cc/sh/v3/cmd/shfmt Instale o shell-format no vscode Encontre a extens\u00e3o shell-format no vscode e instale-a. Valida\u00e7\u00e3o de Build Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o seguinte trecho ao seu arquivo azure-pipelines.yaml . Isso far\u00e1 a verifica\u00e7\u00e3o de linting em qualquer script na pasta ./scripts/ . - bash : | echo \"Isso verifica a formata\u00e7\u00e3o e erros comuns do Bash. Consulte o wiki para detalhes sobre erros e op\u00e7\u00f5es de ignorar: https://github.com/koalaman/shellcheck/wiki/SC1000\" export scversion=\"stable\" wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv sudo mv \"shellcheck-${scversion}/shellcheck\" /usr/bin/ rm -r \"shellcheck-${scversion}\" shellcheck ./scripts/*.sh displayName : \"Validar Scripts: Shellcheck\" Al\u00e9m disso, seus scripts shell podem ser formatados em sua pipeline de build usando a ferramenta shfmt . Para integrar o shfmt em sua pipeline de build, fa\u00e7a o seguinte: - bash : | echo \"Esta etapa faz a formata\u00e7\u00e3o autom\u00e1tica de scripts shell\" shfmt -l -w ./scripts/*.sh displayName : \"Formatar Scripts: shfmt\" A realiza\u00e7\u00e3o de testes unit\u00e1rios usando shunit2 tamb\u00e9m pode ser adicionada \u00e0 pipeline de build, usando o seguinte bloco: - bash : | echo \"Esta etapa realiza testes unit\u00e1rios em scripts shell usando shunit2\" ./shunit2 displayName : \"Formatar Scripts: shfmt\" Hooks Pr\u00e9-Commit Todos os desenvolvedores devem executar o shellcheck e o shfmt como hooks pr\u00e9-commit. Etapa 1 - Instalar o pre-commit Execute pip install pre-commit para instalar o pre-commit. Alternativamente, voc\u00ea pode executar brew install pre-commit se estiver usando o Homebrew. Etapa 2 - Adicione o shellcheck e o shfmt Adicione o arquivo .pre-commit-config.yaml \u00e0 raiz do projeto em Go. Execute o shfmt no pr\u00e9-commit adicionando-o ao arquivo .pre-commit-config.yaml como abaixo. - repo : git://github.com/pecigonzalo/pre-commit-fmt sha : master hooks : - id : shell-fmt args : - --indent=4 - repo : https://github.com/shellcheck-py/shellcheck-py rev : v0.7.1.1 hooks : - id : shellcheck Etapa 3 Execute $ pre-commit install para configurar os scripts de hook do git. Depend\u00eancias Scripts Bash s\u00e3o frequentemente usados para 'ligar' outros sistemas e ferramentas. Portanto, os scripts Bash podem ter muitas e/ou complicadas depend\u00eancias. Considere usar cont\u00eaineres Docker para garantir que os scripts sejam executados em um ambiente port\u00e1til e reproduz\u00edvel que contenha todas as depend\u00eancias corretas. Para garantir que os scripts com Docker sejam f\u00e1ceis de executar, considere tornar o uso do Docker transparente para quem chama o script, envolvendo o script em um 'bootstrap' que verifica se o script est\u00e1 sendo executado no Docker e o reexecuta em Docker se n\u00e3o for o caso. Isso proporciona o melhor dos dois mundos: execu\u00e7\u00e3o f\u00e1cil de script e ambientes consistentes. if [[ \" ${ DOCKER } \" ! = \"true\" ]] ; then docker build -t my_script -f my_script.Dockerfile . > /dev/null docker run -e DOCKER = true my_script \" $@ \" exit $? fi # ... implementa\u00e7\u00e3o do my_script aqui pode assumir que todas as suas depend\u00eancias existem, pois ele sempre est\u00e1 sendo executado no Docker ... Checklist de Revis\u00e3o de C\u00f3digo Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve verificar esses itens espec\u00edficos de revis\u00e3o de c\u00f3digo em Bash Esse c\u00f3digo usa Op\u00e7\u00f5es Internas do Shell como set -o, set -e, set -u para controle de execu\u00e7\u00e3o de scripts shell? O c\u00f3digo est\u00e1 modularizado? Scripts shell podem ser modularizados como m\u00f3dulos Python. Partes de scripts Bash devem ser importadas em projetos Bash complexos. Todas as exce\u00e7\u00f5es s\u00e3o tratadas corretamente? Exce\u00e7\u00f5es devem ser tratadas corretamente usando c\u00f3digos de sa\u00edda ou capturando sinais. O c\u00f3digo passa em todas as verifica\u00e7\u00f5es de linting conforme shellcheck e em todos os testes unit\u00e1rios conforme shunit2? O c\u00f3digo usa caminhos relativos ou caminhos absolutos? Caminhos relativos devem ser evitados, pois s\u00e3o vulner\u00e1veis a ataques de ambiente. Se for necess\u00e1rio um caminho relativo, verifique se a vari\u00e1vel PATH est\u00e1 definida. O c\u00f3digo aceita credenciais como entrada do usu\u00e1rio? As credenciais est\u00e3o ocultas ou criptografadas no script?","title":"Revis\u00e3o de C\u00f3digo em Bash"},{"location":"code-reviews/recipes/bash/#revisao-de-codigo-em-bash","text":"","title":"Revis\u00e3o de C\u00f3digo em Bash"},{"location":"code-reviews/recipes/bash/#guia-de-estilo","text":"Os desenvolvedores devem seguir o Guia de Estilo Bash do Google .","title":"Guia de Estilo"},{"location":"code-reviews/recipes/bash/#analise-de-codigo-linting","text":"Projetos devem verificar o c\u00f3digo Bash com o shellcheck como parte do processo de CI . Al\u00e9m do linting, shfmt pode ser usado para formatar automaticamente scripts shell. Existem algumas extens\u00f5es de c\u00f3digo do vscode baseadas no shfmt, como shell-format, que podem ser usadas para formatar automaticamente scripts shell.","title":"An\u00e1lise de C\u00f3digo / Linting"},{"location":"code-reviews/recipes/bash/#configuracao-do-projeto","text":"","title":"Configura\u00e7\u00e3o do Projeto"},{"location":"code-reviews/recipes/bash/#vscode-shellcheck","text":"A extens\u00e3o Shellcheck deve ser usada no VS Code, ela fornece capacidades de an\u00e1lise de c\u00f3digo est\u00e1tico e corre\u00e7\u00e3o autom\u00e1tica de problemas de linting. Para usar o vscode-shellcheck no VS Code, fa\u00e7a o seguinte:","title":"vscode-shellcheck"},{"location":"code-reviews/recipes/bash/#instale-o-shellcheck-em-sua-maquina","text":"Para macOS brew install shellcheck Para Ubuntu: apt-get install shellcheck","title":"Instale o shellcheck em sua m\u00e1quina"},{"location":"code-reviews/recipes/bash/#instale-o-shellcheck-no-vscode","text":"Encontre a extens\u00e3o vscode-shellcheck no vscode e instale-a.","title":"Instale o shellcheck no vscode"},{"location":"code-reviews/recipes/bash/#formatacao-automatica-de-codigo","text":"","title":"Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo"},{"location":"code-reviews/recipes/bash/#shell-format","text":"A extens\u00e3o shell-format faz a formata\u00e7\u00e3o autom\u00e1tica de seus scripts bash, arquivos Docker e v\u00e1rios arquivos de configura\u00e7\u00e3o. Ela depende do shfmt, que pode aplicar verifica\u00e7\u00f5es do guia de estilo do Google para bash. Para usar o shell-format no vscode, siga os passos abaixo:","title":"shell-format"},{"location":"code-reviews/recipes/bash/#instale-o-shfmt-requer-go-113-ou-posterior-em-sua-maquina","text":"GO111MODULE = on go get mvdan.cc/sh/v3/cmd/shfmt","title":"Instale o shfmt (requer Go 1.13 ou posterior) em sua m\u00e1quina"},{"location":"code-reviews/recipes/bash/#instale-o-shell-format-no-vscode","text":"Encontre a extens\u00e3o shell-format no vscode e instale-a.","title":"Instale o shell-format no vscode"},{"location":"code-reviews/recipes/bash/#validacao-de-build","text":"Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o seguinte trecho ao seu arquivo azure-pipelines.yaml . Isso far\u00e1 a verifica\u00e7\u00e3o de linting em qualquer script na pasta ./scripts/ . - bash : | echo \"Isso verifica a formata\u00e7\u00e3o e erros comuns do Bash. Consulte o wiki para detalhes sobre erros e op\u00e7\u00f5es de ignorar: https://github.com/koalaman/shellcheck/wiki/SC1000\" export scversion=\"stable\" wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv sudo mv \"shellcheck-${scversion}/shellcheck\" /usr/bin/ rm -r \"shellcheck-${scversion}\" shellcheck ./scripts/*.sh displayName : \"Validar Scripts: Shellcheck\" Al\u00e9m disso, seus scripts shell podem ser formatados em sua pipeline de build usando a ferramenta shfmt . Para integrar o shfmt em sua pipeline de build, fa\u00e7a o seguinte: - bash : | echo \"Esta etapa faz a formata\u00e7\u00e3o autom\u00e1tica de scripts shell\" shfmt -l -w ./scripts/*.sh displayName : \"Formatar Scripts: shfmt\" A realiza\u00e7\u00e3o de testes unit\u00e1rios usando shunit2 tamb\u00e9m pode ser adicionada \u00e0 pipeline de build, usando o seguinte bloco: - bash : | echo \"Esta etapa realiza testes unit\u00e1rios em scripts shell usando shunit2\" ./shunit2 displayName : \"Formatar Scripts: shfmt\"","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/bash/#hooks-pre-commit","text":"Todos os desenvolvedores devem executar o shellcheck e o shfmt como hooks pr\u00e9-commit.","title":"Hooks Pr\u00e9-Commit"},{"location":"code-reviews/recipes/bash/#etapa-1-instalar-o-pre-commit","text":"Execute pip install pre-commit para instalar o pre-commit. Alternativamente, voc\u00ea pode executar brew install pre-commit se estiver usando o Homebrew.","title":"Etapa 1 - Instalar o pre-commit"},{"location":"code-reviews/recipes/bash/#etapa-2-adicione-o-shellcheck-e-o-shfmt","text":"Adicione o arquivo .pre-commit-config.yaml \u00e0 raiz do projeto em Go. Execute o shfmt no pr\u00e9-commit adicionando-o ao arquivo .pre-commit-config.yaml como abaixo. - repo : git://github.com/pecigonzalo/pre-commit-fmt sha : master hooks : - id : shell-fmt args : - --indent=4 - repo : https://github.com/shellcheck-py/shellcheck-py rev : v0.7.1.1 hooks : - id : shellcheck","title":"Etapa 2 - Adicione o shellcheck e o shfmt"},{"location":"code-reviews/recipes/bash/#etapa-3","text":"Execute $ pre-commit install para configurar os scripts de hook do git.","title":"Etapa 3"},{"location":"code-reviews/recipes/bash/#dependencias","text":"Scripts Bash s\u00e3o frequentemente usados para 'ligar' outros sistemas e ferramentas. Portanto, os scripts Bash podem ter muitas e/ou complicadas depend\u00eancias. Considere usar cont\u00eaineres Docker para garantir que os scripts sejam executados em um ambiente port\u00e1til e reproduz\u00edvel que contenha todas as depend\u00eancias corretas. Para garantir que os scripts com Docker sejam f\u00e1ceis de executar, considere tornar o uso do Docker transparente para quem chama o script, envolvendo o script em um 'bootstrap' que verifica se o script est\u00e1 sendo executado no Docker e o reexecuta em Docker se n\u00e3o for o caso. Isso proporciona o melhor dos dois mundos: execu\u00e7\u00e3o f\u00e1cil de script e ambientes consistentes. if [[ \" ${ DOCKER } \" ! = \"true\" ]] ; then docker build -t my_script -f my_script.Dockerfile . > /dev/null docker run -e DOCKER = true my_script \" $@ \" exit $? fi # ... implementa\u00e7\u00e3o do my_script aqui pode assumir que todas as suas depend\u00eancias existem, pois ele sempre est\u00e1 sendo executado no Docker ...","title":"Depend\u00eancias"},{"location":"code-reviews/recipes/bash/#checklist-de-revisao-de-codigo","text":"Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve verificar esses itens espec\u00edficos de revis\u00e3o de c\u00f3digo em Bash Esse c\u00f3digo usa Op\u00e7\u00f5es Internas do Shell como set -o, set -e, set -u para controle de execu\u00e7\u00e3o de scripts shell? O c\u00f3digo est\u00e1 modularizado? Scripts shell podem ser modularizados como m\u00f3dulos Python. Partes de scripts Bash devem ser importadas em projetos Bash complexos. Todas as exce\u00e7\u00f5es s\u00e3o tratadas corretamente? Exce\u00e7\u00f5es devem ser tratadas corretamente usando c\u00f3digos de sa\u00edda ou capturando sinais. O c\u00f3digo passa em todas as verifica\u00e7\u00f5es de linting conforme shellcheck e em todos os testes unit\u00e1rios conforme shunit2? O c\u00f3digo usa caminhos relativos ou caminhos absolutos? Caminhos relativos devem ser evitados, pois s\u00e3o vulner\u00e1veis a ataques de ambiente. Se for necess\u00e1rio um caminho relativo, verifique se a vari\u00e1vel PATH est\u00e1 definida. O c\u00f3digo aceita credenciais como entrada do usu\u00e1rio? As credenciais est\u00e3o ocultas ou criptografadas no script?","title":"Checklist de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/csharp/","text":"Revis\u00f5es de C\u00f3digo em C Guia de Estilo Os desenvolvedores devem seguir as Conven\u00e7\u00f5es de Codifica\u00e7\u00e3o C# da Microsoft e, quando aplic\u00e1vel, as Diretrizes de Codifica\u00e7\u00e3o Segura da Microsoft . An\u00e1lise de C\u00f3digo / Linting Acreditamos firmemente que um estilo consistente aumenta a legibilidade e a manutenibilidade de uma base de c\u00f3digo. Portanto, estamos recomendando o uso de analisadores / linters para impor regras de consist\u00eancia e estilo. Configura\u00e7\u00e3o do Projeto Recomendamos o uso de uma configura\u00e7\u00e3o comum para sua solu\u00e7\u00e3o que voc\u00ea pode referenciar em todos os projetos que fazem parte da solu\u00e7\u00e3o. Crie um arquivo common.props que contenha as configura\u00e7\u00f5es padr\u00e3o para todos os seus projetos: <Project> ... <ItemGroup> <PackageReference Include= \"Microsoft.CodeAnalysis.NetAnalyzers\" Version= \"5.0.3\" > <PrivateAssets> all </PrivateAssets> <IncludeAssets> runtime; build; native; contentfiles; analyzers; buildtransitive </IncludeAssets> </PackageReference> <PackageReference Include= \"StyleCop.Analyzers\" Version= \"1.1.118\" > <PrivateAssets> all </PrivateAssets> <IncludeAssets> runtime; build; native; contentfiles; analyzers; buildtransitive </IncludeAssets> </PackageReference> </ItemGroup> <PropertyGroup> <TreatWarningsAsErrors> true </TreatWarningsAsErrors> </PropertyGroup> <ItemGroup Condition= \"Exists('$(MSBuildThisFileDirectory)../.editorconfig')\" > <AdditionalFiles Include= \"$(MSBuildThisFileDirectory)../.editorconfig\" /> </ItemGroup> ... </Project> Voc\u00ea pode ent\u00e3o fazer refer\u00eancia ao common.props em seus outros arquivos de projeto para garantir uma configura\u00e7\u00e3o consistente. <Project Sdk= \"Microsoft.NET.Sdk.Web\" > <Import Project= \"..\\common.props\" /> </Project> O arquivo .editorconfig permite a configura\u00e7\u00e3o e substitui\u00e7\u00e3o de regras. Voc\u00ea pode ter um arquivo .editorconfig no n\u00edvel do projeto para personalizar regras para diferentes projetos (por exemplo, projetos de teste). Detalhes sobre a configura\u00e7\u00e3o de diferentes regras . Analisadores .NET Os analisadores .NET da Microsoft possuem regras de qualidade de c\u00f3digo e regras de uso de APIs .NET implementadas como analisadores usando a plataforma .NET Compiler (Roslyn). Isso \u00e9 a substitui\u00e7\u00e3o para os analisadores legados do FxCop da Microsoft. Habilite ou instale os analisadores .NET de primeira parte . Se voc\u00ea estiver usando os analisadores legados do FxCop atualmente, migre dos analisadores FxCop para os analisadores .NET . Analisador StyleCop O analisador StyleCop \u00e9 um pacote NuGet (StyleCop.Analyzers) que pode ser instalado em qualquer um de seus projetos. Ele se concentra principalmente em regras de estilo de c\u00f3digo e garante que a equipe esteja seguindo as mesmas regras sem a necessidade de discuss\u00f5es subjetivas sobre chaves e espa\u00e7os. Informa\u00e7\u00f5es detalhadas podem ser encontradas aqui: Analisadores StyleCop para a Plataforma de Compilador .NET . O conjunto m\u00ednimo de regras que as equipes devem adotar \u00e9 o conjunto de regras Managed Recommended Rules . Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo Use o .editorconfig para configurar regras de formata\u00e7\u00e3o de c\u00f3digo em seu projeto. Valida\u00e7\u00e3o de Build \u00c9 importante que voc\u00ea apl ique seu estilo de c\u00f3digo e regras na integra\u00e7\u00e3o cont\u00ednua (CI) para evitar que qualquer membro da equipe fa\u00e7a merge de c\u00f3digo que n\u00e3o esteja em conformidade com seus padr\u00f5es em seu reposit\u00f3rio Git. Se voc\u00ea estiver usando analisadores do FxCop e o analisador StyleCop, \u00e9 muito simples habilit\u00e1-los na CI. Voc\u00ea deve garantir que esteja configurando o projeto usando o NuGet e o .editorconfig ( veja a Configura\u00e7\u00e3o do Projeto ). Uma vez que voc\u00ea tenha essa configura\u00e7\u00e3o, voc\u00ea precisar\u00e1 configurar o pipeline para construir seu c\u00f3digo. Isso \u00e9 basicamente tudo. Os analisadores do FxCop ser\u00e3o executados e reportar\u00e3o o resultado em seu pipeline de build. Se houver regras que estejam sendo violadas, sua build ficar\u00e1 vermelha. - task : DotNetCoreCLI@2 displayName : 'Verifica\u00e7\u00e3o de Estilo & Build' inputs : command : 'build' projects : '**/*.csproj' Habilitar Suporte ao Roslyn no Visual Studio Code As etapas acima tamb\u00e9m funcionam no Visual Studio Code, desde que voc\u00ea habilite o suporte ao Roslyn para o Omnisharp. A configura\u00e7\u00e3o \u00e9 omnisharp.enableRoslynAnalyzers e deve ser definida como true . Ap\u00f3s habilitar essa configura\u00e7\u00e3o, voc\u00ea deve \"Reiniciar o Omnisharp\" (isso pode ser feito a partir da Paleta de Comandos no Visual Studio Code ou reiniciando o Visual Studio Code). Checklist de Revis\u00e3o de C\u00f3digo Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos de revis\u00e3o de c\u00f3digo em C#: Este c\u00f3digo faz uso correto de constru\u00e7\u00f5es de programa\u00e7\u00e3o ass\u00edncrona , incluindo o uso adequado de await e Task.WhenAll incluindo CancellationTokens? O c\u00f3digo est\u00e1 sujeito a problemas de concorr\u00eancia? Os objetos compartilhados est\u00e3o devidamente protegidos? A inje\u00e7\u00e3o de depend\u00eancia (DI) \u00e9 usada? Est\u00e1 configurada corretamente? Os middleware inclu\u00eddos neste projeto est\u00e3o configurados corretamente? Os recursos s\u00e3o liberados de forma determin\u00edstica usando o padr\u00e3o IDispose? Todos os objetos descart\u00e1veis s\u00e3o devidamente liberados ( usando o padr\u00e3o )? O c\u00f3digo est\u00e1 criando muitos objetos de curta dura\u00e7\u00e3o. Poder\u00edamos otimizar a press\u00e3o no coletor de lixo? O c\u00f3digo est\u00e1 escrito de uma forma que causa opera\u00e7\u00f5es de boxing? O c\u00f3digo manipula exce\u00e7\u00f5es corretamente ? O gerenciamento de pacotes est\u00e1 sendo usado (NuGet) em vez de DLLs sendo commitadas? Este c\u00f3digo faz uso apropriado do LINQ? Trazer o LINQ para um projeto para substituir um \u00fanico loop curto ou de maneiras que n\u00e3o tenham bom desempenho geralmente n\u00e3o \u00e9 apropriado. Este c\u00f3digo valida corretamente a sanidade dos argumentos (ou seja, CA1062 )? Considere o uso de extens\u00f5es como Ensure.That Este c\u00f3digo inclui instrumenta\u00e7\u00e3o de telemetria ( m\u00e9tricas, rastreamento e registro )? Este c\u00f3digo aproveita o padr\u00e3o de design de op\u00e7\u00f5es usando classes para fornecer acesso fortemente tipado a grupos de configura\u00e7\u00f5es relacionadas? Em vez de usar strings literais, s\u00e3o usadas constantes na classe principal? Ou se essas strings s\u00e3o usadas em v\u00e1rios arquivos/classes, existe uma classe est\u00e1tica para as constantes? Os n\u00fameros m\u00e1gicos s\u00e3o explicados? N\u00e3o deve haver n\u00fameros no c\u00f3digo sem pelo menos um coment\u00e1rio explicando por que est\u00e3o l\u00e1. Se o n\u00famero for repetitivo, existe uma constante/enumerador ou equivalente? A manipula\u00e7\u00e3o de exce\u00e7\u00f5es adequada est\u00e1 configurada? Capturar a classe base de exce\u00e7\u00e3o ( catch (Exception) ) geralmente n\u00e3o \u00e9 o padr\u00e3o correto. Em vez disso, capture as exce\u00e7\u00f5es espec\u00edficas que podem acontecer, por exemplo, IOException . O uso de #pragma \u00e9 justo? Os testes est\u00e3o organizados corretamente com o padr\u00e3o Arrange/Act/Assert e devidamente documentados dessa forma? Se houver um m\u00e9todo ass\u00edncrono, o nome do m\u00e9todo termina com o sufixo Async ? Se um m\u00e9todo for ass\u00edncrono, \u00e9 usado Task.Delay em vez de Thread.Sleep ? O Task.Delay n\u00e3o bloqueia a thread atual e cria uma tarefa que ser\u00e1 conclu\u00edda sem bloquear a thread, portanto, em um ambiente com v\u00e1rias threads e tarefas, esta \u00e9 a prefer\u00edvel. \u00c9 necess\u00e1rio um token de cancelamento para tarefas ass\u00edncronas em vez de padr\u00f5es booleanos? Existe um n\u00edvel m\u00ednimo de registro? Os n\u00edveis de registro usados s\u00e3o sensatos? As classes internas versus privadas versus p\u00fablicas e os m\u00e9todos s\u00e3o usados da maneira certa? As propriedades autom\u00e1ticas get e set s\u00e3o usadas da maneira certa? Em um modelo sem construtor e para desserializa\u00e7\u00e3o, \u00e9 aceit\u00e1vel ter todas as propriedades acess\u00edveis. Para outras classes, geralmente \u00e9 melhor usar set privado ou set interno. O padr\u00e3o using para fluxos e outras classes descart\u00e1veis \u00e9 usado? Se n\u00e3o for, \u00e9 melhor chamar explicitamente o m\u00e9todo Dispose . As classes que mant\u00eam cole\u00e7\u00f5es na mem\u00f3ria s\u00e3o seguras para multithreading? Quando usadas em concorr\u00eancia, use o padr\u00e3o de bloqueio.","title":"Revis\u00f5es de C\u00f3digo em C#"},{"location":"code-reviews/recipes/csharp/#revisoes-de-codigo-em-c","text":"","title":"Revis\u00f5es de C\u00f3digo em C"},{"location":"code-reviews/recipes/csharp/#guia-de-estilo","text":"Os desenvolvedores devem seguir as Conven\u00e7\u00f5es de Codifica\u00e7\u00e3o C# da Microsoft e, quando aplic\u00e1vel, as Diretrizes de Codifica\u00e7\u00e3o Segura da Microsoft .","title":"Guia de Estilo"},{"location":"code-reviews/recipes/csharp/#analise-de-codigo-linting","text":"Acreditamos firmemente que um estilo consistente aumenta a legibilidade e a manutenibilidade de uma base de c\u00f3digo. Portanto, estamos recomendando o uso de analisadores / linters para impor regras de consist\u00eancia e estilo.","title":"An\u00e1lise de C\u00f3digo / Linting"},{"location":"code-reviews/recipes/csharp/#configuracao-do-projeto","text":"Recomendamos o uso de uma configura\u00e7\u00e3o comum para sua solu\u00e7\u00e3o que voc\u00ea pode referenciar em todos os projetos que fazem parte da solu\u00e7\u00e3o. Crie um arquivo common.props que contenha as configura\u00e7\u00f5es padr\u00e3o para todos os seus projetos: <Project> ... <ItemGroup> <PackageReference Include= \"Microsoft.CodeAnalysis.NetAnalyzers\" Version= \"5.0.3\" > <PrivateAssets> all </PrivateAssets> <IncludeAssets> runtime; build; native; contentfiles; analyzers; buildtransitive </IncludeAssets> </PackageReference> <PackageReference Include= \"StyleCop.Analyzers\" Version= \"1.1.118\" > <PrivateAssets> all </PrivateAssets> <IncludeAssets> runtime; build; native; contentfiles; analyzers; buildtransitive </IncludeAssets> </PackageReference> </ItemGroup> <PropertyGroup> <TreatWarningsAsErrors> true </TreatWarningsAsErrors> </PropertyGroup> <ItemGroup Condition= \"Exists('$(MSBuildThisFileDirectory)../.editorconfig')\" > <AdditionalFiles Include= \"$(MSBuildThisFileDirectory)../.editorconfig\" /> </ItemGroup> ... </Project> Voc\u00ea pode ent\u00e3o fazer refer\u00eancia ao common.props em seus outros arquivos de projeto para garantir uma configura\u00e7\u00e3o consistente. <Project Sdk= \"Microsoft.NET.Sdk.Web\" > <Import Project= \"..\\common.props\" /> </Project> O arquivo .editorconfig permite a configura\u00e7\u00e3o e substitui\u00e7\u00e3o de regras. Voc\u00ea pode ter um arquivo .editorconfig no n\u00edvel do projeto para personalizar regras para diferentes projetos (por exemplo, projetos de teste). Detalhes sobre a configura\u00e7\u00e3o de diferentes regras .","title":"Configura\u00e7\u00e3o do Projeto"},{"location":"code-reviews/recipes/csharp/#analisadores-net","text":"Os analisadores .NET da Microsoft possuem regras de qualidade de c\u00f3digo e regras de uso de APIs .NET implementadas como analisadores usando a plataforma .NET Compiler (Roslyn). Isso \u00e9 a substitui\u00e7\u00e3o para os analisadores legados do FxCop da Microsoft. Habilite ou instale os analisadores .NET de primeira parte . Se voc\u00ea estiver usando os analisadores legados do FxCop atualmente, migre dos analisadores FxCop para os analisadores .NET .","title":"Analisadores .NET"},{"location":"code-reviews/recipes/csharp/#analisador-stylecop","text":"O analisador StyleCop \u00e9 um pacote NuGet (StyleCop.Analyzers) que pode ser instalado em qualquer um de seus projetos. Ele se concentra principalmente em regras de estilo de c\u00f3digo e garante que a equipe esteja seguindo as mesmas regras sem a necessidade de discuss\u00f5es subjetivas sobre chaves e espa\u00e7os. Informa\u00e7\u00f5es detalhadas podem ser encontradas aqui: Analisadores StyleCop para a Plataforma de Compilador .NET . O conjunto m\u00ednimo de regras que as equipes devem adotar \u00e9 o conjunto de regras Managed Recommended Rules .","title":"Analisador StyleCop"},{"location":"code-reviews/recipes/csharp/#formatacao-automatica-de-codigo","text":"Use o .editorconfig para configurar regras de formata\u00e7\u00e3o de c\u00f3digo em seu projeto.","title":"Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo"},{"location":"code-reviews/recipes/csharp/#validacao-de-build","text":"\u00c9 importante que voc\u00ea apl ique seu estilo de c\u00f3digo e regras na integra\u00e7\u00e3o cont\u00ednua (CI) para evitar que qualquer membro da equipe fa\u00e7a merge de c\u00f3digo que n\u00e3o esteja em conformidade com seus padr\u00f5es em seu reposit\u00f3rio Git. Se voc\u00ea estiver usando analisadores do FxCop e o analisador StyleCop, \u00e9 muito simples habilit\u00e1-los na CI. Voc\u00ea deve garantir que esteja configurando o projeto usando o NuGet e o .editorconfig ( veja a Configura\u00e7\u00e3o do Projeto ). Uma vez que voc\u00ea tenha essa configura\u00e7\u00e3o, voc\u00ea precisar\u00e1 configurar o pipeline para construir seu c\u00f3digo. Isso \u00e9 basicamente tudo. Os analisadores do FxCop ser\u00e3o executados e reportar\u00e3o o resultado em seu pipeline de build. Se houver regras que estejam sendo violadas, sua build ficar\u00e1 vermelha. - task : DotNetCoreCLI@2 displayName : 'Verifica\u00e7\u00e3o de Estilo & Build' inputs : command : 'build' projects : '**/*.csproj'","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/csharp/#habilitar-suporte-ao-roslyn-no-visual-studio-code","text":"As etapas acima tamb\u00e9m funcionam no Visual Studio Code, desde que voc\u00ea habilite o suporte ao Roslyn para o Omnisharp. A configura\u00e7\u00e3o \u00e9 omnisharp.enableRoslynAnalyzers e deve ser definida como true . Ap\u00f3s habilitar essa configura\u00e7\u00e3o, voc\u00ea deve \"Reiniciar o Omnisharp\" (isso pode ser feito a partir da Paleta de Comandos no Visual Studio Code ou reiniciando o Visual Studio Code).","title":"Habilitar Suporte ao Roslyn no Visual Studio Code"},{"location":"code-reviews/recipes/csharp/#checklist-de-revisao-de-codigo","text":"Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos de revis\u00e3o de c\u00f3digo em C#: Este c\u00f3digo faz uso correto de constru\u00e7\u00f5es de programa\u00e7\u00e3o ass\u00edncrona , incluindo o uso adequado de await e Task.WhenAll incluindo CancellationTokens? O c\u00f3digo est\u00e1 sujeito a problemas de concorr\u00eancia? Os objetos compartilhados est\u00e3o devidamente protegidos? A inje\u00e7\u00e3o de depend\u00eancia (DI) \u00e9 usada? Est\u00e1 configurada corretamente? Os middleware inclu\u00eddos neste projeto est\u00e3o configurados corretamente? Os recursos s\u00e3o liberados de forma determin\u00edstica usando o padr\u00e3o IDispose? Todos os objetos descart\u00e1veis s\u00e3o devidamente liberados ( usando o padr\u00e3o )? O c\u00f3digo est\u00e1 criando muitos objetos de curta dura\u00e7\u00e3o. Poder\u00edamos otimizar a press\u00e3o no coletor de lixo? O c\u00f3digo est\u00e1 escrito de uma forma que causa opera\u00e7\u00f5es de boxing? O c\u00f3digo manipula exce\u00e7\u00f5es corretamente ? O gerenciamento de pacotes est\u00e1 sendo usado (NuGet) em vez de DLLs sendo commitadas? Este c\u00f3digo faz uso apropriado do LINQ? Trazer o LINQ para um projeto para substituir um \u00fanico loop curto ou de maneiras que n\u00e3o tenham bom desempenho geralmente n\u00e3o \u00e9 apropriado. Este c\u00f3digo valida corretamente a sanidade dos argumentos (ou seja, CA1062 )? Considere o uso de extens\u00f5es como Ensure.That Este c\u00f3digo inclui instrumenta\u00e7\u00e3o de telemetria ( m\u00e9tricas, rastreamento e registro )? Este c\u00f3digo aproveita o padr\u00e3o de design de op\u00e7\u00f5es usando classes para fornecer acesso fortemente tipado a grupos de configura\u00e7\u00f5es relacionadas? Em vez de usar strings literais, s\u00e3o usadas constantes na classe principal? Ou se essas strings s\u00e3o usadas em v\u00e1rios arquivos/classes, existe uma classe est\u00e1tica para as constantes? Os n\u00fameros m\u00e1gicos s\u00e3o explicados? N\u00e3o deve haver n\u00fameros no c\u00f3digo sem pelo menos um coment\u00e1rio explicando por que est\u00e3o l\u00e1. Se o n\u00famero for repetitivo, existe uma constante/enumerador ou equivalente? A manipula\u00e7\u00e3o de exce\u00e7\u00f5es adequada est\u00e1 configurada? Capturar a classe base de exce\u00e7\u00e3o ( catch (Exception) ) geralmente n\u00e3o \u00e9 o padr\u00e3o correto. Em vez disso, capture as exce\u00e7\u00f5es espec\u00edficas que podem acontecer, por exemplo, IOException . O uso de #pragma \u00e9 justo? Os testes est\u00e3o organizados corretamente com o padr\u00e3o Arrange/Act/Assert e devidamente documentados dessa forma? Se houver um m\u00e9todo ass\u00edncrono, o nome do m\u00e9todo termina com o sufixo Async ? Se um m\u00e9todo for ass\u00edncrono, \u00e9 usado Task.Delay em vez de Thread.Sleep ? O Task.Delay n\u00e3o bloqueia a thread atual e cria uma tarefa que ser\u00e1 conclu\u00edda sem bloquear a thread, portanto, em um ambiente com v\u00e1rias threads e tarefas, esta \u00e9 a prefer\u00edvel. \u00c9 necess\u00e1rio um token de cancelamento para tarefas ass\u00edncronas em vez de padr\u00f5es booleanos? Existe um n\u00edvel m\u00ednimo de registro? Os n\u00edveis de registro usados s\u00e3o sensatos? As classes internas versus privadas versus p\u00fablicas e os m\u00e9todos s\u00e3o usados da maneira certa? As propriedades autom\u00e1ticas get e set s\u00e3o usadas da maneira certa? Em um modelo sem construtor e para desserializa\u00e7\u00e3o, \u00e9 aceit\u00e1vel ter todas as propriedades acess\u00edveis. Para outras classes, geralmente \u00e9 melhor usar set privado ou set interno. O padr\u00e3o using para fluxos e outras classes descart\u00e1veis \u00e9 usado? Se n\u00e3o for, \u00e9 melhor chamar explicitamente o m\u00e9todo Dispose . As classes que mant\u00eam cole\u00e7\u00f5es na mem\u00f3ria s\u00e3o seguras para multithreading? Quando usadas em concorr\u00eancia, use o padr\u00e3o de bloqueio.","title":"Checklist de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/go/","text":"Revis\u00f5es de C\u00f3digo em Go Guia de Estilo Os desenvolvedores devem seguir o Guia de Estilo Effective Go . An\u00e1lise de C\u00f3digo / Verifica\u00e7\u00e3o de Estilo Configura\u00e7\u00e3o do Projeto Abaixo est\u00e1 a configura\u00e7\u00e3o do projeto que voc\u00ea gostaria de ter em seu Visual Studio Code. Extens\u00e3o vscode-go Usando a extens\u00e3o Go para o Visual Studio Code, voc\u00ea obt\u00e9m recursos de linguagem como IntelliSense, navega\u00e7\u00e3o de c\u00f3digo, pesquisa de s\u00edmbolos, correspond\u00eancia de colchetes, snippets, etc. Esta extens\u00e3o inclui suporte de linguagem avan\u00e7ado para Go no VS Code. go vet go vet \u00e9 uma ferramenta de an\u00e1lise est\u00e1tica que verifica erros comuns em Go, como uso incorreto de vari\u00e1veis de loop range ou argumentos printf desalinhados. O c\u00f3digo Go deve ser capaz de ser compilado sem erros do go vet . Isso far\u00e1 parte da extens\u00e3o vscode-go. golint :exclamation: AVISO: A biblioteca golint est\u00e1 descontinuada e arquivada. O linter revive (abaixo) pode ser uma substitui\u00e7\u00e3o adequada. golint pode ser uma ferramenta eficaz para encontrar muitos problemas, mas pode gerar falsos positivos. \u00c9 melhor usado por desenvolvedores ao trabalhar no c\u00f3digo, n\u00e3o como parte de um processo de build automatizado. Este \u00e9 o linter padr\u00e3o que est\u00e1 configurado como parte da extens\u00e3o vscode-go. revive Revive \u00e9 um linter para Go, que fornece um framework para o desenvolvimento de regras personalizadas e permite que voc\u00ea defina um conjunto r\u00edgido para melhorar seus processos de desenvolvimento e revis\u00e3o de c\u00f3digo. Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo gofmt gofmt \u00e9 o guia de estilo de formata\u00e7\u00e3o de c\u00f3digo automatizado para Go. Isso faz parte da extens\u00e3o vs-code e \u00e9 ativado por padr\u00e3o para rodar sempre que um arquivo \u00e9 salvo. Agregador golangci-lint golangci-lint \u00e9 a substitui\u00e7\u00e3o do agora descontinuado gometalinter . Ele \u00e9 de 2 a 7 vezes mais r\u00e1pido que gometalinter juntamente com uma s\u00e9rie de outros benef\u00edcios . golangci-lint \u00e9 um agregador poderoso e personaliz\u00e1vel de linters. Por padr\u00e3o, v\u00e1rios est\u00e3o habilitados, mas nem todos. Uma lista completa de linters e seus usos pode ser encontrada aqui . Ele permitir\u00e1 que voc\u00ea configure cada linter e escolha quais deseja habilitar em seu projeto. Uma caracter\u00edstica incr\u00edvel do golangci-lint \u00e9 que ele pode ser facilmente introduzido em um c\u00f3digo legado existente usando --new-from-rev COMMITID . Com essa configura\u00e7\u00e3o, apenas novos problemas s\u00e3o sinalizados, permitindo que uma equipe melhore o novo c\u00f3digo sem precisar corrigir todos os problemas hist\u00f3ricos em um c\u00f3digo legado grande. O golangci-lint tamb\u00e9m pode ser configurado como o linter padr\u00e3o no VS Code. Op\u00e7\u00f5es de instala\u00e7\u00e3o para golangci-lint est\u00e3o presentes em golangci-lint . Para usar golangci-lint com o VS Code, use as configura\u00e7\u00f5es recomendadas abaixo: \"go.lintTool\" : \"golangci-lint\" , \"go.lintFlags\" : [ \"--fast\" ] Hooks Pr\u00e9-Commit Todos os desenvolvedores devem executar gofmt em um hook pr\u00e9-commit para garantir a formata\u00e7\u00e3o padr\u00e3o. Passo 1 - Instalar pre-commit Execute pip install pre-commit para instalar o pre-commit. Alternativamente, voc\u00ea pode executar brew install pre-commit se estiver usando o Homebrew. Passo 2 - Adicionar go-fmt no pr\u00e9-commit Adicione o arquivo .pre-commit-config.yaml \u00e0 raiz do projeto Go. Execute go-fmt no pr\u00e9-commit adicionando-o ao arquivo .pre-commit-config.yaml como abaixo. - repo : git://github.com/dnephin/pre-commit-golang rev : master hooks : - id : go-fmt Passo 3 Execute $ pre-commit install para configurar os scripts de hook do Git. Valida\u00e7\u00e3o de Build gofmt deve ser executado como parte de cada build para impor o padr\u00e3o comum. Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o trecho a seguir ao seu arquivo azure-pipelines.yaml . Isso formatar\u00e1 os scripts na pasta ./scripts/ . - script : go fmt workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar formata\u00e7\u00e3o de c\u00f3digo\" govet deve ser executado como parte de cada build para verificar a verifica\u00e7\u00e3o de c\u00f3digo. Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o trecho a seguir ao seu arquivo azure-pipelines.yaml . Isso verificar\u00e1 a verifica\u00e7\u00e3o de linting de qualquer script na pasta ./scripts/ . - script : go vet workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar verifica\u00e7\u00e3o de c\u00f3digo\" Alternativamente, voc\u00ea pode usar o golangci-lint como uma etapa no pipeline para realizar v\u00e1rias valida\u00e7\u00f5es habilitadas (incluindo go vet e go fmt) do golangci-lint. - script : golangci-lint run --enable gofmt --fix workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar verifica\u00e7\u00e3o de c\u00f3digo\" Exemplo de Pipeline de Valida\u00e7\u00e3o de Build no Azure DevOps trigger : master pool : vmImage : 'ubuntu-latest' steps : - task : GoTool@0 inputs : version : '1.13.5' - task : Go@0 inputs : command : 'get' arguments : '-d' workingDirectory : '$(System.DefaultWorkingDirectory)/scripts' - script : go fmt workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar formata\u00e7\u00e3o de c\u00f3digo\" - script : go vet workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : 'Executar go vet' - task : Go@0 inputs : command : 'build' workingDirectory : '$(System.DefaultWorking Directory)' - task : CopyFiles@2 inputs : TargetFolder : '$(Build.ArtifactStagingDirectory)' - task : PublishBuildArtifacts@1 inputs : artifactName : drop Checklist de Revis\u00e3o de C\u00f3digo A equipe de linguagem Go mant\u00e9m uma lista de Coment\u00e1rios de Revis\u00e3o de C\u00f3digo Comuns para Go que formam a base para um s\u00f3lido checklist para uma equipe que trabalha em Go, que deve ser seguido al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo ISE Este c\u00f3digo trata erros corretamente? Isso inclui n\u00e3o descartar erros com atribui\u00e7\u00f5es _ e retornar erros, em vez de valores de erro no pr\u00f3prio canal ? Este c\u00f3digo segue os padr\u00f5es Go para tipos de receptor de m\u00e9todo receiver types ? Este c\u00f3digo passa valores quando necess\u00e1rio? As interfaces neste c\u00f3digo s\u00e3o definidas nos pacotes corretos ? As go-routines neste c\u00f3digo t\u00eam lifetimes claros ? O paralelismo neste c\u00f3digo \u00e9 tratado por meio de go-routines e canais com m\u00e9todos s\u00edncronos ? Este c\u00f3digo possui Coment\u00e1rios de Documenta\u00e7\u00e3o significativos? Este c\u00f3digo possui Coment\u00e1rios de Pacote significativos? Este c\u00f3digo usa Contextos corretamente? Os testes unit\u00e1rios falham com mensagens significativas ?","title":"Revis\u00f5es de C\u00f3digo em Go"},{"location":"code-reviews/recipes/go/#revisoes-de-codigo-em-go","text":"","title":"Revis\u00f5es de C\u00f3digo em Go"},{"location":"code-reviews/recipes/go/#guia-de-estilo","text":"Os desenvolvedores devem seguir o Guia de Estilo Effective Go .","title":"Guia de Estilo"},{"location":"code-reviews/recipes/go/#analise-de-codigo-verificacao-de-estilo","text":"","title":"An\u00e1lise de C\u00f3digo / Verifica\u00e7\u00e3o de Estilo"},{"location":"code-reviews/recipes/go/#configuracao-do-projeto","text":"Abaixo est\u00e1 a configura\u00e7\u00e3o do projeto que voc\u00ea gostaria de ter em seu Visual Studio Code.","title":"Configura\u00e7\u00e3o do Projeto"},{"location":"code-reviews/recipes/go/#extensao-vscode-go","text":"Usando a extens\u00e3o Go para o Visual Studio Code, voc\u00ea obt\u00e9m recursos de linguagem como IntelliSense, navega\u00e7\u00e3o de c\u00f3digo, pesquisa de s\u00edmbolos, correspond\u00eancia de colchetes, snippets, etc. Esta extens\u00e3o inclui suporte de linguagem avan\u00e7ado para Go no VS Code.","title":"Extens\u00e3o vscode-go"},{"location":"code-reviews/recipes/go/#go-vet","text":"go vet \u00e9 uma ferramenta de an\u00e1lise est\u00e1tica que verifica erros comuns em Go, como uso incorreto de vari\u00e1veis de loop range ou argumentos printf desalinhados. O c\u00f3digo Go deve ser capaz de ser compilado sem erros do go vet . Isso far\u00e1 parte da extens\u00e3o vscode-go.","title":"go vet"},{"location":"code-reviews/recipes/go/#golint","text":":exclamation: AVISO: A biblioteca golint est\u00e1 descontinuada e arquivada. O linter revive (abaixo) pode ser uma substitui\u00e7\u00e3o adequada. golint pode ser uma ferramenta eficaz para encontrar muitos problemas, mas pode gerar falsos positivos. \u00c9 melhor usado por desenvolvedores ao trabalhar no c\u00f3digo, n\u00e3o como parte de um processo de build automatizado. Este \u00e9 o linter padr\u00e3o que est\u00e1 configurado como parte da extens\u00e3o vscode-go.","title":"golint"},{"location":"code-reviews/recipes/go/#revive","text":"Revive \u00e9 um linter para Go, que fornece um framework para o desenvolvimento de regras personalizadas e permite que voc\u00ea defina um conjunto r\u00edgido para melhorar seus processos de desenvolvimento e revis\u00e3o de c\u00f3digo.","title":"revive"},{"location":"code-reviews/recipes/go/#formatacao-automatica-de-codigo","text":"","title":"Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo"},{"location":"code-reviews/recipes/go/#gofmt","text":"gofmt \u00e9 o guia de estilo de formata\u00e7\u00e3o de c\u00f3digo automatizado para Go. Isso faz parte da extens\u00e3o vs-code e \u00e9 ativado por padr\u00e3o para rodar sempre que um arquivo \u00e9 salvo.","title":"gofmt"},{"location":"code-reviews/recipes/go/#agregador","text":"","title":"Agregador"},{"location":"code-reviews/recipes/go/#golangci-lint","text":"golangci-lint \u00e9 a substitui\u00e7\u00e3o do agora descontinuado gometalinter . Ele \u00e9 de 2 a 7 vezes mais r\u00e1pido que gometalinter juntamente com uma s\u00e9rie de outros benef\u00edcios . golangci-lint \u00e9 um agregador poderoso e personaliz\u00e1vel de linters. Por padr\u00e3o, v\u00e1rios est\u00e3o habilitados, mas nem todos. Uma lista completa de linters e seus usos pode ser encontrada aqui . Ele permitir\u00e1 que voc\u00ea configure cada linter e escolha quais deseja habilitar em seu projeto. Uma caracter\u00edstica incr\u00edvel do golangci-lint \u00e9 que ele pode ser facilmente introduzido em um c\u00f3digo legado existente usando --new-from-rev COMMITID . Com essa configura\u00e7\u00e3o, apenas novos problemas s\u00e3o sinalizados, permitindo que uma equipe melhore o novo c\u00f3digo sem precisar corrigir todos os problemas hist\u00f3ricos em um c\u00f3digo legado grande. O golangci-lint tamb\u00e9m pode ser configurado como o linter padr\u00e3o no VS Code. Op\u00e7\u00f5es de instala\u00e7\u00e3o para golangci-lint est\u00e3o presentes em golangci-lint . Para usar golangci-lint com o VS Code, use as configura\u00e7\u00f5es recomendadas abaixo: \"go.lintTool\" : \"golangci-lint\" , \"go.lintFlags\" : [ \"--fast\" ]","title":"golangci-lint"},{"location":"code-reviews/recipes/go/#hooks-pre-commit","text":"Todos os desenvolvedores devem executar gofmt em um hook pr\u00e9-commit para garantir a formata\u00e7\u00e3o padr\u00e3o.","title":"Hooks Pr\u00e9-Commit"},{"location":"code-reviews/recipes/go/#passo-1-instalar-pre-commit","text":"Execute pip install pre-commit para instalar o pre-commit. Alternativamente, voc\u00ea pode executar brew install pre-commit se estiver usando o Homebrew.","title":"Passo 1 - Instalar pre-commit"},{"location":"code-reviews/recipes/go/#passo-2-adicionar-go-fmt-no-pre-commit","text":"Adicione o arquivo .pre-commit-config.yaml \u00e0 raiz do projeto Go. Execute go-fmt no pr\u00e9-commit adicionando-o ao arquivo .pre-commit-config.yaml como abaixo. - repo : git://github.com/dnephin/pre-commit-golang rev : master hooks : - id : go-fmt","title":"Passo 2 - Adicionar go-fmt no pr\u00e9-commit"},{"location":"code-reviews/recipes/go/#passo-3","text":"Execute $ pre-commit install para configurar os scripts de hook do Git.","title":"Passo 3"},{"location":"code-reviews/recipes/go/#validacao-de-build","text":"gofmt deve ser executado como parte de cada build para impor o padr\u00e3o comum. Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o trecho a seguir ao seu arquivo azure-pipelines.yaml . Isso formatar\u00e1 os scripts na pasta ./scripts/ . - script : go fmt workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar formata\u00e7\u00e3o de c\u00f3digo\" govet deve ser executado como parte de cada build para verificar a verifica\u00e7\u00e3o de c\u00f3digo. Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o trecho a seguir ao seu arquivo azure-pipelines.yaml . Isso verificar\u00e1 a verifica\u00e7\u00e3o de linting de qualquer script na pasta ./scripts/ . - script : go vet workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar verifica\u00e7\u00e3o de c\u00f3digo\" Alternativamente, voc\u00ea pode usar o golangci-lint como uma etapa no pipeline para realizar v\u00e1rias valida\u00e7\u00f5es habilitadas (incluindo go vet e go fmt) do golangci-lint. - script : golangci-lint run --enable gofmt --fix workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar verifica\u00e7\u00e3o de c\u00f3digo\"","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/go/#exemplo-de-pipeline-de-validacao-de-build-no-azure-devops","text":"trigger : master pool : vmImage : 'ubuntu-latest' steps : - task : GoTool@0 inputs : version : '1.13.5' - task : Go@0 inputs : command : 'get' arguments : '-d' workingDirectory : '$(System.DefaultWorkingDirectory)/scripts' - script : go fmt workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : \"Executar formata\u00e7\u00e3o de c\u00f3digo\" - script : go vet workingDirectory : $(System.DefaultWorkingDirectory)/scripts displayName : 'Executar go vet' - task : Go@0 inputs : command : 'build' workingDirectory : '$(System.DefaultWorking Directory)' - task : CopyFiles@2 inputs : TargetFolder : '$(Build.ArtifactStagingDirectory)' - task : PublishBuildArtifacts@1 inputs : artifactName : drop","title":"Exemplo de Pipeline de Valida\u00e7\u00e3o de Build no Azure DevOps"},{"location":"code-reviews/recipes/go/#checklist-de-revisao-de-codigo","text":"A equipe de linguagem Go mant\u00e9m uma lista de Coment\u00e1rios de Revis\u00e3o de C\u00f3digo Comuns para Go que formam a base para um s\u00f3lido checklist para uma equipe que trabalha em Go, que deve ser seguido al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo ISE Este c\u00f3digo trata erros corretamente? Isso inclui n\u00e3o descartar erros com atribui\u00e7\u00f5es _ e retornar erros, em vez de valores de erro no pr\u00f3prio canal ? Este c\u00f3digo segue os padr\u00f5es Go para tipos de receptor de m\u00e9todo receiver types ? Este c\u00f3digo passa valores quando necess\u00e1rio? As interfaces neste c\u00f3digo s\u00e3o definidas nos pacotes corretos ? As go-routines neste c\u00f3digo t\u00eam lifetimes claros ? O paralelismo neste c\u00f3digo \u00e9 tratado por meio de go-routines e canais com m\u00e9todos s\u00edncronos ? Este c\u00f3digo possui Coment\u00e1rios de Documenta\u00e7\u00e3o significativos? Este c\u00f3digo possui Coment\u00e1rios de Pacote significativos? Este c\u00f3digo usa Contextos corretamente? Os testes unit\u00e1rios falham com mensagens significativas ?","title":"Checklist de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/java/","text":"Revis\u00f5es de C\u00f3digo em Java Guia de Estilo Java Os desenvolvedores devem seguir o Guia de Estilo Java do Google . An\u00e1lise de C\u00f3digo / Verifica\u00e7\u00e3o de Estilo Acreditamos firmemente que um estilo consistente aumenta a legibilidade e a manuten\u00e7\u00e3o de uma base de c\u00f3digo. Portanto, recomendamos o uso de analisadores para impor regras de estilo e consist\u00eancia. Fazemos uso do Checkstyle usando a mesma configura\u00e7\u00e3o usada no Azure Java SDK . FindBugs e PMD tamb\u00e9m s\u00e3o comumente usados. Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo O Eclipse e outros IDEs Java oferecem suporte para formata\u00e7\u00e3o autom\u00e1tica de c\u00f3digo. Se estiver usando o Maven, alguns desenvolvedores tamb\u00e9m fazem uso do formatter-maven-plugin . Valida\u00e7\u00e3o de Build \u00c9 importante impor o estilo de c\u00f3digo e as regras na integra\u00e7\u00e3o cont\u00ednua (CI) para evitar que os membros da equipe fa\u00e7am merge de c\u00f3digo que n\u00e3o esteja em conformidade com os padr\u00f5es em seu reposit\u00f3rio Git. Se estiver construindo usando o Azure DevOps, o Azure DevOps oferece suporte para tarefas de build do Maven e Gradle usando ferramentas de an\u00e1lise de c\u00f3digo PMD , Checkstyle e FindBugs como parte de cada build. Aqui est\u00e1 um exemplo de YAML para uma tarefa de build Maven com todas as tr\u00eas ferramentas de an\u00e1lise habilitadas: - task : Maven@3 displayName : 'Maven pom.xml' inputs : mavenPomFile : '$(Parameters.mavenPOMFile)' checkStyleRunAnalysis : true pmdRunAnalysis : true findBugsRunAnalysis : true Aqui est\u00e1 um exemplo de YAML para uma tarefa de build Gradle com todas as tr\u00eas ferramentas de an\u00e1lise habilitadas: - task : Gradle@2 displayName : 'gradlew build' inputs : checkStyleRunAnalysis : true findBugsRunAnalysis : true pmdRunAnalysis : true Checklist de Revis\u00e3o de C\u00f3digo Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos de revis\u00e3o de c\u00f3digo em Java: O projeto utiliza Lambdas para tornar o c\u00f3digo mais limpo? A inje\u00e7\u00e3o de depend\u00eancia (DI) \u00e9 usada? Est\u00e1 configurada corretamente? Se o c\u00f3digo usa o Spring Boot, voc\u00ea est\u00e1 usando @Inject em vez de @Autowire? O c\u00f3digo lida com exce\u00e7\u00f5es corretamente? O Azul Zulu OpenJDK est\u00e1 sendo usado? Uma ferramenta de automa\u00e7\u00e3o de build e gerenciamento de pacotes (Gradle ou Maven) est\u00e1 sendo usada?","title":"Revis\u00f5es de C\u00f3digo em Java"},{"location":"code-reviews/recipes/java/#revisoes-de-codigo-em-java","text":"","title":"Revis\u00f5es de C\u00f3digo em Java"},{"location":"code-reviews/recipes/java/#guia-de-estilo-java","text":"Os desenvolvedores devem seguir o Guia de Estilo Java do Google .","title":"Guia de Estilo Java"},{"location":"code-reviews/recipes/java/#analise-de-codigo-verificacao-de-estilo","text":"Acreditamos firmemente que um estilo consistente aumenta a legibilidade e a manuten\u00e7\u00e3o de uma base de c\u00f3digo. Portanto, recomendamos o uso de analisadores para impor regras de estilo e consist\u00eancia. Fazemos uso do Checkstyle usando a mesma configura\u00e7\u00e3o usada no Azure Java SDK . FindBugs e PMD tamb\u00e9m s\u00e3o comumente usados.","title":"An\u00e1lise de C\u00f3digo / Verifica\u00e7\u00e3o de Estilo"},{"location":"code-reviews/recipes/java/#formatacao-automatica-de-codigo","text":"O Eclipse e outros IDEs Java oferecem suporte para formata\u00e7\u00e3o autom\u00e1tica de c\u00f3digo. Se estiver usando o Maven, alguns desenvolvedores tamb\u00e9m fazem uso do formatter-maven-plugin .","title":"Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo"},{"location":"code-reviews/recipes/java/#validacao-de-build","text":"\u00c9 importante impor o estilo de c\u00f3digo e as regras na integra\u00e7\u00e3o cont\u00ednua (CI) para evitar que os membros da equipe fa\u00e7am merge de c\u00f3digo que n\u00e3o esteja em conformidade com os padr\u00f5es em seu reposit\u00f3rio Git. Se estiver construindo usando o Azure DevOps, o Azure DevOps oferece suporte para tarefas de build do Maven e Gradle usando ferramentas de an\u00e1lise de c\u00f3digo PMD , Checkstyle e FindBugs como parte de cada build. Aqui est\u00e1 um exemplo de YAML para uma tarefa de build Maven com todas as tr\u00eas ferramentas de an\u00e1lise habilitadas: - task : Maven@3 displayName : 'Maven pom.xml' inputs : mavenPomFile : '$(Parameters.mavenPOMFile)' checkStyleRunAnalysis : true pmdRunAnalysis : true findBugsRunAnalysis : true Aqui est\u00e1 um exemplo de YAML para uma tarefa de build Gradle com todas as tr\u00eas ferramentas de an\u00e1lise habilitadas: - task : Gradle@2 displayName : 'gradlew build' inputs : checkStyleRunAnalysis : true findBugsRunAnalysis : true pmdRunAnalysis : true","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/java/#checklist-de-revisao-de-codigo","text":"Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos de revis\u00e3o de c\u00f3digo em Java: O projeto utiliza Lambdas para tornar o c\u00f3digo mais limpo? A inje\u00e7\u00e3o de depend\u00eancia (DI) \u00e9 usada? Est\u00e1 configurada corretamente? Se o c\u00f3digo usa o Spring Boot, voc\u00ea est\u00e1 usando @Inject em vez de @Autowire? O c\u00f3digo lida com exce\u00e7\u00f5es corretamente? O Azul Zulu OpenJDK est\u00e1 sendo usado? Uma ferramenta de automa\u00e7\u00e3o de build e gerenciamento de pacotes (Gradle ou Maven) est\u00e1 sendo usada?","title":"Checklist de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/javascript-and-typescript/","text":"Revis\u00f5es de C\u00f3digo em JavaScript/TypeScript Guia de Estilo Os desenvolvedores devem usar o Prettier para formata\u00e7\u00e3o de c\u00f3digo em JavaScript. O uso de uma ferramenta automatizada de formata\u00e7\u00e3o de c\u00f3digo, como o Prettier, imp\u00f5e um guia de estilo amplamente aceito que foi colaborativamente desenvolvido por uma ampla gama de empresas, incluindo Microsoft, Facebook e AirBnB. Para orienta\u00e7\u00e3o de estilo de n\u00edvel superior n\u00e3o abrangida pelo Prettier, seguimos o Guia de Estilo AirBnB . An\u00e1lise de C\u00f3digo / Verifica\u00e7\u00e3o de Estilo eslint De acordo com as orienta\u00e7\u00f5es delineadas no roadmap TSLint da Palantir de 2019 , o c\u00f3digo TypeScript deve ser lintado com o ESLint . Consulte a documenta\u00e7\u00e3o do typescript-eslint para obter mais informa\u00e7\u00f5es sobre a verifica\u00e7\u00e3o de c\u00f3digo TypeScript com o ESLint. Para instalar e configurar a verifica\u00e7\u00e3o de c\u00f3digo com o ESLint , instale os seguintes pacotes como depend\u00eancias de desenvolvimento: npm install -D eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin Adicione um arquivo .eslintrc.js \u00e0 raiz do seu projeto: module . exports = { root : true , parser : '@typescript-eslint/parser' , plugins : [ '@typescript-eslint' , ], extends : [ 'eslint:recommended' , 'plugin:@typescript-eslint/eslint-recommended' , 'plugin:@typescript-eslint/recommended' , ], }; Adicione o seguinte ao scripts do seu package.json : \"scripts\" : { \"lint\" : \"eslint . --ext .js,.jsx,.ts,.tsx --ignore-path .gitignore\" } Isso vai lintar todos os arquivos .js , .jsx , .ts , .tsx em seu projeto e omitir quaisquer arquivos ou diret\u00f3rios especificados no seu .gitignore . Voc\u00ea pode executar a verifica\u00e7\u00e3o de lintagem com: npm run lint Configura\u00e7\u00e3o do Prettier Prettier \u00e9 um formatador de c\u00f3digo com opini\u00f5es. Guia de in\u00edcio . Instale com npm como uma depend\u00eancia de desenvolvimento: npm install -D prettier eslint-config-prettier eslint-plugin-prettier Adicione prettier ao seu .eslintrc.js : module . exports = { root : true , parser : '@typescript-eslint/parser' , plugins : [ '@typescript-eslint' , ], extends : [ 'eslint:recommended' , 'plugin:@typescript-eslint/eslint-recommended' , 'plugin:@typescript-eslint/recommended' , 'prettier/@typescript-eslint' , 'plugin:prettier/recommended' , ], }; Isso aplicar\u00e1 o conjunto de regras prettier ao fazer a lintagem com o ESLint. Formata\u00e7\u00e3o Autom\u00e1tica com o VS Code O VS Code pode ser configurado para executar automaticamente eslint --fix ao salvar. Crie uma pasta .vscode na raiz do seu projeto e adicione o seguinte ao seu .vscode/settings.json : { \"editor.codeActionsOnSave\" : { \"source.fixAll.eslint\" : true }, } Por padr\u00e3o, usamos as seguintes substitui\u00e7\u00f5es que devem ser adicionadas \u00e0 configura\u00e7\u00e3o do VS Code para padronizar as aspas simples, uma indenta\u00e7\u00e3o de quatro espa\u00e7os e para realizar a verifica\u00e7\u00e3o de linting com ESLint: { \"prettier.singleQuote\" : true , \"prettier.eslintIntegration\" : true , \"prettier.tabWidth\" : 4 } Configura\u00e7\u00e3o de Testes Recomenda-se fortemente a configura\u00e7\u00e3o do Playwright em um projeto. \u00c9 uma su\u00edte de testes de c\u00f3digo aberto criada pela Microsoft. Para instal\u00e1-lo, use o seguinte comando: npm install playwright Como o Playwright mostra os testes no navegador, voc\u00ea deve escolher qual navegador deseja executar, a menos que esteja usando o Chrome, que \u00e9 o padr\u00e3o. Voc\u00ea pode fazer isso Valida\u00e7\u00e3o de Build Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o seguinte trecho ao seu arquivo de defini\u00e7\u00e3o de pipeline yaml. Isso realizar\u00e1 a lintagem de quaisquer scripts na pasta ./scripts/ . - task : Npm@1 displayName : 'Lint' inputs : command : 'custom' customCommand : 'run lint' workingDir : './scripts/' Hooks Pr\u00e9-Commit Todos os desenvolvedores devem executar o eslint em um hook pr\u00e9-commit para garantir a formata\u00e7\u00e3o padr\u00e3o. Recomendamos fortemente o uso de uma integra\u00e7\u00e3o com o editor, como o vscode-eslint , para fornecer feedback em tempo real. Em .git/hooks , renomeie pre-commit.sample para pre-commit Remova o c\u00f3digo de exemplo existente nesse arquivo Existem muitos exemplos de scripts para isso no gist, como pre-commit-eslint Modifique de acordo para incluir arquivos TypeScript (inclua a extens\u00e3o ts e certifique-se de que typescript-eslint esteja configurado) Torne o arquivo execut\u00e1vel: chmod +x .git/hooks/pre-commit Como alternativa, husky pode ser considerado para simplificar os hooks pr\u00e9-commit. Checklist de Revis\u00e3o de C\u00f3digo Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve verificar esses itens espec\u00edficos de revis\u00e3o de c\u00f3digo em JavaScript e TypeScript. Checklist de JavaScript / TypeScript O c\u00f3digo segue nossos padr\u00f5es de formata\u00e7\u00e3o e c\u00f3digo? Executar prettier e ESLint no c\u00f3digo n\u00e3o deve gerar avisos ou erros, respectivamente? A mudan\u00e7a re-implementa c\u00f3digo que seria melhor servido por um m\u00f3dulo bem conhecido do ecossistema? \u00c9 usado \"use strict\"; para reduzir erros com vari\u00e1veis n\u00e3o declaradas? S\u00e3o usados testes unit\u00e1rios sempre que poss\u00edvel, tamb\u00e9m para APIs? Os testes s\u00e3o organizados corretamente no padr\u00e3o Arrange/Act/Assert e devidamente documentados dessa forma? S\u00e3o seguidas as melhores pr\u00e1ticas para tratamento de erros, bem como as declara\u00e7\u00f5es try catch finally ? As chamadas ass\u00edncronas seguem corretamente o padr\u00e3o doWork().then(doSomething).then(checkSomething) , incluindo expect , done ? Em vez de usar strings brutas, s\u00e3o usadas constantes na classe principal? Ou, se essas strings s\u00e3o usadas em v\u00e1rios arquivos/classes, existe uma classe est\u00e1tica para as constantes? N\u00fameros m\u00e1gicos s\u00e3o explicados? N\u00e3o deve haver n\u00fameros no c\u00f3digo sem pelo menos um coment\u00e1rio explicando por que est\u00e3o l\u00e1. Se o n\u00famero for repetitivo, existe uma constante/enum ou equivalente? Se houver um m\u00e9todo ass\u00edncrono, o nome do m\u00e9todo termina com o sufixo Async ? Existe um n\u00edvel m\u00ednimo de registro de eventos? Os n\u00edveis de registro usados s\u00e3o sensatos? A manipula\u00e7\u00e3o do fragmento de documento \u00e9 limitada quando \u00e9 necess\u00e1rio manipular v\u00e1rios subelementos? O c\u00f3digo TypeScript \u00e9 compilado sem gerar erros de lintagem? Em vez de usar strings brutas, s\u00e3o usadas constantes na classe principal? Ou, se essas strings s\u00e3o usadas em v\u00e1rios arquivos/classes, existe uma classe est\u00e1tica para as constantes? N\u00fameros m\u00e1gicos s\u00e3o explicados? N\u00e3o deve haver n\u00fameros no c\u00f3digo sem pelo menos um coment\u00e1rio explicando por que est\u00e3o l\u00e1. Se o n\u00famero for repetitivo, existe uma constante/enum ou equivalente? Existem coment\u00e1rios apropriados /* */ nas v\u00e1rias classes e m\u00e9todos? Opera\u00e7\u00f5es pesadas s\u00e3o implementadas no backend, mantendo o controlador o mais leve poss\u00edvel? O tratamento de eventos no HTML \u00e9 eficiente?","title":"Revis\u00f5es de C\u00f3digo em JavaScript/TypeScript"},{"location":"code-reviews/recipes/javascript-and-typescript/#revisoes-de-codigo-em-javascripttypescript","text":"","title":"Revis\u00f5es de C\u00f3digo em JavaScript/TypeScript"},{"location":"code-reviews/recipes/javascript-and-typescript/#guia-de-estilo","text":"Os desenvolvedores devem usar o Prettier para formata\u00e7\u00e3o de c\u00f3digo em JavaScript. O uso de uma ferramenta automatizada de formata\u00e7\u00e3o de c\u00f3digo, como o Prettier, imp\u00f5e um guia de estilo amplamente aceito que foi colaborativamente desenvolvido por uma ampla gama de empresas, incluindo Microsoft, Facebook e AirBnB. Para orienta\u00e7\u00e3o de estilo de n\u00edvel superior n\u00e3o abrangida pelo Prettier, seguimos o Guia de Estilo AirBnB .","title":"Guia de Estilo"},{"location":"code-reviews/recipes/javascript-and-typescript/#analise-de-codigo-verificacao-de-estilo","text":"","title":"An\u00e1lise de C\u00f3digo / Verifica\u00e7\u00e3o de Estilo"},{"location":"code-reviews/recipes/javascript-and-typescript/#eslint","text":"De acordo com as orienta\u00e7\u00f5es delineadas no roadmap TSLint da Palantir de 2019 , o c\u00f3digo TypeScript deve ser lintado com o ESLint . Consulte a documenta\u00e7\u00e3o do typescript-eslint para obter mais informa\u00e7\u00f5es sobre a verifica\u00e7\u00e3o de c\u00f3digo TypeScript com o ESLint. Para instalar e configurar a verifica\u00e7\u00e3o de c\u00f3digo com o ESLint , instale os seguintes pacotes como depend\u00eancias de desenvolvimento: npm install -D eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin Adicione um arquivo .eslintrc.js \u00e0 raiz do seu projeto: module . exports = { root : true , parser : '@typescript-eslint/parser' , plugins : [ '@typescript-eslint' , ], extends : [ 'eslint:recommended' , 'plugin:@typescript-eslint/eslint-recommended' , 'plugin:@typescript-eslint/recommended' , ], }; Adicione o seguinte ao scripts do seu package.json : \"scripts\" : { \"lint\" : \"eslint . --ext .js,.jsx,.ts,.tsx --ignore-path .gitignore\" } Isso vai lintar todos os arquivos .js , .jsx , .ts , .tsx em seu projeto e omitir quaisquer arquivos ou diret\u00f3rios especificados no seu .gitignore . Voc\u00ea pode executar a verifica\u00e7\u00e3o de lintagem com: npm run lint","title":"eslint"},{"location":"code-reviews/recipes/javascript-and-typescript/#configuracao-do-prettier","text":"Prettier \u00e9 um formatador de c\u00f3digo com opini\u00f5es. Guia de in\u00edcio . Instale com npm como uma depend\u00eancia de desenvolvimento: npm install -D prettier eslint-config-prettier eslint-plugin-prettier Adicione prettier ao seu .eslintrc.js : module . exports = { root : true , parser : '@typescript-eslint/parser' , plugins : [ '@typescript-eslint' , ], extends : [ 'eslint:recommended' , 'plugin:@typescript-eslint/eslint-recommended' , 'plugin:@typescript-eslint/recommended' , 'prettier/@typescript-eslint' , 'plugin:prettier/recommended' , ], }; Isso aplicar\u00e1 o conjunto de regras prettier ao fazer a lintagem com o ESLint.","title":"Configura\u00e7\u00e3o do Prettier"},{"location":"code-reviews/recipes/javascript-and-typescript/#formatacao-automatica-com-o-vs-code","text":"O VS Code pode ser configurado para executar automaticamente eslint --fix ao salvar. Crie uma pasta .vscode na raiz do seu projeto e adicione o seguinte ao seu .vscode/settings.json : { \"editor.codeActionsOnSave\" : { \"source.fixAll.eslint\" : true }, } Por padr\u00e3o, usamos as seguintes substitui\u00e7\u00f5es que devem ser adicionadas \u00e0 configura\u00e7\u00e3o do VS Code para padronizar as aspas simples, uma indenta\u00e7\u00e3o de quatro espa\u00e7os e para realizar a verifica\u00e7\u00e3o de linting com ESLint: { \"prettier.singleQuote\" : true , \"prettier.eslintIntegration\" : true , \"prettier.tabWidth\" : 4 }","title":"Formata\u00e7\u00e3o Autom\u00e1tica com o VS Code"},{"location":"code-reviews/recipes/javascript-and-typescript/#configuracao-de-testes","text":"Recomenda-se fortemente a configura\u00e7\u00e3o do Playwright em um projeto. \u00c9 uma su\u00edte de testes de c\u00f3digo aberto criada pela Microsoft. Para instal\u00e1-lo, use o seguinte comando: npm install playwright Como o Playwright mostra os testes no navegador, voc\u00ea deve escolher qual navegador deseja executar, a menos que esteja usando o Chrome, que \u00e9 o padr\u00e3o. Voc\u00ea pode fazer isso","title":"Configura\u00e7\u00e3o de Testes"},{"location":"code-reviews/recipes/javascript-and-typescript/#validacao-de-build","text":"Para automatizar esse processo no Azure DevOps, voc\u00ea pode adicionar o seguinte trecho ao seu arquivo de defini\u00e7\u00e3o de pipeline yaml. Isso realizar\u00e1 a lintagem de quaisquer scripts na pasta ./scripts/ . - task : Npm@1 displayName : 'Lint' inputs : command : 'custom' customCommand : 'run lint' workingDir : './scripts/'","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/javascript-and-typescript/#hooks-pre-commit","text":"Todos os desenvolvedores devem executar o eslint em um hook pr\u00e9-commit para garantir a formata\u00e7\u00e3o padr\u00e3o. Recomendamos fortemente o uso de uma integra\u00e7\u00e3o com o editor, como o vscode-eslint , para fornecer feedback em tempo real. Em .git/hooks , renomeie pre-commit.sample para pre-commit Remova o c\u00f3digo de exemplo existente nesse arquivo Existem muitos exemplos de scripts para isso no gist, como pre-commit-eslint Modifique de acordo para incluir arquivos TypeScript (inclua a extens\u00e3o ts e certifique-se de que typescript-eslint esteja configurado) Torne o arquivo execut\u00e1vel: chmod +x .git/hooks/pre-commit Como alternativa, husky pode ser considerado para simplificar os hooks pr\u00e9-commit.","title":"Hooks Pr\u00e9-Commit"},{"location":"code-reviews/recipes/javascript-and-typescript/#checklist-de-revisao-de-codigo","text":"Al\u00e9m do Checklist de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve verificar esses itens espec\u00edficos de revis\u00e3o de c\u00f3digo em JavaScript e TypeScript.","title":"Checklist de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/javascript-and-typescript/#checklist-de-javascript-typescript","text":"O c\u00f3digo segue nossos padr\u00f5es de formata\u00e7\u00e3o e c\u00f3digo? Executar prettier e ESLint no c\u00f3digo n\u00e3o deve gerar avisos ou erros, respectivamente? A mudan\u00e7a re-implementa c\u00f3digo que seria melhor servido por um m\u00f3dulo bem conhecido do ecossistema? \u00c9 usado \"use strict\"; para reduzir erros com vari\u00e1veis n\u00e3o declaradas? S\u00e3o usados testes unit\u00e1rios sempre que poss\u00edvel, tamb\u00e9m para APIs? Os testes s\u00e3o organizados corretamente no padr\u00e3o Arrange/Act/Assert e devidamente documentados dessa forma? S\u00e3o seguidas as melhores pr\u00e1ticas para tratamento de erros, bem como as declara\u00e7\u00f5es try catch finally ? As chamadas ass\u00edncronas seguem corretamente o padr\u00e3o doWork().then(doSomething).then(checkSomething) , incluindo expect , done ? Em vez de usar strings brutas, s\u00e3o usadas constantes na classe principal? Ou, se essas strings s\u00e3o usadas em v\u00e1rios arquivos/classes, existe uma classe est\u00e1tica para as constantes? N\u00fameros m\u00e1gicos s\u00e3o explicados? N\u00e3o deve haver n\u00fameros no c\u00f3digo sem pelo menos um coment\u00e1rio explicando por que est\u00e3o l\u00e1. Se o n\u00famero for repetitivo, existe uma constante/enum ou equivalente? Se houver um m\u00e9todo ass\u00edncrono, o nome do m\u00e9todo termina com o sufixo Async ? Existe um n\u00edvel m\u00ednimo de registro de eventos? Os n\u00edveis de registro usados s\u00e3o sensatos? A manipula\u00e7\u00e3o do fragmento de documento \u00e9 limitada quando \u00e9 necess\u00e1rio manipular v\u00e1rios subelementos? O c\u00f3digo TypeScript \u00e9 compilado sem gerar erros de lintagem? Em vez de usar strings brutas, s\u00e3o usadas constantes na classe principal? Ou, se essas strings s\u00e3o usadas em v\u00e1rios arquivos/classes, existe uma classe est\u00e1tica para as constantes? N\u00fameros m\u00e1gicos s\u00e3o explicados? N\u00e3o deve haver n\u00fameros no c\u00f3digo sem pelo menos um coment\u00e1rio explicando por que est\u00e3o l\u00e1. Se o n\u00famero for repetitivo, existe uma constante/enum ou equivalente? Existem coment\u00e1rios apropriados /* */ nas v\u00e1rias classes e m\u00e9todos? Opera\u00e7\u00f5es pesadas s\u00e3o implementadas no backend, mantendo o controlador o mais leve poss\u00edvel? O tratamento de eventos no HTML \u00e9 eficiente?","title":"Checklist de JavaScript / TypeScript"},{"location":"code-reviews/recipes/markdown/","text":"Revis\u00f5es de C\u00f3digo em Markdown Guia de Estilo Os desenvolvedores devem tratar a documenta\u00e7\u00e3o como qualquer outro c\u00f3digo fonte e seguir as mesmas regras e listas de verifica\u00e7\u00e3o ao revisar a documenta\u00e7\u00e3o como c\u00f3digo. A documenta\u00e7\u00e3o deve utilizar uma boa sintaxe Markdown para garantir que seja interpretada corretamente e seguir boas diretrizes de estilo de escrita para garantir que o documento seja f\u00e1cil de ler e entender. Markdown Markdown \u00e9 uma linguagem de marca\u00e7\u00e3o leve que voc\u00ea pode usar para adicionar elementos de formata\u00e7\u00e3o a documentos de texto simples. Criado por John Gruber em 2004, o Markdown agora \u00e9 uma das linguagens de marca\u00e7\u00e3o mais populares do mundo. Usar o Markdown \u00e9 diferente de usar um editor WYSIWYG. Em um aplicativo como o Microsoft Word, voc\u00ea clica em bot\u00f5es para formatar palavras e frases, e as altera\u00e7\u00f5es s\u00e3o vis\u00edveis imediatamente. O Markdown n\u00e3o \u00e9 assim. Quando voc\u00ea cria um arquivo formatado em Markdown, voc\u00ea adiciona a sintaxe do Markdown ao texto para indicar quais palavras e frases devem parecer diferentes. Voc\u00ea pode encontrar mais informa\u00e7\u00f5es e documenta\u00e7\u00e3o completa aqui . Linters O Markdown tem uma maneira espec\u00edfica de ser formatado. \u00c9 importante respeitar essa formata\u00e7\u00e3o, caso contr\u00e1rio, alguns interpretadores que s\u00e3o rigorosos podem n\u00e3o exibir corretamente o documento. Os linters s\u00e3o frequentemente usados para ajudar os desenvolvedores a criar documentos adequadamente, verificando tanto a sintaxe correta do Markdown quanto a gram\u00e1tica e o uso adequado do idioma ingl\u00eas. Uma boa configura\u00e7\u00e3o inclui um linter de Markdown usado durante a edi\u00e7\u00e3o e verifica\u00e7\u00e3o de build de PR, e um linter de gram\u00e1tica usado durante a edi\u00e7\u00e3o do documento. A seguir, est\u00e3o listados alguns linters que podem ser usados nessa configura\u00e7\u00e3o. markdownlint markdownlint \u00e9 um linter para Markdown que verifica a sintaxe do Markdown e tamb\u00e9m imp\u00f5e regras que tornam o texto mais leg\u00edvel. Markdownlint-cli \u00e9 uma CLI f\u00e1cil de usar baseada no Markdownlint. Est\u00e1 dispon\u00edvel como um gem Ruby , um pacote npm , uma CLI Node.js e uma extens\u00e3o do VS Code . A extens\u00e3o do VS Code Prettier tamb\u00e9m captura todos os erros do markdownlint. Instalando a CLI Node.js npm install -g markdownlint-cli Executando o markdownlint em um projeto Node.js markdownlint **/*.md --ignore node_modules Corrigindo erros automaticamente markdownlint **/*.md --ignore node_modules --fix Uma lista completa de regras do markdownlint est\u00e1 dispon\u00edvel aqui . proselint proselint \u00e9 um utilit\u00e1rio de linha de comando que verifica o conte\u00fado de texto do documento. Ele verifica jarg\u00f5es, erros de ortografia, redund\u00e2ncia, linguagem corporativa e outros problemas relacionados ao idioma. Est\u00e1 dispon\u00edvel como um pacote Python e um pacote Node . pip install proselint npm install -g proselint Execute o proselint proselint document.md write-good write-good \u00e9 um linter para texto em ingl\u00eas que ajuda a escrever uma documenta\u00e7\u00e3o melhor. npm install -g write-good Execute o write-good write-good *.md Execute o write-good sem instal\u00e1-lo npx write-good *.md O Write Good tamb\u00e9m est\u00e1 dispon\u00edvel como uma extens\u00e3o para o VS Code Extens\u00f5es do VS Code Extens\u00e3o Write Good Linter A Extens\u00e3o Write Good Linter integra-se ao VS Code para fornecer dicas de gram\u00e1tica e linguagem durante a edi\u00e7\u00e3o do documento. Extens\u00e3o markdownlint A Extens\u00e3o markdownlint examina os documentos Markdown, exibindo avisos para viola\u00e7\u00f5es de regras durante a edi\u00e7\u00e3o. Valida\u00e7\u00e3o de Build Lintagem Para automatizar a lintagem com o markdownlint para valida\u00e7\u00e3o de PR em a\u00e7\u00f5es do GitHub, voc\u00ea pode usar um agregador de linters, como fazemos com o MegaLinter neste reposit\u00f3rio , ou usar o seguinte YAML. name : Markdownlint on : push : paths : - \"**/*.md\" pull_request : paths : - \"**/*.md\" jobs : lint : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Use o Node.js uses : actions/setup-node@v1 with : node-version : 12.x - name : Execute o Markdownlint run : | npm i -g markdownlint-cli markdownlint \"**/*.md\" --ignore node_modules Verifica\u00e7\u00e3o de Links Para automatizar a verifica\u00e7\u00e3o de links em seus arquivos Markdown, adicione a a\u00e7\u00e3o markdown-link-check ao seu pipeline de valida\u00e7\u00e3o: markdown-link-check : runs-on : ubuntu-latest steps : - uses : actions/checkout@master - uses : gaurav-nelson/github-action-markdown-link-check@v1 Mais informa\u00e7\u00f5es sobre as op\u00e7\u00f5es da a\u00e7\u00e3o markdown-link-check podem ser encontradas na p\u00e1gina principal do markdown-link-check . Checklist de Revis\u00e3o de C\u00f3digo Al\u00e9m do [Checklist de Revis\u00e3o de C\u00f3digo](../process-guidance/reviewer-guidance.md), voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos de revis\u00e3o de c\u00f3digo de documenta\u00e7\u00e3o: O documento \u00e9 f\u00e1cil de ler e entender e segue as boas diretrizes de escrita ? Existe uma \u00fanica fonte de verdade ou o conte\u00fado \u00e9 repetido em mais de um documento? A documenta\u00e7\u00e3o est\u00e1 atualizada com o c\u00f3digo? A documenta\u00e7\u00e3o \u00e9 tecnicamente e eticamente correta? Diretrizes de Estilo de Escrita A seguir, alguns exemplos de diretrizes de estilo de escrita. Concordem em sua equipe quais diretrizes voc\u00eas devem aplicar \u00e0 documenta\u00e7\u00e3o do projeto. Salve suas diretrizes juntamente com sua documenta\u00e7\u00e3o, para que seja f\u00e1cil consult\u00e1-las. Reda\u00e7\u00e3o Use linguagem inclusiva e evite jarg\u00f5es e palavras incomuns. A documenta\u00e7\u00e3o deve ser f\u00e1cil de entender. Seja claro e conciso, siga o objetivo do documento. Use voz ativa. Verifique a ortografia e a gram\u00e1tica do texto. Siga sempre a ordem cronol\u00f3gica. Visite Plain English para dicas sobre como escrever documenta\u00e7\u00e3o f\u00e1cil de entender. Organiza\u00e7\u00e3o do Documento Organize os documentos por t\u00f3pico em vez de tipo, isso facilita a localiza\u00e7\u00e3o da documenta\u00e7\u00e3o. Cada pasta deve ter um README.md de n\u00edvel superior e qualquer outro documento dentro dessa pasta deve ter links diretos ou indiretos a partir desse README.md. Nomes de documentos com mais de uma palavra devem usar sublinhados em vez de espa\u00e7os, por exemplo, machine_learning_pipeline_design.md . O mesmo se aplica \u00e0s imagens. Cabe\u00e7alhos Comece com um H1 (um \u00fanico # em Markdown) e respeite a ordem H1 > H2 > H3 etc. Siga cada cabe\u00e7alho com texto antes de prosseguir para o pr\u00f3ximo cabe\u00e7alho. Evite colocar n\u00fameros nos cabe\u00e7alhos. N\u00fameros mudam e podem criar t\u00edtulos desatualizados. Evite usar s\u00edmbolos e caracteres especiais em cabe\u00e7alhos, isso causa problemas com links de \u00e2ncora. Evite links em cabe\u00e7alhos. Links Evite duplica\u00e7\u00e3o de conte\u00fado, em vez disso, fa\u00e7a um link para a \u00fanica fonte de verdade . Fa\u00e7a link, mas n\u00e3o resuma. Resumir o conte\u00fado em outra p\u00e1gina faz com que o conte\u00fado exista em dois lugares. Use textos de \u00e2ncora significativos, por exemplo, em vez de escrever Siga as instru\u00e7\u00f5es [aqui](../recipes/markdown.md) , escreva Siga as [diretrizes do Markdown](../recipes/markdown.md) . Certifique-se de que os links para a documenta\u00e7\u00e3o da Microsoft n\u00e3o contenham o marcador de idioma /en-us/ ou /fr-fr/ , pois isso \u00e9 determinado automaticamente pelo pr\u00f3prio site. Listas Itens de lista devem come\u00e7ar com letras mai\u00fasculas, se poss\u00edvel. Use listas ordenadas quando os itens descrevem uma sequ\u00eancia a seguir, caso contr\u00e1rio, use listas n\u00e3o ordenadas. Para listas ordenadas, prefixe cada item com 1. . Quando renderizado, os itens da lista aparecer\u00e3o com numera\u00e7\u00e3o sequencial. Isso evita lacunas de n\u00fameros na lista. N\u00e3o adicione v\u00edrgulas , ou ponto e v\u00edrgulas ; no final dos itens da lista e evite pontos . a menos que o item da lista represente uma frase completa. Imagens Coloque as imagens em um diret\u00f3rio separado chamado img . Nomeie as imagens apropriadamente, evitando nomes gen\u00e9ricos como screenshot.png . Evite adicionar imagens ou v\u00eddeos grandes ao controle de origem, fa\u00e7a um link para um local externo. \u00canfase e se\u00e7\u00f5es especiais Use negrito ou it\u00e1lico para enfatizar. Para se\u00e7\u00f5es que todos que leem este documento precisam estar cientes, use blocos. Use crases para c\u00f3digo, uma crase simples para c\u00f3digo inline como pip install flake8 e 3 crases para blocos de c\u00f3digo seguidos pelo idioma para destacar a sintaxe. def add ( num1 : int , num2 : int ): return num1 + num2 Use caixas de sele\u00e7\u00e3o para listas de tarefas. Item 1 Item 2 Item 3 Adicione uma se\u00e7\u00e3o de Refer\u00eancias ao final do documento com links para refer\u00eancias externas. Prefira tabelas a listas para compara\u00e7\u00f5es e relat\u00f3rios para tornar a pesquisa e os resultados mais leg\u00edveis. Op\u00e7\u00e3o Pr\u00f3s Contras Op\u00e7\u00e3o 1 Alguns pr\u00f3s Alguns contras Op\u00e7\u00e3o 2 Alguns pr\u00f3s Alguns contras Geral Sempre use a sintaxe Markdown, n\u00e3o misture com HTML. Certifique-se de que a extens\u00e3o dos arquivos seja .md . Se a extens\u00e3o estiver faltando, um linter pode ignorar os arquivos.","title":"Revis\u00f5es de C\u00f3digo em Markdown"},{"location":"code-reviews/recipes/markdown/#revisoes-de-codigo-em-markdown","text":"","title":"Revis\u00f5es de C\u00f3digo em Markdown"},{"location":"code-reviews/recipes/markdown/#guia-de-estilo","text":"Os desenvolvedores devem tratar a documenta\u00e7\u00e3o como qualquer outro c\u00f3digo fonte e seguir as mesmas regras e listas de verifica\u00e7\u00e3o ao revisar a documenta\u00e7\u00e3o como c\u00f3digo. A documenta\u00e7\u00e3o deve utilizar uma boa sintaxe Markdown para garantir que seja interpretada corretamente e seguir boas diretrizes de estilo de escrita para garantir que o documento seja f\u00e1cil de ler e entender.","title":"Guia de Estilo"},{"location":"code-reviews/recipes/markdown/#markdown","text":"Markdown \u00e9 uma linguagem de marca\u00e7\u00e3o leve que voc\u00ea pode usar para adicionar elementos de formata\u00e7\u00e3o a documentos de texto simples. Criado por John Gruber em 2004, o Markdown agora \u00e9 uma das linguagens de marca\u00e7\u00e3o mais populares do mundo. Usar o Markdown \u00e9 diferente de usar um editor WYSIWYG. Em um aplicativo como o Microsoft Word, voc\u00ea clica em bot\u00f5es para formatar palavras e frases, e as altera\u00e7\u00f5es s\u00e3o vis\u00edveis imediatamente. O Markdown n\u00e3o \u00e9 assim. Quando voc\u00ea cria um arquivo formatado em Markdown, voc\u00ea adiciona a sintaxe do Markdown ao texto para indicar quais palavras e frases devem parecer diferentes. Voc\u00ea pode encontrar mais informa\u00e7\u00f5es e documenta\u00e7\u00e3o completa aqui .","title":"Markdown"},{"location":"code-reviews/recipes/markdown/#linters","text":"O Markdown tem uma maneira espec\u00edfica de ser formatado. \u00c9 importante respeitar essa formata\u00e7\u00e3o, caso contr\u00e1rio, alguns interpretadores que s\u00e3o rigorosos podem n\u00e3o exibir corretamente o documento. Os linters s\u00e3o frequentemente usados para ajudar os desenvolvedores a criar documentos adequadamente, verificando tanto a sintaxe correta do Markdown quanto a gram\u00e1tica e o uso adequado do idioma ingl\u00eas. Uma boa configura\u00e7\u00e3o inclui um linter de Markdown usado durante a edi\u00e7\u00e3o e verifica\u00e7\u00e3o de build de PR, e um linter de gram\u00e1tica usado durante a edi\u00e7\u00e3o do documento. A seguir, est\u00e3o listados alguns linters que podem ser usados nessa configura\u00e7\u00e3o.","title":"Linters"},{"location":"code-reviews/recipes/markdown/#markdownlint","text":"markdownlint \u00e9 um linter para Markdown que verifica a sintaxe do Markdown e tamb\u00e9m imp\u00f5e regras que tornam o texto mais leg\u00edvel. Markdownlint-cli \u00e9 uma CLI f\u00e1cil de usar baseada no Markdownlint. Est\u00e1 dispon\u00edvel como um gem Ruby , um pacote npm , uma CLI Node.js e uma extens\u00e3o do VS Code . A extens\u00e3o do VS Code Prettier tamb\u00e9m captura todos os erros do markdownlint. Instalando a CLI Node.js npm install -g markdownlint-cli Executando o markdownlint em um projeto Node.js markdownlint **/*.md --ignore node_modules Corrigindo erros automaticamente markdownlint **/*.md --ignore node_modules --fix Uma lista completa de regras do markdownlint est\u00e1 dispon\u00edvel aqui .","title":"markdownlint"},{"location":"code-reviews/recipes/markdown/#proselint","text":"proselint \u00e9 um utilit\u00e1rio de linha de comando que verifica o conte\u00fado de texto do documento. Ele verifica jarg\u00f5es, erros de ortografia, redund\u00e2ncia, linguagem corporativa e outros problemas relacionados ao idioma. Est\u00e1 dispon\u00edvel como um pacote Python e um pacote Node . pip install proselint npm install -g proselint Execute o proselint proselint document.md","title":"proselint"},{"location":"code-reviews/recipes/markdown/#write-good","text":"write-good \u00e9 um linter para texto em ingl\u00eas que ajuda a escrever uma documenta\u00e7\u00e3o melhor. npm install -g write-good Execute o write-good write-good *.md Execute o write-good sem instal\u00e1-lo npx write-good *.md O Write Good tamb\u00e9m est\u00e1 dispon\u00edvel como uma extens\u00e3o para o VS Code","title":"write-good"},{"location":"code-reviews/recipes/markdown/#extensoes-do-vs-code","text":"","title":"Extens\u00f5es do VS Code"},{"location":"code-reviews/recipes/markdown/#extensao-write-good-linter","text":"A Extens\u00e3o Write Good Linter integra-se ao VS Code para fornecer dicas de gram\u00e1tica e linguagem durante a edi\u00e7\u00e3o do documento.","title":"Extens\u00e3o Write Good Linter"},{"location":"code-reviews/recipes/markdown/#extensao-markdownlint","text":"A Extens\u00e3o markdownlint examina os documentos Markdown, exibindo avisos para viola\u00e7\u00f5es de regras durante a edi\u00e7\u00e3o.","title":"Extens\u00e3o markdownlint"},{"location":"code-reviews/recipes/markdown/#validacao-de-build","text":"","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/markdown/#lintagem","text":"Para automatizar a lintagem com o markdownlint para valida\u00e7\u00e3o de PR em a\u00e7\u00f5es do GitHub, voc\u00ea pode usar um agregador de linters, como fazemos com o MegaLinter neste reposit\u00f3rio , ou usar o seguinte YAML. name : Markdownlint on : push : paths : - \"**/*.md\" pull_request : paths : - \"**/*.md\" jobs : lint : runs-on : ubuntu-latest steps : - uses : actions/checkout@v2 - name : Use o Node.js uses : actions/setup-node@v1 with : node-version : 12.x - name : Execute o Markdownlint run : | npm i -g markdownlint-cli markdownlint \"**/*.md\" --ignore node_modules","title":"Lintagem"},{"location":"code-reviews/recipes/markdown/#verificacao-de-links","text":"Para automatizar a verifica\u00e7\u00e3o de links em seus arquivos Markdown, adicione a a\u00e7\u00e3o markdown-link-check ao seu pipeline de valida\u00e7\u00e3o: markdown-link-check : runs-on : ubuntu-latest steps : - uses : actions/checkout@master - uses : gaurav-nelson/github-action-markdown-link-check@v1 Mais informa\u00e7\u00f5es sobre as op\u00e7\u00f5es da a\u00e7\u00e3o markdown-link-check podem ser encontradas na p\u00e1gina principal do markdown-link-check .","title":"Verifica\u00e7\u00e3o de Links"},{"location":"code-reviews/recipes/markdown/#checklist-de-revisao-de-codigo","text":"Al\u00e9m do [Checklist de Revis\u00e3o de C\u00f3digo](../process-guidance/reviewer-guidance.md), voc\u00ea tamb\u00e9m deve procurar por itens espec\u00edficos de revis\u00e3o de c\u00f3digo de documenta\u00e7\u00e3o: O documento \u00e9 f\u00e1cil de ler e entender e segue as boas diretrizes de escrita ? Existe uma \u00fanica fonte de verdade ou o conte\u00fado \u00e9 repetido em mais de um documento? A documenta\u00e7\u00e3o est\u00e1 atualizada com o c\u00f3digo? A documenta\u00e7\u00e3o \u00e9 tecnicamente e eticamente correta?","title":"Checklist de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/markdown/#diretrizes-de-estilo-de-escrita","text":"A seguir, alguns exemplos de diretrizes de estilo de escrita. Concordem em sua equipe quais diretrizes voc\u00eas devem aplicar \u00e0 documenta\u00e7\u00e3o do projeto. Salve suas diretrizes juntamente com sua documenta\u00e7\u00e3o, para que seja f\u00e1cil consult\u00e1-las.","title":"Diretrizes de Estilo de Escrita"},{"location":"code-reviews/recipes/markdown/#redacao","text":"Use linguagem inclusiva e evite jarg\u00f5es e palavras incomuns. A documenta\u00e7\u00e3o deve ser f\u00e1cil de entender. Seja claro e conciso, siga o objetivo do documento. Use voz ativa. Verifique a ortografia e a gram\u00e1tica do texto. Siga sempre a ordem cronol\u00f3gica. Visite Plain English para dicas sobre como escrever documenta\u00e7\u00e3o f\u00e1cil de entender.","title":"Reda\u00e7\u00e3o"},{"location":"code-reviews/recipes/markdown/#organizacao-do-documento","text":"Organize os documentos por t\u00f3pico em vez de tipo, isso facilita a localiza\u00e7\u00e3o da documenta\u00e7\u00e3o. Cada pasta deve ter um README.md de n\u00edvel superior e qualquer outro documento dentro dessa pasta deve ter links diretos ou indiretos a partir desse README.md. Nomes de documentos com mais de uma palavra devem usar sublinhados em vez de espa\u00e7os, por exemplo, machine_learning_pipeline_design.md . O mesmo se aplica \u00e0s imagens.","title":"Organiza\u00e7\u00e3o do Documento"},{"location":"code-reviews/recipes/markdown/#cabecalhos","text":"Comece com um H1 (um \u00fanico # em Markdown) e respeite a ordem H1 > H2 > H3 etc. Siga cada cabe\u00e7alho com texto antes de prosseguir para o pr\u00f3ximo cabe\u00e7alho. Evite colocar n\u00fameros nos cabe\u00e7alhos. N\u00fameros mudam e podem criar t\u00edtulos desatualizados. Evite usar s\u00edmbolos e caracteres especiais em cabe\u00e7alhos, isso causa problemas com links de \u00e2ncora. Evite links em cabe\u00e7alhos.","title":"Cabe\u00e7alhos"},{"location":"code-reviews/recipes/markdown/#links","text":"Evite duplica\u00e7\u00e3o de conte\u00fado, em vez disso, fa\u00e7a um link para a \u00fanica fonte de verdade . Fa\u00e7a link, mas n\u00e3o resuma. Resumir o conte\u00fado em outra p\u00e1gina faz com que o conte\u00fado exista em dois lugares. Use textos de \u00e2ncora significativos, por exemplo, em vez de escrever Siga as instru\u00e7\u00f5es [aqui](../recipes/markdown.md) , escreva Siga as [diretrizes do Markdown](../recipes/markdown.md) . Certifique-se de que os links para a documenta\u00e7\u00e3o da Microsoft n\u00e3o contenham o marcador de idioma /en-us/ ou /fr-fr/ , pois isso \u00e9 determinado automaticamente pelo pr\u00f3prio site.","title":"Links"},{"location":"code-reviews/recipes/markdown/#listas","text":"Itens de lista devem come\u00e7ar com letras mai\u00fasculas, se poss\u00edvel. Use listas ordenadas quando os itens descrevem uma sequ\u00eancia a seguir, caso contr\u00e1rio, use listas n\u00e3o ordenadas. Para listas ordenadas, prefixe cada item com 1. . Quando renderizado, os itens da lista aparecer\u00e3o com numera\u00e7\u00e3o sequencial. Isso evita lacunas de n\u00fameros na lista. N\u00e3o adicione v\u00edrgulas , ou ponto e v\u00edrgulas ; no final dos itens da lista e evite pontos . a menos que o item da lista represente uma frase completa.","title":"Listas"},{"location":"code-reviews/recipes/markdown/#imagens","text":"Coloque as imagens em um diret\u00f3rio separado chamado img . Nomeie as imagens apropriadamente, evitando nomes gen\u00e9ricos como screenshot.png . Evite adicionar imagens ou v\u00eddeos grandes ao controle de origem, fa\u00e7a um link para um local externo.","title":"Imagens"},{"location":"code-reviews/recipes/markdown/#enfase-e-secoes-especiais","text":"Use negrito ou it\u00e1lico para enfatizar. Para se\u00e7\u00f5es que todos que leem este documento precisam estar cientes, use blocos. Use crases para c\u00f3digo, uma crase simples para c\u00f3digo inline como pip install flake8 e 3 crases para blocos de c\u00f3digo seguidos pelo idioma para destacar a sintaxe. def add ( num1 : int , num2 : int ): return num1 + num2 Use caixas de sele\u00e7\u00e3o para listas de tarefas. Item 1 Item 2 Item 3 Adicione uma se\u00e7\u00e3o de Refer\u00eancias ao final do documento com links para refer\u00eancias externas. Prefira tabelas a listas para compara\u00e7\u00f5es e relat\u00f3rios para tornar a pesquisa e os resultados mais leg\u00edveis. Op\u00e7\u00e3o Pr\u00f3s Contras Op\u00e7\u00e3o 1 Alguns pr\u00f3s Alguns contras Op\u00e7\u00e3o 2 Alguns pr\u00f3s Alguns contras","title":"\u00canfase e se\u00e7\u00f5es especiais"},{"location":"code-reviews/recipes/markdown/#geral","text":"Sempre use a sintaxe Markdown, n\u00e3o misture com HTML. Certifique-se de que a extens\u00e3o dos arquivos seja .md . Se a extens\u00e3o estiver faltando, um linter pode ignorar os arquivos.","title":"Geral"},{"location":"code-reviews/recipes/python/","text":"Revis\u00e3o de C\u00f3digo em Python Guia de Estilo Os desenvolvedores devem seguir o guia de estilo PEP8 com dicas de tipo . O uso de dicas de tipo em conjunto com a lintagem e verifica\u00e7\u00e3o de dicas de tipo evita erros comuns que s\u00e3o dif\u00edceis de depurar. Projetos devem verificar o c\u00f3digo Python com ferramentas automatizadas. A lintagem deve ser adicionada \u00e0 valida\u00e7\u00e3o de build, e tanto a lintagem quanto a formata\u00e7\u00e3o de c\u00f3digo podem ser adicionadas aos seus ganchos de pr\u00e9-compromisso e ao VS Code. An\u00e1lise de C\u00f3digo / Lintagem Os dois linters Python mais populares s\u00e3o o Pylint e o Flake8 . Ambos verificam a ader\u00eancia ao PEP8 , mas variam um pouco no que diz respeito a outras regras que verificam. Em geral, o Pylint tende a ser um pouco mais rigoroso e pode gerar mais falsos positivos, mas ambos s\u00e3o boas op\u00e7\u00f5es para a lintagem de c\u00f3digo Python. Tanto o Pylint quanto o Flake8 podem ser configurados no VS Code usando a extens\u00e3o Python do VS Code. Flake8 O Flake8 \u00e9 um wrapper simples e r\u00e1pido em torno do Pyflakes (para detec\u00e7\u00e3o de erros de codifica\u00e7\u00e3o) e pycodestyle (para o PEP8 ). Instale o Flake8 pip install flake8 Adicione uma extens\u00e3o para a ferramenta pydocstyle (para strings de documenta\u00e7\u00e3o ) ao Flake8 . pip install flake8-docstrings Adicione uma extens\u00e3o para o pep8-naming (para conven\u00e7\u00f5es de nomenclatura no PEP8 ) ao Flake8 . pip install pep8-naming Execute o Flake8 flake8 . # Lintagem do projeto inteiro Pylint Instale o Pylint pip install pylint Execute o Pylint pylint src # Lintagem do diret\u00f3rio de c\u00f3digo-fonte Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo Black O Black \u00e9 uma ferramenta de formata\u00e7\u00e3o de c\u00f3digo sem desculpas. Ele remove todas as reclama\u00e7\u00f5es do pycodestyle sobre formata\u00e7\u00e3o, para que a equipe possa se concentrar no conte\u00fado em vez do estilo. N\u00e3o \u00e9 poss\u00edvel configurar o Black de acordo com suas pr\u00f3prias necessidades de estilo. pip install black Formate o c\u00f3digo Python black [ arquivo/pasta ] Autopep8 O Autopep8 \u00e9 mais flex\u00edvel e permite mais configura\u00e7\u00e3o se voc\u00ea deseja uma formata\u00e7\u00e3o menos rigorosa. pip install autopep8 Formate o c\u00f3digo Python autopep8 [ arquivo/pasta ] --in-place yapf yapf Yet Another Python Formatter \u00e9 um formatador Python da Google baseado em ideias do gofmt. Ele tamb\u00e9m \u00e9 mais configur\u00e1vel e uma boa op\u00e7\u00e3o para formata\u00e7\u00e3o autom\u00e1tica de c\u00f3digo. pip install yapf Formate o c\u00f3digo Python yapf [ arquivo/pasta ] --in-place Extens\u00f5es do VS Code Python A extens\u00e3o da linguagem Python \u00e9 a extens\u00e3o base que voc\u00ea deve ter instalada para desenvolvimento Python com o VS Code. Ela permite intellisense, depura\u00e7\u00e3o, lintagem (com os linters mencionados acima), testes com pytest ou unittest e formata\u00e7\u00e3o de c\u00f3digo com os formatadores mencionados acima. Pyright A extens\u00e3o Pyright aprimora o VS Code com verifica\u00e7\u00e3o est\u00e1tica de tipos quando voc\u00ea usa dicas de tipo. def add ( primeiro_valor : int , segundo_valor : int ) -> int : return primeiro_valor + segundo_valor Valida\u00e7\u00e3o de Build Para automatizar a lintagem com o flake8 e os testes com o pytest no Azure Devops, voc\u00ea pode adicionar o seguinte trecho ao seu arquivo azure-pipelines.yaml . trigger : branches : include : - develop - master paths : include : - src/* pool : vmImage : 'ubuntu-latest' jobs : - job : LintAndTest displayName : Lintagem e Teste steps : - checkout : self lfs : true - task : UsePythonVersion@0 displayName : 'Definir a vers\u00e3o do Python para 3.6' inputs : versionSpec : '3.6' - script : pip3 install --user -r requirements.txt displayName : 'Instalar depend\u00eancias' - script : | # Instalar o Flake8 pip3 install --user flake8 # Instalar o PyTest pip3 install --user pytest displayName : 'Instalar o Flake8 e o PyTest' - script : | python3 -m flake8 displayName : 'Executar o linter Flake8' - script : | # Executar o testador PyTest python3 -m pytest --junitxml=./test-results.xml displayName : 'Executar o testador PyTest' - task : PublishTestResults@2 displayName : 'Publicar resultados do PyTest' condition : succeededOrFailed() inputs : testResultsFiles : '**/test-*.xml' testRunTitle : 'Publicar resultados do teste para Python $(python.version)' Para realizar uma valida\u00e7\u00e3o de PR no GitHub, voc\u00ea pode usar uma configura\u00e7\u00e3o YAML semelhante com GitHub Actions . Pre-commit hooks Os Pre-commit hooks permitem que voc\u00ea formate e lint o c\u00f3digo localmente antes de enviar a solicita\u00e7\u00e3o de pull. Adicionar Pre-commit hookso para o seu reposit\u00f3rio Python \u00e9 f\u00e1cil usando o pacote pre-commit. Instale o pre-commit e adicione-o ao requirements.txt pip install pre-commit Adicione um arquivo .pre-commit-config.yaml na raiz do reposit\u00f3rio, com as a\u00e7\u00f5es de pr\u00e9-compromisso desejadas repos : - repo : https://github.com/ambv/black rev : stable hooks : - id : black language_version : python3.6 - repo : https://github.com/pre-commit/pre-commit-hooks rev : v1.2.3 hooks : - id : flake8 Cada desenvolvedor individual que deseja configurar ganchos de pr\u00e9-compromisso pode ent\u00e3o executar pre-commit install Na pr\u00f3xima tentativa de commit, quaisquer falhas de lint bloquear\u00e3o o commit. Observa\u00e7\u00e3o: A instala\u00e7\u00e3o de ganchos de pr\u00e9-compromisso \u00e9 volunt\u00e1ria e feita por cada desenvolvedor individualmente. Portanto, n\u00e3o substitui a valida\u00e7\u00e3o de build no servidor. Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo Al\u00e9m da Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por estes itens espec\u00edficos de revis\u00e3o de c\u00f3digo em Python: Todos os novos pacotes usados est\u00e3o inclu\u00eddos no requirements.txt? O c\u00f3digo passa em todas as verifica\u00e7\u00f5es de lint? As fun\u00e7\u00f5es usam dicas de tipo e h\u00e1 erros de dica de tipo? O c\u00f3digo \u00e9 leg\u00edvel e utiliza constru\u00e7\u00f5es pythonicas sempre que poss\u00edvel.","title":"Revis\u00e3o de C\u00f3digo em Python"},{"location":"code-reviews/recipes/python/#revisao-de-codigo-em-python","text":"","title":"Revis\u00e3o de C\u00f3digo em Python"},{"location":"code-reviews/recipes/python/#guia-de-estilo","text":"Os desenvolvedores devem seguir o guia de estilo PEP8 com dicas de tipo . O uso de dicas de tipo em conjunto com a lintagem e verifica\u00e7\u00e3o de dicas de tipo evita erros comuns que s\u00e3o dif\u00edceis de depurar. Projetos devem verificar o c\u00f3digo Python com ferramentas automatizadas. A lintagem deve ser adicionada \u00e0 valida\u00e7\u00e3o de build, e tanto a lintagem quanto a formata\u00e7\u00e3o de c\u00f3digo podem ser adicionadas aos seus ganchos de pr\u00e9-compromisso e ao VS Code.","title":"Guia de Estilo"},{"location":"code-reviews/recipes/python/#analise-de-codigo-lintagem","text":"Os dois linters Python mais populares s\u00e3o o Pylint e o Flake8 . Ambos verificam a ader\u00eancia ao PEP8 , mas variam um pouco no que diz respeito a outras regras que verificam. Em geral, o Pylint tende a ser um pouco mais rigoroso e pode gerar mais falsos positivos, mas ambos s\u00e3o boas op\u00e7\u00f5es para a lintagem de c\u00f3digo Python. Tanto o Pylint quanto o Flake8 podem ser configurados no VS Code usando a extens\u00e3o Python do VS Code.","title":"An\u00e1lise de C\u00f3digo / Lintagem"},{"location":"code-reviews/recipes/python/#flake8","text":"O Flake8 \u00e9 um wrapper simples e r\u00e1pido em torno do Pyflakes (para detec\u00e7\u00e3o de erros de codifica\u00e7\u00e3o) e pycodestyle (para o PEP8 ). Instale o Flake8 pip install flake8 Adicione uma extens\u00e3o para a ferramenta pydocstyle (para strings de documenta\u00e7\u00e3o ) ao Flake8 . pip install flake8-docstrings Adicione uma extens\u00e3o para o pep8-naming (para conven\u00e7\u00f5es de nomenclatura no PEP8 ) ao Flake8 . pip install pep8-naming Execute o Flake8 flake8 . # Lintagem do projeto inteiro","title":"Flake8"},{"location":"code-reviews/recipes/python/#pylint","text":"Instale o Pylint pip install pylint Execute o Pylint pylint src # Lintagem do diret\u00f3rio de c\u00f3digo-fonte","title":"Pylint"},{"location":"code-reviews/recipes/python/#formatacao-automatica-de-codigo","text":"","title":"Formata\u00e7\u00e3o Autom\u00e1tica de C\u00f3digo"},{"location":"code-reviews/recipes/python/#black","text":"O Black \u00e9 uma ferramenta de formata\u00e7\u00e3o de c\u00f3digo sem desculpas. Ele remove todas as reclama\u00e7\u00f5es do pycodestyle sobre formata\u00e7\u00e3o, para que a equipe possa se concentrar no conte\u00fado em vez do estilo. N\u00e3o \u00e9 poss\u00edvel configurar o Black de acordo com suas pr\u00f3prias necessidades de estilo. pip install black Formate o c\u00f3digo Python black [ arquivo/pasta ]","title":"Black"},{"location":"code-reviews/recipes/python/#autopep8","text":"O Autopep8 \u00e9 mais flex\u00edvel e permite mais configura\u00e7\u00e3o se voc\u00ea deseja uma formata\u00e7\u00e3o menos rigorosa. pip install autopep8 Formate o c\u00f3digo Python autopep8 [ arquivo/pasta ] --in-place","title":"Autopep8"},{"location":"code-reviews/recipes/python/#yapf","text":"yapf Yet Another Python Formatter \u00e9 um formatador Python da Google baseado em ideias do gofmt. Ele tamb\u00e9m \u00e9 mais configur\u00e1vel e uma boa op\u00e7\u00e3o para formata\u00e7\u00e3o autom\u00e1tica de c\u00f3digo. pip install yapf Formate o c\u00f3digo Python yapf [ arquivo/pasta ] --in-place","title":"yapf"},{"location":"code-reviews/recipes/python/#extensoes-do-vs-code","text":"","title":"Extens\u00f5es do VS Code"},{"location":"code-reviews/recipes/python/#python","text":"A extens\u00e3o da linguagem Python \u00e9 a extens\u00e3o base que voc\u00ea deve ter instalada para desenvolvimento Python com o VS Code. Ela permite intellisense, depura\u00e7\u00e3o, lintagem (com os linters mencionados acima), testes com pytest ou unittest e formata\u00e7\u00e3o de c\u00f3digo com os formatadores mencionados acima.","title":"Python"},{"location":"code-reviews/recipes/python/#pyright","text":"A extens\u00e3o Pyright aprimora o VS Code com verifica\u00e7\u00e3o est\u00e1tica de tipos quando voc\u00ea usa dicas de tipo. def add ( primeiro_valor : int , segundo_valor : int ) -> int : return primeiro_valor + segundo_valor","title":"Pyright"},{"location":"code-reviews/recipes/python/#validacao-de-build","text":"Para automatizar a lintagem com o flake8 e os testes com o pytest no Azure Devops, voc\u00ea pode adicionar o seguinte trecho ao seu arquivo azure-pipelines.yaml . trigger : branches : include : - develop - master paths : include : - src/* pool : vmImage : 'ubuntu-latest' jobs : - job : LintAndTest displayName : Lintagem e Teste steps : - checkout : self lfs : true - task : UsePythonVersion@0 displayName : 'Definir a vers\u00e3o do Python para 3.6' inputs : versionSpec : '3.6' - script : pip3 install --user -r requirements.txt displayName : 'Instalar depend\u00eancias' - script : | # Instalar o Flake8 pip3 install --user flake8 # Instalar o PyTest pip3 install --user pytest displayName : 'Instalar o Flake8 e o PyTest' - script : | python3 -m flake8 displayName : 'Executar o linter Flake8' - script : | # Executar o testador PyTest python3 -m pytest --junitxml=./test-results.xml displayName : 'Executar o testador PyTest' - task : PublishTestResults@2 displayName : 'Publicar resultados do PyTest' condition : succeededOrFailed() inputs : testResultsFiles : '**/test-*.xml' testRunTitle : 'Publicar resultados do teste para Python $(python.version)' Para realizar uma valida\u00e7\u00e3o de PR no GitHub, voc\u00ea pode usar uma configura\u00e7\u00e3o YAML semelhante com GitHub Actions .","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/python/#pre-commit-hooks","text":"Os Pre-commit hooks permitem que voc\u00ea formate e lint o c\u00f3digo localmente antes de enviar a solicita\u00e7\u00e3o de pull. Adicionar Pre-commit hookso para o seu reposit\u00f3rio Python \u00e9 f\u00e1cil usando o pacote pre-commit. Instale o pre-commit e adicione-o ao requirements.txt pip install pre-commit Adicione um arquivo .pre-commit-config.yaml na raiz do reposit\u00f3rio, com as a\u00e7\u00f5es de pr\u00e9-compromisso desejadas repos : - repo : https://github.com/ambv/black rev : stable hooks : - id : black language_version : python3.6 - repo : https://github.com/pre-commit/pre-commit-hooks rev : v1.2.3 hooks : - id : flake8 Cada desenvolvedor individual que deseja configurar ganchos de pr\u00e9-compromisso pode ent\u00e3o executar pre-commit install Na pr\u00f3xima tentativa de commit, quaisquer falhas de lint bloquear\u00e3o o commit. Observa\u00e7\u00e3o: A instala\u00e7\u00e3o de ganchos de pr\u00e9-compromisso \u00e9 volunt\u00e1ria e feita por cada desenvolvedor individualmente. Portanto, n\u00e3o substitui a valida\u00e7\u00e3o de build no servidor.","title":"Pre-commit hooks"},{"location":"code-reviews/recipes/python/#lista-de-verificacao-de-revisao-de-codigo","text":"Al\u00e9m da Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por estes itens espec\u00edficos de revis\u00e3o de c\u00f3digo em Python: Todos os novos pacotes usados est\u00e3o inclu\u00eddos no requirements.txt? O c\u00f3digo passa em todas as verifica\u00e7\u00f5es de lint? As fun\u00e7\u00f5es usam dicas de tipo e h\u00e1 erros de dica de tipo? O c\u00f3digo \u00e9 leg\u00edvel e utiliza constru\u00e7\u00f5es pythonicas sempre que poss\u00edvel.","title":"Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/terraform/","text":"Revis\u00e3o de C\u00f3digo em Terraform Guia de Estilo Os desenvolvedores devem seguir o guia de estilo do Terraform . Projetos devem verificar os scripts do Terraform com ferramentas automatizadas. An\u00e1lise de C\u00f3digo / Linting TFLint O TFLint \u00e9 um linter do Terraform focado em poss\u00edveis erros, melhores pr\u00e1ticas, etc. Uma vez instalado o TFLint no ambiente, ele pode ser invocado usando a extens\u00e3o do VS Code terraform . Extens\u00f5es do VS Code As seguintes extens\u00f5es do VS Code s\u00e3o amplamente utilizadas. Extens\u00e3o Terraform Esta extens\u00e3o fornece realce de sintaxe, lintagem, formata\u00e7\u00e3o e capacidades de valida\u00e7\u00e3o. Extens\u00e3o Azure Terraform Esta extens\u00e3o oferece suporte aos comandos do Terraform, visualiza\u00e7\u00e3o de gr\u00e1fico de recursos e integra\u00e7\u00e3o com o CloudShell dentro do VS Code. Valida\u00e7\u00e3o de Build Certifique-se de aplicar os guias de estilo durante a constru\u00e7\u00e3o. O seguinte script de exemplo pode ser usado para instalar o Terraform e um linter que verifica a formata\u00e7\u00e3o e erros comuns. #! /bin/bash set -e SCRIPT_DIR = $( dirname \" $BASH_SOURCE \" ) cd \" $SCRIPT_DIR \" TF_VERSION = 0 .12.4 TF_LINT_VERSION = 0 .9.1 echo -e \"\\n\\n>>> Instalando Terraform 0.12\" # Instale as ferramentas do Terraform para a verifica\u00e7\u00e3o de formata\u00e7\u00e3o wget -q https://releases.hashicorp.com/terraform/ ${ TF_VERSION } /terraform_ ${ TF_VERSION } _linux_amd64.zip -O /tmp/terraform.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/terraform.zip echo \"\" echo -e \"\\n\\n>>> Instalando o TFLint (terceiros)\" wget -q https://github.com/wata727/tflint/releases/download/v ${ TF_LINT_VERSION } /tflint_linux_amd64.zip -O /tmp/tflint.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/tflint.zip echo -e \"\\n\\n>>> Vers\u00e3o do Terraform\" terraform -version echo -e \"\\n\\n>>> Formato do Terraform (se falhar, use o comando 'terraform fmt -recursive' para resolver\" terraform fmt -recursive -diff -check echo -e \"\\n\\n>>> TFLint\" tflint echo -e \"\\n\\n>>> Terraform init\" terraform init echo -e \"\\n\\n>>> Terraform validate\" terraform validate Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo Al\u00e9m da Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por esses itens espec\u00edficos de revis\u00e3o de c\u00f3digo do Terraform. Provedores Todos os provedores usados nos scripts do Terraform est\u00e3o versionados para evitar altera\u00e7\u00f5es quebradas no futuro? Organiza\u00e7\u00e3o do Reposit\u00f3rio O c\u00f3digo foi dividido em m\u00f3dulos reutiliz\u00e1veis? Os m\u00f3dulos foram divididos em arquivos .tf separados quando apropriado? O reposit\u00f3rio cont\u00e9m um README.md descrevendo a arquitetura provisionada? Se o c\u00f3digo do Terraform est\u00e1 misturado com o c\u00f3digo-fonte da aplica\u00e7\u00e3o, o c\u00f3digo do Terraform foi isolado em uma pasta dedicada? Estado do Terraform O projeto do Terraform est\u00e1 configurado usando o Azure Storage como backend de estado remoto? A chave do backend de estado remoto est\u00e1 armazenada em um local seguro (por exemplo, Azure Key Vault)? O projeto est\u00e1 configurado para usar arquivos de estado com base no ambiente, e o pipeline de implanta\u00e7\u00e3o est\u00e1 configurado para fornecer dinamicamente o nome do arquivo de estado? Vari\u00e1veis Se a infraestrutura ser\u00e1 diferente dependendo do ambiente (por exemplo, Dev, UAT, Produ\u00e7\u00e3o), os par\u00e2metros espec\u00edficos do ambiente s\u00e3o fornecidos por meio de um arquivo .tfvars ? Todas as vari\u00e1veis t\u00eam informa\u00e7\u00f5es de type . Por exemplo, list(string) ou string . Todas as vari\u00e1veis t\u00eam uma description que indica o prop\u00f3sito da vari\u00e1vel e seu uso. Valores default n\u00e3o s\u00e3o fornecidos para vari\u00e1veis que devem ser fornecidas por um usu\u00e1rio. Testes Existem testes unit\u00e1rios e de integra\u00e7\u00e3o que cobrem o c\u00f3digo do Terraform (por exemplo, Terratest , terratest-abstraction )? Nomea\u00e7\u00e3o e Estrutura do C\u00f3digo As defini\u00e7\u00f5es de recursos e fontes de dados s\u00e3o usadas corretamente nos scripts do Terraform? resource: Indica ao Terraform que a configura\u00e7\u00e3o atual \u00e9 respons\u00e1vel por gerenciar o ciclo de vida do objeto. data: Indica ao Terraform que voc\u00ea s\u00f3 deseja obter uma refer\u00eancia ao objeto existente, mas n\u00e3o deseja gerenci\u00e1-lo como parte desta configura\u00e7\u00e3o. Os nomes dos recursos come\u00e7am com o nome do provedor que os cont\u00e9m, seguido de um sublinhado? Por exemplo, um recurso do provedor postgresql pode ser nomeado como postgresql_database ? A fun\u00e7\u00e3o try s\u00f3 \u00e9 usada com refer\u00eancias de atributos simples e fun\u00e7\u00f5es de convers\u00e3o de tipo? O uso excessivo da fun\u00e7\u00e3o try para suprimir erros levar\u00e1 a uma configura\u00e7\u00e3o dif\u00edcil de entender e manter. As fun\u00e7\u00f5es de convers\u00e3o de tipo expl\u00edcito usadas para normalizar tipos s\u00f3 s\u00e3o retornadas nas sa\u00eddas do m\u00f3dulo? Convers\u00f5es de tipo expl\u00edcitas raramente s\u00e3o necess\u00e1rias no Terraform, pois ele converter\u00e1 tipos automaticamente quando necess\u00e1rio. A propriedade Sensitive no esquema est\u00e1 definida como true para os campos que cont\u00eam informa\u00e7\u00f5es confidenciais? Isso evitar\u00e1 que os valores do campo apare\u00e7am na sa\u00edda da CLI. Recomenda\u00e7\u00f5es Gerais Tente evitar o aninhamento de configura\u00e7\u00f5es secund\u00e1rias dentro de recursos. Crie uma se\u00e7\u00e3o de recursos separada para recursos, mesmo que possam ser declarados como subelementos de um recurso. Por exemplo, declarar sub-redes dentro da rede virtual versus declarar sub-redes como recursos separados em compara\u00e7\u00e3o com a rede virtual no Azure. Nunca codifique valores est\u00e1ticos na configura\u00e7\u00e3o. Declare-os na se\u00e7\u00e3o locals se uma vari\u00e1vel for necess\u00e1ria v\u00e1rias vezes como um valor est\u00e1tico e for interna \u00e0 configura\u00e7\u00e3o. Os names dos recursos criados no Azure n\u00e3o devem ser codificados ou est\u00e1ticos. Esses nomes devem ser din\u00e2micos e fornecidos pelo usu\u00e1rio usando o bloco variable . Isso \u00e9 \u00fatil especialmente nos testes de unidade quando v\u00e1rios testes s\u00e3o executados em paralelo tentando criar recursos no Azure, mas precisam de nomes diferentes (alguns recursos no Azure precisam ter nomes exclusivos, por exemplo, contas de armazenamento). \u00c9 uma boa pr\u00e1tica output o ID dos recursos criados no Azure a partir da configura\u00e7\u00e3o. Isso \u00e9 especialmente \u00fatil ao adicionar blocos din\u00e2micos para subelementos/elementos filhos ao recurso pai. Use o bloco required_providers para estabelecer a depend\u00eancia de provedores juntamente com a vers\u00e3o predefinida. Use o bloco terraform para declarar a depend\u00eancia do provedor com a vers\u00e3o exata e tamb\u00e9m a vers\u00e3o do terraform CLI necess\u00e1ria para a configura\u00e7\u00e3o. Valide os valores das vari\u00e1veis fornecidos com base no uso e no tipo da vari\u00e1vel. A valida\u00e7\u00e3o pode ser feita nas vari\u00e1veis adicionando o bloco validation .","title":"Revis\u00e3o de C\u00f3digo em Terraform"},{"location":"code-reviews/recipes/terraform/#revisao-de-codigo-em-terraform","text":"","title":"Revis\u00e3o de C\u00f3digo em Terraform"},{"location":"code-reviews/recipes/terraform/#guia-de-estilo","text":"Os desenvolvedores devem seguir o guia de estilo do Terraform . Projetos devem verificar os scripts do Terraform com ferramentas automatizadas.","title":"Guia de Estilo"},{"location":"code-reviews/recipes/terraform/#analise-de-codigo-linting","text":"","title":"An\u00e1lise de C\u00f3digo / Linting"},{"location":"code-reviews/recipes/terraform/#tflint","text":"O TFLint \u00e9 um linter do Terraform focado em poss\u00edveis erros, melhores pr\u00e1ticas, etc. Uma vez instalado o TFLint no ambiente, ele pode ser invocado usando a extens\u00e3o do VS Code terraform .","title":"TFLint"},{"location":"code-reviews/recipes/terraform/#extensoes-do-vs-code","text":"As seguintes extens\u00f5es do VS Code s\u00e3o amplamente utilizadas.","title":"Extens\u00f5es do VS Code"},{"location":"code-reviews/recipes/terraform/#extensao-terraform","text":"Esta extens\u00e3o fornece realce de sintaxe, lintagem, formata\u00e7\u00e3o e capacidades de valida\u00e7\u00e3o.","title":"Extens\u00e3o Terraform"},{"location":"code-reviews/recipes/terraform/#extensao-azure-terraform","text":"Esta extens\u00e3o oferece suporte aos comandos do Terraform, visualiza\u00e7\u00e3o de gr\u00e1fico de recursos e integra\u00e7\u00e3o com o CloudShell dentro do VS Code.","title":"Extens\u00e3o Azure Terraform"},{"location":"code-reviews/recipes/terraform/#validacao-de-build","text":"Certifique-se de aplicar os guias de estilo durante a constru\u00e7\u00e3o. O seguinte script de exemplo pode ser usado para instalar o Terraform e um linter que verifica a formata\u00e7\u00e3o e erros comuns. #! /bin/bash set -e SCRIPT_DIR = $( dirname \" $BASH_SOURCE \" ) cd \" $SCRIPT_DIR \" TF_VERSION = 0 .12.4 TF_LINT_VERSION = 0 .9.1 echo -e \"\\n\\n>>> Instalando Terraform 0.12\" # Instale as ferramentas do Terraform para a verifica\u00e7\u00e3o de formata\u00e7\u00e3o wget -q https://releases.hashicorp.com/terraform/ ${ TF_VERSION } /terraform_ ${ TF_VERSION } _linux_amd64.zip -O /tmp/terraform.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/terraform.zip echo \"\" echo -e \"\\n\\n>>> Instalando o TFLint (terceiros)\" wget -q https://github.com/wata727/tflint/releases/download/v ${ TF_LINT_VERSION } /tflint_linux_amd64.zip -O /tmp/tflint.zip sudo unzip -q -o -d /usr/local/bin/ /tmp/tflint.zip echo -e \"\\n\\n>>> Vers\u00e3o do Terraform\" terraform -version echo -e \"\\n\\n>>> Formato do Terraform (se falhar, use o comando 'terraform fmt -recursive' para resolver\" terraform fmt -recursive -diff -check echo -e \"\\n\\n>>> TFLint\" tflint echo -e \"\\n\\n>>> Terraform init\" terraform init echo -e \"\\n\\n>>> Terraform validate\" terraform validate","title":"Valida\u00e7\u00e3o de Build"},{"location":"code-reviews/recipes/terraform/#lista-de-verificacao-de-revisao-de-codigo","text":"Al\u00e9m da Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo , voc\u00ea tamb\u00e9m deve procurar por esses itens espec\u00edficos de revis\u00e3o de c\u00f3digo do Terraform.","title":"Lista de Verifica\u00e7\u00e3o de Revis\u00e3o de C\u00f3digo"},{"location":"code-reviews/recipes/terraform/#provedores","text":"Todos os provedores usados nos scripts do Terraform est\u00e3o versionados para evitar altera\u00e7\u00f5es quebradas no futuro?","title":"Provedores"},{"location":"code-reviews/recipes/terraform/#organizacao-do-repositorio","text":"O c\u00f3digo foi dividido em m\u00f3dulos reutiliz\u00e1veis? Os m\u00f3dulos foram divididos em arquivos .tf separados quando apropriado? O reposit\u00f3rio cont\u00e9m um README.md descrevendo a arquitetura provisionada? Se o c\u00f3digo do Terraform est\u00e1 misturado com o c\u00f3digo-fonte da aplica\u00e7\u00e3o, o c\u00f3digo do Terraform foi isolado em uma pasta dedicada?","title":"Organiza\u00e7\u00e3o do Reposit\u00f3rio"},{"location":"code-reviews/recipes/terraform/#estado-do-terraform","text":"O projeto do Terraform est\u00e1 configurado usando o Azure Storage como backend de estado remoto? A chave do backend de estado remoto est\u00e1 armazenada em um local seguro (por exemplo, Azure Key Vault)? O projeto est\u00e1 configurado para usar arquivos de estado com base no ambiente, e o pipeline de implanta\u00e7\u00e3o est\u00e1 configurado para fornecer dinamicamente o nome do arquivo de estado?","title":"Estado do Terraform"},{"location":"code-reviews/recipes/terraform/#variaveis","text":"Se a infraestrutura ser\u00e1 diferente dependendo do ambiente (por exemplo, Dev, UAT, Produ\u00e7\u00e3o), os par\u00e2metros espec\u00edficos do ambiente s\u00e3o fornecidos por meio de um arquivo .tfvars ? Todas as vari\u00e1veis t\u00eam informa\u00e7\u00f5es de type . Por exemplo, list(string) ou string . Todas as vari\u00e1veis t\u00eam uma description que indica o prop\u00f3sito da vari\u00e1vel e seu uso. Valores default n\u00e3o s\u00e3o fornecidos para vari\u00e1veis que devem ser fornecidas por um usu\u00e1rio.","title":"Vari\u00e1veis"},{"location":"code-reviews/recipes/terraform/#testes","text":"Existem testes unit\u00e1rios e de integra\u00e7\u00e3o que cobrem o c\u00f3digo do Terraform (por exemplo, Terratest , terratest-abstraction )?","title":"Testes"},{"location":"code-reviews/recipes/terraform/#nomeacao-e-estrutura-do-codigo","text":"As defini\u00e7\u00f5es de recursos e fontes de dados s\u00e3o usadas corretamente nos scripts do Terraform? resource: Indica ao Terraform que a configura\u00e7\u00e3o atual \u00e9 respons\u00e1vel por gerenciar o ciclo de vida do objeto. data: Indica ao Terraform que voc\u00ea s\u00f3 deseja obter uma refer\u00eancia ao objeto existente, mas n\u00e3o deseja gerenci\u00e1-lo como parte desta configura\u00e7\u00e3o. Os nomes dos recursos come\u00e7am com o nome do provedor que os cont\u00e9m, seguido de um sublinhado? Por exemplo, um recurso do provedor postgresql pode ser nomeado como postgresql_database ? A fun\u00e7\u00e3o try s\u00f3 \u00e9 usada com refer\u00eancias de atributos simples e fun\u00e7\u00f5es de convers\u00e3o de tipo? O uso excessivo da fun\u00e7\u00e3o try para suprimir erros levar\u00e1 a uma configura\u00e7\u00e3o dif\u00edcil de entender e manter. As fun\u00e7\u00f5es de convers\u00e3o de tipo expl\u00edcito usadas para normalizar tipos s\u00f3 s\u00e3o retornadas nas sa\u00eddas do m\u00f3dulo? Convers\u00f5es de tipo expl\u00edcitas raramente s\u00e3o necess\u00e1rias no Terraform, pois ele converter\u00e1 tipos automaticamente quando necess\u00e1rio. A propriedade Sensitive no esquema est\u00e1 definida como true para os campos que cont\u00eam informa\u00e7\u00f5es confidenciais? Isso evitar\u00e1 que os valores do campo apare\u00e7am na sa\u00edda da CLI.","title":"Nomea\u00e7\u00e3o e Estrutura do C\u00f3digo"},{"location":"code-reviews/recipes/terraform/#recomendacoes-gerais","text":"Tente evitar o aninhamento de configura\u00e7\u00f5es secund\u00e1rias dentro de recursos. Crie uma se\u00e7\u00e3o de recursos separada para recursos, mesmo que possam ser declarados como subelementos de um recurso. Por exemplo, declarar sub-redes dentro da rede virtual versus declarar sub-redes como recursos separados em compara\u00e7\u00e3o com a rede virtual no Azure. Nunca codifique valores est\u00e1ticos na configura\u00e7\u00e3o. Declare-os na se\u00e7\u00e3o locals se uma vari\u00e1vel for necess\u00e1ria v\u00e1rias vezes como um valor est\u00e1tico e for interna \u00e0 configura\u00e7\u00e3o. Os names dos recursos criados no Azure n\u00e3o devem ser codificados ou est\u00e1ticos. Esses nomes devem ser din\u00e2micos e fornecidos pelo usu\u00e1rio usando o bloco variable . Isso \u00e9 \u00fatil especialmente nos testes de unidade quando v\u00e1rios testes s\u00e3o executados em paralelo tentando criar recursos no Azure, mas precisam de nomes diferentes (alguns recursos no Azure precisam ter nomes exclusivos, por exemplo, contas de armazenamento). \u00c9 uma boa pr\u00e1tica output o ID dos recursos criados no Azure a partir da configura\u00e7\u00e3o. Isso \u00e9 especialmente \u00fatil ao adicionar blocos din\u00e2micos para subelementos/elementos filhos ao recurso pai. Use o bloco required_providers para estabelecer a depend\u00eancia de provedores juntamente com a vers\u00e3o predefinida. Use o bloco terraform para declarar a depend\u00eancia do provedor com a vers\u00e3o exata e tamb\u00e9m a vers\u00e3o do terraform CLI necess\u00e1ria para a configura\u00e7\u00e3o. Valide os valores das vari\u00e1veis fornecidos com base no uso e no tipo da vari\u00e1vel. A valida\u00e7\u00e3o pode ser feita nas vari\u00e1veis adicionando o bloco validation .","title":"Recomenda\u00e7\u00f5es Gerais"},{"location":"continuous-delivery/","text":"Entrega Cont\u00ednua A inspira\u00e7\u00e3o por tr\u00e1s da entrega cont\u00ednua \u00e9 entregar constantemente software valioso para usu\u00e1rios e desenvolvedores com mais frequ\u00eancia. Aplicar os princ\u00edpios e pr\u00e1ticas delineados neste readme ajudar\u00e1 voc\u00ea a reduzir riscos, eliminar opera\u00e7\u00f5es manuais e aumentar a qualidade e a confian\u00e7a. Implantar software envolve os seguintes princ\u00edpios: Prover e gerenciar o ambiente em nuvem em tempo de execu\u00e7\u00e3o para sua aplica\u00e7\u00e3o (recursos em nuvem, infraestrutura, hardware, servi\u00e7os, etc). Instalar a vers\u00e3o da aplica\u00e7\u00e3o alvo em todos os ambientes em nuvem. Configurar sua aplica\u00e7\u00e3o, incluindo quaisquer dados necess\u00e1rios. Um pipeline de entrega cont\u00ednua \u00e9 uma manifesta\u00e7\u00e3o automatizada de seu processo para otimizar esses princ\u00edpios de maneira consistente e repet\u00edvel. Objetivo Seguir as melhores pr\u00e1ticas da ind\u00fastria para entregar mudan\u00e7as de software para clientes e desenvolvedores. Estabelecer consist\u00eancia para os princ\u00edpios orientadores e melhores pr\u00e1ticas ao montar fluxos de entrega cont\u00ednua. Orienta\u00e7\u00e3o Geral Definir uma Estrat\u00e9gia de Lan\u00e7amento \u00c9 importante estabelecer um entendimento comum entre o L\u00edder de Desenvolvimento e as partes interessadas da aplica\u00e7\u00e3o sobre a estrat\u00e9gia/design de lan\u00e7amento durante a fase de planejamento de um projeto. Esse entendimento comum inclui a implanta\u00e7\u00e3o e manuten\u00e7\u00e3o da aplica\u00e7\u00e3o ao longo de seu ciclo de vida de desenvolvimento de software. Princ\u00edpios da Estrat\u00e9gia de Lan\u00e7amento Continuous Delivery por Jez Humble e David Farley cobre as principais considera\u00e7\u00f5es a seguir ao criar uma estrat\u00e9gia de lan\u00e7amento: Respons\u00e1veis pelos implantes em cada ambiente, bem como respons\u00e1veis pelo lan\u00e7amento. Uma estrat\u00e9gia de gerenciamento de ativos e configura\u00e7\u00f5es. Enumera\u00e7\u00e3o dos ambientes dispon\u00edveis para aceita\u00e7\u00e3o, capacidade, integra\u00e7\u00e3o e teste de aceita\u00e7\u00e3o do usu\u00e1rio, e o processo pelo qual as compila\u00e7\u00f5es ser\u00e3o movidas por esses ambientes. Uma descri\u00e7\u00e3o dos processos a serem seguidos para implanta\u00e7\u00e3o nos ambientes de teste e produ\u00e7\u00e3o, como solicita\u00e7\u00f5es de altera\u00e7\u00e3o a serem abertas e aprova\u00e7\u00f5es a serem concedidas. Uma discuss\u00e3o sobre o m\u00e9todo pelo qual a configura\u00e7\u00e3o em tempo de implanta\u00e7\u00e3o e em tempo de execu\u00e7\u00e3o da aplica\u00e7\u00e3o ser\u00e1 gerenciada, e como isso se relaciona com o processo de implanta\u00e7\u00e3o automatizada. _Descri\u00e7\u00e3o da integra\u00e7\u00e3o com quaisquer sistemas externos. Em que est\u00e1gio e como eles s\u00e3o testados como parte de um lan\u00e7amento? Como o operador t\u00e9cnico se comunica com o provedor em caso de problema? _Um plano de recupera\u00e7\u00e3o de desastres para que o estado da aplica\u00e7\u00e3o possa ser recuperado ap\u00f3s um desastre. Quais etapas ser\u00e3o necess\u00e1rias para reiniciar ou reimplementar a aplica\u00e7\u00e3o em caso de falha. _Dimensionamento e planejamento de capacidade de produ\u00e7\u00e3o: Quanta dados sua aplica\u00e7\u00e3o ao vivo criar\u00e1? Quantos arquivos de log ou bancos de dados voc\u00ea precisar\u00e1? Quanta largura de banda e espa\u00e7o em disco voc\u00ea precisar\u00e1? Qual lat\u00eancia os clientes esperam? Como funciona a implanta\u00e7\u00e3o inicial em produ\u00e7\u00e3o. Como corrigir defeitos e aplicar corre\u00e7\u00f5es no ambiente de produ\u00e7\u00e3o ser\u00e1 tratado. Como as atualiza\u00e7\u00f5es do ambiente de produ\u00e7\u00e3o ser\u00e3o tratadas, incluindo a migra\u00e7\u00e3o de dados. Como as atualiza\u00e7\u00f5es ser\u00e3o realizadas na aplica\u00e7\u00e3o sem destruir seu estado. Lan\u00e7amento da Aplica\u00e7\u00e3o e Promo\u00e7\u00e3o de Ambiente Seu processo de manifesta\u00e7\u00e3o de lan\u00e7amento deve pegar o artefato de constru\u00e7\u00e3o implant\u00e1vel criado em sua etapa de confirma\u00e7\u00e3o e implant\u00e1-lo em todos os ambientes em nuvem, come\u00e7ando pelo ambiente de teste. O ambiente de teste ( muitas vezes chamado de Integra\u00e7\u00e3o ) atua como um port\u00e3o para validar se sua su\u00edte de testes \u00e9 bem-sucedida para todos os candidatos a lan\u00e7amento. Essa valida\u00e7\u00e3o deve sempre come\u00e7ar em um ambiente de teste enquanto inspeciona o lan\u00e7amento implantado a partir do branch de feature/libera\u00e7\u00e3o contendo suas mudan\u00e7as de c\u00f3digo. As mudan\u00e7as de c\u00f3digo lan\u00e7adas no ambiente de teste normalmente t\u00eam como alvo o branch principal (quando usando trunk ) ou o branch de lan\u00e7amento (quando usando gitflow ). O Primeiro Lan\u00e7amento O primeiro lan\u00e7amento de qualquer aplica\u00e7\u00e3o deve ser apresentado ao cliente em um ambiente semelhante \u00e0 produ\u00e7\u00e3o ( UAT ) para obter feedback rapidamente. O ambiente de UAT \u00e9 usado para obter a aceita\u00e7\u00e3o do propriet\u00e1rio do produto para, em \u00faltima an\u00e1lise, promover o lan\u00e7amento para produ\u00e7\u00e3o. Crit\u00e9rios para um ambiente semelhante \u00e0 produ\u00e7\u00e3o Executa o mesmo sistema operacional que a produ\u00e7\u00e3o. Tem o mesmo software instalado que a produ\u00e7\u00e3o. \u00c9 dimensionado e configurado da mesma forma que a produ\u00e7\u00e3o. Reflete a topologia de rede da produ\u00e7\u00e3o. Testes de carga simulados semelhantes \u00e0 produ\u00e7\u00e3o s\u00e3o executados ap\u00f3s um lan\u00e7amento para identificar qualquer degrada\u00e7\u00e3o de lat\u00eancia ou throughput. Modelagem de seu Pipeline de Lan\u00e7amento \u00c9 crucial modelar seu processo de teste e lan\u00e7amento para estabelecer um entendimento comum entre os engenheiros de aplica\u00e7\u00e3o e as partes interessadas do cliente. Alinhar especificamente as expectativas sobre quantos ambientes em nuvem precisam ser pr\u00e9-provisionados, bem como definir os pap\u00e9is e responsabilidades dos port\u00f5es de aprova\u00e7\u00e3o. Considera\u00e7\u00f5es na Modelagem do Pipeline de Lan\u00e7amento Representar todas as etapas pelas quais uma mudan\u00e7a na aplica\u00e7\u00e3o precisaria passar antes de ser lan\u00e7ada na produ\u00e7\u00e3o. Definir todos os controles de port\u00f5es de lan\u00e7amento. Determinar grupos de Cloud RBAC espec\u00edficos do cliente que t\u00eam autoridade para aprovar candidatos a lan\u00e7amento por ambiente. Est\u00e1gios do Pipeline de Lan\u00e7amento Os est\u00e1gios em seu fluxo de trabalho de lan\u00e7amento est\u00e3o testando, em \u00faltima inst\u00e2ncia, uma vers\u00e3o de sua aplica\u00e7\u00e3o para validar se ela pode ser lan\u00e7ada de acordo com seus crit\u00e9rios de aceita\u00e7\u00e3o. O pipeline de lan\u00e7amento deve considerar as seguintes condi\u00e7\u00f5es: Sele\u00e7\u00e3o de Lan\u00e7amento: O desenvolvedor que realiza o teste da aplica\u00e7\u00e3o deve ter a capacidade de selecionar qual vers\u00e3o de lan\u00e7amento implantar no ambiente de teste. * Implanta\u00e7\u00e3o - Libere o artefato de implanta\u00e7\u00e3o da aplica\u00e7\u00e3o ( criado na etapa CI ) para o ambiente em nuvem de destino. * Configura\u00e7\u00e3o - As aplica\u00e7\u00f5es devem ser configuradas de forma consistente em todos os ambientes. Essa configura\u00e7\u00e3o \u00e9 aplicada no momento da implanta\u00e7\u00e3o. Dados sens\u00edveis, como segredos de aplica\u00e7\u00e3o e certificados, devem ser gerenciados em um reposit\u00f3rio totalmente gerenciado de chaves e segredos (por exemplo, Key Vault , KMS ). Quaisquer segredos usados pela aplica\u00e7\u00e3o devem ser obtidos internamente pela pr\u00f3pria aplica\u00e7\u00e3o. Os segredos da aplica\u00e7\u00e3o n\u00e3o devem ser expostos no ambiente de execu\u00e7\u00e3o. Incentivamos os princ\u00edpios do Modelo de 12 Fatores, especialmente quando se trata de gerenciamento de configura\u00e7\u00e3o . * Migra\u00e7\u00e3o de Dados - Pr\u00e9-popular o estado da aplica\u00e7\u00e3o e/ou registros de dados necess\u00e1rios para o ambiente de execu\u00e7\u00e3o. Isso pode incluir dados de teste necess\u00e1rios para sua su\u00edte de testes de integra\u00e7\u00e3o de ponta a ponta. * Teste de Validade de Implanta\u00e7\u00e3o. Seu teste de validade tamb\u00e9m deve verificar se sua aplica\u00e7\u00e3o est\u00e1 apontando para a configura\u00e7\u00e3o correta (por exemplo, produ\u00e7\u00e3o apontando para um banco de dados UAT). * Realizar cen\u00e1rios de teste de aceita\u00e7\u00e3o manuais ou automatizados. * Aprovar o port\u00e3o de lan\u00e7amento para promover a vers\u00e3o da aplica\u00e7\u00e3o para o ambiente em nuvem de destino. Essa promo\u00e7\u00e3o tamb\u00e9m deve incluir o estado de configura\u00e7\u00e3o do ambiente (por exemplo, novas configura\u00e7\u00f5es de ambiente, flags de recursos, etc). Aquecimento do Lan\u00e7amento ao Vivo Um lan\u00e7amento deve estar em execu\u00e7\u00e3o por um per\u00edodo de tempo antes de ser considerado ativo e permitido para aceitar o tr\u00e1fego do usu\u00e1rio. Essas atividades de aquecimento podem incluir o pr\u00e9-preenchimento de servidores de aplica\u00e7\u00e3o e bancos de dados com qualquer cache dependente, bem como estabelecer todas as conex\u00f5es de servi\u00e7o (por exemplo, aloca\u00e7\u00f5es de pool de conex\u00e3o, etc). Lan\u00e7amentos Pr\u00e9-produ\u00e7\u00e3o Os candidatos a lan\u00e7amento da aplica\u00e7\u00e3o devem ser implantados em um ambiente de staging semelhante ao de produ\u00e7\u00e3o para realiza\u00e7\u00e3o de testes manuais/automatizados finais ( incluindo testes de capacidade ). Seus ambientes em nuvem de produ\u00e7\u00e3o e staging/pr\u00e9-produ\u00e7\u00e3o devem ser configurados no in\u00edcio do projeto. O aquecimento da aplica\u00e7\u00e3o deve ser uma medi\u00e7\u00e3o quantificada que \u00e9 validada como parte de seus testes de valida\u00e7\u00e3o pr\u00e9-produ\u00e7\u00e3o. Rollback de Lan\u00e7amentos Sua estrat\u00e9gia de lan\u00e7amento deve considerar cen\u00e1rios de rollback no caso de falhas inesperadas ap\u00f3s uma implanta\u00e7\u00e3o. O rollback de lan\u00e7amentos pode ficar complicado, especialmente quando ocorrem altera\u00e7\u00f5es em registros/objetos de banco de dados como resultado de sua implanta\u00e7\u00e3o ( seja inadvertidamente ou intencionalmente ). Se n\u00e3o houver altera\u00e7\u00f5es de dados que precisem ser revertidas, voc\u00ea pode simplesmente acionar um novo candidato a lan\u00e7amento para a \u00faltima vers\u00e3o conhecida da produ\u00e7\u00e3o e promover esse lan\u00e7amento ao longo de seu pipeline de entrega cont\u00ednua. Para cen\u00e1rios de rollback envolvendo altera\u00e7\u00f5es de dados, existem v\u00e1rias abordagens para mitigar isso, que est\u00e3o fora do escopo deste guia. Algumas envolvem a vers\u00e3o de registros de banco de dados, registro no tempo de registros/objetos de banco de dados, etc. Todos os arquivos de dados e bancos de dados devem ser copiados de backup antes de cada lan\u00e7amento, para que possam ser restaurados. A estrat\u00e9gia de mitiga\u00e7\u00e3o para esse cen\u00e1rio variar\u00e1 entre nossos projetos. A expectativa \u00e9 que essa estrat\u00e9gia de mitiga\u00e7\u00e3o seja abordada como parte de sua estrat\u00e9gia de lan\u00e7amento. Outra abordagem a considerar ao projetar sua estrat\u00e9gia de lan\u00e7amento s\u00e3o os an\u00e9is de implanta\u00e7\u00e3o . Essa abordagem simplifica cen\u00e1rios de rollback ao limitar o impacto de seu lan\u00e7amento nos usu\u00e1rios finais, implantando e validando gradualmente suas altera\u00e7\u00f5es na produ\u00e7\u00e3o. Lan\u00e7amentos sem Interrup\u00e7\u00e3o Uma implanta\u00e7\u00e3o quente segue um processo de troca de usu\u00e1rios de uma vers\u00e3o para outra sem impactar a experi\u00eancia do usu\u00e1rio. Como exemplo, os servi\u00e7os gerenciados pela Azure permitem que os desenvolvedores validem as mudan\u00e7as do aplicativo em um slot de implanta\u00e7\u00e3o de teste antes de troc\u00e1-lo pelo slot de produ\u00e7\u00e3o. A troca de slots de servi\u00e7o de aplicativo tamb\u00e9m pode ser totalmente automatizada assim que o slot de origem estiver totalmente aquecido (e a troca autom\u00e1tica estiver ativada). A troca de slots tamb\u00e9m simplifica a revers\u00e3o de lan\u00e7amentos assim que um operador t\u00e9cnico restaurar os slots para seus estados pr\u00e9-troca. O Kubernetes oferece suporte nativo a atualiza\u00e7\u00f5es cont\u00ednuas . Implanta\u00e7\u00f5es Azuis/Verdes Azul/Verde \u00e9 uma t\u00e9cnica de implanta\u00e7\u00e3o que reduz o tempo de inatividade ao executar duas inst\u00e2ncias id\u00eanticas de um ambiente de produ\u00e7\u00e3o chamadas Azul e Verde . Apenas um desses ambientes aceita tr\u00e1fego de produ\u00e7\u00e3o ao vivo de cada vez. No exemplo acima, o tr\u00e1fego de produ\u00e7\u00e3o ao vivo \u00e9 direcionado para o ambiente Verde. Durante os lan\u00e7amentos da aplica\u00e7\u00e3o, a nova vers\u00e3o \u00e9 implantada no ambiente Azul, o que ocorre independentemente do ambiente Verde. O tr\u00e1fego ao vivo n\u00e3o \u00e9 afetado pelas implanta\u00e7\u00f5es do ambiente Azul. Voc\u00ea pode direcionar sua su\u00edte de testes de ponta a ponta ao ambiente Azul como um de seus pontos de verifica\u00e7\u00e3o de teste. Migrar os usu\u00e1rios para a nova vers\u00e3o do aplicativo \u00e9 t\u00e3o simples quanto alterar a configura\u00e7\u00e3o do roteador para direcionar todo o tr\u00e1fego para o ambiente Azul. Essa t\u00e9cnica simplifica cen\u00e1rios de rollback, pois voc\u00ea pode simplesmente altern ar o roteador de volta para o Verde. Provedores de banco de dados como Cosmos e Azure SQL oferecem suporte nativo \u00e0 replica\u00e7\u00e3o de dados para ajudar a habilitar ambientes de banco de dados Azul/Verde totalmente sincronizados. Implanta\u00e7\u00f5es de Lan\u00e7amento Canary As implanta\u00e7\u00f5es Canary permitem que equipes de desenvolvimento obtenham feedback mais r\u00e1pido ao implantar novos recursos na produ\u00e7\u00e3o. Esses lan\u00e7amentos s\u00e3o implantados em um subconjunto de n\u00f3s de produ\u00e7\u00e3o ( onde nenhum usu\u00e1rio \u00e9 direcionado ) para coletar insights precoces sobre testes de capacidade, completude funcional e impacto. Uma vez conclu\u00eddos os testes de capacidade e fuma\u00e7a, voc\u00ea pode direcionar um pequeno subconjunto de usu\u00e1rios para os n\u00f3s de produ\u00e7\u00e3o que hospedam o candidato a lan\u00e7amento. As implanta\u00e7\u00f5es Canary simplificam os rollbacks, pois voc\u00ea pode evitar direcionar os usu\u00e1rios para vers\u00f5es ruins do aplicativo. Tente limitar o n\u00famero de vers\u00f5es de sua aplica\u00e7\u00e3o em execu\u00e7\u00e3o paralelamente na produ\u00e7\u00e3o, pois isso pode complicar os controles de manuten\u00e7\u00e3o e monitoramento. Solu\u00e7\u00f5es de Baixo C\u00f3digo Solu\u00e7\u00f5es de baixo c\u00f3digo aumentaram sua participa\u00e7\u00e3o nas aplica\u00e7\u00f5es e processos e, por causa disso, \u00e9 necess\u00e1rio uma adequada combina\u00e7\u00e3o de disciplinas para melhorar seu desenvolvimento. Aqui est\u00e1 um guia para entrega cont\u00ednua para Solu\u00e7\u00f5es de Baixo C\u00f3digo . Refer\u00eancias Entrega Cont\u00ednua por Jez Humble e David Farley. Integra\u00e7\u00e3o Cont\u00ednua vs. Entrega Cont\u00ednua vs. Implanta\u00e7\u00e3o Cont\u00ednua An\u00e9is de Implanta\u00e7\u00e3o Ferramentas Confira as seguintes ferramentas que podem ajudar nas melhores pr\u00e1ticas de Entrega Cont\u00ednua mencionadas acima: Flux para GitOps. Tekton para pipelines nativas do Kubernetes. \u00c9 importante observar que o Jenkins-X usa o Tekton em seu funcionamento interno. Argo Workflows para gerenciamento de fluxo de trabalho. Flagger para lan\u00e7amentos poderosos nativos do Kubernetes, incluindo abordagens de implanta\u00e7\u00e3o azul/verde, can\u00e1rio e testes A/B. Embora n\u00e3o diretamente relacionado \u00e0 Entrega Cont\u00ednua, voc\u00ea pode explorar o jsonnet , uma linguagem de modelagem que ajuda a reduzir a redund\u00e2ncia em manifestos YAML/JSON e promove a reutiliza\u00e7\u00e3o. Para solu\u00e7\u00f5es de baixo c\u00f3digo, voc\u00ea pode seguir o guia de entrega cont\u00ednua para Solu\u00e7\u00f5es de Baixo C\u00f3digo .","title":"Entrega Cont\u00ednua"},{"location":"continuous-delivery/#entrega-continua","text":"A inspira\u00e7\u00e3o por tr\u00e1s da entrega cont\u00ednua \u00e9 entregar constantemente software valioso para usu\u00e1rios e desenvolvedores com mais frequ\u00eancia. Aplicar os princ\u00edpios e pr\u00e1ticas delineados neste readme ajudar\u00e1 voc\u00ea a reduzir riscos, eliminar opera\u00e7\u00f5es manuais e aumentar a qualidade e a confian\u00e7a. Implantar software envolve os seguintes princ\u00edpios: Prover e gerenciar o ambiente em nuvem em tempo de execu\u00e7\u00e3o para sua aplica\u00e7\u00e3o (recursos em nuvem, infraestrutura, hardware, servi\u00e7os, etc). Instalar a vers\u00e3o da aplica\u00e7\u00e3o alvo em todos os ambientes em nuvem. Configurar sua aplica\u00e7\u00e3o, incluindo quaisquer dados necess\u00e1rios. Um pipeline de entrega cont\u00ednua \u00e9 uma manifesta\u00e7\u00e3o automatizada de seu processo para otimizar esses princ\u00edpios de maneira consistente e repet\u00edvel.","title":"Entrega Cont\u00ednua"},{"location":"continuous-delivery/#objetivo","text":"Seguir as melhores pr\u00e1ticas da ind\u00fastria para entregar mudan\u00e7as de software para clientes e desenvolvedores. Estabelecer consist\u00eancia para os princ\u00edpios orientadores e melhores pr\u00e1ticas ao montar fluxos de entrega cont\u00ednua.","title":"Objetivo"},{"location":"continuous-delivery/#orientacao-geral","text":"","title":"Orienta\u00e7\u00e3o Geral"},{"location":"continuous-delivery/#definir-uma-estrategia-de-lancamento","text":"\u00c9 importante estabelecer um entendimento comum entre o L\u00edder de Desenvolvimento e as partes interessadas da aplica\u00e7\u00e3o sobre a estrat\u00e9gia/design de lan\u00e7amento durante a fase de planejamento de um projeto. Esse entendimento comum inclui a implanta\u00e7\u00e3o e manuten\u00e7\u00e3o da aplica\u00e7\u00e3o ao longo de seu ciclo de vida de desenvolvimento de software.","title":"Definir uma Estrat\u00e9gia de Lan\u00e7amento"},{"location":"continuous-delivery/#principios-da-estrategia-de-lancamento","text":"Continuous Delivery por Jez Humble e David Farley cobre as principais considera\u00e7\u00f5es a seguir ao criar uma estrat\u00e9gia de lan\u00e7amento: Respons\u00e1veis pelos implantes em cada ambiente, bem como respons\u00e1veis pelo lan\u00e7amento. Uma estrat\u00e9gia de gerenciamento de ativos e configura\u00e7\u00f5es. Enumera\u00e7\u00e3o dos ambientes dispon\u00edveis para aceita\u00e7\u00e3o, capacidade, integra\u00e7\u00e3o e teste de aceita\u00e7\u00e3o do usu\u00e1rio, e o processo pelo qual as compila\u00e7\u00f5es ser\u00e3o movidas por esses ambientes. Uma descri\u00e7\u00e3o dos processos a serem seguidos para implanta\u00e7\u00e3o nos ambientes de teste e produ\u00e7\u00e3o, como solicita\u00e7\u00f5es de altera\u00e7\u00e3o a serem abertas e aprova\u00e7\u00f5es a serem concedidas. Uma discuss\u00e3o sobre o m\u00e9todo pelo qual a configura\u00e7\u00e3o em tempo de implanta\u00e7\u00e3o e em tempo de execu\u00e7\u00e3o da aplica\u00e7\u00e3o ser\u00e1 gerenciada, e como isso se relaciona com o processo de implanta\u00e7\u00e3o automatizada. _Descri\u00e7\u00e3o da integra\u00e7\u00e3o com quaisquer sistemas externos. Em que est\u00e1gio e como eles s\u00e3o testados como parte de um lan\u00e7amento? Como o operador t\u00e9cnico se comunica com o provedor em caso de problema? _Um plano de recupera\u00e7\u00e3o de desastres para que o estado da aplica\u00e7\u00e3o possa ser recuperado ap\u00f3s um desastre. Quais etapas ser\u00e3o necess\u00e1rias para reiniciar ou reimplementar a aplica\u00e7\u00e3o em caso de falha. _Dimensionamento e planejamento de capacidade de produ\u00e7\u00e3o: Quanta dados sua aplica\u00e7\u00e3o ao vivo criar\u00e1? Quantos arquivos de log ou bancos de dados voc\u00ea precisar\u00e1? Quanta largura de banda e espa\u00e7o em disco voc\u00ea precisar\u00e1? Qual lat\u00eancia os clientes esperam? Como funciona a implanta\u00e7\u00e3o inicial em produ\u00e7\u00e3o. Como corrigir defeitos e aplicar corre\u00e7\u00f5es no ambiente de produ\u00e7\u00e3o ser\u00e1 tratado. Como as atualiza\u00e7\u00f5es do ambiente de produ\u00e7\u00e3o ser\u00e3o tratadas, incluindo a migra\u00e7\u00e3o de dados. Como as atualiza\u00e7\u00f5es ser\u00e3o realizadas na aplica\u00e7\u00e3o sem destruir seu estado.","title":"Princ\u00edpios da Estrat\u00e9gia de Lan\u00e7amento"},{"location":"continuous-delivery/#lancamento-da-aplicacao-e-promocao-de-ambiente","text":"Seu processo de manifesta\u00e7\u00e3o de lan\u00e7amento deve pegar o artefato de constru\u00e7\u00e3o implant\u00e1vel criado em sua etapa de confirma\u00e7\u00e3o e implant\u00e1-lo em todos os ambientes em nuvem, come\u00e7ando pelo ambiente de teste. O ambiente de teste ( muitas vezes chamado de Integra\u00e7\u00e3o ) atua como um port\u00e3o para validar se sua su\u00edte de testes \u00e9 bem-sucedida para todos os candidatos a lan\u00e7amento. Essa valida\u00e7\u00e3o deve sempre come\u00e7ar em um ambiente de teste enquanto inspeciona o lan\u00e7amento implantado a partir do branch de feature/libera\u00e7\u00e3o contendo suas mudan\u00e7as de c\u00f3digo. As mudan\u00e7as de c\u00f3digo lan\u00e7adas no ambiente de teste normalmente t\u00eam como alvo o branch principal (quando usando trunk ) ou o branch de lan\u00e7amento (quando usando gitflow ).","title":"Lan\u00e7amento da Aplica\u00e7\u00e3o e Promo\u00e7\u00e3o de Ambiente"},{"location":"continuous-delivery/#o-primeiro-lancamento","text":"O primeiro lan\u00e7amento de qualquer aplica\u00e7\u00e3o deve ser apresentado ao cliente em um ambiente semelhante \u00e0 produ\u00e7\u00e3o ( UAT ) para obter feedback rapidamente. O ambiente de UAT \u00e9 usado para obter a aceita\u00e7\u00e3o do propriet\u00e1rio do produto para, em \u00faltima an\u00e1lise, promover o lan\u00e7amento para produ\u00e7\u00e3o.","title":"O Primeiro Lan\u00e7amento"},{"location":"continuous-delivery/#criterios-para-um-ambiente-semelhante-a-producao","text":"Executa o mesmo sistema operacional que a produ\u00e7\u00e3o. Tem o mesmo software instalado que a produ\u00e7\u00e3o. \u00c9 dimensionado e configurado da mesma forma que a produ\u00e7\u00e3o. Reflete a topologia de rede da produ\u00e7\u00e3o. Testes de carga simulados semelhantes \u00e0 produ\u00e7\u00e3o s\u00e3o executados ap\u00f3s um lan\u00e7amento para identificar qualquer degrada\u00e7\u00e3o de lat\u00eancia ou throughput.","title":"Crit\u00e9rios para um ambiente semelhante \u00e0 produ\u00e7\u00e3o"},{"location":"continuous-delivery/#modelagem-de-seu-pipeline-de-lancamento","text":"\u00c9 crucial modelar seu processo de teste e lan\u00e7amento para estabelecer um entendimento comum entre os engenheiros de aplica\u00e7\u00e3o e as partes interessadas do cliente. Alinhar especificamente as expectativas sobre quantos ambientes em nuvem precisam ser pr\u00e9-provisionados, bem como definir os pap\u00e9is e responsabilidades dos port\u00f5es de aprova\u00e7\u00e3o.","title":"Modelagem de seu Pipeline de Lan\u00e7amento"},{"location":"continuous-delivery/#consideracoes-na-modelagem-do-pipeline-de-lancamento","text":"Representar todas as etapas pelas quais uma mudan\u00e7a na aplica\u00e7\u00e3o precisaria passar antes de ser lan\u00e7ada na produ\u00e7\u00e3o. Definir todos os controles de port\u00f5es de lan\u00e7amento. Determinar grupos de Cloud RBAC espec\u00edficos do cliente que t\u00eam autoridade para aprovar candidatos a lan\u00e7amento por ambiente.","title":"Considera\u00e7\u00f5es na Modelagem do Pipeline de Lan\u00e7amento"},{"location":"continuous-delivery/#estagios-do-pipeline-de-lancamento","text":"Os est\u00e1gios em seu fluxo de trabalho de lan\u00e7amento est\u00e3o testando, em \u00faltima inst\u00e2ncia, uma vers\u00e3o de sua aplica\u00e7\u00e3o para validar se ela pode ser lan\u00e7ada de acordo com seus crit\u00e9rios de aceita\u00e7\u00e3o. O pipeline de lan\u00e7amento deve considerar as seguintes condi\u00e7\u00f5es: Sele\u00e7\u00e3o de Lan\u00e7amento: O desenvolvedor que realiza o teste da aplica\u00e7\u00e3o deve ter a capacidade de selecionar qual vers\u00e3o de lan\u00e7amento implantar no ambiente de teste. * Implanta\u00e7\u00e3o - Libere o artefato de implanta\u00e7\u00e3o da aplica\u00e7\u00e3o ( criado na etapa CI ) para o ambiente em nuvem de destino. * Configura\u00e7\u00e3o - As aplica\u00e7\u00f5es devem ser configuradas de forma consistente em todos os ambientes. Essa configura\u00e7\u00e3o \u00e9 aplicada no momento da implanta\u00e7\u00e3o. Dados sens\u00edveis, como segredos de aplica\u00e7\u00e3o e certificados, devem ser gerenciados em um reposit\u00f3rio totalmente gerenciado de chaves e segredos (por exemplo, Key Vault , KMS ). Quaisquer segredos usados pela aplica\u00e7\u00e3o devem ser obtidos internamente pela pr\u00f3pria aplica\u00e7\u00e3o. Os segredos da aplica\u00e7\u00e3o n\u00e3o devem ser expostos no ambiente de execu\u00e7\u00e3o. Incentivamos os princ\u00edpios do Modelo de 12 Fatores, especialmente quando se trata de gerenciamento de configura\u00e7\u00e3o . * Migra\u00e7\u00e3o de Dados - Pr\u00e9-popular o estado da aplica\u00e7\u00e3o e/ou registros de dados necess\u00e1rios para o ambiente de execu\u00e7\u00e3o. Isso pode incluir dados de teste necess\u00e1rios para sua su\u00edte de testes de integra\u00e7\u00e3o de ponta a ponta. * Teste de Validade de Implanta\u00e7\u00e3o. Seu teste de validade tamb\u00e9m deve verificar se sua aplica\u00e7\u00e3o est\u00e1 apontando para a configura\u00e7\u00e3o correta (por exemplo, produ\u00e7\u00e3o apontando para um banco de dados UAT). * Realizar cen\u00e1rios de teste de aceita\u00e7\u00e3o manuais ou automatizados. * Aprovar o port\u00e3o de lan\u00e7amento para promover a vers\u00e3o da aplica\u00e7\u00e3o para o ambiente em nuvem de destino. Essa promo\u00e7\u00e3o tamb\u00e9m deve incluir o estado de configura\u00e7\u00e3o do ambiente (por exemplo, novas configura\u00e7\u00f5es de ambiente, flags de recursos, etc).","title":"Est\u00e1gios do Pipeline de Lan\u00e7amento"},{"location":"continuous-delivery/#aquecimento-do-lancamento-ao-vivo","text":"Um lan\u00e7amento deve estar em execu\u00e7\u00e3o por um per\u00edodo de tempo antes de ser considerado ativo e permitido para aceitar o tr\u00e1fego do usu\u00e1rio. Essas atividades de aquecimento podem incluir o pr\u00e9-preenchimento de servidores de aplica\u00e7\u00e3o e bancos de dados com qualquer cache dependente, bem como estabelecer todas as conex\u00f5es de servi\u00e7o (por exemplo, aloca\u00e7\u00f5es de pool de conex\u00e3o, etc).","title":"Aquecimento do Lan\u00e7amento ao Vivo"},{"location":"continuous-delivery/#lancamentos-pre-producao","text":"Os candidatos a lan\u00e7amento da aplica\u00e7\u00e3o devem ser implantados em um ambiente de staging semelhante ao de produ\u00e7\u00e3o para realiza\u00e7\u00e3o de testes manuais/automatizados finais ( incluindo testes de capacidade ). Seus ambientes em nuvem de produ\u00e7\u00e3o e staging/pr\u00e9-produ\u00e7\u00e3o devem ser configurados no in\u00edcio do projeto. O aquecimento da aplica\u00e7\u00e3o deve ser uma medi\u00e7\u00e3o quantificada que \u00e9 validada como parte de seus testes de valida\u00e7\u00e3o pr\u00e9-produ\u00e7\u00e3o.","title":"Lan\u00e7amentos Pr\u00e9-produ\u00e7\u00e3o"},{"location":"continuous-delivery/#rollback-de-lancamentos","text":"Sua estrat\u00e9gia de lan\u00e7amento deve considerar cen\u00e1rios de rollback no caso de falhas inesperadas ap\u00f3s uma implanta\u00e7\u00e3o. O rollback de lan\u00e7amentos pode ficar complicado, especialmente quando ocorrem altera\u00e7\u00f5es em registros/objetos de banco de dados como resultado de sua implanta\u00e7\u00e3o ( seja inadvertidamente ou intencionalmente ). Se n\u00e3o houver altera\u00e7\u00f5es de dados que precisem ser revertidas, voc\u00ea pode simplesmente acionar um novo candidato a lan\u00e7amento para a \u00faltima vers\u00e3o conhecida da produ\u00e7\u00e3o e promover esse lan\u00e7amento ao longo de seu pipeline de entrega cont\u00ednua. Para cen\u00e1rios de rollback envolvendo altera\u00e7\u00f5es de dados, existem v\u00e1rias abordagens para mitigar isso, que est\u00e3o fora do escopo deste guia. Algumas envolvem a vers\u00e3o de registros de banco de dados, registro no tempo de registros/objetos de banco de dados, etc. Todos os arquivos de dados e bancos de dados devem ser copiados de backup antes de cada lan\u00e7amento, para que possam ser restaurados. A estrat\u00e9gia de mitiga\u00e7\u00e3o para esse cen\u00e1rio variar\u00e1 entre nossos projetos. A expectativa \u00e9 que essa estrat\u00e9gia de mitiga\u00e7\u00e3o seja abordada como parte de sua estrat\u00e9gia de lan\u00e7amento. Outra abordagem a considerar ao projetar sua estrat\u00e9gia de lan\u00e7amento s\u00e3o os an\u00e9is de implanta\u00e7\u00e3o . Essa abordagem simplifica cen\u00e1rios de rollback ao limitar o impacto de seu lan\u00e7amento nos usu\u00e1rios finais, implantando e validando gradualmente suas altera\u00e7\u00f5es na produ\u00e7\u00e3o.","title":"Rollback de Lan\u00e7amentos"},{"location":"continuous-delivery/#lancamentos-sem-interrupcao","text":"Uma implanta\u00e7\u00e3o quente segue um processo de troca de usu\u00e1rios de uma vers\u00e3o para outra sem impactar a experi\u00eancia do usu\u00e1rio. Como exemplo, os servi\u00e7os gerenciados pela Azure permitem que os desenvolvedores validem as mudan\u00e7as do aplicativo em um slot de implanta\u00e7\u00e3o de teste antes de troc\u00e1-lo pelo slot de produ\u00e7\u00e3o. A troca de slots de servi\u00e7o de aplicativo tamb\u00e9m pode ser totalmente automatizada assim que o slot de origem estiver totalmente aquecido (e a troca autom\u00e1tica estiver ativada). A troca de slots tamb\u00e9m simplifica a revers\u00e3o de lan\u00e7amentos assim que um operador t\u00e9cnico restaurar os slots para seus estados pr\u00e9-troca. O Kubernetes oferece suporte nativo a atualiza\u00e7\u00f5es cont\u00ednuas .","title":"Lan\u00e7amentos sem Interrup\u00e7\u00e3o"},{"location":"continuous-delivery/#implantacoes-azuisverdes","text":"Azul/Verde \u00e9 uma t\u00e9cnica de implanta\u00e7\u00e3o que reduz o tempo de inatividade ao executar duas inst\u00e2ncias id\u00eanticas de um ambiente de produ\u00e7\u00e3o chamadas Azul e Verde . Apenas um desses ambientes aceita tr\u00e1fego de produ\u00e7\u00e3o ao vivo de cada vez. No exemplo acima, o tr\u00e1fego de produ\u00e7\u00e3o ao vivo \u00e9 direcionado para o ambiente Verde. Durante os lan\u00e7amentos da aplica\u00e7\u00e3o, a nova vers\u00e3o \u00e9 implantada no ambiente Azul, o que ocorre independentemente do ambiente Verde. O tr\u00e1fego ao vivo n\u00e3o \u00e9 afetado pelas implanta\u00e7\u00f5es do ambiente Azul. Voc\u00ea pode direcionar sua su\u00edte de testes de ponta a ponta ao ambiente Azul como um de seus pontos de verifica\u00e7\u00e3o de teste. Migrar os usu\u00e1rios para a nova vers\u00e3o do aplicativo \u00e9 t\u00e3o simples quanto alterar a configura\u00e7\u00e3o do roteador para direcionar todo o tr\u00e1fego para o ambiente Azul. Essa t\u00e9cnica simplifica cen\u00e1rios de rollback, pois voc\u00ea pode simplesmente altern ar o roteador de volta para o Verde. Provedores de banco de dados como Cosmos e Azure SQL oferecem suporte nativo \u00e0 replica\u00e7\u00e3o de dados para ajudar a habilitar ambientes de banco de dados Azul/Verde totalmente sincronizados.","title":"Implanta\u00e7\u00f5es Azuis/Verdes"},{"location":"continuous-delivery/#implantacoes-de-lancamento-canary","text":"As implanta\u00e7\u00f5es Canary permitem que equipes de desenvolvimento obtenham feedback mais r\u00e1pido ao implantar novos recursos na produ\u00e7\u00e3o. Esses lan\u00e7amentos s\u00e3o implantados em um subconjunto de n\u00f3s de produ\u00e7\u00e3o ( onde nenhum usu\u00e1rio \u00e9 direcionado ) para coletar insights precoces sobre testes de capacidade, completude funcional e impacto. Uma vez conclu\u00eddos os testes de capacidade e fuma\u00e7a, voc\u00ea pode direcionar um pequeno subconjunto de usu\u00e1rios para os n\u00f3s de produ\u00e7\u00e3o que hospedam o candidato a lan\u00e7amento. As implanta\u00e7\u00f5es Canary simplificam os rollbacks, pois voc\u00ea pode evitar direcionar os usu\u00e1rios para vers\u00f5es ruins do aplicativo. Tente limitar o n\u00famero de vers\u00f5es de sua aplica\u00e7\u00e3o em execu\u00e7\u00e3o paralelamente na produ\u00e7\u00e3o, pois isso pode complicar os controles de manuten\u00e7\u00e3o e monitoramento.","title":"Implanta\u00e7\u00f5es de Lan\u00e7amento Canary"},{"location":"continuous-delivery/#solucoes-de-baixo-codigo","text":"Solu\u00e7\u00f5es de baixo c\u00f3digo aumentaram sua participa\u00e7\u00e3o nas aplica\u00e7\u00f5es e processos e, por causa disso, \u00e9 necess\u00e1rio uma adequada combina\u00e7\u00e3o de disciplinas para melhorar seu desenvolvimento. Aqui est\u00e1 um guia para entrega cont\u00ednua para Solu\u00e7\u00f5es de Baixo C\u00f3digo .","title":"Solu\u00e7\u00f5es de Baixo C\u00f3digo"},{"location":"continuous-delivery/#referencias","text":"Entrega Cont\u00ednua por Jez Humble e David Farley. Integra\u00e7\u00e3o Cont\u00ednua vs. Entrega Cont\u00ednua vs. Implanta\u00e7\u00e3o Cont\u00ednua An\u00e9is de Implanta\u00e7\u00e3o","title":"Refer\u00eancias"},{"location":"continuous-delivery/#ferramentas","text":"Confira as seguintes ferramentas que podem ajudar nas melhores pr\u00e1ticas de Entrega Cont\u00ednua mencionadas acima: Flux para GitOps. Tekton para pipelines nativas do Kubernetes. \u00c9 importante observar que o Jenkins-X usa o Tekton em seu funcionamento interno. Argo Workflows para gerenciamento de fluxo de trabalho. Flagger para lan\u00e7amentos poderosos nativos do Kubernetes, incluindo abordagens de implanta\u00e7\u00e3o azul/verde, can\u00e1rio e testes A/B. Embora n\u00e3o diretamente relacionado \u00e0 Entrega Cont\u00ednua, voc\u00ea pode explorar o jsonnet , uma linguagem de modelagem que ajuda a reduzir a redund\u00e2ncia em manifestos YAML/JSON e promove a reutiliza\u00e7\u00e3o. Para solu\u00e7\u00f5es de baixo c\u00f3digo, voc\u00ea pode seguir o guia de entrega cont\u00ednua para Solu\u00e7\u00f5es de Baixo C\u00f3digo .","title":"Ferramentas"},{"location":"continuous-delivery/azure-devops/secret-management-per-branch/","text":"Azure DevOps: Gerenciando Configura\u00e7\u00f5es de Forma Branch Espec\u00edfica Ao utilizar o Azure DevOps Pipelines para CI/CD, \u00e9 conveniente aproveitar as vari\u00e1veis de pipeline integradas para gerenciamento de segredos , mas o uso de vari\u00e1veis de pipeline para gerenciamento de segredos tem suas desvantagens: Vari\u00e1veis de pipeline s\u00e3o gerenciadas fora do c\u00f3digo que faz refer\u00eancia a elas. Isso torna f\u00e1cil introduzir diverg\u00eancias entre o c\u00f3digo-fonte e os segredos, por exemplo, ao adicionar uma refer\u00eancia a um novo segredo no c\u00f3digo, mas esquecer de adicion\u00e1-lo \u00e0s vari\u00e1veis de pipeline (o que leva a quebras de compila\u00e7\u00e3o confusas) ou excluir uma refer\u00eancia a um segredo no c\u00f3digo e esquecer de remov\u00ea-lo das vari\u00e1veis de pipeline (o que leva a vari\u00e1veis de pipeline confusas). Vari\u00e1veis de pipeline s\u00e3o um estado global compartilhado. Isso pode levar a situa\u00e7\u00f5es confusas e problemas dif\u00edceis de depurar quando os desenvolvedores fazem altera\u00e7\u00f5es simult\u00e2neas nas vari\u00e1veis de pipeline que podem se sobrepor umas \u00e0s outras. Ter um \u00fanico conjunto global de vari\u00e1veis de pipeline tamb\u00e9m torna imposs\u00edvel que os segredos variem por ambiente (por exemplo, ao usar um modelo de implanta\u00e7\u00e3o baseado em branches, onde 'master' faz implanta\u00e7\u00f5es usando os segredos de produ\u00e7\u00e3o, 'development' faz implanta\u00e7\u00f5es usando os segredos de staging, e assim por diante). Uma solu\u00e7\u00e3o para essas limita\u00e7\u00f5es \u00e9 gerenciar os segredos no reposit\u00f3rio Git em conjunto com o c\u00f3digo-fonte do projeto. Conforme descrito em gerenciamento de segredos , n\u00e3o inclua segredos no reposit\u00f3rio em texto simples. Em vez disso, podemos adicionar uma vers\u00e3o criptografada de nossos segredos ao reposit\u00f3rio e permitir que nossos agentes CI/CD e desenvolvedores descriptografem os segredos para uso local com alguma chave pr\u00e9-compartilhada. Isso nos oferece o melhor dos dois mundos: um armazenamento seguro para segredos, bem como o gerenciamento lado a lado de segredos e c\u00f3digo. # Primeiro, certifique-se de nunca cometer nossos segredos em texto simples e gere uma chave de criptografia forte echo \".env\" >> .gitignore ENCRYPTION_KEY = \" $( LC_ALL = C < /dev/urandom tr -dc '_A-Z-a-z-0-9' | head -c128 ) \" # Agora, vamos adicionar algum segredo ao nosso arquivo .env echo \"MEU_SEGREDO=...\" >> .env # Atualize tamb\u00e9m nosso arquivo de documenta\u00e7\u00e3o de segredos cat >> .env.template <<< \" # Insira a descri\u00e7\u00e3o do seu segredo aqui MEU_SEGREDO= \" # Em seguida, criptografe os segredos em texto simples; o arquivo resultante .env.enc pode ser comitado com seguran\u00e7a para o reposit\u00f3rio echo \" ${ ENCRYPTION_KEY } \" | openssl enc -aes-256-cbc -md sha512 -pass stdin -in .env -out .env.enc git add .env.enc .env.template git commit -m \"Atualizar segredos\" Ao executar o CI/CD, o servidor de compila\u00e7\u00e3o agora pode acessar os segredos descriptografando-os. Por exemplo, para o Azure DevOps, configure ENCRYPTION_KEY como uma vari\u00e1vel de pipeline secreta e, em seguida, adicione a seguinte etapa ao arquivo azure-pipelines.yml : steps : - script : echo \"$(ENCRYPTION_KEY)\" | openssl enc -aes-256-cbc -md sha512 -pass stdin -in .env.enc -out .env -d displayName : Descriptografar segredos Voc\u00ea tamb\u00e9m pode usar grupos de vari\u00e1veis vinculados diretamente ao Azure Key Vault para seus pipelines para gerenciar todos os segredos em um local.","title":"Azure DevOps: Gerenciando Configura\u00e7\u00f5es de Forma Branch Espec\u00edfica"},{"location":"continuous-delivery/azure-devops/secret-management-per-branch/#azure-devops-gerenciando-configuracoes-de-forma-branch-especifica","text":"Ao utilizar o Azure DevOps Pipelines para CI/CD, \u00e9 conveniente aproveitar as vari\u00e1veis de pipeline integradas para gerenciamento de segredos , mas o uso de vari\u00e1veis de pipeline para gerenciamento de segredos tem suas desvantagens: Vari\u00e1veis de pipeline s\u00e3o gerenciadas fora do c\u00f3digo que faz refer\u00eancia a elas. Isso torna f\u00e1cil introduzir diverg\u00eancias entre o c\u00f3digo-fonte e os segredos, por exemplo, ao adicionar uma refer\u00eancia a um novo segredo no c\u00f3digo, mas esquecer de adicion\u00e1-lo \u00e0s vari\u00e1veis de pipeline (o que leva a quebras de compila\u00e7\u00e3o confusas) ou excluir uma refer\u00eancia a um segredo no c\u00f3digo e esquecer de remov\u00ea-lo das vari\u00e1veis de pipeline (o que leva a vari\u00e1veis de pipeline confusas). Vari\u00e1veis de pipeline s\u00e3o um estado global compartilhado. Isso pode levar a situa\u00e7\u00f5es confusas e problemas dif\u00edceis de depurar quando os desenvolvedores fazem altera\u00e7\u00f5es simult\u00e2neas nas vari\u00e1veis de pipeline que podem se sobrepor umas \u00e0s outras. Ter um \u00fanico conjunto global de vari\u00e1veis de pipeline tamb\u00e9m torna imposs\u00edvel que os segredos variem por ambiente (por exemplo, ao usar um modelo de implanta\u00e7\u00e3o baseado em branches, onde 'master' faz implanta\u00e7\u00f5es usando os segredos de produ\u00e7\u00e3o, 'development' faz implanta\u00e7\u00f5es usando os segredos de staging, e assim por diante). Uma solu\u00e7\u00e3o para essas limita\u00e7\u00f5es \u00e9 gerenciar os segredos no reposit\u00f3rio Git em conjunto com o c\u00f3digo-fonte do projeto. Conforme descrito em gerenciamento de segredos , n\u00e3o inclua segredos no reposit\u00f3rio em texto simples. Em vez disso, podemos adicionar uma vers\u00e3o criptografada de nossos segredos ao reposit\u00f3rio e permitir que nossos agentes CI/CD e desenvolvedores descriptografem os segredos para uso local com alguma chave pr\u00e9-compartilhada. Isso nos oferece o melhor dos dois mundos: um armazenamento seguro para segredos, bem como o gerenciamento lado a lado de segredos e c\u00f3digo. # Primeiro, certifique-se de nunca cometer nossos segredos em texto simples e gere uma chave de criptografia forte echo \".env\" >> .gitignore ENCRYPTION_KEY = \" $( LC_ALL = C < /dev/urandom tr -dc '_A-Z-a-z-0-9' | head -c128 ) \" # Agora, vamos adicionar algum segredo ao nosso arquivo .env echo \"MEU_SEGREDO=...\" >> .env # Atualize tamb\u00e9m nosso arquivo de documenta\u00e7\u00e3o de segredos cat >> .env.template <<< \" # Insira a descri\u00e7\u00e3o do seu segredo aqui MEU_SEGREDO= \" # Em seguida, criptografe os segredos em texto simples; o arquivo resultante .env.enc pode ser comitado com seguran\u00e7a para o reposit\u00f3rio echo \" ${ ENCRYPTION_KEY } \" | openssl enc -aes-256-cbc -md sha512 -pass stdin -in .env -out .env.enc git add .env.enc .env.template git commit -m \"Atualizar segredos\" Ao executar o CI/CD, o servidor de compila\u00e7\u00e3o agora pode acessar os segredos descriptografando-os. Por exemplo, para o Azure DevOps, configure ENCRYPTION_KEY como uma vari\u00e1vel de pipeline secreta e, em seguida, adicione a seguinte etapa ao arquivo azure-pipelines.yml : steps : - script : echo \"$(ENCRYPTION_KEY)\" | openssl enc -aes-256-cbc -md sha512 -pass stdin -in .env.enc -out .env -d displayName : Descriptografar segredos Voc\u00ea tamb\u00e9m pode usar grupos de vari\u00e1veis vinculados diretamente ao Azure Key Vault para seus pipelines para gerenciar todos os segredos em um local.","title":"Azure DevOps: Gerenciando Configura\u00e7\u00f5es de Forma Branch Espec\u00edfica"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/","text":"Vari\u00e1veis de Tempo de Execu\u00e7\u00e3o no GitHub Actions Objetivo Embora o GitHub Actions seja uma escolha popular para escrever e executar pipelines de CI/CD, especialmente para projetos de c\u00f3digo aberto hospedados no GitHub, ele carece de recursos espec\u00edficos de qualidade de vida encontrados em outros ambientes de CI/CD. Um recurso-chave que o GitHub Actions ainda n\u00e3o implementou \u00e9 a capacidade de simular e injetar vari\u00e1veis de tempo de execu\u00e7\u00e3o em um fluxo de trabalho, a fim de testar o pipeline em si. Isso cria uma ponte entre um recurso existente no Azure DevOps e um recurso que ainda n\u00e3o foi lan\u00e7ado no GitHub Actions. P\u00fablico-Alvo Este guia assume que voc\u00ea est\u00e1 familiarizado com CI/CD e compreende as implica\u00e7\u00f5es de seguran\u00e7a das pipelines de CI/CD. Tamb\u00e9m pressup\u00f5e conhecimento b\u00e1sico do GitHub Actions, incluindo como escrever e executar uma pipeline de CI/CD b\u00e1sica, fazer checkout de reposit\u00f3rios dentro da a\u00e7\u00e3o, usar A\u00e7\u00f5es do Marketplace com controle de vers\u00e3o, etc. Assumimos que voc\u00ea, como engenheiro de CI/CD, deseja injetar vari\u00e1veis de ambiente ou flags de ambiente em suas pipelines e fluxos de trabalho para test\u00e1-los e est\u00e1 usando o GitHub Actions para fazer isso. Cen\u00e1rio de Uso Muitos fluxos de trabalho de integra\u00e7\u00e3o ou de ponta a ponta requerem vari\u00e1veis de ambiente espec\u00edficas que s\u00f3 est\u00e3o dispon\u00edveis durante a execu\u00e7\u00e3o. Por exemplo, um fluxo de trabalho pode estar fazendo o seguinte: Nessa situa\u00e7\u00e3o, testar o pipeline \u00e9 extremamente dif\u00edcil sem a necessidade de fazer chamadas externas para o recurso. Em muitos casos, fazer chamadas externas ao recurso pode ser caro ou demorado, retardando significativamente o desenvolvimento em loop interno. O Azure DevOps, como exemplo, oferece uma maneira de definir vari\u00e1veis de pipeline em um acionador manual: O GitHub Actions ainda n\u00e3o faz isso. Solu\u00e7\u00e3o Para contornar isso, a solu\u00e7\u00e3o mais simples \u00e9 adicionar vari\u00e1veis de tempo de execu\u00e7\u00e3o \u00e0s mensagens de commit ou ao corpo do PR e usar o grep para encontrar a vari\u00e1vel. O GitHub Actions fornece a funcionalidade de grep nativamente usando uma fun\u00e7\u00e3o contains , que \u00e9 o que estaremos usando especificamente. Dentro do escopo: Vamos limitar isso \u00e0 inje\u00e7\u00e3o de uma \u00fanica vari\u00e1vel de ambiente em uma pipeline, com uma chave e valor previamente conhecidos. Fora do escopo: Embora a solu\u00e7\u00e3o seja obviamente extens\u00edvel usando scripts de shell ou qualquer outro meio de criar vari\u00e1veis, essa solu\u00e7\u00e3o serve bem como prova do conceito b\u00e1sico. Nenhum script desse tipo \u00e9 fornecido neste guia. Al\u00e9m disso, as equipes podem desejar formalizar esse processo usando um Modelo de PR que tenha uma se\u00e7\u00e3o adicional para as vari\u00e1veis fornecidas. No entanto, isso n\u00e3o est\u00e1 inclu\u00eddo neste guia. Aviso de Seguran\u00e7a: Isso N\u00c3O \u00e9 para injetar segredos , pois as mensagens de commit e o corpo do PR podem ser recuperados por terceiros, s\u00e3o armazenados no git log e podem ser lidos por um indiv\u00edduo mal-intencionado usando v\u00e1rias ferramentas. Em vez disso, isso \u00e9 para testar um fluxo de trabalho que precisa de vari\u00e1veis simples para serem injetadas, conforme descrito acima. Se voc\u00ea precisa recuperar segredos ou informa\u00e7\u00f5es sens\u00edveis , use a A\u00e7\u00e3o do GitHub para o Azure Key Vault ou algum outro servi\u00e7o de armazenamento e recupera\u00e7\u00e3o de segredos semelhante. Vari\u00e1veis de Mensagem de Commit Como injetar uma \u00fanica vari\u00e1vel no ambiente para uso, com uma chave e valor especificados . Neste exemplo, a chave \u00e9 COMMIT_VAR e o valor \u00e9 [commit var] . Pr\u00e9-requisitos: Os acionadores da pipeline est\u00e3o configurados corretamente para serem acionados por commits enviados (aqui usaremos actions-test-branch como a branch de escolha). Trecho de C\u00f3digo: on : push : branches : - actions-test-branch jobs : Echo-On-Commit : runs-on : ubuntu-latest steps : - name : \"Checkout do Reposit\u00f3rio\" uses : actions/checkout@v2 - name : \"Definir sinalizador a partir do Commit\" env : COMMIT_VAR : ${{ contains(github.event.head_commit.message, '[commit var]') }} run : | if ${COMMIT_VAR} == true; then echo \"flag=true\" >> $GITHUB_ENV echo \"sinalizador definido como verdadeiro\" else echo \"flag=false\" >> $GITHUB_ENV echo \"sinalizador definido como falso\" fi - name : \"Usar sinalizador se verdadeiro\" if : env.flag run : echo \"O sinalizador est\u00e1 dispon\u00edvel e \u00e9 verdadeiro\" Dispon\u00edvel como um arquivo .YAML aqui . Explica\u00e7\u00e3o do C\u00f3digo: A primeira parte do c\u00f3digo configura os acionadores de Push na branch de trabalho e faz o checkout do reposit\u00f3rio, ent\u00e3o n\u00e3o exploraremos isso em detalhes. - name : \"Definir sinalizador a partir do Commit\" env : COMMIT_VAR : ${{ contains(github.event.head_commit.message, '[commit var]') }} Esta \u00e9 uma etapa nomeada dentro do \u00fanico Job em nossa pipeline do GitHub Actions. Aqui, definimos uma vari\u00e1vel de ambiente para a etapa: qualquer c\u00f3digo ou a\u00e7\u00e3o que a etapa chamar agora ter\u00e1 a vari\u00e1vel de ambiente dispon\u00edvel. contains \u00e9 uma fun\u00e7\u00e3o do GitHub Actions que est\u00e1 dispon\u00edvel por padr\u00e3o em todos os fluxos de trabalho. Ela retorna um valor booleano true ou false . Nesta situa\u00e7\u00e3o, ela verifica se a mensagem de commit no \u00faltimo envio, acessada por github.event.head_commit.message , cont\u00e9m a string ${{...}} \u00e9 necess\u00e1rio para usar o Contexto do GitHub e tornar as fun\u00e7\u00f5es e as vari\u00e1veis github.event dispon\u00edveis para o comando. run : | if ${COMMIT_VAR} == true; then echo \"flag=true\" >> $GITHUB_ENV echo \"sinalizador definido como verdadeiro\" else echo \"flag=false\" >> $GITHUB_ENV echo \"sinalizador definido como falso\" fi O comando run aqui verifica se a vari\u00e1vel COMMIT_VAR foi definida como true e, se for o caso, define uma segunda flag como verdadeira e faz um echo disso. Ele faz o mesmo se a vari\u00e1vel for false . A raz\u00e3o espec\u00edfica para fazer isso \u00e9 permitir que a vari\u00e1vel flag seja usada em etapas posteriores em vez de ter que reutilizar a COMMIT_VAR em cada etapa. Al\u00e9m disso, permite que a flag seja usada na etapa if de uma a\u00e7\u00e3o, como na pr\u00f3xima parte do trecho de c\u00f3digo. - name : \"Usar sinalizador se verdadeiro\" if : env.flag run : echo \"O sinalizador est\u00e1 dispon\u00edvel e \u00e9 verdadeiro\" Nesta parte do trecho, a pr\u00f3xima etapa no mesmo job agora est\u00e1 usando o flag que foi definido na etapa anterior. Isso permite ao usu\u00e1rio: Reutilizar o sinalizador em vez de acessar repetidamente o Contexto do GitHub Definir o sinalizador usando v\u00e1rias condi\u00e7\u00f5es, em vez de apenas uma. Por exemplo, uma etapa diferente tamb\u00e9m pode definir o sinalizador como true ou false por diferentes motivos. Alterar a vari\u00e1vel em um \u00fanico local em vez de ter que alter\u00e1-la em v\u00e1rios lugares Alternativa mais curta: A etapa \"Definir sinalizador a partir do Commit\" pode ser simplificada da seguinte forma para tornar o c\u00f3digo muito mais curto, embora n\u00e3o necessariamente mais leg\u00edvel: - name : \"Definir sinalizador a partir do Commit\" env : COMMIT_VAR : ${{ contains(github.event.head_commit.message, '[commit var]') }} run : | echo \"flag=${COMMIT_VAR}\" >> $GITHUB_ENV echo \"sinalizador definido como ${COMMIT_VAR}\" Uso: Incluindo a Vari\u00e1vel Fa\u00e7a push na branch master : > git add. > git commit -m \"Running GitHub Actions Test [commit var]\" > git push Isso aciona o fluxo de trabalho (como qualquer push). Como [commit var] est\u00e1 na mensagem de commit, a vari\u00e1vel ${COMMIT_VAR} no fluxo de trabalho ser\u00e1 definida como true e resultar\u00e1 no seguinte: N\u00e3o Incluindo a Vari\u00e1vel Fa\u00e7a push na branch master : > git add. > git commit -m \"Running GitHub Actions Test\" > git push Isso aciona o fluxo de trabalho (como qualquer push). Como [commit var] n\u00e3o est\u00e1 na mensagem de commit, a vari\u00e1vel ${COMMIT_VAR} no fluxo de trabalho ser\u00e1 definida como false e resultar\u00e1 no seguinte: Vari\u00e1veis no Corpo do PR Quando um PR \u00e9 feito, o Corpo do PR tamb\u00e9m pode ser usado para configurar vari\u00e1veis. Essas vari\u00e1veis podem estar dispon\u00edveis para todas as execu\u00e7\u00f5es de fluxo de trabalho que derivam desse PR, o que pode ajudar a garantir que as mensagens de commit sejam mais informativas e menos polu\u00eddas, al\u00e9m de reduzir o trabalho do desenvolvedor. Mais uma vez, isso \u00e9 para uma chave e valor esperados. Neste caso, a chave \u00e9 PR_VAR e o valor \u00e9 [pr var] . Pr\u00e9-requisitos: Os acionadores da pipeline est\u00e3o configurados corretamente para acionar um pull request para uma branch espec\u00edfica. (Aqui usaremos master como a branch de destino.) Trecho de C\u00f3digo: on : pull_request : branches : - master jobs : Echo-On-PR : runs-on : ubuntu-latest steps : - name : \"Checkout do Reposit\u00f3rio\" uses : actions/checkout@v2 - name : \"Definir sinalizador a partir do PR\" env : PR_VAR : ${{ contains(github.event.pull_request.body, '[pr var]') }} run : | if ${PR_VAR} == true; then echo \"flag=true\" >> $GITHUB_ENV echo \"sinalizador definido como verdadeiro\" else echo \"flag=false\" >> $GITHUB_ENV echo \"sinalizador definido como falso\" fi - name : \"Usar sinalizador se verdadeiro\" if : env.flag run : echo \"O sinalizador est\u00e1 dispon\u00edvel e \u00e9 verdadeiro\" Dispon\u00edvel como um arquivo .YAML aqui . Explica\u00e7\u00e3o do C\u00f3digo: A primeira parte do arquivo YAML simplesmente configura o Acionador de Pull Request. A maior parte do c\u00f3digo a seguir \u00e9 id\u00eantica, ent\u00e3o explicaremos apenas as diferen\u00e7as. - name : \"Definir sinalizador a partir do PR\" env : PR_VAR : ${{ contains(github.event.pull_request.body, '[pr var]') }} Nesta se\u00e7\u00e3o, a vari\u00e1vel de ambiente PR_VAR \u00e9 definida como true ou false , dependendo se a string [pr var] est\u00e1 no Corpo do PR. Alternativa mais curta: Da mesma forma que o acima, a etapa YAML pode ser simplificada da seguinte forma para tornar o c\u00f3digo muito mais curto, embora n\u00e3o necessariamente mais leg\u00edvel: - name : \"Definir sinalizador a partir do PR\" env : PR_VAR : ${{ contains(github.event.pull_request.body, '[pr var]') }} run : | echo \"flag=${PR_VAR}\" >> $GITHUB_ENV echo \" sinalizador definido como ${PR_VAR}\" Uso: Crie um Pull Request para master e inclua a vari\u00e1vel esperada em algum lugar do corpo: A A\u00e7\u00e3o do GitHub ser\u00e1 acionada automaticamente e, como [pr var] est\u00e1 presente no Corpo do PR, ela definir\u00e1 o flag como verdadeiro, como mostrado abaixo: Cen\u00e1rios do Mundo Real Existem muitos cen\u00e1rios do mundo real em que o controle de vari\u00e1veis de ambiente pode ser extremamente \u00fatil. Alguns s\u00e3o destacados abaixo: Evitar Chamadas Externas Caras O Desenvolvedor A est\u00e1 escrevendo e testando um pipeline de integra\u00e7\u00e3o. O pipeline de integra\u00e7\u00e3o precisa fazer uma chamada a um servi\u00e7o externo, como o Azure Data Factory ou o Databricks, aguardar um resultado e depois exibir esse resultado. O fluxo de trabalho pode ser semelhante a este: O fluxo de trabalho inerentemente leva tempo e \u00e9 caro de ser executado, pois envolve a manuten\u00e7\u00e3o de um cluster Databricks e a espera pela resposta. Essa depend\u00eancia externa pode ser removida essencialmente simulando a resposta durante a escrita e teste de outras partes do fluxo de trabalho e simulando a resposta em situa\u00e7\u00f5es em que a resposta real n\u00e3o importa ou n\u00e3o est\u00e1 sendo testada diretamente. Pular Processos de CI Longos O Desenvolvedor B est\u00e1 escrevendo e testando uma pipeline de CI/CD. A pipeline tem v\u00e1rias etapas de CI, cada uma das quais \u00e9 executada sequencialmente. O fluxo de trabalho pode ser assim: Neste caso, cada etapa de CI precisa ser executada antes que a pr\u00f3xima comece, e erros no meio do processo podem fazer com que a pipeline inteira falhe. Embora esse possa ser um comportamento pretendido para a pipeline em algumas situa\u00e7\u00f5es (talvez voc\u00ea n\u00e3o queira executar uma constru\u00e7\u00e3o mais envolvente ou uma su\u00edte de cobertura de testes demorada se o processo de CI estiver falhando), significa que as etapas precisam ser comentadas ou exclu\u00eddas ao testar a pr\u00f3pria pipeline. Em vez disso, uma etapa adicional poderia verificar a presen\u00e7a de uma tag [skip ci $N] nas mensagens de commit ou no Corpo do PR e pular uma etapa espec\u00edfica da compila\u00e7\u00e3o do CI. Isso garante que a pipeline final n\u00e3o tenha altera\u00e7\u00f5es confirmadas que a tornem quebrada, como acontece \u00e0s vezes ao comentar/excluir etapas. Al\u00e9m disso, permite um mecanismo para testar repetidamente etapas individuais pulando as outras, o que facilita significativamente o desenvolvimento da pipeline.","title":"Vari\u00e1veis de Tempo de Execu\u00e7\u00e3o no GitHub Actions"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#variaveis-de-tempo-de-execucao-no-github-actions","text":"","title":"Vari\u00e1veis de Tempo de Execu\u00e7\u00e3o no GitHub Actions"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#objetivo","text":"Embora o GitHub Actions seja uma escolha popular para escrever e executar pipelines de CI/CD, especialmente para projetos de c\u00f3digo aberto hospedados no GitHub, ele carece de recursos espec\u00edficos de qualidade de vida encontrados em outros ambientes de CI/CD. Um recurso-chave que o GitHub Actions ainda n\u00e3o implementou \u00e9 a capacidade de simular e injetar vari\u00e1veis de tempo de execu\u00e7\u00e3o em um fluxo de trabalho, a fim de testar o pipeline em si. Isso cria uma ponte entre um recurso existente no Azure DevOps e um recurso que ainda n\u00e3o foi lan\u00e7ado no GitHub Actions.","title":"Objetivo"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#publico-alvo","text":"Este guia assume que voc\u00ea est\u00e1 familiarizado com CI/CD e compreende as implica\u00e7\u00f5es de seguran\u00e7a das pipelines de CI/CD. Tamb\u00e9m pressup\u00f5e conhecimento b\u00e1sico do GitHub Actions, incluindo como escrever e executar uma pipeline de CI/CD b\u00e1sica, fazer checkout de reposit\u00f3rios dentro da a\u00e7\u00e3o, usar A\u00e7\u00f5es do Marketplace com controle de vers\u00e3o, etc. Assumimos que voc\u00ea, como engenheiro de CI/CD, deseja injetar vari\u00e1veis de ambiente ou flags de ambiente em suas pipelines e fluxos de trabalho para test\u00e1-los e est\u00e1 usando o GitHub Actions para fazer isso.","title":"P\u00fablico-Alvo"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#cenario-de-uso","text":"Muitos fluxos de trabalho de integra\u00e7\u00e3o ou de ponta a ponta requerem vari\u00e1veis de ambiente espec\u00edficas que s\u00f3 est\u00e3o dispon\u00edveis durante a execu\u00e7\u00e3o. Por exemplo, um fluxo de trabalho pode estar fazendo o seguinte: Nessa situa\u00e7\u00e3o, testar o pipeline \u00e9 extremamente dif\u00edcil sem a necessidade de fazer chamadas externas para o recurso. Em muitos casos, fazer chamadas externas ao recurso pode ser caro ou demorado, retardando significativamente o desenvolvimento em loop interno. O Azure DevOps, como exemplo, oferece uma maneira de definir vari\u00e1veis de pipeline em um acionador manual: O GitHub Actions ainda n\u00e3o faz isso.","title":"Cen\u00e1rio de Uso"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#solucao","text":"Para contornar isso, a solu\u00e7\u00e3o mais simples \u00e9 adicionar vari\u00e1veis de tempo de execu\u00e7\u00e3o \u00e0s mensagens de commit ou ao corpo do PR e usar o grep para encontrar a vari\u00e1vel. O GitHub Actions fornece a funcionalidade de grep nativamente usando uma fun\u00e7\u00e3o contains , que \u00e9 o que estaremos usando especificamente. Dentro do escopo: Vamos limitar isso \u00e0 inje\u00e7\u00e3o de uma \u00fanica vari\u00e1vel de ambiente em uma pipeline, com uma chave e valor previamente conhecidos. Fora do escopo: Embora a solu\u00e7\u00e3o seja obviamente extens\u00edvel usando scripts de shell ou qualquer outro meio de criar vari\u00e1veis, essa solu\u00e7\u00e3o serve bem como prova do conceito b\u00e1sico. Nenhum script desse tipo \u00e9 fornecido neste guia. Al\u00e9m disso, as equipes podem desejar formalizar esse processo usando um Modelo de PR que tenha uma se\u00e7\u00e3o adicional para as vari\u00e1veis fornecidas. No entanto, isso n\u00e3o est\u00e1 inclu\u00eddo neste guia. Aviso de Seguran\u00e7a: Isso N\u00c3O \u00e9 para injetar segredos , pois as mensagens de commit e o corpo do PR podem ser recuperados por terceiros, s\u00e3o armazenados no git log e podem ser lidos por um indiv\u00edduo mal-intencionado usando v\u00e1rias ferramentas. Em vez disso, isso \u00e9 para testar um fluxo de trabalho que precisa de vari\u00e1veis simples para serem injetadas, conforme descrito acima. Se voc\u00ea precisa recuperar segredos ou informa\u00e7\u00f5es sens\u00edveis , use a A\u00e7\u00e3o do GitHub para o Azure Key Vault ou algum outro servi\u00e7o de armazenamento e recupera\u00e7\u00e3o de segredos semelhante.","title":"Solu\u00e7\u00e3o"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#variaveis-de-mensagem-de-commit","text":"Como injetar uma \u00fanica vari\u00e1vel no ambiente para uso, com uma chave e valor especificados . Neste exemplo, a chave \u00e9 COMMIT_VAR e o valor \u00e9 [commit var] . Pr\u00e9-requisitos: Os acionadores da pipeline est\u00e3o configurados corretamente para serem acionados por commits enviados (aqui usaremos actions-test-branch como a branch de escolha). Trecho de C\u00f3digo: on : push : branches : - actions-test-branch jobs : Echo-On-Commit : runs-on : ubuntu-latest steps : - name : \"Checkout do Reposit\u00f3rio\" uses : actions/checkout@v2 - name : \"Definir sinalizador a partir do Commit\" env : COMMIT_VAR : ${{ contains(github.event.head_commit.message, '[commit var]') }} run : | if ${COMMIT_VAR} == true; then echo \"flag=true\" >> $GITHUB_ENV echo \"sinalizador definido como verdadeiro\" else echo \"flag=false\" >> $GITHUB_ENV echo \"sinalizador definido como falso\" fi - name : \"Usar sinalizador se verdadeiro\" if : env.flag run : echo \"O sinalizador est\u00e1 dispon\u00edvel e \u00e9 verdadeiro\" Dispon\u00edvel como um arquivo .YAML aqui . Explica\u00e7\u00e3o do C\u00f3digo: A primeira parte do c\u00f3digo configura os acionadores de Push na branch de trabalho e faz o checkout do reposit\u00f3rio, ent\u00e3o n\u00e3o exploraremos isso em detalhes. - name : \"Definir sinalizador a partir do Commit\" env : COMMIT_VAR : ${{ contains(github.event.head_commit.message, '[commit var]') }} Esta \u00e9 uma etapa nomeada dentro do \u00fanico Job em nossa pipeline do GitHub Actions. Aqui, definimos uma vari\u00e1vel de ambiente para a etapa: qualquer c\u00f3digo ou a\u00e7\u00e3o que a etapa chamar agora ter\u00e1 a vari\u00e1vel de ambiente dispon\u00edvel. contains \u00e9 uma fun\u00e7\u00e3o do GitHub Actions que est\u00e1 dispon\u00edvel por padr\u00e3o em todos os fluxos de trabalho. Ela retorna um valor booleano true ou false . Nesta situa\u00e7\u00e3o, ela verifica se a mensagem de commit no \u00faltimo envio, acessada por github.event.head_commit.message , cont\u00e9m a string ${{...}} \u00e9 necess\u00e1rio para usar o Contexto do GitHub e tornar as fun\u00e7\u00f5es e as vari\u00e1veis github.event dispon\u00edveis para o comando. run : | if ${COMMIT_VAR} == true; then echo \"flag=true\" >> $GITHUB_ENV echo \"sinalizador definido como verdadeiro\" else echo \"flag=false\" >> $GITHUB_ENV echo \"sinalizador definido como falso\" fi O comando run aqui verifica se a vari\u00e1vel COMMIT_VAR foi definida como true e, se for o caso, define uma segunda flag como verdadeira e faz um echo disso. Ele faz o mesmo se a vari\u00e1vel for false . A raz\u00e3o espec\u00edfica para fazer isso \u00e9 permitir que a vari\u00e1vel flag seja usada em etapas posteriores em vez de ter que reutilizar a COMMIT_VAR em cada etapa. Al\u00e9m disso, permite que a flag seja usada na etapa if de uma a\u00e7\u00e3o, como na pr\u00f3xima parte do trecho de c\u00f3digo. - name : \"Usar sinalizador se verdadeiro\" if : env.flag run : echo \"O sinalizador est\u00e1 dispon\u00edvel e \u00e9 verdadeiro\" Nesta parte do trecho, a pr\u00f3xima etapa no mesmo job agora est\u00e1 usando o flag que foi definido na etapa anterior. Isso permite ao usu\u00e1rio: Reutilizar o sinalizador em vez de acessar repetidamente o Contexto do GitHub Definir o sinalizador usando v\u00e1rias condi\u00e7\u00f5es, em vez de apenas uma. Por exemplo, uma etapa diferente tamb\u00e9m pode definir o sinalizador como true ou false por diferentes motivos. Alterar a vari\u00e1vel em um \u00fanico local em vez de ter que alter\u00e1-la em v\u00e1rios lugares Alternativa mais curta: A etapa \"Definir sinalizador a partir do Commit\" pode ser simplificada da seguinte forma para tornar o c\u00f3digo muito mais curto, embora n\u00e3o necessariamente mais leg\u00edvel: - name : \"Definir sinalizador a partir do Commit\" env : COMMIT_VAR : ${{ contains(github.event.head_commit.message, '[commit var]') }} run : | echo \"flag=${COMMIT_VAR}\" >> $GITHUB_ENV echo \"sinalizador definido como ${COMMIT_VAR}\" Uso: Incluindo a Vari\u00e1vel Fa\u00e7a push na branch master : > git add. > git commit -m \"Running GitHub Actions Test [commit var]\" > git push Isso aciona o fluxo de trabalho (como qualquer push). Como [commit var] est\u00e1 na mensagem de commit, a vari\u00e1vel ${COMMIT_VAR} no fluxo de trabalho ser\u00e1 definida como true e resultar\u00e1 no seguinte: N\u00e3o Incluindo a Vari\u00e1vel Fa\u00e7a push na branch master : > git add. > git commit -m \"Running GitHub Actions Test\" > git push Isso aciona o fluxo de trabalho (como qualquer push). Como [commit var] n\u00e3o est\u00e1 na mensagem de commit, a vari\u00e1vel ${COMMIT_VAR} no fluxo de trabalho ser\u00e1 definida como false e resultar\u00e1 no seguinte:","title":"Vari\u00e1veis de Mensagem de Commit"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#variaveis-no-corpo-do-pr","text":"Quando um PR \u00e9 feito, o Corpo do PR tamb\u00e9m pode ser usado para configurar vari\u00e1veis. Essas vari\u00e1veis podem estar dispon\u00edveis para todas as execu\u00e7\u00f5es de fluxo de trabalho que derivam desse PR, o que pode ajudar a garantir que as mensagens de commit sejam mais informativas e menos polu\u00eddas, al\u00e9m de reduzir o trabalho do desenvolvedor. Mais uma vez, isso \u00e9 para uma chave e valor esperados. Neste caso, a chave \u00e9 PR_VAR e o valor \u00e9 [pr var] . Pr\u00e9-requisitos: Os acionadores da pipeline est\u00e3o configurados corretamente para acionar um pull request para uma branch espec\u00edfica. (Aqui usaremos master como a branch de destino.) Trecho de C\u00f3digo: on : pull_request : branches : - master jobs : Echo-On-PR : runs-on : ubuntu-latest steps : - name : \"Checkout do Reposit\u00f3rio\" uses : actions/checkout@v2 - name : \"Definir sinalizador a partir do PR\" env : PR_VAR : ${{ contains(github.event.pull_request.body, '[pr var]') }} run : | if ${PR_VAR} == true; then echo \"flag=true\" >> $GITHUB_ENV echo \"sinalizador definido como verdadeiro\" else echo \"flag=false\" >> $GITHUB_ENV echo \"sinalizador definido como falso\" fi - name : \"Usar sinalizador se verdadeiro\" if : env.flag run : echo \"O sinalizador est\u00e1 dispon\u00edvel e \u00e9 verdadeiro\" Dispon\u00edvel como um arquivo .YAML aqui . Explica\u00e7\u00e3o do C\u00f3digo: A primeira parte do arquivo YAML simplesmente configura o Acionador de Pull Request. A maior parte do c\u00f3digo a seguir \u00e9 id\u00eantica, ent\u00e3o explicaremos apenas as diferen\u00e7as. - name : \"Definir sinalizador a partir do PR\" env : PR_VAR : ${{ contains(github.event.pull_request.body, '[pr var]') }} Nesta se\u00e7\u00e3o, a vari\u00e1vel de ambiente PR_VAR \u00e9 definida como true ou false , dependendo se a string [pr var] est\u00e1 no Corpo do PR. Alternativa mais curta: Da mesma forma que o acima, a etapa YAML pode ser simplificada da seguinte forma para tornar o c\u00f3digo muito mais curto, embora n\u00e3o necessariamente mais leg\u00edvel: - name : \"Definir sinalizador a partir do PR\" env : PR_VAR : ${{ contains(github.event.pull_request.body, '[pr var]') }} run : | echo \"flag=${PR_VAR}\" >> $GITHUB_ENV echo \" sinalizador definido como ${PR_VAR}\" Uso: Crie um Pull Request para master e inclua a vari\u00e1vel esperada em algum lugar do corpo: A A\u00e7\u00e3o do GitHub ser\u00e1 acionada automaticamente e, como [pr var] est\u00e1 presente no Corpo do PR, ela definir\u00e1 o flag como verdadeiro, como mostrado abaixo:","title":"Vari\u00e1veis no Corpo do PR"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#cenarios-do-mundo-real","text":"Existem muitos cen\u00e1rios do mundo real em que o controle de vari\u00e1veis de ambiente pode ser extremamente \u00fatil. Alguns s\u00e3o destacados abaixo:","title":"Cen\u00e1rios do Mundo Real"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#evitar-chamadas-externas-caras","text":"O Desenvolvedor A est\u00e1 escrevendo e testando um pipeline de integra\u00e7\u00e3o. O pipeline de integra\u00e7\u00e3o precisa fazer uma chamada a um servi\u00e7o externo, como o Azure Data Factory ou o Databricks, aguardar um resultado e depois exibir esse resultado. O fluxo de trabalho pode ser semelhante a este: O fluxo de trabalho inerentemente leva tempo e \u00e9 caro de ser executado, pois envolve a manuten\u00e7\u00e3o de um cluster Databricks e a espera pela resposta. Essa depend\u00eancia externa pode ser removida essencialmente simulando a resposta durante a escrita e teste de outras partes do fluxo de trabalho e simulando a resposta em situa\u00e7\u00f5es em que a resposta real n\u00e3o importa ou n\u00e3o est\u00e1 sendo testada diretamente.","title":"Evitar Chamadas Externas Caras"},{"location":"continuous-delivery/devops-provider-recipes/github-actions/runtime-variables/runtime-variables/#pular-processos-de-ci-longos","text":"O Desenvolvedor B est\u00e1 escrevendo e testando uma pipeline de CI/CD. A pipeline tem v\u00e1rias etapas de CI, cada uma das quais \u00e9 executada sequencialmente. O fluxo de trabalho pode ser assim: Neste caso, cada etapa de CI precisa ser executada antes que a pr\u00f3xima comece, e erros no meio do processo podem fazer com que a pipeline inteira falhe. Embora esse possa ser um comportamento pretendido para a pipeline em algumas situa\u00e7\u00f5es (talvez voc\u00ea n\u00e3o queira executar uma constru\u00e7\u00e3o mais envolvente ou uma su\u00edte de cobertura de testes demorada se o processo de CI estiver falhando), significa que as etapas precisam ser comentadas ou exclu\u00eddas ao testar a pr\u00f3pria pipeline. Em vez disso, uma etapa adicional poderia verificar a presen\u00e7a de uma tag [skip ci $N] nas mensagens de commit ou no Corpo do PR e pular uma etapa espec\u00edfica da compila\u00e7\u00e3o do CI. Isso garante que a pipeline final n\u00e3o tenha altera\u00e7\u00f5es confirmadas que a tornem quebrada, como acontece \u00e0s vezes ao comentar/excluir etapas. Al\u00e9m disso, permite um mecanismo para testar repetidamente etapas individuais pulando as outras, o que facilita significativamente o desenvolvimento da pipeline.","title":"Pular Processos de CI Longos"},{"location":"continuous-delivery/gitops/deploying/","text":"Implanta\u00e7\u00e3o com GitOps O que \u00e9 GitOps? GitOps \u00e9 uma forma de gerenciar sua infraestrutura e aplicativos para que todo o sistema seja descrito de forma declarativa e controlada por vers\u00f5es (provavelmente em um reposit\u00f3rio Git) e tenha um processo automatizado que garanta que o ambiente implantado corresponda ao estado especificado em um reposit\u00f3rio.\" - WeaveWorks Por que devo usar o GitOps? O GitOps simplesmente permite implanta\u00e7\u00f5es mais r\u00e1pidas, tendo reposit\u00f3rios Git no centro, oferecendo um rastreamento claro por meio de commits do Git e sem acesso direto ao ambiente. Saiba mais em Por que devo usar o GitOps? O diagrama abaixo compara o fluxo de trabalho tradicional de CI/CD com o GitOps: Ferramentas para GitOps Alguns frameworks populares de GitOps para Kubernetes apoiados pela comunidade CNCF : Flux V2 Argo CD Rancher Fleet Implanta\u00e7\u00e3o usando GitOps O GitOps com o Flux v2 pode ser habilitado em clusters gerenciados do Azure Kubernetes Service (AKS) ou em clusters conectados do Kubernetes habilitados para o Azure Arc como uma extens\u00e3o de cluster. Ap\u00f3s a instala\u00e7\u00e3o da extens\u00e3o de cluster microsoft.flux, voc\u00ea pode criar um ou mais recursos de fluxConfigurations que sincronizam as fontes do seu reposit\u00f3rio Git com o cluster e reconciliam o cluster com o estado desejado. Com o GitOps, voc\u00ea pode usar seu reposit\u00f3rio Git como a fonte da verdade para a configura\u00e7\u00e3o do cluster e a implanta\u00e7\u00e3o de aplicativos. Tutorial: Implante configura\u00e7\u00f5es usando GitOps em um cluster Kubernetes habilitado para Azure Arc Tutorial: Implemente CI/CD com GitOps Ambiente com v\u00e1rios clusters e locat\u00e1rios com o Flux v2","title":"Implanta\u00e7\u00e3o com GitOps"},{"location":"continuous-delivery/gitops/deploying/#implantacao-com-gitops","text":"","title":"Implanta\u00e7\u00e3o com GitOps"},{"location":"continuous-delivery/gitops/deploying/#o-que-e-gitops","text":"GitOps \u00e9 uma forma de gerenciar sua infraestrutura e aplicativos para que todo o sistema seja descrito de forma declarativa e controlada por vers\u00f5es (provavelmente em um reposit\u00f3rio Git) e tenha um processo automatizado que garanta que o ambiente implantado corresponda ao estado especificado em um reposit\u00f3rio.\" - WeaveWorks","title":"O que \u00e9 GitOps?"},{"location":"continuous-delivery/gitops/deploying/#por-que-devo-usar-o-gitops","text":"O GitOps simplesmente permite implanta\u00e7\u00f5es mais r\u00e1pidas, tendo reposit\u00f3rios Git no centro, oferecendo um rastreamento claro por meio de commits do Git e sem acesso direto ao ambiente. Saiba mais em Por que devo usar o GitOps? O diagrama abaixo compara o fluxo de trabalho tradicional de CI/CD com o GitOps:","title":"Por que devo usar o GitOps?"},{"location":"continuous-delivery/gitops/deploying/#ferramentas-para-gitops","text":"Alguns frameworks populares de GitOps para Kubernetes apoiados pela comunidade CNCF : Flux V2 Argo CD Rancher Fleet","title":"Ferramentas para GitOps"},{"location":"continuous-delivery/gitops/deploying/#implantacao-usando-gitops","text":"O GitOps com o Flux v2 pode ser habilitado em clusters gerenciados do Azure Kubernetes Service (AKS) ou em clusters conectados do Kubernetes habilitados para o Azure Arc como uma extens\u00e3o de cluster. Ap\u00f3s a instala\u00e7\u00e3o da extens\u00e3o de cluster microsoft.flux, voc\u00ea pode criar um ou mais recursos de fluxConfigurations que sincronizam as fontes do seu reposit\u00f3rio Git com o cluster e reconciliam o cluster com o estado desejado. Com o GitOps, voc\u00ea pode usar seu reposit\u00f3rio Git como a fonte da verdade para a configura\u00e7\u00e3o do cluster e a implanta\u00e7\u00e3o de aplicativos. Tutorial: Implante configura\u00e7\u00f5es usando GitOps em um cluster Kubernetes habilitado para Azure Arc Tutorial: Implemente CI/CD com GitOps Ambiente com v\u00e1rios clusters e locat\u00e1rios com o Flux v2","title":"Implanta\u00e7\u00e3o usando GitOps"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/","text":"Gerenciamento de Senhas com GitOps Projetos GitOps t\u00eam reposit\u00f3rios Git como o ponto central, considerados a fonte da verdade para o gerenciamento tanto da infraestrutura quanto das aplica\u00e7\u00f5es. Essa infraestrutura e aplica\u00e7\u00e3o exigir\u00e3o acesso seguro a outros recursos do sistema por meio de senhas. Fazer commit de senhas em texto claro em reposit\u00f3rios Git \u00e9 inaceit\u00e1vel, mesmo que os reposit\u00f3rios sejam privados para sua equipe e organiza\u00e7\u00e3o. As equipes precisam de uma maneira segura de lidar com senhas ao usar GitOps. Existem v\u00e1rias maneiras de gerenciar senhas com GitOps e, em alto n\u00edvel, podem ser categorizadas em: Senhas criptografadas em reposit\u00f3rios Git Refer\u00eancia a senhas armazenadas em um cofre de chaves externo TLDR : Fazer refer\u00eancia a senhas em um cofre de chaves externo \u00e9 a abordagem recomendada. \u00c9 mais f\u00e1cil orquestrar a rota\u00e7\u00e3o de senhas e mais escal\u00e1vel com v\u00e1rios clusters e/ou equipes. Senhas Criptografadas em Reposit\u00f3rios Git Nessa abordagem, os desenvolvedores criptografam manualmente senhas usando uma chave p\u00fablica, e a chave s\u00f3 pode ser descriptografada pelo controlador Kubernetes personalizado em execu\u00e7\u00e3o no cluster de destino. Algumas ferramentas populares para essa abordagem s\u00e3o Bitnami Sealed Secrets e Mozilla SOPS . Todas as ferramentas de criptografia de senhas compartilham as seguintes caracter\u00edsticas: Altera\u00e7\u00f5es de senhas s\u00e3o gerenciadas fazendo altera\u00e7\u00f5es dentro do reposit\u00f3rio GitOps, o que proporciona grande rastreabilidade. Todas as senhas podem ser rotacionadas fazendo altera\u00e7\u00f5es no GitOps, sem acessar o cluster. Elas suportam cen\u00e1rios de GitOps completamente desconectados. As senhas s\u00e3o armazenadas criptografadas no reposit\u00f3rio GitOps. Se a chave de criptografia privada for vazada e o invasor tiver acesso ao reposit\u00f3rio, todas as senhas podem ser descriptografadas. Bitnami Sealed Secrets O Sealed Secrets usa criptografia assim\u00e9trica para criptografar senhas. Um controlador Kubernetes gera um par de chaves (privada-p\u00fablica) e armazena a chave privada no banco de dados etcd do cluster como um segredo Kubernetes. Os desenvolvedores usam o Kubeseal CLI para selar senhas antes de fazer commit no reposit\u00f3rio Git. Alguns pontos-chave do uso do Sealed Secrets incluem: Suporta rota\u00e7\u00e3o autom\u00e1tica de chaves para a chave privada e pode ser usada para for\u00e7ar a recriptografia de senhas. Devido \u00e0 renova\u00e7\u00e3o autom\u00e1tica da chave de selagem , a chave deve ser pr\u00e9-carregada do cluster ou configurada para armazenar a chave de selagem em um local secund\u00e1rio durante a renova\u00e7\u00e3o. Suporte \u00e0 multi-tenancy no n\u00edvel de namespace pode ser imposto pelo controlador. Ao selar senhas, os desenvolvedores precisam de uma conex\u00e3o com o plano de controle do cluster para buscar a chave p\u00fablica ou a chave p\u00fablica deve ser explicitamente compartilhada com o desenvolvedor. Se a chave privada no cluster for perdida por algum motivo, todas as senhas precisam ser recriptografadas ap\u00f3s a gera\u00e7\u00e3o de um novo par de chaves. N\u00e3o dimensiona bem com m\u00faltiplos clusters, pois cada cluster exigir\u00e1 um controlador com seu pr\u00f3prio par de chaves. S\u00f3 pode criptografar o tipo de recurso secret . A documenta\u00e7\u00e3o do Flux tem inconsist\u00eancias nos exemplos do Azure Key Vault. Mozilla SOPS O SOPS: Secrets OPerationS \u00e9 uma ferramenta de criptografia que suporta formatos YAML, JSON, ENV, INI e BINARY e criptografa com AWS KMS, GCP KMS, Azure Key Vault, age e PGP, n\u00e3o se limitando apenas ao Kubernetes. Ele suporta a integra\u00e7\u00e3o com alguns sistemas comuns de gerenciamento de chaves, incluindo o Azure Key Vault, onde um ou mais sistemas de gerenciamento de chaves s\u00e3o usados para armazenar a chave de criptografia para criptografar senhas e n\u00e3o as pr\u00f3prias senhas. Alguns pontos-chave do uso do SOPS incluem: Flux tem suporte nativo ao SOPS com descriptografia no lado do cluster. Fornece uma camada adicional de seguran\u00e7a, pois a chave privada usada para descriptografar \u00e9 protegida em um cofre de chaves externo. Para usar o CLI Helm para criptografia, \u00e9 necess\u00e1rio o plug-in ( Helm Secrets ). Necessita do plug-in ( KSOPS )([kustomize-sopssecretgenerator]( https://github.com/goabout/kustomize-sopssecretgenerator)) para funcionar com Kustomization. - N\u00e3o dimensiona bem com equipes maiores, pois cada desenvolvedor precisa criptografar as senhas. - A chave p\u00fablica \u00e9 suficiente para criar novos arquivos. A chave secreta \u00e9 necess\u00e1ria para descriptografar e editar arquivos existentes porque o SOPS calcula um c\u00f3digo de autentica\u00e7\u00e3o de mensagem (MAC) em todos os valores. Ao usar apenas a chave p\u00fablica para adicionar ou remover um campo, o arquivo inteiro deve ser exclu\u00eddo e recriado. - Suporta v\u00e1rios tipos de chaves que podem ser usadas em estados conectados e desconectados. Uma senha pode ter uma lista de chaves e tentar\u00e1 descriptografar com todas elas. Refer\u00eancia a Senhas Armazenadas em um Cofre de Chaves Externo (Recomendado) Essa abordagem depende de um sistema de gerenciamento de chaves, como o Azure Key Vault , para armazenar as senhas, e o manifesto Git nas reposit\u00f3rios faz refer\u00eancia \u00e0s senhas do cofre de chaves. Os desenvolvedores n\u00e3o realizam nenhuma opera\u00e7\u00e3o criptogr\u00e1fica com arquivos nos reposit\u00f3rios. Operadores Kubernetes em execu\u00e7\u00e3o no cluster de destino s\u00e3o respons\u00e1veis por recuperar as senhas do cofre de chaves e disponibiliz\u00e1-las como segredos Kubernetes ou volumes de segredos montados no pod. Todas as ferramentas abaixo compartilham as seguintes caracter\u00edsticas: As senhas n\u00e3o s\u00e3o armazenadas no reposit\u00f3rio. Suportam m\u00e9tricas Prometheus para observabilidade. Suportam sincroniza\u00e7\u00e3o com Segredos Kubernetes. Suportam cont\u00eaineres Linux e Windows. Fornecem gerenciamento de segredos externos de n\u00edvel empresarial. Facilmente escal\u00e1veis com m\u00faltiplos clusters e equipes maiores. Ambas as solu\u00e7\u00f5es suportam Azure Active Directory (Azure AD) principal de servi\u00e7o ou identidade gerenciada para autentica\u00e7\u00e3o com o Key Vault . Para ideias sobre rota\u00e7\u00e3o de senhas, consulte Rota\u00e7\u00e3o de Senhas em Vari\u00e1veis de Ambiente e Segredos Montados Para saber como autenticar registros de cont\u00eaineres privados com um principal de servi\u00e7o, consulte: Registro de Cont\u00eainer Privado Autenticado Provedor de Azure Key Vault para Secrets Store CSI Driver O Provedor de Azure Key Vault (AKVP) para Driver de Armazenamento de Segredos CSI para Kubernetes permite que voc\u00ea obtenha o conte\u00fado de segredos armazenados em uma inst\u00e2ncia do Azure Key Vault e use a interface Secrets Store CSI driver para mont\u00e1-los nos pods do Kubernetes. Monta segredos/chaves/certificados no pod usando um volume Inline CSI. Guia de instala\u00e7\u00e3o do Provedor de Azure Key Vault para Secrets Store CSI Driver aqui . O driver CSI precisar\u00e1 de acesso ao Azure Key Vault, seja por meio de um principal de servi\u00e7o ou identidade gerenciada (recomendado). Para tornar esse acesso seguro, voc\u00ea pode aproveitar a Identidade de Carga de Trabalho do Azure AD (recomendado) ou Identidade de Pod do AAD . Observe que a identidade de pod do AAD em breve ser\u00e1 substitu\u00edda pela identidade de carga de trabalho. Links do Grupo de Produtos fornecidos para AKVP com SSCSID: 1. Diferen\u00e7as entre ESO / SSCSID ( GitHub Issue ) 2. Palestra sobre Gerenciamento de Segredos no K8S aqui (Segredos Nativos, Vault.io e ESO vs. SSCSID) Vantagens: Suporta a portabilidade de pods com o SecretProviderClass CRD Suporta a rota\u00e7\u00e3o autom\u00e1tica de segredos com intervalos de sincroniza\u00e7\u00e3o personaliz\u00e1veis por cluster . Parece ser a escolha da Microsoft (o driver Secrets Store CSI \u00e9 fortemente contribu\u00eddo pela MSFT e pelo Kubernetes-SIG) Desvantagens: Suporte ausente para cen\u00e1rios desconectados : Quando o n\u00f3 est\u00e1 offline, o SSCSID falha ao buscar o segredo e, portanto, a montagem do volume falha, tornando a escalabilidade e a reinicializa\u00e7\u00e3o de pods imposs\u00edveis enquanto estiver offline O AKVP s\u00f3 pode acessar o Key Vault de um ambiente n\u00e3o-Azure usando um principal de servi\u00e7o O Segredo Kubernetes contendo as credenciais do principal de servi\u00e7o precisa ser criado como um segredo no mesmo namespace do pod de aplica\u00e7\u00e3o. Se os pods em v\u00e1rios namespaces precisarem usar o mesmo SP para acessar o Key Vault, este Segredo Kubernetes precisa ser criado em cada namespace. O reposit\u00f3rio GitOps deve conter o nome do Key Vault dentro do SecretProviderClass Deve montar segredos como volumes para permitir a sincroniza\u00e7\u00e3o em Segredos Kubernetes Usa mais recursos (4 pods; driver de armazenamento CSI e provedor) e \u00e9 um daemonset - n\u00e3o testado quanto ao uso de recursos/RPS. Operador de Segredos Externos com Azure Key Vault O Operador de Segredos Externos (ESO) \u00e9 um operador Kubernetes de c\u00f3digo aberto que pode ler segredos de armazenamentos de segred os externos (por exemplo, Azure Key Vault) e sincroniz\u00e1-los com Segredos Kubernetes. Em contraste com o Driver CSI, o controlador ESO cria os segredos no cluster como Segredos K8s, em vez de mont\u00e1-los como volumes em pods. Documenta\u00e7\u00e3o sobre o uso do provedor Azure Key Vault do ESO aqui . O ESO precisar\u00e1 de acesso ao Azure Key Vault, seja por meio de um principal de servi\u00e7o ou identidade gerenciada (por meio da Identidade de Carga de Trabalho do Azure AD (recomendado) ou Identidade de Pod do AAD ). Vantagens: Suporta a rota\u00e7\u00e3o autom\u00e1tica de segredos com intervalos de sincroniza\u00e7\u00e3o personaliz\u00e1veis por segredo . Os componentes s\u00e3o divididos em diferentes CRDs para namespace (ExternalSecret, SecretStore) e cluster-wide (ClusterSecretStore, ClusterExternalSecret), tornando a sincroniza\u00e7\u00e3o mais gerenci\u00e1vel em rela\u00e7\u00e3o a diferentes implanta\u00e7\u00f5es/pods, etc. O segredo do principal de servi\u00e7o para os (Cluster)SecretStores pode ser colocado em um namespace que apenas o ESO pode acessar (veja Shared ClusterSecretStore ). Eficiente em recursos (um \u00fanico pod) - n\u00e3o testado quanto ao uso de recursos/RPS. C\u00f3digo aberto e alto n\u00famero de contribui\u00e7\u00f5es, ( GitHub ) A montagem de segredos como volumes \u00e9 suportada por meio das APIs do K8S (veja aqui ) Suporta cen\u00e1rios parcialmente desconectados: como o ESO usa segredos nativos do K8s, o cluster pode estar offline e isso n\u00e3o afeta a reinicializa\u00e7\u00e3o e a escalabilidade de pods enquanto estiver offline Desvantagens: O reposit\u00f3rio GitOps deve conter o nome do Key Vault dentro do SecretStore / ClusterSecretStore ou um ConfigMap que fa\u00e7a refer\u00eancia a ele. Deve criar segredos como segredos K8s. Links Importantes Sealed Secrets com Flux v2 Mozilla SOPS com Flux v2 Gerenciamento de Segredos com Argo CD Fluxo de Trabalho de Gerenciamento de Segredos Ap\u00eandice Registro de Cont\u00eainer Privado Autenticado Uma op\u00e7\u00e3o de como autenticar registros de cont\u00eainer privados (por exemplo, ACR): Use um Segredo Kubernetes dockerconfigjson no n\u00edvel do pod com ImagePullSecret (Isso tamb\u00e9m pode ser definido no n\u00edvel do namespace ) Espero que esta tradu\u00e7\u00e3o seja \u00fatil para voc\u00ea. Se tiver alguma d\u00favida adicional ou precisar de mais informa\u00e7\u00f5es, sinta-se \u00e0 vontade para perguntar.","title":"Gerenciamento de Senhas com GitOps"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#gerenciamento-de-senhas-com-gitops","text":"Projetos GitOps t\u00eam reposit\u00f3rios Git como o ponto central, considerados a fonte da verdade para o gerenciamento tanto da infraestrutura quanto das aplica\u00e7\u00f5es. Essa infraestrutura e aplica\u00e7\u00e3o exigir\u00e3o acesso seguro a outros recursos do sistema por meio de senhas. Fazer commit de senhas em texto claro em reposit\u00f3rios Git \u00e9 inaceit\u00e1vel, mesmo que os reposit\u00f3rios sejam privados para sua equipe e organiza\u00e7\u00e3o. As equipes precisam de uma maneira segura de lidar com senhas ao usar GitOps. Existem v\u00e1rias maneiras de gerenciar senhas com GitOps e, em alto n\u00edvel, podem ser categorizadas em: Senhas criptografadas em reposit\u00f3rios Git Refer\u00eancia a senhas armazenadas em um cofre de chaves externo TLDR : Fazer refer\u00eancia a senhas em um cofre de chaves externo \u00e9 a abordagem recomendada. \u00c9 mais f\u00e1cil orquestrar a rota\u00e7\u00e3o de senhas e mais escal\u00e1vel com v\u00e1rios clusters e/ou equipes.","title":"Gerenciamento de Senhas com GitOps"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#senhas-criptografadas-em-repositorios-git","text":"Nessa abordagem, os desenvolvedores criptografam manualmente senhas usando uma chave p\u00fablica, e a chave s\u00f3 pode ser descriptografada pelo controlador Kubernetes personalizado em execu\u00e7\u00e3o no cluster de destino. Algumas ferramentas populares para essa abordagem s\u00e3o Bitnami Sealed Secrets e Mozilla SOPS . Todas as ferramentas de criptografia de senhas compartilham as seguintes caracter\u00edsticas: Altera\u00e7\u00f5es de senhas s\u00e3o gerenciadas fazendo altera\u00e7\u00f5es dentro do reposit\u00f3rio GitOps, o que proporciona grande rastreabilidade. Todas as senhas podem ser rotacionadas fazendo altera\u00e7\u00f5es no GitOps, sem acessar o cluster. Elas suportam cen\u00e1rios de GitOps completamente desconectados. As senhas s\u00e3o armazenadas criptografadas no reposit\u00f3rio GitOps. Se a chave de criptografia privada for vazada e o invasor tiver acesso ao reposit\u00f3rio, todas as senhas podem ser descriptografadas.","title":"Senhas Criptografadas em Reposit\u00f3rios Git"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#bitnami-sealed-secrets","text":"O Sealed Secrets usa criptografia assim\u00e9trica para criptografar senhas. Um controlador Kubernetes gera um par de chaves (privada-p\u00fablica) e armazena a chave privada no banco de dados etcd do cluster como um segredo Kubernetes. Os desenvolvedores usam o Kubeseal CLI para selar senhas antes de fazer commit no reposit\u00f3rio Git. Alguns pontos-chave do uso do Sealed Secrets incluem: Suporta rota\u00e7\u00e3o autom\u00e1tica de chaves para a chave privada e pode ser usada para for\u00e7ar a recriptografia de senhas. Devido \u00e0 renova\u00e7\u00e3o autom\u00e1tica da chave de selagem , a chave deve ser pr\u00e9-carregada do cluster ou configurada para armazenar a chave de selagem em um local secund\u00e1rio durante a renova\u00e7\u00e3o. Suporte \u00e0 multi-tenancy no n\u00edvel de namespace pode ser imposto pelo controlador. Ao selar senhas, os desenvolvedores precisam de uma conex\u00e3o com o plano de controle do cluster para buscar a chave p\u00fablica ou a chave p\u00fablica deve ser explicitamente compartilhada com o desenvolvedor. Se a chave privada no cluster for perdida por algum motivo, todas as senhas precisam ser recriptografadas ap\u00f3s a gera\u00e7\u00e3o de um novo par de chaves. N\u00e3o dimensiona bem com m\u00faltiplos clusters, pois cada cluster exigir\u00e1 um controlador com seu pr\u00f3prio par de chaves. S\u00f3 pode criptografar o tipo de recurso secret . A documenta\u00e7\u00e3o do Flux tem inconsist\u00eancias nos exemplos do Azure Key Vault.","title":"Bitnami Sealed Secrets"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#mozilla-sops","text":"O SOPS: Secrets OPerationS \u00e9 uma ferramenta de criptografia que suporta formatos YAML, JSON, ENV, INI e BINARY e criptografa com AWS KMS, GCP KMS, Azure Key Vault, age e PGP, n\u00e3o se limitando apenas ao Kubernetes. Ele suporta a integra\u00e7\u00e3o com alguns sistemas comuns de gerenciamento de chaves, incluindo o Azure Key Vault, onde um ou mais sistemas de gerenciamento de chaves s\u00e3o usados para armazenar a chave de criptografia para criptografar senhas e n\u00e3o as pr\u00f3prias senhas. Alguns pontos-chave do uso do SOPS incluem: Flux tem suporte nativo ao SOPS com descriptografia no lado do cluster. Fornece uma camada adicional de seguran\u00e7a, pois a chave privada usada para descriptografar \u00e9 protegida em um cofre de chaves externo. Para usar o CLI Helm para criptografia, \u00e9 necess\u00e1rio o plug-in ( Helm Secrets ). Necessita do plug-in ( KSOPS )([kustomize-sopssecretgenerator]( https://github.com/goabout/kustomize-sopssecretgenerator)) para funcionar com Kustomization. - N\u00e3o dimensiona bem com equipes maiores, pois cada desenvolvedor precisa criptografar as senhas. - A chave p\u00fablica \u00e9 suficiente para criar novos arquivos. A chave secreta \u00e9 necess\u00e1ria para descriptografar e editar arquivos existentes porque o SOPS calcula um c\u00f3digo de autentica\u00e7\u00e3o de mensagem (MAC) em todos os valores. Ao usar apenas a chave p\u00fablica para adicionar ou remover um campo, o arquivo inteiro deve ser exclu\u00eddo e recriado. - Suporta v\u00e1rios tipos de chaves que podem ser usadas em estados conectados e desconectados. Uma senha pode ter uma lista de chaves e tentar\u00e1 descriptografar com todas elas.","title":"Mozilla SOPS"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#referencia-a-senhas-armazenadas-em-um-cofre-de-chaves-externo-recomendado","text":"Essa abordagem depende de um sistema de gerenciamento de chaves, como o Azure Key Vault , para armazenar as senhas, e o manifesto Git nas reposit\u00f3rios faz refer\u00eancia \u00e0s senhas do cofre de chaves. Os desenvolvedores n\u00e3o realizam nenhuma opera\u00e7\u00e3o criptogr\u00e1fica com arquivos nos reposit\u00f3rios. Operadores Kubernetes em execu\u00e7\u00e3o no cluster de destino s\u00e3o respons\u00e1veis por recuperar as senhas do cofre de chaves e disponibiliz\u00e1-las como segredos Kubernetes ou volumes de segredos montados no pod. Todas as ferramentas abaixo compartilham as seguintes caracter\u00edsticas: As senhas n\u00e3o s\u00e3o armazenadas no reposit\u00f3rio. Suportam m\u00e9tricas Prometheus para observabilidade. Suportam sincroniza\u00e7\u00e3o com Segredos Kubernetes. Suportam cont\u00eaineres Linux e Windows. Fornecem gerenciamento de segredos externos de n\u00edvel empresarial. Facilmente escal\u00e1veis com m\u00faltiplos clusters e equipes maiores. Ambas as solu\u00e7\u00f5es suportam Azure Active Directory (Azure AD) principal de servi\u00e7o ou identidade gerenciada para autentica\u00e7\u00e3o com o Key Vault . Para ideias sobre rota\u00e7\u00e3o de senhas, consulte Rota\u00e7\u00e3o de Senhas em Vari\u00e1veis de Ambiente e Segredos Montados Para saber como autenticar registros de cont\u00eaineres privados com um principal de servi\u00e7o, consulte: Registro de Cont\u00eainer Privado Autenticado","title":"Refer\u00eancia a Senhas Armazenadas em um Cofre de Chaves Externo (Recomendado)"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#provedor-de-azure-key-vault-para-secrets-store-csi-driver","text":"O Provedor de Azure Key Vault (AKVP) para Driver de Armazenamento de Segredos CSI para Kubernetes permite que voc\u00ea obtenha o conte\u00fado de segredos armazenados em uma inst\u00e2ncia do Azure Key Vault e use a interface Secrets Store CSI driver para mont\u00e1-los nos pods do Kubernetes. Monta segredos/chaves/certificados no pod usando um volume Inline CSI. Guia de instala\u00e7\u00e3o do Provedor de Azure Key Vault para Secrets Store CSI Driver aqui . O driver CSI precisar\u00e1 de acesso ao Azure Key Vault, seja por meio de um principal de servi\u00e7o ou identidade gerenciada (recomendado). Para tornar esse acesso seguro, voc\u00ea pode aproveitar a Identidade de Carga de Trabalho do Azure AD (recomendado) ou Identidade de Pod do AAD . Observe que a identidade de pod do AAD em breve ser\u00e1 substitu\u00edda pela identidade de carga de trabalho. Links do Grupo de Produtos fornecidos para AKVP com SSCSID: 1. Diferen\u00e7as entre ESO / SSCSID ( GitHub Issue ) 2. Palestra sobre Gerenciamento de Segredos no K8S aqui (Segredos Nativos, Vault.io e ESO vs. SSCSID) Vantagens: Suporta a portabilidade de pods com o SecretProviderClass CRD Suporta a rota\u00e7\u00e3o autom\u00e1tica de segredos com intervalos de sincroniza\u00e7\u00e3o personaliz\u00e1veis por cluster . Parece ser a escolha da Microsoft (o driver Secrets Store CSI \u00e9 fortemente contribu\u00eddo pela MSFT e pelo Kubernetes-SIG) Desvantagens: Suporte ausente para cen\u00e1rios desconectados : Quando o n\u00f3 est\u00e1 offline, o SSCSID falha ao buscar o segredo e, portanto, a montagem do volume falha, tornando a escalabilidade e a reinicializa\u00e7\u00e3o de pods imposs\u00edveis enquanto estiver offline O AKVP s\u00f3 pode acessar o Key Vault de um ambiente n\u00e3o-Azure usando um principal de servi\u00e7o O Segredo Kubernetes contendo as credenciais do principal de servi\u00e7o precisa ser criado como um segredo no mesmo namespace do pod de aplica\u00e7\u00e3o. Se os pods em v\u00e1rios namespaces precisarem usar o mesmo SP para acessar o Key Vault, este Segredo Kubernetes precisa ser criado em cada namespace. O reposit\u00f3rio GitOps deve conter o nome do Key Vault dentro do SecretProviderClass Deve montar segredos como volumes para permitir a sincroniza\u00e7\u00e3o em Segredos Kubernetes Usa mais recursos (4 pods; driver de armazenamento CSI e provedor) e \u00e9 um daemonset - n\u00e3o testado quanto ao uso de recursos/RPS.","title":"Provedor de Azure Key Vault para Secrets Store CSI Driver"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#operador-de-segredos-externos-com-azure-key-vault","text":"O Operador de Segredos Externos (ESO) \u00e9 um operador Kubernetes de c\u00f3digo aberto que pode ler segredos de armazenamentos de segred os externos (por exemplo, Azure Key Vault) e sincroniz\u00e1-los com Segredos Kubernetes. Em contraste com o Driver CSI, o controlador ESO cria os segredos no cluster como Segredos K8s, em vez de mont\u00e1-los como volumes em pods. Documenta\u00e7\u00e3o sobre o uso do provedor Azure Key Vault do ESO aqui . O ESO precisar\u00e1 de acesso ao Azure Key Vault, seja por meio de um principal de servi\u00e7o ou identidade gerenciada (por meio da Identidade de Carga de Trabalho do Azure AD (recomendado) ou Identidade de Pod do AAD ). Vantagens: Suporta a rota\u00e7\u00e3o autom\u00e1tica de segredos com intervalos de sincroniza\u00e7\u00e3o personaliz\u00e1veis por segredo . Os componentes s\u00e3o divididos em diferentes CRDs para namespace (ExternalSecret, SecretStore) e cluster-wide (ClusterSecretStore, ClusterExternalSecret), tornando a sincroniza\u00e7\u00e3o mais gerenci\u00e1vel em rela\u00e7\u00e3o a diferentes implanta\u00e7\u00f5es/pods, etc. O segredo do principal de servi\u00e7o para os (Cluster)SecretStores pode ser colocado em um namespace que apenas o ESO pode acessar (veja Shared ClusterSecretStore ). Eficiente em recursos (um \u00fanico pod) - n\u00e3o testado quanto ao uso de recursos/RPS. C\u00f3digo aberto e alto n\u00famero de contribui\u00e7\u00f5es, ( GitHub ) A montagem de segredos como volumes \u00e9 suportada por meio das APIs do K8S (veja aqui ) Suporta cen\u00e1rios parcialmente desconectados: como o ESO usa segredos nativos do K8s, o cluster pode estar offline e isso n\u00e3o afeta a reinicializa\u00e7\u00e3o e a escalabilidade de pods enquanto estiver offline Desvantagens: O reposit\u00f3rio GitOps deve conter o nome do Key Vault dentro do SecretStore / ClusterSecretStore ou um ConfigMap que fa\u00e7a refer\u00eancia a ele. Deve criar segredos como segredos K8s.","title":"Operador de Segredos Externos com Azure Key Vault"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#links-importantes","text":"Sealed Secrets com Flux v2 Mozilla SOPS com Flux v2 Gerenciamento de Segredos com Argo CD Fluxo de Trabalho de Gerenciamento de Segredos","title":"Links Importantes"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#apendice","text":"","title":"Ap\u00eandice"},{"location":"continuous-delivery/gitops/secret-management/secret-management-gitops/#registro-de-conteiner-privado-autenticado","text":"Uma op\u00e7\u00e3o de como autenticar registros de cont\u00eainer privados (por exemplo, ACR): Use um Segredo Kubernetes dockerconfigjson no n\u00edvel do pod com ImagePullSecret (Isso tamb\u00e9m pode ser definido no n\u00edvel do namespace ) Espero que esta tradu\u00e7\u00e3o seja \u00fatil para voc\u00ea. Se tiver alguma d\u00favida adicional ou precisar de mais informa\u00e7\u00f5es, sinta-se \u00e0 vontade para perguntar.","title":"Registro de Cont\u00eainer Privado Autenticado"},{"location":"continuous-delivery/gitops/secret-management/secret-rotation-in-pods/","text":"Rota\u00e7\u00e3o de Segredos de Vari\u00e1veis de Ambiente e Segredos Montados em Pods Este documento aborda algumas maneiras de realizar a rota\u00e7\u00e3o de segredos com vari\u00e1veis de ambiente e segredos montados em pods do Kubernetes. Mapeamento de Segredos via secretKeyRef com Vari\u00e1veis de Ambiente Se mapearmos um segredo nativo do Kubernetes via secretKeyRef em uma vari\u00e1vel de ambiente e rotacionarmos as chaves, a vari\u00e1vel de ambiente n\u00e3o \u00e9 atualizada, mesmo que o segredo nativo do Kubernetes tenha sido atualizado. Precisamos reiniciar o Pod para que as altera\u00e7\u00f5es sejam populadas. O Reloader resolve esse problema com um controlador do Kubernetes. ... env : - name : EVENTHUB_CONNECTION_STRING valueFrom : secretKeyRef : name : poc-creds key : EventhubConnectionString ... Mapeamento de Segredos via volumeMounts (Abordagem do ESO) Se mapearmos um segredo nativo do Kubernetes via um volume mount e rotacionarmos as chaves, o arquivo \u00e9 atualizado. A aplica\u00e7\u00e3o precisa ser capaz de captar as altera\u00e7\u00f5es sem a necessidade de reiniciar (provavelmente exigindo l\u00f3gica personalizada na aplica\u00e7\u00e3o para oferecer suporte a isso). Nesse caso, n\u00e3o \u00e9 necess\u00e1ria a reinicializa\u00e7\u00e3o da aplica\u00e7\u00e3o. ... volumeMounts : - name : mounted-secret mountPath : /mnt/secrets-store readOnly : true volumes : - name : mounted-secret secret : secretName : poc-creds ... Mapeamento de Segredos via volumeMounts (Abordagem do AKVP SSCSID) O SSCSID concentra-se em montar segredos externos no CSI. Portanto, se rotacionarmos as chaves, o arquivo \u00e9 atualizado. A aplica\u00e7\u00e3o precisa ser capaz de captar as altera\u00e7\u00f5es sem a necessidade de reiniciar (provavelmente exigindo l\u00f3gica personalizada na aplica\u00e7\u00e3o para oferecer suporte a isso). Nesse caso, n\u00e3o \u00e9 necess\u00e1ria a reinicializa\u00e7\u00e3o da aplica\u00e7\u00e3o. ... volumeMounts : - name : app-secrets-store-inline mountPath : \"/mnt/app-secrets-store\" readOnly : true volumes : - name : app-secrets-store-inline csi : driver : secrets-store.csi.k8s.io readOnly : true volumeAttributes : secretProviderClass : akvp-app nodePublishSecretRef : name : secrets-store-sp-creds ...","title":"Rota\u00e7\u00e3o de Segredos de Vari\u00e1veis de Ambiente e Segredos Montados em Pods"},{"location":"continuous-delivery/gitops/secret-management/secret-rotation-in-pods/#rotacao-de-segredos-de-variaveis-de-ambiente-e-segredos-montados-em-pods","text":"Este documento aborda algumas maneiras de realizar a rota\u00e7\u00e3o de segredos com vari\u00e1veis de ambiente e segredos montados em pods do Kubernetes.","title":"Rota\u00e7\u00e3o de Segredos de Vari\u00e1veis de Ambiente e Segredos Montados em Pods"},{"location":"continuous-delivery/gitops/secret-management/secret-rotation-in-pods/#mapeamento-de-segredos-via-secretkeyref-com-variaveis-de-ambiente","text":"Se mapearmos um segredo nativo do Kubernetes via secretKeyRef em uma vari\u00e1vel de ambiente e rotacionarmos as chaves, a vari\u00e1vel de ambiente n\u00e3o \u00e9 atualizada, mesmo que o segredo nativo do Kubernetes tenha sido atualizado. Precisamos reiniciar o Pod para que as altera\u00e7\u00f5es sejam populadas. O Reloader resolve esse problema com um controlador do Kubernetes. ... env : - name : EVENTHUB_CONNECTION_STRING valueFrom : secretKeyRef : name : poc-creds key : EventhubConnectionString ...","title":"Mapeamento de Segredos via secretKeyRef com Vari\u00e1veis de Ambiente"},{"location":"continuous-delivery/gitops/secret-management/secret-rotation-in-pods/#mapeamento-de-segredos-via-volumemounts-abordagem-do-eso","text":"Se mapearmos um segredo nativo do Kubernetes via um volume mount e rotacionarmos as chaves, o arquivo \u00e9 atualizado. A aplica\u00e7\u00e3o precisa ser capaz de captar as altera\u00e7\u00f5es sem a necessidade de reiniciar (provavelmente exigindo l\u00f3gica personalizada na aplica\u00e7\u00e3o para oferecer suporte a isso). Nesse caso, n\u00e3o \u00e9 necess\u00e1ria a reinicializa\u00e7\u00e3o da aplica\u00e7\u00e3o. ... volumeMounts : - name : mounted-secret mountPath : /mnt/secrets-store readOnly : true volumes : - name : mounted-secret secret : secretName : poc-creds ...","title":"Mapeamento de Segredos via volumeMounts (Abordagem do ESO)"},{"location":"continuous-delivery/gitops/secret-management/secret-rotation-in-pods/#mapeamento-de-segredos-via-volumemounts-abordagem-do-akvp-sscsid","text":"O SSCSID concentra-se em montar segredos externos no CSI. Portanto, se rotacionarmos as chaves, o arquivo \u00e9 atualizado. A aplica\u00e7\u00e3o precisa ser capaz de captar as altera\u00e7\u00f5es sem a necessidade de reiniciar (provavelmente exigindo l\u00f3gica personalizada na aplica\u00e7\u00e3o para oferecer suporte a isso). Nesse caso, n\u00e3o \u00e9 necess\u00e1ria a reinicializa\u00e7\u00e3o da aplica\u00e7\u00e3o. ... volumeMounts : - name : app-secrets-store-inline mountPath : \"/mnt/app-secrets-store\" readOnly : true volumes : - name : app-secrets-store-inline csi : driver : secrets-store.csi.k8s.io readOnly : true volumeAttributes : secretProviderClass : akvp-app nodePublishSecretRef : name : secrets-store-sp-creds ...","title":"Mapeamento de Segredos via volumeMounts (Abordagem do AKVP SSCSID)"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/","text":"Entrega Cont\u00ednua em Solu\u00e7\u00f5es de Low-Code e No-Code As plataformas de low-code e no-code ocuparam um lugar em uma ampla variedade de Solu\u00e7\u00f5es de Neg\u00f3cios envolvendo automa\u00e7\u00e3o de processos, modelos de IA, Bots, Aplica\u00e7\u00f5es de Neg\u00f3cios e Intelig\u00eancia de Neg\u00f3cios. Os cen\u00e1rios habilitados por essas plataformas est\u00e3o constantemente evoluindo e abrindo espa\u00e7o para fun\u00e7\u00f5es produtivas. Este tem sido exatamente o motivo pelo qual a introdu\u00e7\u00e3o de ferramentas profissionais em seu desenvolvimento se tornou necess\u00e1ria, como entrega controlada e automatizada. No caso dos produtos da Power Platform, a ado\u00e7\u00e3o de um processo de CI/CD pode parecer aumentar a complexidade do desenvolvimento para uma solu\u00e7\u00e3o orientada a Desenvolvedores Cidad\u00e3os . No entanto, \u00e9 mais importante tornar o processo de desenvolvimento mais escal\u00e1vel e capaz de lidar com novos recursos e corre\u00e7\u00f5es de bugs de forma mais r\u00e1pida. Ambientes em Solu\u00e7\u00f5es da Power Platform Os ambientes s\u00e3o espa\u00e7os onde as Solu\u00e7\u00f5es da Power Platform existem. Eles armazenam, gerenciam e compartilham tudo relacionado \u00e0 solu\u00e7\u00e3o, como dados, aplicativos, chat bots, fluxos e modelos. Eles tamb\u00e9m funcionam como cont\u00eaineres para separar aplicativos que podem ter diferentes fun\u00e7\u00f5es, requisitos de seguran\u00e7a ou apenas p\u00fablicos-alvo diferentes. Eles podem ser usados para criar diferentes est\u00e1gios do processo de desenvolvimento da solu\u00e7\u00e3o, e o modelo esperado de trabalho com ambientes em um processo de CI/CD \u00e9 como a imagem a seguir sugere. Considera\u00e7\u00f5es sobre Ambientes Sempre que um ambiente \u00e9 criado, seus recursos s\u00f3 podem ser acessados por usu\u00e1rios dentro do mesmo locat\u00e1rio, que \u00e9 um locat\u00e1rio do Azure Active Directory, na verdade. Quando voc\u00ea cria um aplicativo em um ambiente, esse aplicativo s\u00f3 pode interagir com fontes de dados que tamb\u00e9m est\u00e3o implantadas no mesmo ambiente, o que inclui conex\u00f5es, fluxos e bancos de dados do Dataverse. Isso \u00e9 uma considera\u00e7\u00e3o importante ao lidar com um processo de Entrega Cont\u00ednua. Estrat\u00e9gia de Implanta\u00e7\u00e3o Com tr\u00eas ambientes j\u00e1 criados para representar os est\u00e1gios da implanta\u00e7\u00e3o, o objetivo agora \u00e9 automatizar a implanta\u00e7\u00e3o de um ambiente para outro. Cada ambiente exigir\u00e1 a cria\u00e7\u00e3o de sua pr\u00f3pria solu\u00e7\u00e3o: l\u00f3gica de neg\u00f3cios e dados. Etapa 1 A equipe de desenvolvimento trabalhar\u00e1 em um ambiente Dev . Esses ambientes, de acordo com a equipe, podem ser um para a equipe ou um para cada desenvolvedor. Depois que as altera\u00e7\u00f5es forem feitas, o primeiro passo ser\u00e1 empacotar a solu\u00e7\u00e3o e export\u00e1-la para o controle de origem. Etapa 2 A segunda etapa envolve a solu\u00e7\u00e3o. Voc\u00ea precisa ter uma solu\u00e7\u00e3o gerenciada para implantar em outros ambientes, como Stage ou Production , ent\u00e3o agora voc\u00ea deve usar um ambiente JIT onde importar\u00e1 sua solu\u00e7\u00e3o n\u00e3o gerenciada e a exportar\u00e1 como gerenciada. Esses arquivos de solu\u00e7\u00e3o n\u00e3o ser\u00e3o verificados no controle de origem, mas ser\u00e3o armazenados como um artefato de build no pipeline, tornando-os dispon\u00edveis para implanta\u00e7\u00e3o no pipeline de release. \u00c9 aqui que o segundo ambiente ser\u00e1 usado. Este segundo ambiente ser\u00e1 respons\u00e1vel por receber a solu\u00e7\u00e3o gerenciada de sa\u00edda vinda do artefato. Etapa 3 A terceira e \u00faltima etapa importar\u00e1 a solu\u00e7\u00e3o no ambiente de produ\u00e7\u00e3o, o que significa que esta etapa pegar\u00e1 o artefato da \u00faltima etapa e o exportar\u00e1. Ao trabalhar neste ambiente, voc\u00ea tamb\u00e9m pode versionar seu produto para fazer um rastreamento mais eficiente do produto. Ferramentas As ferramentas mais usadas para concluir esse processo s\u00e3o: Ferramentas de Compila\u00e7\u00e3o da Power Platform . Tamb\u00e9m existe uma ferramenta n\u00e3o gr\u00e1fica que pode ser usada para trabalhar com esse processo de Entrega Cont\u00ednua. A ferramenta Power CLI . Refer\u00eancias Gerenciamento de Ciclo de Vida de Aplicativos com a Microsoft Power Platform","title":"Entrega Cont\u00ednua em Solu\u00e7\u00f5es de Low-Code e No-Code"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#entrega-continua-em-solucoes-de-low-code-e-no-code","text":"As plataformas de low-code e no-code ocuparam um lugar em uma ampla variedade de Solu\u00e7\u00f5es de Neg\u00f3cios envolvendo automa\u00e7\u00e3o de processos, modelos de IA, Bots, Aplica\u00e7\u00f5es de Neg\u00f3cios e Intelig\u00eancia de Neg\u00f3cios. Os cen\u00e1rios habilitados por essas plataformas est\u00e3o constantemente evoluindo e abrindo espa\u00e7o para fun\u00e7\u00f5es produtivas. Este tem sido exatamente o motivo pelo qual a introdu\u00e7\u00e3o de ferramentas profissionais em seu desenvolvimento se tornou necess\u00e1ria, como entrega controlada e automatizada. No caso dos produtos da Power Platform, a ado\u00e7\u00e3o de um processo de CI/CD pode parecer aumentar a complexidade do desenvolvimento para uma solu\u00e7\u00e3o orientada a Desenvolvedores Cidad\u00e3os . No entanto, \u00e9 mais importante tornar o processo de desenvolvimento mais escal\u00e1vel e capaz de lidar com novos recursos e corre\u00e7\u00f5es de bugs de forma mais r\u00e1pida.","title":"Entrega Cont\u00ednua em Solu\u00e7\u00f5es de Low-Code e No-Code"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#ambientes-em-solucoes-da-power-platform","text":"Os ambientes s\u00e3o espa\u00e7os onde as Solu\u00e7\u00f5es da Power Platform existem. Eles armazenam, gerenciam e compartilham tudo relacionado \u00e0 solu\u00e7\u00e3o, como dados, aplicativos, chat bots, fluxos e modelos. Eles tamb\u00e9m funcionam como cont\u00eaineres para separar aplicativos que podem ter diferentes fun\u00e7\u00f5es, requisitos de seguran\u00e7a ou apenas p\u00fablicos-alvo diferentes. Eles podem ser usados para criar diferentes est\u00e1gios do processo de desenvolvimento da solu\u00e7\u00e3o, e o modelo esperado de trabalho com ambientes em um processo de CI/CD \u00e9 como a imagem a seguir sugere.","title":"Ambientes em Solu\u00e7\u00f5es da Power Platform"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#consideracoes-sobre-ambientes","text":"Sempre que um ambiente \u00e9 criado, seus recursos s\u00f3 podem ser acessados por usu\u00e1rios dentro do mesmo locat\u00e1rio, que \u00e9 um locat\u00e1rio do Azure Active Directory, na verdade. Quando voc\u00ea cria um aplicativo em um ambiente, esse aplicativo s\u00f3 pode interagir com fontes de dados que tamb\u00e9m est\u00e3o implantadas no mesmo ambiente, o que inclui conex\u00f5es, fluxos e bancos de dados do Dataverse. Isso \u00e9 uma considera\u00e7\u00e3o importante ao lidar com um processo de Entrega Cont\u00ednua.","title":"Considera\u00e7\u00f5es sobre Ambientes"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#estrategia-de-implantacao","text":"Com tr\u00eas ambientes j\u00e1 criados para representar os est\u00e1gios da implanta\u00e7\u00e3o, o objetivo agora \u00e9 automatizar a implanta\u00e7\u00e3o de um ambiente para outro. Cada ambiente exigir\u00e1 a cria\u00e7\u00e3o de sua pr\u00f3pria solu\u00e7\u00e3o: l\u00f3gica de neg\u00f3cios e dados.","title":"Estrat\u00e9gia de Implanta\u00e7\u00e3o"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#etapa-1","text":"A equipe de desenvolvimento trabalhar\u00e1 em um ambiente Dev . Esses ambientes, de acordo com a equipe, podem ser um para a equipe ou um para cada desenvolvedor. Depois que as altera\u00e7\u00f5es forem feitas, o primeiro passo ser\u00e1 empacotar a solu\u00e7\u00e3o e export\u00e1-la para o controle de origem.","title":"Etapa 1"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#etapa-2","text":"A segunda etapa envolve a solu\u00e7\u00e3o. Voc\u00ea precisa ter uma solu\u00e7\u00e3o gerenciada para implantar em outros ambientes, como Stage ou Production , ent\u00e3o agora voc\u00ea deve usar um ambiente JIT onde importar\u00e1 sua solu\u00e7\u00e3o n\u00e3o gerenciada e a exportar\u00e1 como gerenciada. Esses arquivos de solu\u00e7\u00e3o n\u00e3o ser\u00e3o verificados no controle de origem, mas ser\u00e3o armazenados como um artefato de build no pipeline, tornando-os dispon\u00edveis para implanta\u00e7\u00e3o no pipeline de release. \u00c9 aqui que o segundo ambiente ser\u00e1 usado. Este segundo ambiente ser\u00e1 respons\u00e1vel por receber a solu\u00e7\u00e3o gerenciada de sa\u00edda vinda do artefato.","title":"Etapa 2"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#etapa-3","text":"A terceira e \u00faltima etapa importar\u00e1 a solu\u00e7\u00e3o no ambiente de produ\u00e7\u00e3o, o que significa que esta etapa pegar\u00e1 o artefato da \u00faltima etapa e o exportar\u00e1. Ao trabalhar neste ambiente, voc\u00ea tamb\u00e9m pode versionar seu produto para fazer um rastreamento mais eficiente do produto.","title":"Etapa 3"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#ferramentas","text":"As ferramentas mais usadas para concluir esse processo s\u00e3o: Ferramentas de Compila\u00e7\u00e3o da Power Platform . Tamb\u00e9m existe uma ferramenta n\u00e3o gr\u00e1fica que pode ser usada para trabalhar com esse processo de Entrega Cont\u00ednua. A ferramenta Power CLI .","title":"Ferramentas"},{"location":"continuous-delivery/low-code-solutions/low-code-solutions/#referencias","text":"Gerenciamento de Ciclo de Vida de Aplicativos com a Microsoft Power Platform","title":"Refer\u00eancias"},{"location":"continuous-delivery/recipes/github-workflows/workflow-per-environment/","text":"Fluxos de Trabalho no GitHub Um fluxo de trabalho \u00e9 um processo automatizado configur\u00e1vel composto por um ou mais trabalhos, onde cada um desses trabalhos pode ser uma a\u00e7\u00e3o no GitHub. Atualmente, \u00e9 suportado um formato de arquivo YAML para definir um fluxo de trabalho no GitHub. Informa\u00e7\u00f5es adicionais sobre a\u00e7\u00f5es do GitHub e Fluxos de Trabalho no GitHub est\u00e3o nos links postados na se\u00e7\u00e3o de refer\u00eancias abaixo. Fluxo de Trabalho por Ambiente A abordagem geral \u00e9 ter um pipeline, onde o c\u00f3digo \u00e9 constru\u00eddo, testado e implantado, e o artefato \u00e9 ent\u00e3o promovido para o pr\u00f3ximo ambiente, eventualmente sendo implantado na produ\u00e7\u00e3o. Existem v\u00e1rias maneiras no GitHub de configurar um ambiente. Uma maneira de fazer isso \u00e9 ter um fluxo de trabalho para v\u00e1rios ambientes, mas a complexidade aumenta \u00e0 medida que processos e trabalhos adicionais s\u00e3o adicionados a um fluxo de trabalho, o que n\u00e3o significa que n\u00e3o pode ser feito para pipelines pequenos. O ponto positivo de ter um \u00fanico fluxo de trabalho \u00e9 que, quando um artefato flui de um ambiente para outro, os valores de estado e ambiente entre os ambientes de implanta\u00e7\u00e3o podem ser facilmente passados. Uma maneira de contornar a complexidade de um \u00fanico fluxo de trabalho \u00e9 ter fluxos de trabalho separados para diferentes ambientes, garantindo que apenas os artefatos criados e validados sejam promovidos de um ambiente para outro, bem como que o fluxo de trabalho seja pequeno o suficiente para depurar problemas em qualquer um dos fluxos de trabalho. Nesse caso, os valores de estado e ambiente precisam ser passados de um ambiente de implanta\u00e7\u00e3o para outro. M\u00faltiplos fluxos de trabalho tamb\u00e9m ajudam a manter as implanta\u00e7\u00f5es nos ambientes independentes, reduzindo assim o tempo para implantar e encontrar problemas mais cedo do que tarde no processo. Al\u00e9m disso, como os ambientes s\u00e3o independentes entre si, qualquer falha na implanta\u00e7\u00e3o em um ambiente n\u00e3o bloqueia as implanta\u00e7\u00f5es em outros ambientes. Um trade-off neste m\u00e9todo \u00e9 que, com diferentes fluxos de trabalho para cada ambiente, a manuten\u00e7\u00e3o aumenta \u00e0 medida que a complexidade dos fluxos de trabalho aumenta ao longo do tempo. Refer\u00eancias A\u00e7\u00f5es do GitHub Fluxos de Trabalho do GitHub","title":"Fluxos de Trabalho no GitHub"},{"location":"continuous-delivery/recipes/github-workflows/workflow-per-environment/#fluxos-de-trabalho-no-github","text":"Um fluxo de trabalho \u00e9 um processo automatizado configur\u00e1vel composto por um ou mais trabalhos, onde cada um desses trabalhos pode ser uma a\u00e7\u00e3o no GitHub. Atualmente, \u00e9 suportado um formato de arquivo YAML para definir um fluxo de trabalho no GitHub. Informa\u00e7\u00f5es adicionais sobre a\u00e7\u00f5es do GitHub e Fluxos de Trabalho no GitHub est\u00e3o nos links postados na se\u00e7\u00e3o de refer\u00eancias abaixo.","title":"Fluxos de Trabalho no GitHub"},{"location":"continuous-delivery/recipes/github-workflows/workflow-per-environment/#fluxo-de-trabalho-por-ambiente","text":"A abordagem geral \u00e9 ter um pipeline, onde o c\u00f3digo \u00e9 constru\u00eddo, testado e implantado, e o artefato \u00e9 ent\u00e3o promovido para o pr\u00f3ximo ambiente, eventualmente sendo implantado na produ\u00e7\u00e3o. Existem v\u00e1rias maneiras no GitHub de configurar um ambiente. Uma maneira de fazer isso \u00e9 ter um fluxo de trabalho para v\u00e1rios ambientes, mas a complexidade aumenta \u00e0 medida que processos e trabalhos adicionais s\u00e3o adicionados a um fluxo de trabalho, o que n\u00e3o significa que n\u00e3o pode ser feito para pipelines pequenos. O ponto positivo de ter um \u00fanico fluxo de trabalho \u00e9 que, quando um artefato flui de um ambiente para outro, os valores de estado e ambiente entre os ambientes de implanta\u00e7\u00e3o podem ser facilmente passados. Uma maneira de contornar a complexidade de um \u00fanico fluxo de trabalho \u00e9 ter fluxos de trabalho separados para diferentes ambientes, garantindo que apenas os artefatos criados e validados sejam promovidos de um ambiente para outro, bem como que o fluxo de trabalho seja pequeno o suficiente para depurar problemas em qualquer um dos fluxos de trabalho. Nesse caso, os valores de estado e ambiente precisam ser passados de um ambiente de implanta\u00e7\u00e3o para outro. M\u00faltiplos fluxos de trabalho tamb\u00e9m ajudam a manter as implanta\u00e7\u00f5es nos ambientes independentes, reduzindo assim o tempo para implantar e encontrar problemas mais cedo do que tarde no processo. Al\u00e9m disso, como os ambientes s\u00e3o independentes entre si, qualquer falha na implanta\u00e7\u00e3o em um ambiente n\u00e3o bloqueia as implanta\u00e7\u00f5es em outros ambientes. Um trade-off neste m\u00e9todo \u00e9 que, com diferentes fluxos de trabalho para cada ambiente, a manuten\u00e7\u00e3o aumenta \u00e0 medida que a complexidade dos fluxos de trabalho aumenta ao longo do tempo.","title":"Fluxo de Trabalho por Ambiente"},{"location":"continuous-delivery/recipes/github-workflows/workflow-per-environment/#referencias","text":"A\u00e7\u00f5es do GitHub Fluxos de Trabalho do GitHub","title":"Refer\u00eancias"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/","text":"Salvar sa\u00edda do Terraform em um grupo de vari\u00e1veis (Azure DevOps) Esta receita se aplica apenas ao uso do Terraform com o Azure DevOps. Ela pressup\u00f5e que voc\u00ea est\u00e1 familiarizado com os comandos do Terraform e com os pipelines do Azure. Contexto Quando o Terraform \u00e9 usado para automatizar o provisionamento da infraestrutura, geralmente \u00e9 dedicado um Pipeline do Azure para aplicar os arquivos de configura\u00e7\u00e3o do Terraform. Isso criar\u00e1, atualizar\u00e1, excluir\u00e1 recursos do Azure para provisionar as altera\u00e7\u00f5es em sua infraestrutura. Depois que os arquivos s\u00e3o aplicados, algumas Valores de Sa\u00edda (por exemplo, nome do grupo de recursos, nome do servi\u00e7o de aplicativo) podem ser referenciados e retornados pelo Terraform. Esses valores geralmente precisam ser recuperados posteriormente e usados como vari\u00e1veis de entrada para a implanta\u00e7\u00e3o de servi\u00e7os em pipelines separados. output \"core_resource_group_name\" { description = \"O nome do grupo de recursos\" value = module.core.resource_group_name } output \"core_key_vault_name\" { description = \"O nome do Key Vault.\" value = module.core.key_vault_name } output \"core_key_vault_url\" { description = \"A URL do Key Vault.\" value = module.core.key_vault_url } O objetivo desta receita \u00e9 responder \u00e0 seguinte declara\u00e7\u00e3o: Como tornar os valores de sa\u00edda do Terraform dispon\u00edveis em v\u00e1rios pipelines? Solu\u00e7\u00e3o Uma solu\u00e7\u00e3o sugerida \u00e9 armazenar os valores de sa\u00edda na Biblioteca com um Grupo de Vari\u00e1veis . Grupos de vari\u00e1veis s\u00e3o uma maneira conveniente de armazenar valores que voc\u00ea deseja passar para um pipeline YAML. Al\u00e9m disso, todos os ativos definidos na Biblioteca compartilham um modelo de seguran\u00e7a comum. Voc\u00ea pode controlar quem pode definir novos itens em uma biblioteca e quem pode usar um item existente. Para esse fim, estamos usando os seguintes comandos: terraform output para extrair o valor de uma vari\u00e1vel de sa\u00edda do arquivo de estado (fornecido pelo Terraform CLI ) az pipelines variable-group para gerenciar grupos de vari\u00e1veis (fornecido pelo Azure DevOps CLI ) Voc\u00ea pode usar o seguinte script ap\u00f3s a conclus\u00e3o do terraform apply para criar/atualizar o grupo de vari\u00e1veis. Script (update-variablegroup.sh) Par\u00e2metros Nome Descri\u00e7\u00e3o DEVOPS_ORGANIZATION A URI da organiza\u00e7\u00e3o do Azure DevOps. DEVOPS_PROJECT O nome ou ID do projeto do Azure DevOps. GROUP_NAME O nome do grupo de vari\u00e1veis alvo. Escolhas de implementa\u00e7\u00e3o: Se um grupo de vari\u00e1veis j\u00e1 existe, uma op\u00e7\u00e3o v\u00e1lida pode ser exclu\u00ed-lo e reconstruir o grupo do zero. No entanto, como a autoriza\u00e7\u00e3o pode ter sido atualizada no n\u00edvel do grupo, preferimos evitar essa op\u00e7\u00e3o. O script remove todos os valores das vari\u00e1veis no grupo alvo e os adiciona novamente com os valores mais recentes. As permiss\u00f5es n\u00e3o s\u00e3o afetadas. Um grupo de vari\u00e1veis n\u00e3o pode estar vazio. Ele deve conter pelo menos uma vari\u00e1vel. Um valor tempor\u00e1rio UUID \u00e9 criado para mitigar esse problema e \u00e9 removido assim que as vari\u00e1veis s\u00e3o atualizadas. #!/bin/bash set -e export DEVOPS_ORGANIZATION = $1 export DEVOPS_PROJECT = $2 export GROUP_NAME = $3 # Configurar o CLI do Azure DevOps az devops configure --defaults organization = ${ DEVOPS_ORGANIZATION } project = ${ DEVOPS_PROJECT } --use-git-aliases true # Obter o ID do grupo de vari\u00e1veis (se j\u00e1 existir) group_id = $( az pipelines variable-group list --group-name ${ GROUP_NAME } --query '[0].id' -o json ) if [ -z \" ${ group_id } \" ] ; then # Criar um novo grupo de vari\u00e1veis tf_output = $( terraform output -json | jq -r 'to_entries[] | \"\\(.key)=\\(.value.value)\"' ) az pipelines variable-group create --name ${ GROUP_NAME } --variables ${ tf_output } --authorize true else # Obter vari\u00e1veis existentes var_list = $( az pipelines variable-group variable list --group-id ${ group_id } ) # Adicionar vari\u00e1vel UUID tempor\u00e1ria (um grupo de vari\u00e1veis n\u00e3o pode estar vazio) uuid = $( cat /proc/sys/kernel/random/uuid ) az pipelines variable-group variable create --group-id ${ group_id } --name ${ uuid } # Excluir vari\u00e1veis existentes for row in $( echo ${ var_list } | jq -r 'to_entries[] | \"\\(.key)\"' ) ; do az pipelines variable-group variable delete --group-id ${ group_id } --name ${ row } --yes done # Criar vari\u00e1veis com os valores mais recentes (do Terraform) for row in $( terraform output -json | jq -c 'to_entries[]' ) ; do _jq () { echo ${ row } | jq -r ${ 1 } } az pipelines variable-group variable create --group-id ${ group_id } --name $( _jq '.key' ) --value $( _jq '.value.value' ) --secret $( _jq '.value.sensitive' ) done # Excluir vari\u00e1vel UUID tempor\u00e1ria az pipelines variable-group variable delete --group-id ${ group_id } --name ${ uuid } --yes fi Autentica\u00e7\u00e3o no Azure DevOps A maioria dos comandos usados no script anterior interage com o Azure DevOps e requer autentica\u00e7\u00e3o. Voc\u00ea pode autenticar usando o token de seguran\u00e7a System.AccessToken usado pelo pipeline em execu\u00e7\u00e3o, atribuindo-o a uma vari\u00e1vel de ambiente chamada AZURE_DEVOPS_EXT_PAT , como mostrado no exemplo a seguir (consulte Azure DevOps CLI in Azure Pipeline YAML para obter informa\u00e7\u00f5es adicionais). Al\u00e9m disso, voc\u00ea pode notar que tamb\u00e9m estamos usando vari\u00e1veis predefinidas para direcionar a organiza\u00e7\u00e3o e o projeto do Azure DevOps (respectivamente System.TeamFoundationCollectionUri e System.TeamProjectId ). - task : Bash@3 displayName : 'Atualizar grupo de vari\u00e1veis usando sa\u00eddas do Terraform' inputs : targetType : filePath arguments : $(System.TeamFoundationCollectionUri) $(System.TeamProjectId) \"Platform-VG\" workingDirectory : $(terraformDirectory) filePath : $(scriptsDirectory)/update-variablegroup.sh env : AZURE_DEVOPS_EXT_PAT : $(System.AccessToken) Vari\u00e1veis do sistema Descri\u00e7\u00e3o System.AccessToken Vari\u00e1vel especial que carrega o token de seguran\u00e7a usado pela compila\u00e7\u00e3o em execu\u00e7\u00e3o. System.TeamFoundationCollectionUri A URI da organiza\u00e7\u00e3o do Azure DevOps. System.TeamProjectId O ID do projeto ao qual esta compila\u00e7\u00e3o pertence. Seguran\u00e7a da Biblioteca Fun\u00e7\u00f5es s\u00e3o definidas para os itens da Biblioteca, e a associa\u00e7\u00e3o a essas fun\u00e7\u00f5es governa as opera\u00e7\u00f5es que voc\u00ea pode executar nesses itens. Fun\u00e7\u00e3o para item da biblioteca Descri\u00e7\u00e3o Leitor Pode visualizar o item. Usu\u00e1rio Pode usar o item ao criar pipelines de compila\u00e7\u00e3o ou libera\u00e7\u00e3o. Por exemplo, voc\u00ea deve ser um 'Usu\u00e1rio' de um grupo de vari\u00e1veis para us\u00e1-lo em um pipeline de libera\u00e7\u00e3o. Administrador Tamb\u00e9m pode gerenciar a associa\u00e7\u00e3o de todas as outras fun\u00e7\u00f5es para o item. O usu\u00e1rio que criou um item \u00e9 automaticamente adicionado \u00e0 fun\u00e7\u00e3o de Administrador desse item. Por padr\u00e3o, os seguintes grupos s\u00e3o adicionados \u00e0 fun\u00e7\u00e3o de Administrador da biblioteca: Administradores de Compila\u00e7\u00e3o, Administradores de Libera\u00e7\u00e3o e Administradores de Projeto. Criador Pode criar novos itens na biblioteca, mas essa fun\u00e7\u00e3o n\u00e3o inclui permiss\u00f5es de Leitura ou Usu\u00e1rio. A fun\u00e7\u00e3o de Criador n\u00e3o pode gerenciar permiss\u00f5es para outros usu\u00e1rios. Ao usar System.AccessToken , a identidade da conta de servi\u00e7o <NomeDoProjeto> Build Service ser\u00e1 usada para acessar a Biblioteca. Certifique-se de que, na se\u00e7\u00e3o Pipelines > Biblioteca > Seguran\u00e7a , esta conta de servi\u00e7o tenha a fun\u00e7\u00e3o de Administrador no n\u00edvel da Biblioteca ou do Grupo de Vari\u00e1veis para criar/atualizar/excluir vari\u00e1veis (consulte Biblioteca de ativos para informa\u00e7\u00f5es adicionais).","title":"Salvar sa\u00edda do Terraform em um grupo de vari\u00e1veis (Azure DevOps)"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#salvar-saida-do-terraform-em-um-grupo-de-variaveis-azure-devops","text":"Esta receita se aplica apenas ao uso do Terraform com o Azure DevOps. Ela pressup\u00f5e que voc\u00ea est\u00e1 familiarizado com os comandos do Terraform e com os pipelines do Azure.","title":"Salvar sa\u00edda do Terraform em um grupo de vari\u00e1veis (Azure DevOps)"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#contexto","text":"Quando o Terraform \u00e9 usado para automatizar o provisionamento da infraestrutura, geralmente \u00e9 dedicado um Pipeline do Azure para aplicar os arquivos de configura\u00e7\u00e3o do Terraform. Isso criar\u00e1, atualizar\u00e1, excluir\u00e1 recursos do Azure para provisionar as altera\u00e7\u00f5es em sua infraestrutura. Depois que os arquivos s\u00e3o aplicados, algumas Valores de Sa\u00edda (por exemplo, nome do grupo de recursos, nome do servi\u00e7o de aplicativo) podem ser referenciados e retornados pelo Terraform. Esses valores geralmente precisam ser recuperados posteriormente e usados como vari\u00e1veis de entrada para a implanta\u00e7\u00e3o de servi\u00e7os em pipelines separados. output \"core_resource_group_name\" { description = \"O nome do grupo de recursos\" value = module.core.resource_group_name } output \"core_key_vault_name\" { description = \"O nome do Key Vault.\" value = module.core.key_vault_name } output \"core_key_vault_url\" { description = \"A URL do Key Vault.\" value = module.core.key_vault_url } O objetivo desta receita \u00e9 responder \u00e0 seguinte declara\u00e7\u00e3o: Como tornar os valores de sa\u00edda do Terraform dispon\u00edveis em v\u00e1rios pipelines?","title":"Contexto"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#solucao","text":"Uma solu\u00e7\u00e3o sugerida \u00e9 armazenar os valores de sa\u00edda na Biblioteca com um Grupo de Vari\u00e1veis . Grupos de vari\u00e1veis s\u00e3o uma maneira conveniente de armazenar valores que voc\u00ea deseja passar para um pipeline YAML. Al\u00e9m disso, todos os ativos definidos na Biblioteca compartilham um modelo de seguran\u00e7a comum. Voc\u00ea pode controlar quem pode definir novos itens em uma biblioteca e quem pode usar um item existente. Para esse fim, estamos usando os seguintes comandos: terraform output para extrair o valor de uma vari\u00e1vel de sa\u00edda do arquivo de estado (fornecido pelo Terraform CLI ) az pipelines variable-group para gerenciar grupos de vari\u00e1veis (fornecido pelo Azure DevOps CLI ) Voc\u00ea pode usar o seguinte script ap\u00f3s a conclus\u00e3o do terraform apply para criar/atualizar o grupo de vari\u00e1veis.","title":"Solu\u00e7\u00e3o"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#script-update-variablegroupsh","text":"","title":"Script (update-variablegroup.sh)"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#parametros","text":"Nome Descri\u00e7\u00e3o DEVOPS_ORGANIZATION A URI da organiza\u00e7\u00e3o do Azure DevOps. DEVOPS_PROJECT O nome ou ID do projeto do Azure DevOps. GROUP_NAME O nome do grupo de vari\u00e1veis alvo. Escolhas de implementa\u00e7\u00e3o: Se um grupo de vari\u00e1veis j\u00e1 existe, uma op\u00e7\u00e3o v\u00e1lida pode ser exclu\u00ed-lo e reconstruir o grupo do zero. No entanto, como a autoriza\u00e7\u00e3o pode ter sido atualizada no n\u00edvel do grupo, preferimos evitar essa op\u00e7\u00e3o. O script remove todos os valores das vari\u00e1veis no grupo alvo e os adiciona novamente com os valores mais recentes. As permiss\u00f5es n\u00e3o s\u00e3o afetadas. Um grupo de vari\u00e1veis n\u00e3o pode estar vazio. Ele deve conter pelo menos uma vari\u00e1vel. Um valor tempor\u00e1rio UUID \u00e9 criado para mitigar esse problema e \u00e9 removido assim que as vari\u00e1veis s\u00e3o atualizadas. #!/bin/bash set -e export DEVOPS_ORGANIZATION = $1 export DEVOPS_PROJECT = $2 export GROUP_NAME = $3 # Configurar o CLI do Azure DevOps az devops configure --defaults organization = ${ DEVOPS_ORGANIZATION } project = ${ DEVOPS_PROJECT } --use-git-aliases true # Obter o ID do grupo de vari\u00e1veis (se j\u00e1 existir) group_id = $( az pipelines variable-group list --group-name ${ GROUP_NAME } --query '[0].id' -o json ) if [ -z \" ${ group_id } \" ] ; then # Criar um novo grupo de vari\u00e1veis tf_output = $( terraform output -json | jq -r 'to_entries[] | \"\\(.key)=\\(.value.value)\"' ) az pipelines variable-group create --name ${ GROUP_NAME } --variables ${ tf_output } --authorize true else # Obter vari\u00e1veis existentes var_list = $( az pipelines variable-group variable list --group-id ${ group_id } ) # Adicionar vari\u00e1vel UUID tempor\u00e1ria (um grupo de vari\u00e1veis n\u00e3o pode estar vazio) uuid = $( cat /proc/sys/kernel/random/uuid ) az pipelines variable-group variable create --group-id ${ group_id } --name ${ uuid } # Excluir vari\u00e1veis existentes for row in $( echo ${ var_list } | jq -r 'to_entries[] | \"\\(.key)\"' ) ; do az pipelines variable-group variable delete --group-id ${ group_id } --name ${ row } --yes done # Criar vari\u00e1veis com os valores mais recentes (do Terraform) for row in $( terraform output -json | jq -c 'to_entries[]' ) ; do _jq () { echo ${ row } | jq -r ${ 1 } } az pipelines variable-group variable create --group-id ${ group_id } --name $( _jq '.key' ) --value $( _jq '.value.value' ) --secret $( _jq '.value.sensitive' ) done # Excluir vari\u00e1vel UUID tempor\u00e1ria az pipelines variable-group variable delete --group-id ${ group_id } --name ${ uuid } --yes fi","title":"Par\u00e2metros"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#autenticacao-no-azure-devops","text":"A maioria dos comandos usados no script anterior interage com o Azure DevOps e requer autentica\u00e7\u00e3o. Voc\u00ea pode autenticar usando o token de seguran\u00e7a System.AccessToken usado pelo pipeline em execu\u00e7\u00e3o, atribuindo-o a uma vari\u00e1vel de ambiente chamada AZURE_DEVOPS_EXT_PAT , como mostrado no exemplo a seguir (consulte Azure DevOps CLI in Azure Pipeline YAML para obter informa\u00e7\u00f5es adicionais). Al\u00e9m disso, voc\u00ea pode notar que tamb\u00e9m estamos usando vari\u00e1veis predefinidas para direcionar a organiza\u00e7\u00e3o e o projeto do Azure DevOps (respectivamente System.TeamFoundationCollectionUri e System.TeamProjectId ). - task : Bash@3 displayName : 'Atualizar grupo de vari\u00e1veis usando sa\u00eddas do Terraform' inputs : targetType : filePath arguments : $(System.TeamFoundationCollectionUri) $(System.TeamProjectId) \"Platform-VG\" workingDirectory : $(terraformDirectory) filePath : $(scriptsDirectory)/update-variablegroup.sh env : AZURE_DEVOPS_EXT_PAT : $(System.AccessToken) Vari\u00e1veis do sistema Descri\u00e7\u00e3o System.AccessToken Vari\u00e1vel especial que carrega o token de seguran\u00e7a usado pela compila\u00e7\u00e3o em execu\u00e7\u00e3o. System.TeamFoundationCollectionUri A URI da organiza\u00e7\u00e3o do Azure DevOps. System.TeamProjectId O ID do projeto ao qual esta compila\u00e7\u00e3o pertence.","title":"Autentica\u00e7\u00e3o no Azure DevOps"},{"location":"continuous-delivery/recipes/terraform/save-output-to-variable-group/#seguranca-da-biblioteca","text":"Fun\u00e7\u00f5es s\u00e3o definidas para os itens da Biblioteca, e a associa\u00e7\u00e3o a essas fun\u00e7\u00f5es governa as opera\u00e7\u00f5es que voc\u00ea pode executar nesses itens. Fun\u00e7\u00e3o para item da biblioteca Descri\u00e7\u00e3o Leitor Pode visualizar o item. Usu\u00e1rio Pode usar o item ao criar pipelines de compila\u00e7\u00e3o ou libera\u00e7\u00e3o. Por exemplo, voc\u00ea deve ser um 'Usu\u00e1rio' de um grupo de vari\u00e1veis para us\u00e1-lo em um pipeline de libera\u00e7\u00e3o. Administrador Tamb\u00e9m pode gerenciar a associa\u00e7\u00e3o de todas as outras fun\u00e7\u00f5es para o item. O usu\u00e1rio que criou um item \u00e9 automaticamente adicionado \u00e0 fun\u00e7\u00e3o de Administrador desse item. Por padr\u00e3o, os seguintes grupos s\u00e3o adicionados \u00e0 fun\u00e7\u00e3o de Administrador da biblioteca: Administradores de Compila\u00e7\u00e3o, Administradores de Libera\u00e7\u00e3o e Administradores de Projeto. Criador Pode criar novos itens na biblioteca, mas essa fun\u00e7\u00e3o n\u00e3o inclui permiss\u00f5es de Leitura ou Usu\u00e1rio. A fun\u00e7\u00e3o de Criador n\u00e3o pode gerenciar permiss\u00f5es para outros usu\u00e1rios. Ao usar System.AccessToken , a identidade da conta de servi\u00e7o <NomeDoProjeto> Build Service ser\u00e1 usada para acessar a Biblioteca. Certifique-se de que, na se\u00e7\u00e3o Pipelines > Biblioteca > Seguran\u00e7a , esta conta de servi\u00e7o tenha a fun\u00e7\u00e3o de Administrador no n\u00edvel da Biblioteca ou do Grupo de Vari\u00e1veis para criar/atualizar/excluir vari\u00e1veis (consulte Biblioteca de ativos para informa\u00e7\u00f5es adicionais).","title":"Seguran\u00e7a da Biblioteca"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/","text":"Compartilhando Vari\u00e1veis Comuns / Conven\u00e7\u00f5es de Nomenclatura Entre M\u00f3dulos do Terraform O que estamos tentando resolver? Ao implantar infraestrutura por meio de c\u00f3digo, \u00e9 pr\u00e1tica comum dividir o c\u00f3digo em diferentes m\u00f3dulos respons\u00e1veis pela implanta\u00e7\u00e3o de uma parte ou componente da infraestrutura. No Terraform, isso pode ser feito usando m\u00f3dulos . Neste caso, \u00e9 \u00fatil ser capaz de compartilhar algumas vari\u00e1veis comuns, bem como centralizar as conven\u00e7\u00f5es de nomenclatura dos diferentes recursos, para garantir que seja f\u00e1cil refatorar quando necess\u00e1rio, apesar das depend\u00eancias entre m\u00f3dulos. Por exemplo, considere 2 m\u00f3dulos: M\u00f3dulo de rede, respons\u00e1vel pela implanta\u00e7\u00e3o de Rede Virtual, Sub-redes, Grupos de Seguran\u00e7a de Rede (NSGs) e Zonas DNS Privadas M\u00f3dulo Azure Kubernetes Service respons\u00e1vel pela implanta\u00e7\u00e3o do cluster AKS Existem depend\u00eancias entre esses m\u00f3dulos, como o cluster Kubernetes que ser\u00e1 implantado na rede virtual do M\u00f3dulo de Rede. Para fazer isso, ele deve fazer refer\u00eancia ao nome da rede virtual, bem como ao grupo de recursos no qual est\u00e1 implantado. E idealmente, gostar\u00edamos que essas depend\u00eancias fossem fracamente acopladas, o m\u00e1ximo poss\u00edvel, para manter a agilidade na forma como os m\u00f3dulos s\u00e3o implantados e manter o ciclo de vida independente. Esta p\u00e1gina explica uma maneira de resolver isso com o Terraform. Como fazer isso? Contexto Vamos considerar a seguinte estrutura para nossos m\u00f3dulos: modules \u251c\u2500\u2500 kubernetes \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 network \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf Agora, suponha que voc\u00ea implanta uma rede virtual para o ambiente de desenvolvimento, com as seguintes propriedades: Nome: vnet-dev Grupo de recursos: rg-dev-network Em algum momento, voc\u00ea precisa injetar esses valores no m\u00f3dulo Kubernetes, para obter uma refer\u00eancia a ele por meio de uma fonte de dados, por exemplo: data \"azurem_virtual_network\" \"vnet\" { name = var.vnet_name resource_group_name = var.vnet_rg_name } No trecho acima, o nome da rede virtual e o grupo de recursos s\u00e3o definidos por meio de vari\u00e1veis. Isso \u00e9 \u00f3timo, mas se isso mudar no futuro, os valores dessas vari\u00e1veis tamb\u00e9m devem ser alterados. Em todos os m\u00f3dulos em que s\u00e3o usados. Ser capaz de gerenciar a nomenclatura em um local central garantir\u00e1 que o c\u00f3digo possa ser facilmente refatorado no futuro, sem atualizar todos os m\u00f3dulos. Sobre Vari\u00e1veis do Terraform No Terraform, cada vari\u00e1vel de entrada deve ser definida no n\u00edvel de configura\u00e7\u00e3o (ou m\u00f3dulo), usando o bloco variable . Por conven\u00e7\u00e3o, isso \u00e9 frequentemente feito em um arquivo variables.tf , no m\u00f3dulo. Este arquivo cont\u00e9m a declara\u00e7\u00e3o de vari\u00e1veis e seus valores padr\u00e3o. Valores podem ser definidos usando arquivos de configura\u00e7\u00e3o de vari\u00e1veis (.tfvars), vari\u00e1veis de ambiente ou argumentos CLI ao usar os comandos terraform plan ou terraform apply . Uma das limita\u00e7\u00f5es da declara\u00e7\u00e3o de vari\u00e1veis \u00e9 que n\u00e3o \u00e9 poss\u00edvel compor vari\u00e1veis, locals ou fun\u00e7\u00f5es incorporadas do Terraform s\u00e3o usadas para isso. M\u00f3dulo Comum do Terraform Uma maneira de contornar essas limita\u00e7\u00f5es \u00e9 introduzir um m\u00f3dulo \"comum\" que n\u00e3o implantar\u00e1 recursos, mas apenas calcular\u00e1/solucionar\u00e1 e produzir\u00e1 os nomes de recursos e vari\u00e1veis compartilhadas e ser\u00e1 usado por todos os outros m\u00f3dulos, como uma depend\u00eancia. modules \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 output.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 kubernetes \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 network \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf variables.tf: variable \"environment_name\" { type = string description = \"O nome do ambiente.\" } variable \"location\" { type = string description = \"A regi\u00e3o do Azure onde os recursos ser\u00e3o criados. O padr\u00e3o \u00e9 oeste da Europa.\" default = \"westeurope\" } output.tf: # Vari\u00e1veis compartilhadas output \"location\" { value = var.location } output \"subscription\" { value = var.subscription } # Nomenclatura de Rede Virtual output \"vnet_rg_name\" { value = \"rg-network-${var.environment_name}\" } output \"vnet_name\" { value = \"vnet-${var.environment_name}\" } # Nomenclatura do AKS output \"aks_rg_name\" { value = \"rg-aks-${var.environment_name}\" } output \"aks_name\" { value = \"aks-${var.environment_name}\" } Agora, se voc\u00ea executar o terraform apply para o m\u00f3dulo comum, voc\u00ea obter\u00e1 todas as vari\u00e1veis comuns compartilhadas nas sa\u00eddas: $ terraform plan -var environment_name = \"dev\" -var subscription = \" $( az account show --query id -o tsv ) \" Mudan\u00e7as nas Sa\u00eddas: + aks_name = \"aks-dev\" + aks_rg_name = \"rg-aks-dev\" + location = \"westeurope\" + subscription = \"01010101-1010-0101-1010-010101010101\" + vnet_name = \"vnet-dev\" + vnet_rg_name = \"rg-network-dev\" Voc\u00ea pode aplicar este plano para salvar esses novos valores de sa\u00edda no estado do Terraform, sem alterar nenhuma infraestrutura real. Usando o M\u00f3dulo Comum do Terraform Usar o m\u00f3dulo comum do Terraform em qualquer outro m\u00f3dulo \u00e9 muito f\u00e1cil. Por exemplo, isso \u00e9 o que voc\u00ea pode fazer no arquivo main.tf do m\u00f3dulo Azure Kubernetes: module \"common\" { source = \"../common\" environment_name = var.environment_name subscription = var.subscription } data \"azurerm_subnet\" \"aks_subnet\" { name = \"AksSubnet\" virtual_network _name = module.common.vnet_name resource_group_name = module.common.vnet_rg_name } resource \"azurerm_kubernetes_cluster\" \"aks\" { name = module.common.aks_name resource_group_name = module.common.aks_rg_name location = module.common.location dns_prefix = module.common.aks_name identity { type = \"SystemAssigned\" } default_node_pool { name = \"default\" vm_size = \"Standard_DS2_v2\" vnet_subnet_id = data.azurerm_subnet.aks_subnet.id } } Em seguida, voc\u00ea pode executar os comandos terraform plan e terraform apply para implantar! terraform plan -var environment_name=\"dev\" -var subscription=\"$(az account show --query id -o tsv)\" data.azurerm_subnet.aks_subnet: Reading... data.azurerm_subnet.aks_subnet: Read complete after 1s [id=/subscriptions/01010101-1010-0101-1010-010101010101/resourceGroups/rg-network-dev/providers/Microsoft.Network/virtualNetworks/vnet-dev/subnets/AksSubnet] O Terraform usou os provedores selecionados para gerar o seguinte plano de execu\u00e7\u00e3o. As a\u00e7\u00f5es de recursos s\u00e3o indicadas pelos seguintes s\u00edmbolos: + criar O Terraform executar\u00e1 as seguintes a\u00e7\u00f5es: # azurerm_kubernetes_cluster.aks ser\u00e1 criado + resource \"azurerm_kubernetes_cluster\" \"aks\" { + dns_prefix = \"aks-dev\" + fqdn = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + kube_admin_config = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + kube_admin_config_raw = (valor sens\u00edvel) + kube_config = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + kube_config_raw = (valor sens\u00edvel) + kubernetes_version = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + location = \"westeurope\" + name = \"aks-dev\" + node_resource_group = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + portal_fqdn = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_cluster_enabled = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_cluster_public_fqdn_enabled = false + private_dns_zone_id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_fqdn = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_link_enabled = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + public_network_access_enabled = true + resource_group_name = \"rg-aks-dev\" + sku_tier = \"Free\" [...] truncado + default_node_pool { + kubelet_disk_type = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + max_pods = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + name = \"default\" + node_count = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + node_labels = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + orchestrator_version = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + os_disk_size_gb = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + os_disk_type = \"Managed\" + os_sku = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + type = \"VirtualMachineScaleSets\" + ultra_ssd_enabled = false + vm_size = \"Standard_DS2_v2\" + vnet_subnet_id = \"/subscriptions/01010101-1010-0101-1010-010101010101/resourceGroups/rg-network-dev/providers/Microsoft.Network/virtualNetworks/vnet-dev/subnets/AksSubnet\" } + identity { + principal_id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + tenant_id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + type = \"SystemAssigned\" } [...] truncado } Plano: 1 para adicionar, 0 para alterar, 0 para destruir. Observa\u00e7\u00e3o: o uso de um m\u00f3dulo comum tamb\u00e9m \u00e9 v\u00e1lido se voc\u00ea decidir implantar todos os seus m\u00f3dulos na mesma opera\u00e7\u00e3o a partir de um arquivo de configura\u00e7\u00e3o principal do Terraform, como: module \"common\" { source = \"./common\" environment_name = var.environment_name subscription = var.subscription } module \"network\" { source = \"./network\" vnet_name = module.common.vnet_name vnet_rg_name = module.common.vnet_rg_name } module \"kubernetes\" { source = \"./kubernetes\" aks_name = module.common.aks_name aks_rg = module.common.aks_rg_name } Centralizando as Defini\u00e7\u00f5es de Vari\u00e1veis de Entrada No caso de voc\u00ea optar por definir os valores das vari\u00e1veis diretamente no controle de origem (por exemplo, cen\u00e1rio gitops) usando arquivos de defini\u00e7\u00e3o de vari\u00e1veis ( .tfvars ), ter um m\u00f3dulo comum tamb\u00e9m ajudar\u00e1 a n\u00e3o duplicar as defini\u00e7\u00f5es de vari\u00e1veis comuns em todos os m\u00f3dulos. Na verdade, \u00e9 poss\u00edvel ter um arquivo global que seja definido uma vez, no n\u00edvel do m\u00f3dulo comum, e mescl\u00e1-lo com arquivos de defini\u00e7\u00f5es de vari\u00e1veis espec\u00edficas do m\u00f3dulo no momento do plan ou apply do Terraform. Considere a seguinte estrutura: modules \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 dev.tfvars \u2502 \u251c\u2500\u2500 prod.tfvars \u2502 \u251c\u2500\u2500 output.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 kubernetes \u2502 \u251c\u2500\u2500 dev.tfvars \u2502 \u251c\u2500\u2500 prod.tfvars \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 network \u2502 \u251c\u2500\u2500 dev.tfvars \u2502 \u251c\u2500\u2500 prod.tfvars \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf O m\u00f3dulo comum, assim como todos os outros m\u00f3dulos, cont\u00e9m arquivos de vari\u00e1veis para os ambientes dev e prod . Os arquivos tfvars do m\u00f3dulo comum definir\u00e3o todas as vari\u00e1veis globais que ser\u00e3o compartilhadas com outros m\u00f3dulos (como assinatura, nome do ambiente, etc.), e os arquivos .tfvars de cada m\u00f3dulo definir\u00e3o apenas os valores espec\u00edficos do m\u00f3dulo. Em seguida, \u00e9 poss\u00edvel mesclar esses arquivos ao executar os comandos terraform apply ou terraform plan , usando a seguinte sintaxe: terraform plan -var-file = < ( cat ../common/dev.tfvars ./dev.tf vars ) Observa\u00e7\u00e3o: ao usar isso, \u00e9 realmente importante garantir que voc\u00ea n\u00e3o tenha os mesmos nomes de vari\u00e1veis em ambos os arquivos, caso contr\u00e1rio, isso gerar\u00e1 um erro. Conclus\u00e3o Ao ter um m\u00f3dulo comum que possua vari\u00e1veis compartilhadas, bem como conven\u00e7\u00f5es de nomenclatura, agora \u00e9 mais f\u00e1cil refatorar o c\u00f3digo de configura\u00e7\u00e3o do Terraform. Imagine que, por algum motivo, voc\u00ea precisa alterar o padr\u00e3o usado para o nome da rede virtual: voc\u00ea o altera nos arquivos de sa\u00edda do m\u00f3dulo comum e s\u00f3 precisa reaplicar todos os m\u00f3dulos!","title":"Compartilhando Vari\u00e1veis Comuns / Conven\u00e7\u00f5es de Nomenclatura Entre M\u00f3dulos do Terraform"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#compartilhando-variaveis-comuns-convencoes-de-nomenclatura-entre-modulos-do-terraform","text":"","title":"Compartilhando Vari\u00e1veis Comuns / Conven\u00e7\u00f5es de Nomenclatura Entre M\u00f3dulos do Terraform"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#o-que-estamos-tentando-resolver","text":"Ao implantar infraestrutura por meio de c\u00f3digo, \u00e9 pr\u00e1tica comum dividir o c\u00f3digo em diferentes m\u00f3dulos respons\u00e1veis pela implanta\u00e7\u00e3o de uma parte ou componente da infraestrutura. No Terraform, isso pode ser feito usando m\u00f3dulos . Neste caso, \u00e9 \u00fatil ser capaz de compartilhar algumas vari\u00e1veis comuns, bem como centralizar as conven\u00e7\u00f5es de nomenclatura dos diferentes recursos, para garantir que seja f\u00e1cil refatorar quando necess\u00e1rio, apesar das depend\u00eancias entre m\u00f3dulos. Por exemplo, considere 2 m\u00f3dulos: M\u00f3dulo de rede, respons\u00e1vel pela implanta\u00e7\u00e3o de Rede Virtual, Sub-redes, Grupos de Seguran\u00e7a de Rede (NSGs) e Zonas DNS Privadas M\u00f3dulo Azure Kubernetes Service respons\u00e1vel pela implanta\u00e7\u00e3o do cluster AKS Existem depend\u00eancias entre esses m\u00f3dulos, como o cluster Kubernetes que ser\u00e1 implantado na rede virtual do M\u00f3dulo de Rede. Para fazer isso, ele deve fazer refer\u00eancia ao nome da rede virtual, bem como ao grupo de recursos no qual est\u00e1 implantado. E idealmente, gostar\u00edamos que essas depend\u00eancias fossem fracamente acopladas, o m\u00e1ximo poss\u00edvel, para manter a agilidade na forma como os m\u00f3dulos s\u00e3o implantados e manter o ciclo de vida independente. Esta p\u00e1gina explica uma maneira de resolver isso com o Terraform.","title":"O que estamos tentando resolver?"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#como-fazer-isso","text":"","title":"Como fazer isso?"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#contexto","text":"Vamos considerar a seguinte estrutura para nossos m\u00f3dulos: modules \u251c\u2500\u2500 kubernetes \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 network \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf Agora, suponha que voc\u00ea implanta uma rede virtual para o ambiente de desenvolvimento, com as seguintes propriedades: Nome: vnet-dev Grupo de recursos: rg-dev-network Em algum momento, voc\u00ea precisa injetar esses valores no m\u00f3dulo Kubernetes, para obter uma refer\u00eancia a ele por meio de uma fonte de dados, por exemplo: data \"azurem_virtual_network\" \"vnet\" { name = var.vnet_name resource_group_name = var.vnet_rg_name } No trecho acima, o nome da rede virtual e o grupo de recursos s\u00e3o definidos por meio de vari\u00e1veis. Isso \u00e9 \u00f3timo, mas se isso mudar no futuro, os valores dessas vari\u00e1veis tamb\u00e9m devem ser alterados. Em todos os m\u00f3dulos em que s\u00e3o usados. Ser capaz de gerenciar a nomenclatura em um local central garantir\u00e1 que o c\u00f3digo possa ser facilmente refatorado no futuro, sem atualizar todos os m\u00f3dulos.","title":"Contexto"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#sobre-variaveis-do-terraform","text":"No Terraform, cada vari\u00e1vel de entrada deve ser definida no n\u00edvel de configura\u00e7\u00e3o (ou m\u00f3dulo), usando o bloco variable . Por conven\u00e7\u00e3o, isso \u00e9 frequentemente feito em um arquivo variables.tf , no m\u00f3dulo. Este arquivo cont\u00e9m a declara\u00e7\u00e3o de vari\u00e1veis e seus valores padr\u00e3o. Valores podem ser definidos usando arquivos de configura\u00e7\u00e3o de vari\u00e1veis (.tfvars), vari\u00e1veis de ambiente ou argumentos CLI ao usar os comandos terraform plan ou terraform apply . Uma das limita\u00e7\u00f5es da declara\u00e7\u00e3o de vari\u00e1veis \u00e9 que n\u00e3o \u00e9 poss\u00edvel compor vari\u00e1veis, locals ou fun\u00e7\u00f5es incorporadas do Terraform s\u00e3o usadas para isso.","title":"Sobre Vari\u00e1veis do Terraform"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#modulo-comum-do-terraform","text":"Uma maneira de contornar essas limita\u00e7\u00f5es \u00e9 introduzir um m\u00f3dulo \"comum\" que n\u00e3o implantar\u00e1 recursos, mas apenas calcular\u00e1/solucionar\u00e1 e produzir\u00e1 os nomes de recursos e vari\u00e1veis compartilhadas e ser\u00e1 usado por todos os outros m\u00f3dulos, como uma depend\u00eancia. modules \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 output.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 kubernetes \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 network \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf variables.tf: variable \"environment_name\" { type = string description = \"O nome do ambiente.\" } variable \"location\" { type = string description = \"A regi\u00e3o do Azure onde os recursos ser\u00e3o criados. O padr\u00e3o \u00e9 oeste da Europa.\" default = \"westeurope\" } output.tf: # Vari\u00e1veis compartilhadas output \"location\" { value = var.location } output \"subscription\" { value = var.subscription } # Nomenclatura de Rede Virtual output \"vnet_rg_name\" { value = \"rg-network-${var.environment_name}\" } output \"vnet_name\" { value = \"vnet-${var.environment_name}\" } # Nomenclatura do AKS output \"aks_rg_name\" { value = \"rg-aks-${var.environment_name}\" } output \"aks_name\" { value = \"aks-${var.environment_name}\" } Agora, se voc\u00ea executar o terraform apply para o m\u00f3dulo comum, voc\u00ea obter\u00e1 todas as vari\u00e1veis comuns compartilhadas nas sa\u00eddas: $ terraform plan -var environment_name = \"dev\" -var subscription = \" $( az account show --query id -o tsv ) \" Mudan\u00e7as nas Sa\u00eddas: + aks_name = \"aks-dev\" + aks_rg_name = \"rg-aks-dev\" + location = \"westeurope\" + subscription = \"01010101-1010-0101-1010-010101010101\" + vnet_name = \"vnet-dev\" + vnet_rg_name = \"rg-network-dev\" Voc\u00ea pode aplicar este plano para salvar esses novos valores de sa\u00edda no estado do Terraform, sem alterar nenhuma infraestrutura real.","title":"M\u00f3dulo Comum do Terraform"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#usando-o-modulo-comum-do-terraform","text":"Usar o m\u00f3dulo comum do Terraform em qualquer outro m\u00f3dulo \u00e9 muito f\u00e1cil. Por exemplo, isso \u00e9 o que voc\u00ea pode fazer no arquivo main.tf do m\u00f3dulo Azure Kubernetes: module \"common\" { source = \"../common\" environment_name = var.environment_name subscription = var.subscription } data \"azurerm_subnet\" \"aks_subnet\" { name = \"AksSubnet\" virtual_network _name = module.common.vnet_name resource_group_name = module.common.vnet_rg_name } resource \"azurerm_kubernetes_cluster\" \"aks\" { name = module.common.aks_name resource_group_name = module.common.aks_rg_name location = module.common.location dns_prefix = module.common.aks_name identity { type = \"SystemAssigned\" } default_node_pool { name = \"default\" vm_size = \"Standard_DS2_v2\" vnet_subnet_id = data.azurerm_subnet.aks_subnet.id } } Em seguida, voc\u00ea pode executar os comandos terraform plan e terraform apply para implantar! terraform plan -var environment_name=\"dev\" -var subscription=\"$(az account show --query id -o tsv)\" data.azurerm_subnet.aks_subnet: Reading... data.azurerm_subnet.aks_subnet: Read complete after 1s [id=/subscriptions/01010101-1010-0101-1010-010101010101/resourceGroups/rg-network-dev/providers/Microsoft.Network/virtualNetworks/vnet-dev/subnets/AksSubnet] O Terraform usou os provedores selecionados para gerar o seguinte plano de execu\u00e7\u00e3o. As a\u00e7\u00f5es de recursos s\u00e3o indicadas pelos seguintes s\u00edmbolos: + criar O Terraform executar\u00e1 as seguintes a\u00e7\u00f5es: # azurerm_kubernetes_cluster.aks ser\u00e1 criado + resource \"azurerm_kubernetes_cluster\" \"aks\" { + dns_prefix = \"aks-dev\" + fqdn = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + kube_admin_config = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + kube_admin_config_raw = (valor sens\u00edvel) + kube_config = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + kube_config_raw = (valor sens\u00edvel) + kubernetes_version = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + location = \"westeurope\" + name = \"aks-dev\" + node_resource_group = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + portal_fqdn = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_cluster_enabled = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_cluster_public_fqdn_enabled = false + private_dns_zone_id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_fqdn = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + private_link_enabled = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + public_network_access_enabled = true + resource_group_name = \"rg-aks-dev\" + sku_tier = \"Free\" [...] truncado + default_node_pool { + kubelet_disk_type = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + max_pods = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + name = \"default\" + node_count = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + node_labels = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + orchestrator_version = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + os_disk_size_gb = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + os_disk_type = \"Managed\" + os_sku = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + type = \"VirtualMachineScaleSets\" + ultra_ssd_enabled = false + vm_size = \"Standard_DS2_v2\" + vnet_subnet_id = \"/subscriptions/01010101-1010-0101-1010-010101010101/resourceGroups/rg-network-dev/providers/Microsoft.Network/virtualNetworks/vnet-dev/subnets/AksSubnet\" } + identity { + principal_id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + tenant_id = (conhecido ap\u00f3s a aplica\u00e7\u00e3o) + type = \"SystemAssigned\" } [...] truncado } Plano: 1 para adicionar, 0 para alterar, 0 para destruir. Observa\u00e7\u00e3o: o uso de um m\u00f3dulo comum tamb\u00e9m \u00e9 v\u00e1lido se voc\u00ea decidir implantar todos os seus m\u00f3dulos na mesma opera\u00e7\u00e3o a partir de um arquivo de configura\u00e7\u00e3o principal do Terraform, como: module \"common\" { source = \"./common\" environment_name = var.environment_name subscription = var.subscription } module \"network\" { source = \"./network\" vnet_name = module.common.vnet_name vnet_rg_name = module.common.vnet_rg_name } module \"kubernetes\" { source = \"./kubernetes\" aks_name = module.common.aks_name aks_rg = module.common.aks_rg_name }","title":"Usando o M\u00f3dulo Comum do Terraform"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#centralizando-as-definicoes-de-variaveis-de-entrada","text":"No caso de voc\u00ea optar por definir os valores das vari\u00e1veis diretamente no controle de origem (por exemplo, cen\u00e1rio gitops) usando arquivos de defini\u00e7\u00e3o de vari\u00e1veis ( .tfvars ), ter um m\u00f3dulo comum tamb\u00e9m ajudar\u00e1 a n\u00e3o duplicar as defini\u00e7\u00f5es de vari\u00e1veis comuns em todos os m\u00f3dulos. Na verdade, \u00e9 poss\u00edvel ter um arquivo global que seja definido uma vez, no n\u00edvel do m\u00f3dulo comum, e mescl\u00e1-lo com arquivos de defini\u00e7\u00f5es de vari\u00e1veis espec\u00edficas do m\u00f3dulo no momento do plan ou apply do Terraform. Considere a seguinte estrutura: modules \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 dev.tfvars \u2502 \u251c\u2500\u2500 prod.tfvars \u2502 \u251c\u2500\u2500 output.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 kubernetes \u2502 \u251c\u2500\u2500 dev.tfvars \u2502 \u251c\u2500\u2500 prod.tfvars \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 network \u2502 \u251c\u2500\u2500 dev.tfvars \u2502 \u251c\u2500\u2500 prod.tfvars \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf O m\u00f3dulo comum, assim como todos os outros m\u00f3dulos, cont\u00e9m arquivos de vari\u00e1veis para os ambientes dev e prod . Os arquivos tfvars do m\u00f3dulo comum definir\u00e3o todas as vari\u00e1veis globais que ser\u00e3o compartilhadas com outros m\u00f3dulos (como assinatura, nome do ambiente, etc.), e os arquivos .tfvars de cada m\u00f3dulo definir\u00e3o apenas os valores espec\u00edficos do m\u00f3dulo. Em seguida, \u00e9 poss\u00edvel mesclar esses arquivos ao executar os comandos terraform apply ou terraform plan , usando a seguinte sintaxe: terraform plan -var-file = < ( cat ../common/dev.tfvars ./dev.tf vars ) Observa\u00e7\u00e3o: ao usar isso, \u00e9 realmente importante garantir que voc\u00ea n\u00e3o tenha os mesmos nomes de vari\u00e1veis em ambos os arquivos, caso contr\u00e1rio, isso gerar\u00e1 um erro.","title":"Centralizando as Defini\u00e7\u00f5es de Vari\u00e1veis de Entrada"},{"location":"continuous-delivery/recipes/terraform/share-common-variables-naming-conventions/#conclusao","text":"Ao ter um m\u00f3dulo comum que possua vari\u00e1veis compartilhadas, bem como conven\u00e7\u00f5es de nomenclatura, agora \u00e9 mais f\u00e1cil refatorar o c\u00f3digo de configura\u00e7\u00e3o do Terraform. Imagine que, por algum motivo, voc\u00ea precisa alterar o padr\u00e3o usado para o nome da rede virtual: voc\u00ea o altera nos arquivos de sa\u00edda do m\u00f3dulo comum e s\u00f3 precisa reaplicar todos os m\u00f3dulos!","title":"Conclus\u00e3o"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/","text":"Diretrizes para Estruturar a Configura\u00e7\u00e3o do Terraform Contexto Ao criar uma configura\u00e7\u00e3o de infraestrutura, \u00e9 importante seguir uma estrutura consistente e organizada para garantir a manutenibilidade, escalabilidade e reutiliza\u00e7\u00e3o do c\u00f3digo. O objetivo desta se\u00e7\u00e3o \u00e9 descrever brevemente como estruturar sua configura\u00e7\u00e3o do Terraform para alcan\u00e7ar esses objetivos. Estruturando a Configura\u00e7\u00e3o do Terraform A estrutura recomendada \u00e9 a seguinte: Coloque cada componente que deseja configurar em sua pr\u00f3pria pasta de m\u00f3dulo. Analise o c\u00f3digo de sua infraestrutura e identifique os componentes l\u00f3gicos que podem ser separados em m\u00f3dulos reutiliz\u00e1veis. Isso dar\u00e1 a voc\u00ea uma clara separa\u00e7\u00e3o de preocupa\u00e7\u00f5es e tornar\u00e1 f\u00e1cil incluir novos recursos, atualizar os existentes ou reutiliz\u00e1-los no futuro. Para obter mais detalhes sobre m\u00f3dulos e quando us\u00e1-los, consulte o guia do Terraform . Coloque os arquivos de m\u00f3dulo .tf na raiz de cada pasta e certifique-se de incluir um arquivo README em formato markdown que pode ser gerado automaticamente com base no c\u00f3digo do m\u00f3dulo. \u00c9 recomend\u00e1vel seguir esta abordagem, pois essa estrutura de arquivo ser\u00e1 automaticamente reconhecida pelo Terraform Registry . Use um conjunto consistente de arquivos para estruturar seus m\u00f3dulos. Embora isso possa variar dependendo das necessidades espec\u00edficas do projeto, um bom exemplo pode ser o seguinte: provider.tf : define a lista de provedores de acordo com os plugins usados data.tf : define informa\u00e7\u00f5es lidas de diferentes fontes de dados main.tf : define os objetos de infraestrutura necess\u00e1rios para sua configura\u00e7\u00e3o (por exemplo, grupo de recursos, atribui\u00e7\u00e3o de fun\u00e7\u00e3o, registro de cont\u00eainer) backend.tf : arquivo de configura\u00e7\u00e3o de backend outputs.tf : define dados estruturados que s\u00e3o exportados variables.tf : define valores est\u00e1ticos e reutiliz\u00e1veis Inclua em cada m\u00f3dulo subpastas para documenta\u00e7\u00e3o, exemplos e testes. A documenta\u00e7\u00e3o inclui informa\u00e7\u00f5es b\u00e1sicas sobre o m\u00f3dulo: o que ele est\u00e1 instalando, quais s\u00e3o as op\u00e7\u00f5es, um exemplo de caso de uso, e assim por diante. Voc\u00ea tamb\u00e9m pode adicionar aqui quaisquer outros detalhes relevantes que possa ter. A pasta de exemplos pode incluir um ou mais exemplos de como usar o m\u00f3dulo, cada exemplo tendo o mesmo conjunto de arquivos de configura\u00e7\u00e3o decidido na etapa anterior. \u00c9 recomend\u00e1vel tamb\u00e9m incluir um README que forne\u00e7a uma compreens\u00e3o clara de como ele pode ser usado na pr\u00e1tica. A pasta de testes inclui um ou mais arquivos para testar o m\u00f3dulo de exemplo junto com um arquivo de documenta\u00e7\u00e3o com instru\u00e7\u00f5es sobre como esses testes podem ser executados . Coloque o m\u00f3dulo raiz em uma pasta separada chamada main : este \u00e9 o ponto de entrada principal para a configura\u00e7\u00e3o. Assim como nos outros m\u00f3dulos, ele conter\u00e1 seus arquivos de configura\u00e7\u00e3o correspondentes. Uma estrutura de configura\u00e7\u00e3o de exemplo obtida usando as diretrizes acima \u00e9: modules \u251c\u2500\u2500 mlops \u2502 \u251c\u2500\u2500 doc \u2502 \u251c\u2500\u2500 example \u2502 \u251c\u2500\u2500 test \u2502 \u251c\u2500\u2500 backend.tf \u2502 \u251c\u2500\u2500 data.tf \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 outputs.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u251c\u2500\u2500 variables.tf \u2502 \u251c\u2500\u2500 README.md \u251c\u2500\u2500 common \u251c\u2500\u2500 main Conven\u00e7\u00e3o de Nomenclatura Ao nomear vari\u00e1veis do Terraform, \u00e9 essencial usar conven\u00e7\u00f5es de nomenclatura claras e consistentes que sejam f\u00e1ceis de entender e seguir. A conven\u00e7\u00e3o geral \u00e9 usar letras min\u00fasculas e n\u00fameros, com underscores em vez de tra\u00e7os, por exemplo: \"azurerm_resource_group\". Ao nomear recursos, comece com o nome do provedor, seguido pelo recurso de destino, separado por underscores. Por exemplo, \"azurerm_postgresql_server\" \u00e9 um nome apropriado para um recurso de provedor Azure. Quando se trata de fontes de dados, use uma conven\u00e7\u00e3o de nomenclatura semelhante, mas certifique-se de usar nomes no plural para listas de itens. Por exemplo, \"azurerm_resource_groups\" \u00e9 um bom nome para uma fonte de dados que representa uma lista de grupos de recursos. Nomes de vari\u00e1veis e sa\u00eddas devem ser descritivos e refletir o prop\u00f3sito ou uso da vari\u00e1vel. Tamb\u00e9m \u00e9 \u00fatil agrupar itens relacionados usando um prefixo comum. Por exemplo, todas as vari\u00e1veis relacionadas a contas de armazenamento podem come\u00e7ar com \"storage_\". Tenha em mente que as sa\u00eddas devem ser compreens\u00edveis fora de seu escopo. Um padr\u00e3o de nomenclatura \u00fatil a seguir \u00e9 \"{nome}_{atributo}\", onde \"nome\" representa o nome de um recurso ou fonte de dados, e \"atributo\" \u00e9 o atributo retornado pela sa\u00edda. Por exemplo, \"storage_primary_connection_string\" poderia ser um nome de sa\u00edda v\u00e1lido. Certifique-se de incluir uma descri\u00e7\u00e3o para sa\u00eddas e vari\u00e1veis, al\u00e9m de marcar os valores como 'default' ou 'sensitive' quando necess\u00e1rio. Essas informa\u00e7\u00f5es ser\u00e3o capturadas na documenta\u00e7\u00e3o gerada. Gerando a Documenta\u00e7\u00e3o A documenta\u00e7\u00e3o pode ser gerada automaticamente com base no c\u00f3digo de configura\u00e7\u00e3o em seus m\u00f3dulos com a ajuda do terraform-docs . Para gerar a documenta\u00e7\u00e3o do m\u00f3dulo Terraform, v\u00e1 para a pasta do m\u00f3dulo e insira este comando: terraform-docs markdown table --output-file README.md --output-mode inject . Em seguida, a documenta\u00e7\u00e3o ser\u00e1 gerada dentro do diret\u00f3rio raiz do componente. Conclus\u00e3o A abordagem apresentada nesta se\u00e7\u00e3o foi projetada para ser flex\u00edvel e f\u00e1cil de usar, tornando simples adicionar novos recursos ou atualizar os existentes. A separa\u00e7\u00e3o de preocupa\u00e7\u00f5es tamb\u00e9m facilita a reutiliza\u00e7\u00e3o de componentes existentes em outros projetos, com todas as informa\u00e7\u00f5es (m\u00f3dulos, exemplos, documenta\u00e7\u00e3o e testes) localizadas em um s\u00f3 lugar. Refer\u00eancias e Leituras Adicionais Terraform-docs Terraform Registry Terraform Module Guidance Terratest Testing HashiCorp Terraform Build Infrastructure - Terraform Azure Example","title":"Diretrizes para Estruturar a Configura\u00e7\u00e3o do Terraform"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#diretrizes-para-estruturar-a-configuracao-do-terraform","text":"","title":"Diretrizes para Estruturar a Configura\u00e7\u00e3o do Terraform"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#contexto","text":"Ao criar uma configura\u00e7\u00e3o de infraestrutura, \u00e9 importante seguir uma estrutura consistente e organizada para garantir a manutenibilidade, escalabilidade e reutiliza\u00e7\u00e3o do c\u00f3digo. O objetivo desta se\u00e7\u00e3o \u00e9 descrever brevemente como estruturar sua configura\u00e7\u00e3o do Terraform para alcan\u00e7ar esses objetivos.","title":"Contexto"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#estruturando-a-configuracao-do-terraform","text":"A estrutura recomendada \u00e9 a seguinte: Coloque cada componente que deseja configurar em sua pr\u00f3pria pasta de m\u00f3dulo. Analise o c\u00f3digo de sua infraestrutura e identifique os componentes l\u00f3gicos que podem ser separados em m\u00f3dulos reutiliz\u00e1veis. Isso dar\u00e1 a voc\u00ea uma clara separa\u00e7\u00e3o de preocupa\u00e7\u00f5es e tornar\u00e1 f\u00e1cil incluir novos recursos, atualizar os existentes ou reutiliz\u00e1-los no futuro. Para obter mais detalhes sobre m\u00f3dulos e quando us\u00e1-los, consulte o guia do Terraform . Coloque os arquivos de m\u00f3dulo .tf na raiz de cada pasta e certifique-se de incluir um arquivo README em formato markdown que pode ser gerado automaticamente com base no c\u00f3digo do m\u00f3dulo. \u00c9 recomend\u00e1vel seguir esta abordagem, pois essa estrutura de arquivo ser\u00e1 automaticamente reconhecida pelo Terraform Registry . Use um conjunto consistente de arquivos para estruturar seus m\u00f3dulos. Embora isso possa variar dependendo das necessidades espec\u00edficas do projeto, um bom exemplo pode ser o seguinte: provider.tf : define a lista de provedores de acordo com os plugins usados data.tf : define informa\u00e7\u00f5es lidas de diferentes fontes de dados main.tf : define os objetos de infraestrutura necess\u00e1rios para sua configura\u00e7\u00e3o (por exemplo, grupo de recursos, atribui\u00e7\u00e3o de fun\u00e7\u00e3o, registro de cont\u00eainer) backend.tf : arquivo de configura\u00e7\u00e3o de backend outputs.tf : define dados estruturados que s\u00e3o exportados variables.tf : define valores est\u00e1ticos e reutiliz\u00e1veis Inclua em cada m\u00f3dulo subpastas para documenta\u00e7\u00e3o, exemplos e testes. A documenta\u00e7\u00e3o inclui informa\u00e7\u00f5es b\u00e1sicas sobre o m\u00f3dulo: o que ele est\u00e1 instalando, quais s\u00e3o as op\u00e7\u00f5es, um exemplo de caso de uso, e assim por diante. Voc\u00ea tamb\u00e9m pode adicionar aqui quaisquer outros detalhes relevantes que possa ter. A pasta de exemplos pode incluir um ou mais exemplos de como usar o m\u00f3dulo, cada exemplo tendo o mesmo conjunto de arquivos de configura\u00e7\u00e3o decidido na etapa anterior. \u00c9 recomend\u00e1vel tamb\u00e9m incluir um README que forne\u00e7a uma compreens\u00e3o clara de como ele pode ser usado na pr\u00e1tica. A pasta de testes inclui um ou mais arquivos para testar o m\u00f3dulo de exemplo junto com um arquivo de documenta\u00e7\u00e3o com instru\u00e7\u00f5es sobre como esses testes podem ser executados . Coloque o m\u00f3dulo raiz em uma pasta separada chamada main : este \u00e9 o ponto de entrada principal para a configura\u00e7\u00e3o. Assim como nos outros m\u00f3dulos, ele conter\u00e1 seus arquivos de configura\u00e7\u00e3o correspondentes. Uma estrutura de configura\u00e7\u00e3o de exemplo obtida usando as diretrizes acima \u00e9: modules \u251c\u2500\u2500 mlops \u2502 \u251c\u2500\u2500 doc \u2502 \u251c\u2500\u2500 example \u2502 \u251c\u2500\u2500 test \u2502 \u251c\u2500\u2500 backend.tf \u2502 \u251c\u2500\u2500 data.tf \u2502 \u251c\u2500\u2500 main.tf \u2502 \u251c\u2500\u2500 outputs.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u251c\u2500\u2500 variables.tf \u2502 \u251c\u2500\u2500 README.md \u251c\u2500\u2500 common \u251c\u2500\u2500 main","title":"Estruturando a Configura\u00e7\u00e3o do Terraform"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#convencao-de-nomenclatura","text":"Ao nomear vari\u00e1veis do Terraform, \u00e9 essencial usar conven\u00e7\u00f5es de nomenclatura claras e consistentes que sejam f\u00e1ceis de entender e seguir. A conven\u00e7\u00e3o geral \u00e9 usar letras min\u00fasculas e n\u00fameros, com underscores em vez de tra\u00e7os, por exemplo: \"azurerm_resource_group\". Ao nomear recursos, comece com o nome do provedor, seguido pelo recurso de destino, separado por underscores. Por exemplo, \"azurerm_postgresql_server\" \u00e9 um nome apropriado para um recurso de provedor Azure. Quando se trata de fontes de dados, use uma conven\u00e7\u00e3o de nomenclatura semelhante, mas certifique-se de usar nomes no plural para listas de itens. Por exemplo, \"azurerm_resource_groups\" \u00e9 um bom nome para uma fonte de dados que representa uma lista de grupos de recursos. Nomes de vari\u00e1veis e sa\u00eddas devem ser descritivos e refletir o prop\u00f3sito ou uso da vari\u00e1vel. Tamb\u00e9m \u00e9 \u00fatil agrupar itens relacionados usando um prefixo comum. Por exemplo, todas as vari\u00e1veis relacionadas a contas de armazenamento podem come\u00e7ar com \"storage_\". Tenha em mente que as sa\u00eddas devem ser compreens\u00edveis fora de seu escopo. Um padr\u00e3o de nomenclatura \u00fatil a seguir \u00e9 \"{nome}_{atributo}\", onde \"nome\" representa o nome de um recurso ou fonte de dados, e \"atributo\" \u00e9 o atributo retornado pela sa\u00edda. Por exemplo, \"storage_primary_connection_string\" poderia ser um nome de sa\u00edda v\u00e1lido. Certifique-se de incluir uma descri\u00e7\u00e3o para sa\u00eddas e vari\u00e1veis, al\u00e9m de marcar os valores como 'default' ou 'sensitive' quando necess\u00e1rio. Essas informa\u00e7\u00f5es ser\u00e3o capturadas na documenta\u00e7\u00e3o gerada.","title":"Conven\u00e7\u00e3o de Nomenclatura"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#gerando-a-documentacao","text":"A documenta\u00e7\u00e3o pode ser gerada automaticamente com base no c\u00f3digo de configura\u00e7\u00e3o em seus m\u00f3dulos com a ajuda do terraform-docs . Para gerar a documenta\u00e7\u00e3o do m\u00f3dulo Terraform, v\u00e1 para a pasta do m\u00f3dulo e insira este comando: terraform-docs markdown table --output-file README.md --output-mode inject . Em seguida, a documenta\u00e7\u00e3o ser\u00e1 gerada dentro do diret\u00f3rio raiz do componente.","title":"Gerando a Documenta\u00e7\u00e3o"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#conclusao","text":"A abordagem apresentada nesta se\u00e7\u00e3o foi projetada para ser flex\u00edvel e f\u00e1cil de usar, tornando simples adicionar novos recursos ou atualizar os existentes. A separa\u00e7\u00e3o de preocupa\u00e7\u00f5es tamb\u00e9m facilita a reutiliza\u00e7\u00e3o de componentes existentes em outros projetos, com todas as informa\u00e7\u00f5es (m\u00f3dulos, exemplos, documenta\u00e7\u00e3o e testes) localizadas em um s\u00f3 lugar.","title":"Conclus\u00e3o"},{"location":"continuous-delivery/recipes/terraform/terraform-structure-guidelines/#referencias-e-leituras-adicionais","text":"Terraform-docs Terraform Registry Terraform Module Guidance Terratest Testing HashiCorp Terraform Build Infrastructure - Terraform Azure Example","title":"Refer\u00eancias e Leituras Adicionais"},{"location":"continuous-delivery/secrets-management/","text":"Gerenciamento de Segredos O Gerenciamento de Segredos se refere \u00e0 maneira como protegemos configura\u00e7\u00f5es e outros dados sens\u00edveis que, se tornados p\u00fablicos, permitiriam o acesso n\u00e3o autorizado a recursos. Exemplos de segredos incluem nomes de usu\u00e1rio, senhas, chaves de API, tokens SAS, etc. Devemos assumir que qualquer reposit\u00f3rio em que trabalhamos pode se tornar p\u00fablico a qualquer momento e proteger nossos segredos, mesmo que o reposit\u00f3rio seja inicialmente privado. Abordagem Geral A abordagem geral \u00e9 manter segredos em arquivos de configura\u00e7\u00e3o separados que n\u00e3o s\u00e3o inclu\u00eddos no reposit\u00f3rio. Adicione os arquivos ao .gitignore para evitar que eles sejam inclu\u00eddos. Cada desenvolvedor mant\u00e9m sua pr\u00f3pria vers\u00e3o local do arquivo ou, se necess\u00e1rio, os distribui por canais privados, como um chat no Teams. Em um sistema de produ\u00e7\u00e3o, assumindo o uso do Azure, crie os segredos no ambiente em que o processo est\u00e1 em execu\u00e7\u00e3o. Isso pode ser feito editando manualmente a se\u00e7\u00e3o 'Configura\u00e7\u00f5es de Aplicativos' do recurso, mas um script usando o Azure CLI para fazer o mesmo \u00e9 uma ferramenta \u00fatil que economiza tempo. Consulte az webapp config appsettings para obter mais detalhes. \u00c9 uma boa pr\u00e1tica manter configura\u00e7\u00f5es de segredos separadas para cada ambiente que voc\u00ea utiliza, como desenvolvimento, teste, produ\u00e7\u00e3o, local, etc. A receita de segredos por ramifica\u00e7\u00e3o descreve uma maneira simples de gerenciar configura\u00e7\u00f5es de segredos separadas para cada ambiente. Observa\u00e7\u00e3o: mesmo que o segredo tenha sido apenas enviado para uma ramifica\u00e7\u00e3o de recurso e nunca mesclado, ele ainda faz parte do hist\u00f3rico do git. Siga essas instru\u00e7\u00f5es para remover quaisquer dados sens\u00edveis e/ou regenerar quaisquer chaves e outras informa\u00e7\u00f5es sens\u00edveis adicionadas ao reposit\u00f3rio. Se uma chave ou segredo foi inclu\u00eddo no c\u00f3digo-base, fa\u00e7a a rota\u00e7\u00e3o da chave/segredo para que ele n\u00e3o esteja mais ativo. Mantendo os Segredos em Sigilo O cuidado em proteger nossos segredos se aplica tanto \u00e0 forma como os obtemos e armazenamos quanto \u00e0 forma como os utilizamos. N\u00e3o registre segredos N\u00e3o os inclua em relat\u00f3rios N\u00e3o os envie para outras aplica\u00e7\u00f5es, como parte de URLs, formul\u00e1rios ou de qualquer outra forma, exceto para fazer uma solicita\u00e7\u00e3o ao servi\u00e7o que requer esse segredo Aplica\u00e7\u00f5es com Seguran\u00e7a Refor\u00e7ada As t\u00e9cnicas descritas abaixo fornecem boa seguran\u00e7a e um padr\u00e3o comum para uma ampla gama de linguagens. Elas dependem do fato de que o Azure mant\u00e9m as configura\u00e7\u00f5es de aplicativos (o ambiente) criptografadas at\u00e9 que seu aplicativo seja executado. Elas n\u00e3o impedem que os segredos existam em texto simples na mem\u00f3ria em tempo de execu\u00e7\u00e3o. Em particular, para linguagens com coleta de lixo, esses valores podem existir por mais tempo do que a vida \u00fatil da vari\u00e1vel e podem ser vis\u00edveis durante a depura\u00e7\u00e3o de um despejo de mem\u00f3ria do processo. Se voc\u00ea estiver trabalhando em um aplicativo com requisitos de seguran\u00e7a mais rigorosos, deve considerar o uso de t\u00e9cnicas adicionais para manter a criptografia dos segredos durante toda a vida \u00fatil do aplicativo. Sempre fa\u00e7a a rota\u00e7\u00e3o das chaves de criptografia regularmente. T\u00e9cnicas para o Gerenciamento de Segredos Essas t\u00e9cnicas tornam o carregamento de segredos transparente para o desenvolvedor. C#/.NET Solu\u00e7\u00e3o Moderna .NET Para o SDK .NET (vers\u00e3o 2.0 ou superior), temos o dotnet secrets , uma ferramenta fornecida pelo SDK .NET que permite gerenciar e proteger informa\u00e7\u00f5es sens\u00edveis, como chaves de API, strings de conex\u00e3o e outros segredos, durante o desenvolvimento. Os segredos s\u00e3o armazenados com seguran\u00e7a em sua m\u00e1quina e podem ser acessados por suas aplica\u00e7\u00f5es .NET. # Inicialize o dotnet secret dotnet user-secrets init # Adicione um segredo # dotnet user-secrets set <CHAVE> <VALOR> dotnet user-secrets set ExternalServiceApiKey minha-api-key-12345 # Atualize o segredo dotnet user-secrets set ExternalServiceApiKey api-key-atualizada-67890 Para acessar os segredos: using Microsoft.Extensions.Configuration ; var builder = new ConfigurationBuilder () . AddUserSecrets < Startup > (); var configuration = builder . Build (); var externalServiceApiKey = configuration [ \"ExternalServiceApiKey\" ]; Considera\u00e7\u00f5es de Implanta\u00e7\u00e3o Ao implantar sua aplica\u00e7\u00e3o em produ\u00e7\u00e3o, \u00e9 essencial garantir que seus segredos sejam gerenciados com seguran\u00e7a. Aqui est\u00e3o algumas implica\u00e7\u00f5es relacionadas \u00e0 implanta\u00e7\u00e3o: Remova Segredos de Desenvolvimento: Antes de implantar em produ\u00e7\u00e3o, remova quaisquer segredos de desenvolvimento da configura\u00e7\u00e3o de sua aplica\u00e7\u00e3o. Voc\u00ea pode usar vari\u00e1veis de ambiente ou uma solu\u00e7\u00e3o de gerenciamento de segredos mais segura, como o Azure Key Vault ou o AWS Secrets Manager em produ\u00e7\u00e3o. Implanta\u00e7\u00e3o Segura: Garanta que seu servidor de produ\u00e7\u00e3o seja seguro e que o acesso aos segredos seja controlado. Nunca armazene segredos diretamente no c\u00f3digo-fonte ou em arquivos de configura\u00e7\u00e3o. Rota\u00e7\u00e3o de Chaves: Considere implementar uma pol\u00edtica de rota\u00e7\u00e3o de segredos para atualizar regularmente seus segredos em produ\u00e7\u00e3o. Solu\u00e7\u00e3o .NET Framework Use o atributo file do elemento appSettings para carregar segredos de um arquivo local. <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings file= \"..\\..\\secrets.config\" > \u2026 </appSettings> <startup> <supportedRuntime version= \"v4.0\" sku= \".NETFramework,Version=v4.6.1\" /> </startup> \u2026 </configuration> Acesso aos segredos: static void Main ( string [] args ) { String mySecret = System . Configuration . ConfigurationManager . AppSettings [ \"mySecret\" ]; } Quando em execu\u00e7\u00e3o no Azure, o ConfigurationManager carregar\u00e1 essas configura\u00e7\u00f5es do ambiente do processo. N\u00e3o \u00e9 necess\u00e1rio fazer upload de arquivos de segredos para o servidor nem alterar o c\u00f3digo. Node Armazene segredos em vari\u00e1veis de ambiente ou em um arquivo .env $ cat .env MY_SECRET = mySecret Use o pacote dotenv para carregar e acessar vari\u00e1veis de ambiente require('dotenv').config() let mySecret = process.env.MY_SECRET Python Armazene segredos em vari\u00e1veis de ambiente ou em um arquivo .env $ cat .env MY_SECRET = mySecret Use o pacote dotenv para carregar e acessar vari\u00e1veis de ambiente import os from dotenv import load_dotenv load_dotenv () my_secret = os . getenv ( 'MY_SECRET' ) Outra boa biblioteca para ler vari\u00e1veis de ambiente \u00e9 environs from environs import Env env = Env () env . read_env () my_secret = os . environ [ \"MY_SECRET\" ] Databricks O Databricks oferece a op\u00e7\u00e3o de usar o dbutils como uma maneira segura de recuperar credenciais e n\u00e3o revel\u00e1-las nos notebooks em execu\u00e7\u00e3o no Databricks Os seguintes passos descrevem claramente como criar novos segredos e utiliz\u00e1-los em um notebook no Databricks: Instale e configure o Databricks CLI em sua m\u00e1quina local Obtenha o token de acesso pessoal do Databricks Crie um escopo para os segredos Crie segredos Valida\u00e7\u00e3o A verifica\u00e7\u00e3o automatizada de credenciais pode ser realizada no c\u00f3digo, independentemente da linguagem de programa\u00e7\u00e3o utilizada. Saiba mais sobre isso aqui","title":"Gerenciamento de Segredos"},{"location":"continuous-delivery/secrets-management/#gerenciamento-de-segredos","text":"O Gerenciamento de Segredos se refere \u00e0 maneira como protegemos configura\u00e7\u00f5es e outros dados sens\u00edveis que, se tornados p\u00fablicos, permitiriam o acesso n\u00e3o autorizado a recursos. Exemplos de segredos incluem nomes de usu\u00e1rio, senhas, chaves de API, tokens SAS, etc. Devemos assumir que qualquer reposit\u00f3rio em que trabalhamos pode se tornar p\u00fablico a qualquer momento e proteger nossos segredos, mesmo que o reposit\u00f3rio seja inicialmente privado.","title":"Gerenciamento de Segredos"},{"location":"continuous-delivery/secrets-management/#abordagem-geral","text":"A abordagem geral \u00e9 manter segredos em arquivos de configura\u00e7\u00e3o separados que n\u00e3o s\u00e3o inclu\u00eddos no reposit\u00f3rio. Adicione os arquivos ao .gitignore para evitar que eles sejam inclu\u00eddos. Cada desenvolvedor mant\u00e9m sua pr\u00f3pria vers\u00e3o local do arquivo ou, se necess\u00e1rio, os distribui por canais privados, como um chat no Teams. Em um sistema de produ\u00e7\u00e3o, assumindo o uso do Azure, crie os segredos no ambiente em que o processo est\u00e1 em execu\u00e7\u00e3o. Isso pode ser feito editando manualmente a se\u00e7\u00e3o 'Configura\u00e7\u00f5es de Aplicativos' do recurso, mas um script usando o Azure CLI para fazer o mesmo \u00e9 uma ferramenta \u00fatil que economiza tempo. Consulte az webapp config appsettings para obter mais detalhes. \u00c9 uma boa pr\u00e1tica manter configura\u00e7\u00f5es de segredos separadas para cada ambiente que voc\u00ea utiliza, como desenvolvimento, teste, produ\u00e7\u00e3o, local, etc. A receita de segredos por ramifica\u00e7\u00e3o descreve uma maneira simples de gerenciar configura\u00e7\u00f5es de segredos separadas para cada ambiente. Observa\u00e7\u00e3o: mesmo que o segredo tenha sido apenas enviado para uma ramifica\u00e7\u00e3o de recurso e nunca mesclado, ele ainda faz parte do hist\u00f3rico do git. Siga essas instru\u00e7\u00f5es para remover quaisquer dados sens\u00edveis e/ou regenerar quaisquer chaves e outras informa\u00e7\u00f5es sens\u00edveis adicionadas ao reposit\u00f3rio. Se uma chave ou segredo foi inclu\u00eddo no c\u00f3digo-base, fa\u00e7a a rota\u00e7\u00e3o da chave/segredo para que ele n\u00e3o esteja mais ativo.","title":"Abordagem Geral"},{"location":"continuous-delivery/secrets-management/#mantendo-os-segredos-em-sigilo","text":"O cuidado em proteger nossos segredos se aplica tanto \u00e0 forma como os obtemos e armazenamos quanto \u00e0 forma como os utilizamos. N\u00e3o registre segredos N\u00e3o os inclua em relat\u00f3rios N\u00e3o os envie para outras aplica\u00e7\u00f5es, como parte de URLs, formul\u00e1rios ou de qualquer outra forma, exceto para fazer uma solicita\u00e7\u00e3o ao servi\u00e7o que requer esse segredo","title":"Mantendo os Segredos em Sigilo"},{"location":"continuous-delivery/secrets-management/#aplicacoes-com-seguranca-reforcada","text":"As t\u00e9cnicas descritas abaixo fornecem boa seguran\u00e7a e um padr\u00e3o comum para uma ampla gama de linguagens. Elas dependem do fato de que o Azure mant\u00e9m as configura\u00e7\u00f5es de aplicativos (o ambiente) criptografadas at\u00e9 que seu aplicativo seja executado. Elas n\u00e3o impedem que os segredos existam em texto simples na mem\u00f3ria em tempo de execu\u00e7\u00e3o. Em particular, para linguagens com coleta de lixo, esses valores podem existir por mais tempo do que a vida \u00fatil da vari\u00e1vel e podem ser vis\u00edveis durante a depura\u00e7\u00e3o de um despejo de mem\u00f3ria do processo. Se voc\u00ea estiver trabalhando em um aplicativo com requisitos de seguran\u00e7a mais rigorosos, deve considerar o uso de t\u00e9cnicas adicionais para manter a criptografia dos segredos durante toda a vida \u00fatil do aplicativo. Sempre fa\u00e7a a rota\u00e7\u00e3o das chaves de criptografia regularmente.","title":"Aplica\u00e7\u00f5es com Seguran\u00e7a Refor\u00e7ada"},{"location":"continuous-delivery/secrets-management/#tecnicas-para-o-gerenciamento-de-segredos","text":"Essas t\u00e9cnicas tornam o carregamento de segredos transparente para o desenvolvedor.","title":"T\u00e9cnicas para o Gerenciamento de Segredos"},{"location":"continuous-delivery/secrets-management/#cnet","text":"","title":"C#/.NET"},{"location":"continuous-delivery/secrets-management/#solucao-moderna-net","text":"Para o SDK .NET (vers\u00e3o 2.0 ou superior), temos o dotnet secrets , uma ferramenta fornecida pelo SDK .NET que permite gerenciar e proteger informa\u00e7\u00f5es sens\u00edveis, como chaves de API, strings de conex\u00e3o e outros segredos, durante o desenvolvimento. Os segredos s\u00e3o armazenados com seguran\u00e7a em sua m\u00e1quina e podem ser acessados por suas aplica\u00e7\u00f5es .NET. # Inicialize o dotnet secret dotnet user-secrets init # Adicione um segredo # dotnet user-secrets set <CHAVE> <VALOR> dotnet user-secrets set ExternalServiceApiKey minha-api-key-12345 # Atualize o segredo dotnet user-secrets set ExternalServiceApiKey api-key-atualizada-67890 Para acessar os segredos: using Microsoft.Extensions.Configuration ; var builder = new ConfigurationBuilder () . AddUserSecrets < Startup > (); var configuration = builder . Build (); var externalServiceApiKey = configuration [ \"ExternalServiceApiKey\" ];","title":"Solu\u00e7\u00e3o Moderna .NET"},{"location":"continuous-delivery/secrets-management/#consideracoes-de-implantacao","text":"Ao implantar sua aplica\u00e7\u00e3o em produ\u00e7\u00e3o, \u00e9 essencial garantir que seus segredos sejam gerenciados com seguran\u00e7a. Aqui est\u00e3o algumas implica\u00e7\u00f5es relacionadas \u00e0 implanta\u00e7\u00e3o: Remova Segredos de Desenvolvimento: Antes de implantar em produ\u00e7\u00e3o, remova quaisquer segredos de desenvolvimento da configura\u00e7\u00e3o de sua aplica\u00e7\u00e3o. Voc\u00ea pode usar vari\u00e1veis de ambiente ou uma solu\u00e7\u00e3o de gerenciamento de segredos mais segura, como o Azure Key Vault ou o AWS Secrets Manager em produ\u00e7\u00e3o. Implanta\u00e7\u00e3o Segura: Garanta que seu servidor de produ\u00e7\u00e3o seja seguro e que o acesso aos segredos seja controlado. Nunca armazene segredos diretamente no c\u00f3digo-fonte ou em arquivos de configura\u00e7\u00e3o. Rota\u00e7\u00e3o de Chaves: Considere implementar uma pol\u00edtica de rota\u00e7\u00e3o de segredos para atualizar regularmente seus segredos em produ\u00e7\u00e3o.","title":"Considera\u00e7\u00f5es de Implanta\u00e7\u00e3o"},{"location":"continuous-delivery/secrets-management/#solucao-net-framework","text":"Use o atributo file do elemento appSettings para carregar segredos de um arquivo local. <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings file= \"..\\..\\secrets.config\" > \u2026 </appSettings> <startup> <supportedRuntime version= \"v4.0\" sku= \".NETFramework,Version=v4.6.1\" /> </startup> \u2026 </configuration> Acesso aos segredos: static void Main ( string [] args ) { String mySecret = System . Configuration . ConfigurationManager . AppSettings [ \"mySecret\" ]; } Quando em execu\u00e7\u00e3o no Azure, o ConfigurationManager carregar\u00e1 essas configura\u00e7\u00f5es do ambiente do processo. N\u00e3o \u00e9 necess\u00e1rio fazer upload de arquivos de segredos para o servidor nem alterar o c\u00f3digo.","title":"Solu\u00e7\u00e3o .NET Framework"},{"location":"continuous-delivery/secrets-management/#node","text":"Armazene segredos em vari\u00e1veis de ambiente ou em um arquivo .env $ cat .env MY_SECRET = mySecret Use o pacote dotenv para carregar e acessar vari\u00e1veis de ambiente require('dotenv').config() let mySecret = process.env.MY_SECRET","title":"Node"},{"location":"continuous-delivery/secrets-management/#python","text":"Armazene segredos em vari\u00e1veis de ambiente ou em um arquivo .env $ cat .env MY_SECRET = mySecret Use o pacote dotenv para carregar e acessar vari\u00e1veis de ambiente import os from dotenv import load_dotenv load_dotenv () my_secret = os . getenv ( 'MY_SECRET' ) Outra boa biblioteca para ler vari\u00e1veis de ambiente \u00e9 environs from environs import Env env = Env () env . read_env () my_secret = os . environ [ \"MY_SECRET\" ]","title":"Python"},{"location":"continuous-delivery/secrets-management/#databricks","text":"O Databricks oferece a op\u00e7\u00e3o de usar o dbutils como uma maneira segura de recuperar credenciais e n\u00e3o revel\u00e1-las nos notebooks em execu\u00e7\u00e3o no Databricks Os seguintes passos descrevem claramente como criar novos segredos e utiliz\u00e1-los em um notebook no Databricks: Instale e configure o Databricks CLI em sua m\u00e1quina local Obtenha o token de acesso pessoal do Databricks Crie um escopo para os segredos Crie segredos","title":"Databricks"},{"location":"continuous-delivery/secrets-management/#validacao","text":"A verifica\u00e7\u00e3o automatizada de credenciais pode ser realizada no c\u00f3digo, independentemente da linguagem de programa\u00e7\u00e3o utilizada. Saiba mais sobre isso aqui","title":"Valida\u00e7\u00e3o"},{"location":"continuous-integration/","text":"Integra\u00e7\u00e3o Cont\u00ednua Incentivamos equipes de engenharia a fazer um investimento inicial durante o Sprint 0 de um projeto para estabelecer um pipeline automatizado e repet\u00edvel que integre continuamente o c\u00f3digo e libere execut\u00e1veis do sistema para ambientes de nuvem espec\u00edficos. Cada integra\u00e7\u00e3o deve ser verificada por um processo de compila\u00e7\u00e3o automatizado que assegura que um conjunto de testes de valida\u00e7\u00e3o seja aprovado e identifica quaisquer erros para toda a equipe de desenvolvedores. Encorajamos as equipes a implementar os pipelines de CI/CD antes que qualquer c\u00f3digo de servi\u00e7o seja escrito para os clientes, o que geralmente acontece no Sprint 0(N). Dessa forma, a equipe de engenharia pode desenvolver e testar seu trabalho de forma isolada sem impactar outros desenvolvedores e promover um fluxo de trabalho DevOps consistente ao longo do envolvimento. Esses princ\u00edpios est\u00e3o diretamente alinhados com as pr\u00e1ticas do ciclo de vida de desenvolvimento de software \u00e1gil. Objetivos A automa\u00e7\u00e3o de integra\u00e7\u00e3o cont\u00ednua \u00e9 uma parte integral do ciclo de desenvolvimento de software destinada a reduzir erros de integra\u00e7\u00e3o de compila\u00e7\u00e3o e maximizar a velocidade em uma equipe de desenvolvimento. Um pipeline de automa\u00e7\u00e3o de compila\u00e7\u00e3o robusto deve: Acelerar a velocidade da equipe Evitar problemas de integra\u00e7\u00e3o Evitar caos de \u00faltima hora durante as datas de lan\u00e7amento Fornecer um ciclo de feedback r\u00e1pido para o impacto em todo o sistema das mudan\u00e7as locais Separar as etapas de compila\u00e7\u00e3o e implanta\u00e7\u00e3o Medir e relatar m\u00e9tricas sobre falhas/sucessos de compila\u00e7\u00e3o Aumentar a visibilidade entre a equipe, facilitando a comunica\u00e7\u00e3o Reduzir erros humanos, que \u00e9 provavelmente a parte mais importante da automa\u00e7\u00e3o de compila\u00e7\u00f5es Defini\u00e7\u00e3o de Compila\u00e7\u00e3o Gerenciada no Git C\u00f3digo / artefatos de manifesto necess\u00e1rios para compilar seu projeto devem ser mantidos dentro de seus reposit\u00f3rios Git de projeto As defini\u00e7\u00f5es de pipeline de compila\u00e7\u00e3o espec\u00edficas do provedor de CI devem residir dentro dos reposit\u00f3rios Git de projeto. Automa\u00e7\u00e3o de Compila\u00e7\u00e3o Uma compila\u00e7\u00e3o automatizada deve abranger os seguintes princ\u00edpios: Tarefa de Compila\u00e7\u00e3o Uma etapa \u00fanica dentro do seu pipeline de compila\u00e7\u00e3o que compila o projeto de c\u00f3digo em um \u00fanico artefato de compila\u00e7\u00e3o. Testes Unit\u00e1rios Sua defini\u00e7\u00e3o de compila\u00e7\u00e3o inclui etapas de valida\u00e7\u00e3o para executar um conjunto de testes unit\u00e1rios automatizados para garantir que os componentes da aplica\u00e7\u00e3o atendam ao seu design e se comportem conforme o esperado. Verifica\u00e7\u00e3o de Estilo de C\u00f3digo O c\u00f3digo em toda a equipe de engenharia deve estar formatado de acordo com os padr\u00f5es de codifica\u00e7\u00e3o acordados. Esses padr\u00f5es mant\u00eam o c\u00f3digo consistente e, o mais importante, f\u00e1cil para a equipe e os clientes lerem e refatorarem. A consist\u00eancia de estilo de c\u00f3digo incentiva a propriedade coletiva das equipes de scrum do projeto e nossos parceiros. Existem v\u00e1rias ferramentas de valida\u00e7\u00e3o de estilo de c\u00f3digo de c\u00f3digo aberto dispon\u00edveis para escolher ( verifica\u00e7\u00f5es de estilo de c\u00f3digo , StyleCop ). A se\u00e7\u00e3o Receitas de Revis\u00e3o de C\u00f3digo do guia tem sugest\u00f5es de linters e estilos preferidos para v\u00e1rias linguagens. Seu c\u00f3digo e documenta\u00e7\u00e3o devem evitar o uso de linguagem n\u00e3o inclusiva sempre que poss\u00edvel. Siga a se\u00e7\u00e3o Verifica\u00e7\u00e3o Inclusiva para garantir que seu projeto promova um ambiente de trabalho inclusivo tanto para a equipe quanto para os clientes. Recomendamos incorporar ferramentas de an\u00e1lise de seguran\u00e7a na fase de compila\u00e7\u00e3o de seu pipeline, como scanner de credenciais de c\u00f3digo, detec\u00e7\u00e3o de riscos de seguran\u00e7a, an\u00e1lise est\u00e1tica, etc. Para o Azure DevOps, voc\u00ea pode adicionar uma tarefa de an\u00e1lise de seguran\u00e7a ao seu pipeline instalando a Extens\u00e3o de An\u00e1lise de C\u00f3digo de Seguran\u00e7a da Microsoft . O GitHub Actions suporta uma extens\u00e3o semelhante com a solu\u00e7\u00e3o de an\u00e1lise de seguran\u00e7a RIPS . Os padr\u00f5es de c\u00f3digo s\u00e3o mantidos dentro de um \u00fanico arquivo de configura\u00e7\u00e3o. Deve haver uma etapa em seu pipeline de compila\u00e7\u00e3o que assegure que o c\u00f3digo no \u00faltimo commit esteja em conformidade com a defini\u00e7\u00e3o de estilo conhecida. Alvo do Script de Compila\u00e7\u00e3o Um \u00fanico comando deve ter a capacidade de compilar o sistema. Isso tamb\u00e9m \u00e9 verdade para compila\u00e7\u00f5es em um servidor de CI ou em uma m\u00e1quina local de desenvolvedores. Sem Depend\u00eancias de IDE \u00c9 essencial ter uma compila\u00e7\u00e3o que possa ser executada por meio de scripts independentes e n\u00e3o seja dependente de uma IDE espec\u00edfica. Os alvos do pipeline de compila\u00e7\u00e3o podem ser acionados localmente em suas esta\u00e7\u00f5es de trabalho por meio da IDE de sua escolha. O processo de compila\u00e7\u00e3o deve manter flexibilidade suficiente para ser executado em um servidor de CI tamb\u00e9m. Como exemplo, a dockeriza\u00e7\u00e3o do processo de compila\u00e7\u00e3o oferece esse n\u00edvel de flexibilidade, j\u00e1 que o VSCode e o IntelliJ suportam extens\u00f5es de plugin Docker . Verifica\u00e7\u00f5es de Seguran\u00e7a do DevOps Introduza seguran\u00e7a em seu projeto nas fases iniciais. Siga a se\u00e7\u00e3o DevSecOps para introduzir pr\u00e1ticas de seguran\u00e7a, automa\u00e7\u00e3o, ferramentas e estruturas como parte do CI. Depend\u00eancias do Ambiente de Compila\u00e7\u00e3o Configura\u00e7\u00e3o autom\u00e1tica do ambiente local Incentivamos manter uma experi\u00eancia de desenvolvedor consistente para todos os membros da equipe. Deve haver um manifesto/processo automatizado central que simplifica a instala\u00e7\u00e3o e configura\u00e7\u00e3o de quaisquer depend\u00eancias de software. Isso permite que os desenvolvedores repliquem o mesmo ambiente de compila\u00e7\u00e3o localmente que o ambiente em execu\u00e7\u00e3o em um servidor de CI. Os scripts de automa\u00e7\u00e3o de compila\u00e7\u00e3o frequentemente requerem pacotes de software espec\u00edficos e vers\u00f5es pr\u00e9-instaladas dentro do ambiente de tempo de execu\u00e7\u00e3o do sistema operacional. Isso apresenta alguns desafios, j\u00e1 que os processos de compila\u00e7\u00e3o geralmente travam essas depend\u00eancias em uma vers\u00e3o espec\u00edfica. Todos os desenvolvedores da equipe devem ser capazes de emular o ambiente de compila\u00e7\u00e3o de suas esta\u00e7\u00f5es de trabalho locais, independentemente do sistema operacional. Para projetos que usam o VS Code, aproveitar Cont\u00eaineres de Desenvolvedor pode realmente ajudar a padronizar a experi\u00eancia de desenvolvimento local em toda a equipe. Ferramentas de empacotamento de software bem estabelecidas, como Docker, Maven, npm, etc., devem ser consideradas ao projetar sua cadeia de ferramentas de automa\u00e7\u00e3o de compila\u00e7\u00e3o. Documenta\u00e7\u00e3o da configura\u00e7\u00e3o local O processo de configura\u00e7\u00e3o para configurar um ambiente de compila\u00e7\u00e3o local deve ser bem documentado e de f\u00e1cil acompanhamento para os desenvolvedores. Infraestrutura como C\u00f3digo Gerencie o m\u00e1ximo poss\u00edvel dos seguintes como c\u00f3digo: Arquivos de Configura\u00e7\u00e3o Gerenciamento de Configura\u00e7\u00e3o (automa\u00e7\u00e3o de vari\u00e1veis de ambiente via terraform ) Gerenciamento de Segredos (cria\u00e7\u00e3o de segredos Azure via terraform ) Provisionamento de Recursos de Nuvem Atribui\u00e7\u00f5es de Fun\u00e7\u00f5es Cen\u00e1rios de Teste de Carga Alertas de Disponibilidade / Regras e Condi\u00e7\u00f5es de Monitoramento Desacoplar a infraestrutura do c\u00f3digo da aplica\u00e7\u00e3o simplifica a transi\u00e7\u00e3o das equipes de engenharia para aplicativos nativos em nuvem. Provedores de recursos do Terraform, como Azure DevOps , est\u00e3o tornando mais f\u00e1cil para os desenvolvedores gerenciar vari\u00e1veis de pipeline de compila\u00e7\u00e3o, conex\u00f5es de servi\u00e7o e defini\u00e7\u00f5es de pipeline de CI/CD. Exemplo de Fluxo de Trabalho DevOps usando Terraform e Cobalt Por que Altera\u00e7\u00f5es repet\u00edveis e audit\u00e1veis na infraestrutura facilitam o retorno a configura\u00e7\u00f5es conhecidas e a expans\u00e3o r\u00e1pida para novos est\u00e1gios e regi\u00f5es sem a necessidade de configurar manualmente os recursos da nuvem. Projetos de refer\u00eancia testados e com modelos de IAC, como Cobalt e Bedrock , permitem que equipes de engenharia implementem solu\u00e7\u00f5es seguras e escal\u00e1veis de forma muito mais r\u00e1pida. Simplificar cen\u00e1rios de \"migrar e executar\" abstraindo as complexidades da computa\u00e7\u00e3o nativa em nuvem das equipes de desenvolvimento de aplicativos. IAC DevOPS: Opera\u00e7\u00f5es por Pull Request O processo de implanta\u00e7\u00e3o de infraestrutura \u00e9 baseado em um reposit\u00f3rio que mant\u00e9m o estado atual esperado do ambiente do sistema / ambiente Azure. As mudan\u00e7as operacionais s\u00e3o feitas no sistema em execu\u00e7\u00e3o, fazendo commits neste reposit\u00f3rio. O Git tamb\u00e9m fornece um modelo simples para auditoria de implanta\u00e7\u00f5es e retorno a um estado anterior. Padr\u00f5es de Infraestrutura Recomendados Defina a infraestrutura como c\u00f3digo em modelos Terraform / ARM / Ansible. Os modelos s\u00e3o pilhas repet\u00edveis de recursos de nuvem com foco em conjuntos de configura\u00e7\u00f5es alinhados com escalabilidade e necessidades de throughput da aplica\u00e7\u00e3o. Princ\u00edpios de IAC Automatize o Ambiente Azure Todos os recursos de nuvem s\u00e3o provisionados por meio de um conjunto de modelos de infraestrutura como c\u00f3digo. Isso inclui segredos, configura\u00e7\u00f5es de servi\u00e7o, atribui\u00e7\u00f5es de fun\u00e7\u00e3o e condi\u00e7\u00f5es de monitoramento. O Portal Azure deve fornecer uma visualiza\u00e7\u00e3o somente leitura dos recursos do ambiente. Qualquer altera\u00e7\u00e3o aplicada ao ambiente deve ser feita apenas por meio da cadeia de ferramentas de IAC. Fluxo de Trabalho de CI de IAC Quando os arquivos de modelo IAC mudam por meio de um fluxo de trabalho baseado em git, um pipeline de compila\u00e7\u00e3o CI constr\u00f3i, valida e concilia o estado atual do ambiente de infraestrutura de destino com o estado esperado. O plano de execu\u00e7\u00e3o de infraestrutura candidato para esses ambientes fixos \u00e9 revisado por um administrador de nuvem como uma verifica\u00e7\u00e3o de porta antes da etapa de implanta\u00e7\u00e3o do pipeline aplicar o plano de execu\u00e7\u00e3o. Acesso de Desenvolvedor Somente Leitura a Recursos de Nuvem Contas de desenvolvedores no portal Azure devem ter acesso somente leitura aos recursos de ambiente IAC no Azure. Automa\u00e7\u00e3o de Segredos Model os IAC s\u00e3o implantados por meio de um sistema CI/CD que possui automa\u00e7\u00e3o de segredos integrada. Evite aplicar altera\u00e7\u00f5es a segredos e/ou certificados diretamente no Portal Azure. Automa\u00e7\u00e3o de Testes de Integra\u00e7\u00e3o de Infraestrutura Testes de integra\u00e7\u00e3o de ponta a ponta s\u00e3o executados como parte de seu processo de CI IAC para inspecionar e validar que um ambiente Azure est\u00e1 pronto para uso. Documenta\u00e7\u00e3o de Infraestrutura A implanta\u00e7\u00e3o e a topologia de modelo de recurso em nuvem devem ser documentadas e bem compreendidas dentro do README do reposit\u00f3rio git IAC. As etapas de configura\u00e7\u00e3o do ambiente local e do fluxo de trabalho de CI devem ser documentadas. Valida\u00e7\u00e3o de Configura\u00e7\u00e3o As aplica\u00e7\u00f5es usam configura\u00e7\u00f5es para permitir diferentes comportamentos em tempo de execu\u00e7\u00e3o e \u00e9 bastante comum usar arquivos para armazenar essas configura\u00e7\u00f5es. Como desenvolvedores, podemos introduzir erros ao editar esses arquivos, o que causaria problemas para a inicializa\u00e7\u00e3o e/ou execu\u00e7\u00e3o correta da aplica\u00e7\u00e3o. Aplicando t\u00e9cnicas de valida\u00e7\u00e3o na sintaxe e sem\u00e2ntica de nossa configura\u00e7\u00e3o, podemos detectar erros antes que a aplica\u00e7\u00e3o seja implantada e executada, melhorando a experi\u00eancia do desenvolvedor (usu\u00e1rio). Exemplos de Arquivos de Configura\u00e7\u00e3o de Aplicativos JSON, com suporte para tipos de dados complexos e estruturas de dados complexas. YAML, um superconjunto de JSON com suporte para tipos de dados e estruturas complexas. TOML, um superconjunto de JSON e um formato de arquivo de configura\u00e7\u00e3o formalmente especificado. Por que Validar a Configura\u00e7\u00e3o da Aplica\u00e7\u00e3o como uma Etapa Separada? Facilita a Depura\u00e7\u00e3o e Economiza Tempo - Com uma etapa de valida\u00e7\u00e3o de configura\u00e7\u00e3o em nosso pipeline, podemos evitar a execu\u00e7\u00e3o da aplica\u00e7\u00e3o apenas para descobrir que ela falha. Isso economiza tempo ao evitar a implanta\u00e7\u00e3o e execu\u00e7\u00e3o, esperar e, em seguida, perceber que algo est\u00e1 errado na configura\u00e7\u00e3o. Al\u00e9m disso, economiza tempo ao passar pelos registros para descobrir o que deu errado e por qu\u00ea. Melhor experi\u00eancia do usu\u00e1rio/desenvolvedor - Um lembrete simples para o usu\u00e1rio de que algo na configura\u00e7\u00e3o n\u00e3o est\u00e1 no formato correto pode fazer toda a diferen\u00e7a entre a alegria de um processo de implanta\u00e7\u00e3o bem-sucedido e a intensa frustra\u00e7\u00e3o de ter que adivinhar o que deu errado. Por exemplo, quando se espera um valor booleano, ele pode ser uma string como \"True\" ou \"False\" ou um valor inteiro como \"0\" ou \"1\". Com a valida\u00e7\u00e3o da configura\u00e7\u00e3o, garantimos que o significado esteja correto para nossa aplica\u00e7\u00e3o. Evitar corrup\u00e7\u00e3o de dados e viola\u00e7\u00f5es de seguran\u00e7a - Como os dados v\u00eam de uma fonte n\u00e3o confi\u00e1vel, como um usu\u00e1rio ou um servi\u00e7o externo, \u00e9 especialmente importante validar a entrada. Caso contr\u00e1rio, ele correr\u00e1 o risco de executar erros, corromper dados ou, pior ainda, ser vulner\u00e1vel a uma s\u00e9rie de ataques de inje\u00e7\u00e3o. O que \u00e9 o Esquema JSON? JSON-Schema \u00e9 o padr\u00e3o de documentos JSON que descreve a estrutura e os requisitos dos seus dados JSON. Embora seja chamado de JSON-Schema, tamb\u00e9m \u00e9 comum usar esse m\u00e9todo para YAMLs, j\u00e1 que ele \u00e9 um superconjunto do JSON. O esquema \u00e9 muito simples: aponta quais campos podem existir, quais s\u00e3o obrigat\u00f3rios ou opcionais, que formato de dados eles usam. Outras regras de valida\u00e7\u00e3o podem ser adicionadas a essa premissa b\u00e1sica, juntamente com informa\u00e7\u00f5es leg\u00edveis por humanos. Os metadados ficam nos esquemas, que s\u00e3o arquivos .json tamb\u00e9m. Al\u00e9m disso, o esquema tem a maior ado\u00e7\u00e3o entre todos os padr\u00f5es de valida\u00e7\u00e3o JSON, pois cobre uma grande parte dos cen\u00e1rios de valida\u00e7\u00e3o. Ele usa documentos JSON f\u00e1ceis de analisar para esquemas e \u00e9 facilmente extens\u00edvel. Como Implementar a Valida\u00e7\u00e3o de Esquema? A implementa\u00e7\u00e3o da valida\u00e7\u00e3o de esquema \u00e9 dividida em duas partes: a gera\u00e7\u00e3o dos esquemas e a valida\u00e7\u00e3o de arquivos YAML/JSON com esses esquemas. Gera\u00e7\u00e3o Existem duas op\u00e7\u00f5es para gerar um esquema: A partir do c\u00f3digo - podemos aproveitar os modelos e objetos existentes no c\u00f3digo e gerar um esquema personalizado. A partir de dados - podemos pegar amostras de yaml/json que refletem a configura\u00e7\u00e3o em geral e usar v\u00e1rias ferramentas online para gerar um esquema. Valida\u00e7\u00e3o O esquema possui mais de 30 validadores para diferentes linguagens, incluindo mais de 10 para JavaScript, portanto, n\u00e3o \u00e9 necess\u00e1rio codific\u00e1-lo voc\u00ea mesmo. Valida\u00e7\u00e3o de Integra\u00e7\u00e3o Uma maneira eficaz de identificar erros em sua compila\u00e7\u00e3o rapidamente \u00e9 investir cedo em um conjunto confi\u00e1vel de testes automatizados que validem a funcionalidade b\u00e1sica do sistema: Testes de Integra\u00e7\u00e3o de Ponta a Ponta Inclua testes em seu pipeline para validar que o candidato \u00e0 compila\u00e7\u00e3o est\u00e1 em conformidade com as asser\u00e7\u00f5es automatizadas de funcionalidade de neg\u00f3cios. Quaisquer erros ou c\u00f3digo quebrado devem ser relatados nos resultados dos testes, incluindo o teste falhado e o rastreamento de pilha relevante. Todos os testes devem ser invocados por meio de um \u00fanico comando. Mantenha a compila\u00e7\u00e3o r\u00e1pida. Considere o tempo de execu\u00e7\u00e3o dos testes automatizados ao decidir trazer depend\u00eancias como bancos de dados, servi\u00e7os externos e carga de dados fict\u00edcios para o seu conjunto de testes. Compila\u00e7\u00f5es lentas frequentemente se tornam um gargalo para equipes de desenvolvimento quando compila\u00e7\u00f5es paralelas em um servidor de Integra\u00e7\u00e3o Cont\u00ednua n\u00e3o s\u00e3o uma op\u00e7\u00e3o. Considere adicionar limites m\u00e1ximos de tempo para valida\u00e7\u00f5es demoradas para falhar rapidamente e manter uma alta velocidade em toda a equipe. Evite enviar compila\u00e7\u00f5es quebradas Verifica\u00e7\u00f5es automatizadas de compila\u00e7\u00e3o, testes, execu\u00e7\u00f5es de an\u00e1lise de c\u00f3digo etc. devem ser validadas localmente antes de enviar suas altera\u00e7\u00f5es para o reposit\u00f3rio de controle de vers\u00e3o. A Desenvolvimento Orientado a Testes \u00e9 uma pr\u00e1tica que equipes de desenvolvimento devem considerar para ajudar a identificar erros e falhas o mais cedo poss\u00edvel no ciclo de desenvolvimento. Relatando falhas de compila\u00e7\u00e3o Se a etapa de compila\u00e7\u00e3o falhar, o status da execu\u00e7\u00e3o do pipeline de compila\u00e7\u00e3o deve ser relatado como falho, incluindo logs relevantes e rastreamentos de pilha. Depend\u00eancias de Dados de Automa\u00e7\u00e3o de Teste Qualquer conjunto de dados fict\u00edcios usado para testes unit\u00e1rios e de integra\u00e7\u00e3o de ponta a ponta deve ser inclu\u00eddo no reposit\u00f3rio principal. Minimize quaisquer depend\u00eancias de dados externos no processo de compila\u00e7\u00e3o. Verifica\u00e7\u00f5es de Cobertura de C\u00f3digo Recomendamos integrar ferramentas de cobertura de c\u00f3digo em sua etapa de compila\u00e7\u00e3o. A maioria das ferramentas de cobertura de c\u00f3digo falha nas compila\u00e7\u00f5es quando a cobertura de teste fica abaixo de um limite m\u00ednimo (80% de cobertura). O relat\u00f3rio de cobertura deve ser publicado em seu sistema de Integra\u00e7\u00e3o Cont\u00ednua para acompanhar uma s\u00e9rie temporal de varia\u00e7\u00f5es. Fluxo de Trabalho Orientado pelo Git Compila\u00e7\u00e3o na Confirma\u00e7\u00e3o Cada confirma\u00e7\u00e3o no reposit\u00f3rio base deve acionar o pipeline de Integra\u00e7\u00e3o Cont\u00ednua para criar um novo candidato \u00e0 compila\u00e7\u00e3o. Os artefatos de compila\u00e7\u00e3o s\u00e3o criados, empacotados, validados e implantados continuamente em um ambiente n\u00e3o produtivo por confirma\u00e7\u00e3o. Cada confirma\u00e7\u00e3o no reposit\u00f3rio resulta em uma execu\u00e7\u00e3o de Integra\u00e7\u00e3o Cont\u00ednua que verifica as fontes na m\u00e1quina de integra\u00e7\u00e3o, inicia uma compila\u00e7\u00e3o e notifica o autor da confirma\u00e7\u00e3o sobre o resultado da compila\u00e7\u00e3o. Evite comentar testes falhados Evite comentar testes na ramifica\u00e7\u00e3o principal. Ao comentar testes, obtemos uma indica\u00e7\u00e3o incorreta do estado da compila\u00e7\u00e3o. Aplica\u00e7\u00e3o da Pol\u00edtica de Ramifica\u00e7\u00e3o Pol\u00edticas de ramifica\u00e7\u00e3o protegidas devem ser configuradas na ramifica\u00e7\u00e3o principal para garantir que as etapas de Integra\u00e7\u00e3o Cont\u00ednua tenham sido conclu\u00eddas antes de iniciar uma revis\u00e3o de c\u00f3digo. Os aprovadores de revis\u00e3o de c\u00f3digo s\u00f3 iniciar\u00e3o a revis\u00e3o de uma solicita\u00e7\u00e3o de pull quando a execu\u00e7\u00e3o do pipeline de Integra\u00e7\u00e3o Cont\u00ednua for bem-sucedida para a confirma\u00e7\u00e3o mais recentemente enviada para o Git. Compila\u00e7\u00f5es quebradas devem bloquear revis\u00f5es de solicita\u00e7\u00f5es de pull. Evite confirma\u00e7\u00f5es diretas na ramifica\u00e7\u00e3o principal. Estrat\u00e9gia de Ramifica\u00e7\u00e3o Ramifica\u00e7\u00f5es de lan\u00e7amento devem acionar automaticamente a implanta\u00e7\u00e3o de um artefato de compila\u00e7\u00e3o em seu ambiente de nuvem de destino. Voc\u00ea pode encontrar orienta\u00e7\u00f5es adicionais no site de documenta\u00e7\u00e3o do Azure DevOps na se\u00e7\u00e3o Gerenciar implanta\u00e7\u00f5es . Entregar Rapidamente e Diariamente \"Ao confirmar regularmente, cada colaborador pode reduzir o n\u00famero de altera\u00e7\u00f5es conflitantes. Fazer confirma\u00e7\u00f5es semanais de trabalho corre o risco de entrar em conflito com outras funcionalidades e pode ser muito dif\u00edcil de resolver. Conflitos iniciais e pequenos em uma \u00e1rea do sistema fazem com que os membros da equipe se comuniquem sobre a altera\u00e7\u00e3o que est\u00e3o fazendo.\" No esp\u00edrito da transpar\u00eancia e da comunica\u00e7\u00e3o frequente em uma equipe de desenvolvimento, incentivamos os desenvolvedores a confirmar o c\u00f3digo diariamente. Essa abordagem fornece visibilidade ao progresso das funcionalidades e acelera a programa\u00e7\u00e3o em pares em toda a equipe. Aqui est\u00e3o alguns princ\u00edpios a serem considerados: Todos confirmam no reposit\u00f3rio git todos os dias No final do dia, o c\u00f3digo confirmado deve conter testes unit\u00e1rios no m\u00ednimo. Execute a compila\u00e7\u00e3o localmente antes de confirmar para evitar a satura\u00e7\u00e3o do pipeline de Integra\u00e7\u00e3o Cont\u00ednua. Voc\u00ea deve verificar o que causou o erro e tentar resolv\u00ea-lo o mais r\u00e1pido poss\u00edvel, em vez de confirmar o c\u00f3digo. Incentivamos os desenvolvedores a seguir princ\u00edpios de Desenvolvimento Lean . Isolar o trabalho em pequenos peda\u00e7os que se relacionam diretamente com o valor comercial e refatorar incrementalmente. Ambientes Isolados Um dos principais objetivos da valida\u00e7\u00e3o de compila\u00e7\u00e3o \u00e9 isolar e identificar falhas em ambientes de prepara\u00e7\u00e3o e minimizar qualquer interrup\u00e7\u00e3o no tr\u00e1fego de produ\u00e7\u00e3o ao vivo. Nossos testes automatizados de ponta a ponta devem ser executados em um ambiente que reproduza nosso ambiente de produ\u00e7\u00e3o (o m\u00e1ximo poss\u00edvel). Isso inclui vers\u00f5es de software consistent es, SO, simula\u00e7\u00f5es de volume de dados de teste, paridade de tr\u00e1fego de rede com produ\u00e7\u00e3o, etc. Teste em um clone da produ\u00e7\u00e3o O ambiente de produ\u00e7\u00e3o deve ser duplicado em um ambiente de prepara\u00e7\u00e3o (QA e/ou Pr\u00e9-Produ\u00e7\u00e3o) no m\u00ednimo. Atualiza\u00e7\u00f5es de solicita\u00e7\u00e3o de pull acionam lan\u00e7amentos em est\u00e1gios Novas confirma\u00e7\u00f5es relacionadas a uma solicita\u00e7\u00e3o de pull devem acionar uma compila\u00e7\u00e3o/libera\u00e7\u00e3o em um ambiente de integra\u00e7\u00e3o. O ambiente de produ\u00e7\u00e3o deve ser totalmente isolado desse processo. Promover altera\u00e7\u00f5es de infraestrutura em ambientes fixos Altera\u00e7\u00f5es de infraestrutura como c\u00f3digo devem ser testadas em um ambiente de integra\u00e7\u00e3o e promovidas para todos os ambientes de prepara\u00e7\u00e3o, depois migradas para produ\u00e7\u00e3o sem tempo de inatividade para os usu\u00e1rios do sistema. Testando em produ\u00e7\u00e3o Existem v\u00e1rias abordagens para realizar testes automatizados para implanta\u00e7\u00f5es em produ\u00e7\u00e3o com seguran\u00e7a. Algumas dessas abordagens podem incluir: Sinaliza\u00e7\u00e3o de recursos Teste A/B Deslocamento de tr\u00e1fego Acesso do Desenvolvedor aos \u00daltimos Artefatos de Lan\u00e7amento Nosso fluxo de trabalho de DevOps deve permitir que os desenvolvedores obtenham, instalem e executem o execut\u00e1vel do sistema mais recente. Os execut\u00e1veis de lan\u00e7amento devem ser gerados automaticamente como parte de nossos pipelines de CI/CD. Os desenvolvedores podem acessar o execut\u00e1vel mais recente O execut\u00e1vel do sistema mais recente est\u00e1 dispon\u00edvel para todos os desenvolvedores da equipe. Deve haver um local conhecido onde os desenvolvedores possam consultar o artefato de lan\u00e7amento. O artefato de lan\u00e7amento \u00e9 publicado para cada solicita\u00e7\u00e3o de pull ou mesclagem na ramifica\u00e7\u00e3o principal Observabilidade da Integra\u00e7\u00e3o As mudan\u00e7as de estado aplicadas \u00e0 compila\u00e7\u00e3o principal devem estar dispon\u00edveis e ser comunicadas em toda a equipe. Centralizar logs e status de falhas de pipeline de compila\u00e7\u00e3o e lan\u00e7amento \u00e9 essencial para desenvolvedores que investigam compila\u00e7\u00f5es quebradas. Recomendamos integrar Teams ou Slack com as execu\u00e7\u00f5es de pipeline de CI/CD, o que ajuda a manter a equipe constantemente informada sobre falhas e status de candidatos \u00e0 compila\u00e7\u00e3o. Painel de n\u00edvel superior de Integra\u00e7\u00e3o Cont\u00ednua Os provedores modernos de CI t\u00eam a capacidade de consolidar e relatar status de compila\u00e7\u00e3o em um painel espec\u00edfico. Seu painel de CI deve ser capaz de correlacionar uma falha de compila\u00e7\u00e3o com um commit do Git. Emblema de status de compila\u00e7\u00e3o no README do projeto Deve haver um emblema de status de compila\u00e7\u00e3o inclu\u00eddo no README raiz do projeto. Notifica\u00e7\u00f5es de compila\u00e7\u00e3o Seu processo de CI deve ser configurado para enviar notifica\u00e7\u00f5es para plataformas de mensagens como Teams/Slack assim que a compila\u00e7\u00e3o for conclu\u00edda. Recomendamos criar um canal separado para ajudar a consolidar e isolar essas notifica\u00e7\u00f5es. Recursos Melhores Pr\u00e1ticas de Integra\u00e7\u00e3o Cont\u00ednua de Martin Fowler Guia R\u00e1pido de In\u00edcio do Bedrock Guia R\u00e1pido do Cobalt Provedor Azure DevOps do Terraform Pipelines de V\u00e1rios Est\u00e1gios do Azure DevOps Conceitos Chave do Azure Pipeline Ambientes do Azure Pipeline Artefatos no Azure Pipelines Permiss\u00f5es e Fun\u00e7\u00f5es de Seguran\u00e7a do Azure Pipeline Aprova\u00e7\u00f5es e Verifica\u00e7\u00f5es de Ambiente do Azure Guia de In\u00edcio R\u00e1pido do Terraform com Azure Configura\u00e7\u00e3o Remota do Estado do Terraform no Azure Terratest - Framework de Infraestrutura de Testes Unit\u00e1rios e de Integra\u00e7\u00e3o","title":"Integra\u00e7\u00e3o Cont\u00ednua"},{"location":"continuous-integration/#integracao-continua","text":"Incentivamos equipes de engenharia a fazer um investimento inicial durante o Sprint 0 de um projeto para estabelecer um pipeline automatizado e repet\u00edvel que integre continuamente o c\u00f3digo e libere execut\u00e1veis do sistema para ambientes de nuvem espec\u00edficos. Cada integra\u00e7\u00e3o deve ser verificada por um processo de compila\u00e7\u00e3o automatizado que assegura que um conjunto de testes de valida\u00e7\u00e3o seja aprovado e identifica quaisquer erros para toda a equipe de desenvolvedores. Encorajamos as equipes a implementar os pipelines de CI/CD antes que qualquer c\u00f3digo de servi\u00e7o seja escrito para os clientes, o que geralmente acontece no Sprint 0(N). Dessa forma, a equipe de engenharia pode desenvolver e testar seu trabalho de forma isolada sem impactar outros desenvolvedores e promover um fluxo de trabalho DevOps consistente ao longo do envolvimento. Esses princ\u00edpios est\u00e3o diretamente alinhados com as pr\u00e1ticas do ciclo de vida de desenvolvimento de software \u00e1gil.","title":"Integra\u00e7\u00e3o Cont\u00ednua"},{"location":"continuous-integration/#objetivos","text":"A automa\u00e7\u00e3o de integra\u00e7\u00e3o cont\u00ednua \u00e9 uma parte integral do ciclo de desenvolvimento de software destinada a reduzir erros de integra\u00e7\u00e3o de compila\u00e7\u00e3o e maximizar a velocidade em uma equipe de desenvolvimento. Um pipeline de automa\u00e7\u00e3o de compila\u00e7\u00e3o robusto deve: Acelerar a velocidade da equipe Evitar problemas de integra\u00e7\u00e3o Evitar caos de \u00faltima hora durante as datas de lan\u00e7amento Fornecer um ciclo de feedback r\u00e1pido para o impacto em todo o sistema das mudan\u00e7as locais Separar as etapas de compila\u00e7\u00e3o e implanta\u00e7\u00e3o Medir e relatar m\u00e9tricas sobre falhas/sucessos de compila\u00e7\u00e3o Aumentar a visibilidade entre a equipe, facilitando a comunica\u00e7\u00e3o Reduzir erros humanos, que \u00e9 provavelmente a parte mais importante da automa\u00e7\u00e3o de compila\u00e7\u00f5es","title":"Objetivos"},{"location":"continuous-integration/#definicao-de-compilacao-gerenciada-no-git","text":"","title":"Defini\u00e7\u00e3o de Compila\u00e7\u00e3o Gerenciada no Git"},{"location":"continuous-integration/#codigo-artefatos-de-manifesto-necessarios-para-compilar-seu-projeto-devem-ser-mantidos-dentro-de-seus-repositorios-git-de-projeto","text":"As defini\u00e7\u00f5es de pipeline de compila\u00e7\u00e3o espec\u00edficas do provedor de CI devem residir dentro dos reposit\u00f3rios Git de projeto.","title":"C\u00f3digo / artefatos de manifesto necess\u00e1rios para compilar seu projeto devem ser mantidos dentro de seus reposit\u00f3rios Git de projeto"},{"location":"continuous-integration/#automacao-de-compilacao","text":"Uma compila\u00e7\u00e3o automatizada deve abranger os seguintes princ\u00edpios:","title":"Automa\u00e7\u00e3o de Compila\u00e7\u00e3o"},{"location":"continuous-integration/#tarefa-de-compilacao","text":"Uma etapa \u00fanica dentro do seu pipeline de compila\u00e7\u00e3o que compila o projeto de c\u00f3digo em um \u00fanico artefato de compila\u00e7\u00e3o.","title":"Tarefa de Compila\u00e7\u00e3o"},{"location":"continuous-integration/#testes-unitarios","text":"Sua defini\u00e7\u00e3o de compila\u00e7\u00e3o inclui etapas de valida\u00e7\u00e3o para executar um conjunto de testes unit\u00e1rios automatizados para garantir que os componentes da aplica\u00e7\u00e3o atendam ao seu design e se comportem conforme o esperado.","title":"Testes Unit\u00e1rios"},{"location":"continuous-integration/#verificacao-de-estilo-de-codigo","text":"O c\u00f3digo em toda a equipe de engenharia deve estar formatado de acordo com os padr\u00f5es de codifica\u00e7\u00e3o acordados. Esses padr\u00f5es mant\u00eam o c\u00f3digo consistente e, o mais importante, f\u00e1cil para a equipe e os clientes lerem e refatorarem. A consist\u00eancia de estilo de c\u00f3digo incentiva a propriedade coletiva das equipes de scrum do projeto e nossos parceiros. Existem v\u00e1rias ferramentas de valida\u00e7\u00e3o de estilo de c\u00f3digo de c\u00f3digo aberto dispon\u00edveis para escolher ( verifica\u00e7\u00f5es de estilo de c\u00f3digo , StyleCop ). A se\u00e7\u00e3o Receitas de Revis\u00e3o de C\u00f3digo do guia tem sugest\u00f5es de linters e estilos preferidos para v\u00e1rias linguagens. Seu c\u00f3digo e documenta\u00e7\u00e3o devem evitar o uso de linguagem n\u00e3o inclusiva sempre que poss\u00edvel. Siga a se\u00e7\u00e3o Verifica\u00e7\u00e3o Inclusiva para garantir que seu projeto promova um ambiente de trabalho inclusivo tanto para a equipe quanto para os clientes. Recomendamos incorporar ferramentas de an\u00e1lise de seguran\u00e7a na fase de compila\u00e7\u00e3o de seu pipeline, como scanner de credenciais de c\u00f3digo, detec\u00e7\u00e3o de riscos de seguran\u00e7a, an\u00e1lise est\u00e1tica, etc. Para o Azure DevOps, voc\u00ea pode adicionar uma tarefa de an\u00e1lise de seguran\u00e7a ao seu pipeline instalando a Extens\u00e3o de An\u00e1lise de C\u00f3digo de Seguran\u00e7a da Microsoft . O GitHub Actions suporta uma extens\u00e3o semelhante com a solu\u00e7\u00e3o de an\u00e1lise de seguran\u00e7a RIPS . Os padr\u00f5es de c\u00f3digo s\u00e3o mantidos dentro de um \u00fanico arquivo de configura\u00e7\u00e3o. Deve haver uma etapa em seu pipeline de compila\u00e7\u00e3o que assegure que o c\u00f3digo no \u00faltimo commit esteja em conformidade com a defini\u00e7\u00e3o de estilo conhecida.","title":"Verifica\u00e7\u00e3o de Estilo de C\u00f3digo"},{"location":"continuous-integration/#alvo-do-script-de-compilacao","text":"Um \u00fanico comando deve ter a capacidade de compilar o sistema. Isso tamb\u00e9m \u00e9 verdade para compila\u00e7\u00f5es em um servidor de CI ou em uma m\u00e1quina local de desenvolvedores.","title":"Alvo do Script de Compila\u00e7\u00e3o"},{"location":"continuous-integration/#sem-dependencias-de-ide","text":"\u00c9 essencial ter uma compila\u00e7\u00e3o que possa ser executada por meio de scripts independentes e n\u00e3o seja dependente de uma IDE espec\u00edfica. Os alvos do pipeline de compila\u00e7\u00e3o podem ser acionados localmente em suas esta\u00e7\u00f5es de trabalho por meio da IDE de sua escolha. O processo de compila\u00e7\u00e3o deve manter flexibilidade suficiente para ser executado em um servidor de CI tamb\u00e9m. Como exemplo, a dockeriza\u00e7\u00e3o do processo de compila\u00e7\u00e3o oferece esse n\u00edvel de flexibilidade, j\u00e1 que o VSCode e o IntelliJ suportam extens\u00f5es de plugin Docker .","title":"Sem Depend\u00eancias de IDE"},{"location":"continuous-integration/#verificacoes-de-seguranca-do-devops","text":"Introduza seguran\u00e7a em seu projeto nas fases iniciais. Siga a se\u00e7\u00e3o DevSecOps para introduzir pr\u00e1ticas de seguran\u00e7a, automa\u00e7\u00e3o, ferramentas e estruturas como parte do CI.","title":"Verifica\u00e7\u00f5es de Seguran\u00e7a do DevOps"},{"location":"continuous-integration/#dependencias-do-ambiente-de-compilacao","text":"","title":"Depend\u00eancias do Ambiente de Compila\u00e7\u00e3o"},{"location":"continuous-integration/#configuracao-automatica-do-ambiente-local","text":"Incentivamos manter uma experi\u00eancia de desenvolvedor consistente para todos os membros da equipe. Deve haver um manifesto/processo automatizado central que simplifica a instala\u00e7\u00e3o e configura\u00e7\u00e3o de quaisquer depend\u00eancias de software. Isso permite que os desenvolvedores repliquem o mesmo ambiente de compila\u00e7\u00e3o localmente que o ambiente em execu\u00e7\u00e3o em um servidor de CI. Os scripts de automa\u00e7\u00e3o de compila\u00e7\u00e3o frequentemente requerem pacotes de software espec\u00edficos e vers\u00f5es pr\u00e9-instaladas dentro do ambiente de tempo de execu\u00e7\u00e3o do sistema operacional. Isso apresenta alguns desafios, j\u00e1 que os processos de compila\u00e7\u00e3o geralmente travam essas depend\u00eancias em uma vers\u00e3o espec\u00edfica. Todos os desenvolvedores da equipe devem ser capazes de emular o ambiente de compila\u00e7\u00e3o de suas esta\u00e7\u00f5es de trabalho locais, independentemente do sistema operacional. Para projetos que usam o VS Code, aproveitar Cont\u00eaineres de Desenvolvedor pode realmente ajudar a padronizar a experi\u00eancia de desenvolvimento local em toda a equipe. Ferramentas de empacotamento de software bem estabelecidas, como Docker, Maven, npm, etc., devem ser consideradas ao projetar sua cadeia de ferramentas de automa\u00e7\u00e3o de compila\u00e7\u00e3o.","title":"Configura\u00e7\u00e3o autom\u00e1tica do ambiente local"},{"location":"continuous-integration/#documentacao-da-configuracao-local","text":"O processo de configura\u00e7\u00e3o para configurar um ambiente de compila\u00e7\u00e3o local deve ser bem documentado e de f\u00e1cil acompanhamento para os desenvolvedores.","title":"Documenta\u00e7\u00e3o da configura\u00e7\u00e3o local"},{"location":"continuous-integration/#infraestrutura-como-codigo","text":"Gerencie o m\u00e1ximo poss\u00edvel dos seguintes como c\u00f3digo: Arquivos de Configura\u00e7\u00e3o Gerenciamento de Configura\u00e7\u00e3o (automa\u00e7\u00e3o de vari\u00e1veis de ambiente via terraform ) Gerenciamento de Segredos (cria\u00e7\u00e3o de segredos Azure via terraform ) Provisionamento de Recursos de Nuvem Atribui\u00e7\u00f5es de Fun\u00e7\u00f5es Cen\u00e1rios de Teste de Carga Alertas de Disponibilidade / Regras e Condi\u00e7\u00f5es de Monitoramento Desacoplar a infraestrutura do c\u00f3digo da aplica\u00e7\u00e3o simplifica a transi\u00e7\u00e3o das equipes de engenharia para aplicativos nativos em nuvem. Provedores de recursos do Terraform, como Azure DevOps , est\u00e3o tornando mais f\u00e1cil para os desenvolvedores gerenciar vari\u00e1veis de pipeline de compila\u00e7\u00e3o, conex\u00f5es de servi\u00e7o e defini\u00e7\u00f5es de pipeline de CI/CD.","title":"Infraestrutura como C\u00f3digo"},{"location":"continuous-integration/#exemplo-de-fluxo-de-trabalho-devops-usando-terraform-e-cobalt","text":"","title":"Exemplo de Fluxo de Trabalho DevOps usando Terraform e Cobalt"},{"location":"continuous-integration/#por-que","text":"Altera\u00e7\u00f5es repet\u00edveis e audit\u00e1veis na infraestrutura facilitam o retorno a configura\u00e7\u00f5es conhecidas e a expans\u00e3o r\u00e1pida para novos est\u00e1gios e regi\u00f5es sem a necessidade de configurar manualmente os recursos da nuvem. Projetos de refer\u00eancia testados e com modelos de IAC, como Cobalt e Bedrock , permitem que equipes de engenharia implementem solu\u00e7\u00f5es seguras e escal\u00e1veis de forma muito mais r\u00e1pida. Simplificar cen\u00e1rios de \"migrar e executar\" abstraindo as complexidades da computa\u00e7\u00e3o nativa em nuvem das equipes de desenvolvimento de aplicativos.","title":"Por que"},{"location":"continuous-integration/#iac-devops-operacoes-por-pull-request","text":"O processo de implanta\u00e7\u00e3o de infraestrutura \u00e9 baseado em um reposit\u00f3rio que mant\u00e9m o estado atual esperado do ambiente do sistema / ambiente Azure. As mudan\u00e7as operacionais s\u00e3o feitas no sistema em execu\u00e7\u00e3o, fazendo commits neste reposit\u00f3rio. O Git tamb\u00e9m fornece um modelo simples para auditoria de implanta\u00e7\u00f5es e retorno a um estado anterior.","title":"IAC DevOPS: Opera\u00e7\u00f5es por Pull Request"},{"location":"continuous-integration/#padroes-de-infraestrutura-recomendados","text":"Defina a infraestrutura como c\u00f3digo em modelos Terraform / ARM / Ansible. Os modelos s\u00e3o pilhas repet\u00edveis de recursos de nuvem com foco em conjuntos de configura\u00e7\u00f5es alinhados com escalabilidade e necessidades de throughput da aplica\u00e7\u00e3o.","title":"Padr\u00f5es de Infraestrutura Recomendados"},{"location":"continuous-integration/#principios-de-iac","text":"","title":"Princ\u00edpios de IAC"},{"location":"continuous-integration/#automatize-o-ambiente-azure","text":"Todos os recursos de nuvem s\u00e3o provisionados por meio de um conjunto de modelos de infraestrutura como c\u00f3digo. Isso inclui segredos, configura\u00e7\u00f5es de servi\u00e7o, atribui\u00e7\u00f5es de fun\u00e7\u00e3o e condi\u00e7\u00f5es de monitoramento. O Portal Azure deve fornecer uma visualiza\u00e7\u00e3o somente leitura dos recursos do ambiente. Qualquer altera\u00e7\u00e3o aplicada ao ambiente deve ser feita apenas por meio da cadeia de ferramentas de IAC.","title":"Automatize o Ambiente Azure"},{"location":"continuous-integration/#fluxo-de-trabalho-de-ci-de-iac","text":"Quando os arquivos de modelo IAC mudam por meio de um fluxo de trabalho baseado em git, um pipeline de compila\u00e7\u00e3o CI constr\u00f3i, valida e concilia o estado atual do ambiente de infraestrutura de destino com o estado esperado. O plano de execu\u00e7\u00e3o de infraestrutura candidato para esses ambientes fixos \u00e9 revisado por um administrador de nuvem como uma verifica\u00e7\u00e3o de porta antes da etapa de implanta\u00e7\u00e3o do pipeline aplicar o plano de execu\u00e7\u00e3o.","title":"Fluxo de Trabalho de CI de IAC"},{"location":"continuous-integration/#acesso-de-desenvolvedor-somente-leitura-a-recursos-de-nuvem","text":"Contas de desenvolvedores no portal Azure devem ter acesso somente leitura aos recursos de ambiente IAC no Azure.","title":"Acesso de Desenvolvedor Somente Leitura a Recursos de Nuvem"},{"location":"continuous-integration/#automacao-de-segredos","text":"Model os IAC s\u00e3o implantados por meio de um sistema CI/CD que possui automa\u00e7\u00e3o de segredos integrada. Evite aplicar altera\u00e7\u00f5es a segredos e/ou certificados diretamente no Portal Azure.","title":"Automa\u00e7\u00e3o de Segredos"},{"location":"continuous-integration/#automacao-de-testes-de-integracao-de-infraestrutura","text":"Testes de integra\u00e7\u00e3o de ponta a ponta s\u00e3o executados como parte de seu processo de CI IAC para inspecionar e validar que um ambiente Azure est\u00e1 pronto para uso.","title":"Automa\u00e7\u00e3o de Testes de Integra\u00e7\u00e3o de Infraestrutura"},{"location":"continuous-integration/#documentacao-de-infraestrutura","text":"A implanta\u00e7\u00e3o e a topologia de modelo de recurso em nuvem devem ser documentadas e bem compreendidas dentro do README do reposit\u00f3rio git IAC. As etapas de configura\u00e7\u00e3o do ambiente local e do fluxo de trabalho de CI devem ser documentadas.","title":"Documenta\u00e7\u00e3o de Infraestrutura"},{"location":"continuous-integration/#validacao-de-configuracao","text":"As aplica\u00e7\u00f5es usam configura\u00e7\u00f5es para permitir diferentes comportamentos em tempo de execu\u00e7\u00e3o e \u00e9 bastante comum usar arquivos para armazenar essas configura\u00e7\u00f5es. Como desenvolvedores, podemos introduzir erros ao editar esses arquivos, o que causaria problemas para a inicializa\u00e7\u00e3o e/ou execu\u00e7\u00e3o correta da aplica\u00e7\u00e3o. Aplicando t\u00e9cnicas de valida\u00e7\u00e3o na sintaxe e sem\u00e2ntica de nossa configura\u00e7\u00e3o, podemos detectar erros antes que a aplica\u00e7\u00e3o seja implantada e executada, melhorando a experi\u00eancia do desenvolvedor (usu\u00e1rio).","title":"Valida\u00e7\u00e3o de Configura\u00e7\u00e3o"},{"location":"continuous-integration/#exemplos-de-arquivos-de-configuracao-de-aplicativos","text":"JSON, com suporte para tipos de dados complexos e estruturas de dados complexas. YAML, um superconjunto de JSON com suporte para tipos de dados e estruturas complexas. TOML, um superconjunto de JSON e um formato de arquivo de configura\u00e7\u00e3o formalmente especificado.","title":"Exemplos de Arquivos de Configura\u00e7\u00e3o de Aplicativos"},{"location":"continuous-integration/#por-que-validar-a-configuracao-da-aplicacao-como-uma-etapa-separada","text":"Facilita a Depura\u00e7\u00e3o e Economiza Tempo - Com uma etapa de valida\u00e7\u00e3o de configura\u00e7\u00e3o em nosso pipeline, podemos evitar a execu\u00e7\u00e3o da aplica\u00e7\u00e3o apenas para descobrir que ela falha. Isso economiza tempo ao evitar a implanta\u00e7\u00e3o e execu\u00e7\u00e3o, esperar e, em seguida, perceber que algo est\u00e1 errado na configura\u00e7\u00e3o. Al\u00e9m disso, economiza tempo ao passar pelos registros para descobrir o que deu errado e por qu\u00ea. Melhor experi\u00eancia do usu\u00e1rio/desenvolvedor - Um lembrete simples para o usu\u00e1rio de que algo na configura\u00e7\u00e3o n\u00e3o est\u00e1 no formato correto pode fazer toda a diferen\u00e7a entre a alegria de um processo de implanta\u00e7\u00e3o bem-sucedido e a intensa frustra\u00e7\u00e3o de ter que adivinhar o que deu errado. Por exemplo, quando se espera um valor booleano, ele pode ser uma string como \"True\" ou \"False\" ou um valor inteiro como \"0\" ou \"1\". Com a valida\u00e7\u00e3o da configura\u00e7\u00e3o, garantimos que o significado esteja correto para nossa aplica\u00e7\u00e3o. Evitar corrup\u00e7\u00e3o de dados e viola\u00e7\u00f5es de seguran\u00e7a - Como os dados v\u00eam de uma fonte n\u00e3o confi\u00e1vel, como um usu\u00e1rio ou um servi\u00e7o externo, \u00e9 especialmente importante validar a entrada. Caso contr\u00e1rio, ele correr\u00e1 o risco de executar erros, corromper dados ou, pior ainda, ser vulner\u00e1vel a uma s\u00e9rie de ataques de inje\u00e7\u00e3o.","title":"Por que Validar a Configura\u00e7\u00e3o da Aplica\u00e7\u00e3o como uma Etapa Separada?"},{"location":"continuous-integration/#o-que-e-o-esquema-json","text":"JSON-Schema \u00e9 o padr\u00e3o de documentos JSON que descreve a estrutura e os requisitos dos seus dados JSON. Embora seja chamado de JSON-Schema, tamb\u00e9m \u00e9 comum usar esse m\u00e9todo para YAMLs, j\u00e1 que ele \u00e9 um superconjunto do JSON. O esquema \u00e9 muito simples: aponta quais campos podem existir, quais s\u00e3o obrigat\u00f3rios ou opcionais, que formato de dados eles usam. Outras regras de valida\u00e7\u00e3o podem ser adicionadas a essa premissa b\u00e1sica, juntamente com informa\u00e7\u00f5es leg\u00edveis por humanos. Os metadados ficam nos esquemas, que s\u00e3o arquivos .json tamb\u00e9m. Al\u00e9m disso, o esquema tem a maior ado\u00e7\u00e3o entre todos os padr\u00f5es de valida\u00e7\u00e3o JSON, pois cobre uma grande parte dos cen\u00e1rios de valida\u00e7\u00e3o. Ele usa documentos JSON f\u00e1ceis de analisar para esquemas e \u00e9 facilmente extens\u00edvel.","title":"O que \u00e9 o Esquema JSON?"},{"location":"continuous-integration/#como-implementar-a-validacao-de-esquema","text":"A implementa\u00e7\u00e3o da valida\u00e7\u00e3o de esquema \u00e9 dividida em duas partes: a gera\u00e7\u00e3o dos esquemas e a valida\u00e7\u00e3o de arquivos YAML/JSON com esses esquemas.","title":"Como Implementar a Valida\u00e7\u00e3o de Esquema?"},{"location":"continuous-integration/#geracao","text":"Existem duas op\u00e7\u00f5es para gerar um esquema: A partir do c\u00f3digo - podemos aproveitar os modelos e objetos existentes no c\u00f3digo e gerar um esquema personalizado. A partir de dados - podemos pegar amostras de yaml/json que refletem a configura\u00e7\u00e3o em geral e usar v\u00e1rias ferramentas online para gerar um esquema.","title":"Gera\u00e7\u00e3o"},{"location":"continuous-integration/#validacao","text":"O esquema possui mais de 30 validadores para diferentes linguagens, incluindo mais de 10 para JavaScript, portanto, n\u00e3o \u00e9 necess\u00e1rio codific\u00e1-lo voc\u00ea mesmo. Valida\u00e7\u00e3o de Integra\u00e7\u00e3o Uma maneira eficaz de identificar erros em sua compila\u00e7\u00e3o rapidamente \u00e9 investir cedo em um conjunto confi\u00e1vel de testes automatizados que validem a funcionalidade b\u00e1sica do sistema: Testes de Integra\u00e7\u00e3o de Ponta a Ponta Inclua testes em seu pipeline para validar que o candidato \u00e0 compila\u00e7\u00e3o est\u00e1 em conformidade com as asser\u00e7\u00f5es automatizadas de funcionalidade de neg\u00f3cios. Quaisquer erros ou c\u00f3digo quebrado devem ser relatados nos resultados dos testes, incluindo o teste falhado e o rastreamento de pilha relevante. Todos os testes devem ser invocados por meio de um \u00fanico comando. Mantenha a compila\u00e7\u00e3o r\u00e1pida. Considere o tempo de execu\u00e7\u00e3o dos testes automatizados ao decidir trazer depend\u00eancias como bancos de dados, servi\u00e7os externos e carga de dados fict\u00edcios para o seu conjunto de testes. Compila\u00e7\u00f5es lentas frequentemente se tornam um gargalo para equipes de desenvolvimento quando compila\u00e7\u00f5es paralelas em um servidor de Integra\u00e7\u00e3o Cont\u00ednua n\u00e3o s\u00e3o uma op\u00e7\u00e3o. Considere adicionar limites m\u00e1ximos de tempo para valida\u00e7\u00f5es demoradas para falhar rapidamente e manter uma alta velocidade em toda a equipe. Evite enviar compila\u00e7\u00f5es quebradas Verifica\u00e7\u00f5es automatizadas de compila\u00e7\u00e3o, testes, execu\u00e7\u00f5es de an\u00e1lise de c\u00f3digo etc. devem ser validadas localmente antes de enviar suas altera\u00e7\u00f5es para o reposit\u00f3rio de controle de vers\u00e3o. A Desenvolvimento Orientado a Testes \u00e9 uma pr\u00e1tica que equipes de desenvolvimento devem considerar para ajudar a identificar erros e falhas o mais cedo poss\u00edvel no ciclo de desenvolvimento. Relatando falhas de compila\u00e7\u00e3o Se a etapa de compila\u00e7\u00e3o falhar, o status da execu\u00e7\u00e3o do pipeline de compila\u00e7\u00e3o deve ser relatado como falho, incluindo logs relevantes e rastreamentos de pilha. Depend\u00eancias de Dados de Automa\u00e7\u00e3o de Teste Qualquer conjunto de dados fict\u00edcios usado para testes unit\u00e1rios e de integra\u00e7\u00e3o de ponta a ponta deve ser inclu\u00eddo no reposit\u00f3rio principal. Minimize quaisquer depend\u00eancias de dados externos no processo de compila\u00e7\u00e3o. Verifica\u00e7\u00f5es de Cobertura de C\u00f3digo Recomendamos integrar ferramentas de cobertura de c\u00f3digo em sua etapa de compila\u00e7\u00e3o. A maioria das ferramentas de cobertura de c\u00f3digo falha nas compila\u00e7\u00f5es quando a cobertura de teste fica abaixo de um limite m\u00ednimo (80% de cobertura). O relat\u00f3rio de cobertura deve ser publicado em seu sistema de Integra\u00e7\u00e3o Cont\u00ednua para acompanhar uma s\u00e9rie temporal de varia\u00e7\u00f5es. Fluxo de Trabalho Orientado pelo Git Compila\u00e7\u00e3o na Confirma\u00e7\u00e3o Cada confirma\u00e7\u00e3o no reposit\u00f3rio base deve acionar o pipeline de Integra\u00e7\u00e3o Cont\u00ednua para criar um novo candidato \u00e0 compila\u00e7\u00e3o. Os artefatos de compila\u00e7\u00e3o s\u00e3o criados, empacotados, validados e implantados continuamente em um ambiente n\u00e3o produtivo por confirma\u00e7\u00e3o. Cada confirma\u00e7\u00e3o no reposit\u00f3rio resulta em uma execu\u00e7\u00e3o de Integra\u00e7\u00e3o Cont\u00ednua que verifica as fontes na m\u00e1quina de integra\u00e7\u00e3o, inicia uma compila\u00e7\u00e3o e notifica o autor da confirma\u00e7\u00e3o sobre o resultado da compila\u00e7\u00e3o. Evite comentar testes falhados Evite comentar testes na ramifica\u00e7\u00e3o principal. Ao comentar testes, obtemos uma indica\u00e7\u00e3o incorreta do estado da compila\u00e7\u00e3o. Aplica\u00e7\u00e3o da Pol\u00edtica de Ramifica\u00e7\u00e3o Pol\u00edticas de ramifica\u00e7\u00e3o protegidas devem ser configuradas na ramifica\u00e7\u00e3o principal para garantir que as etapas de Integra\u00e7\u00e3o Cont\u00ednua tenham sido conclu\u00eddas antes de iniciar uma revis\u00e3o de c\u00f3digo. Os aprovadores de revis\u00e3o de c\u00f3digo s\u00f3 iniciar\u00e3o a revis\u00e3o de uma solicita\u00e7\u00e3o de pull quando a execu\u00e7\u00e3o do pipeline de Integra\u00e7\u00e3o Cont\u00ednua for bem-sucedida para a confirma\u00e7\u00e3o mais recentemente enviada para o Git. Compila\u00e7\u00f5es quebradas devem bloquear revis\u00f5es de solicita\u00e7\u00f5es de pull. Evite confirma\u00e7\u00f5es diretas na ramifica\u00e7\u00e3o principal. Estrat\u00e9gia de Ramifica\u00e7\u00e3o Ramifica\u00e7\u00f5es de lan\u00e7amento devem acionar automaticamente a implanta\u00e7\u00e3o de um artefato de compila\u00e7\u00e3o em seu ambiente de nuvem de destino. Voc\u00ea pode encontrar orienta\u00e7\u00f5es adicionais no site de documenta\u00e7\u00e3o do Azure DevOps na se\u00e7\u00e3o Gerenciar implanta\u00e7\u00f5es . Entregar Rapidamente e Diariamente \"Ao confirmar regularmente, cada colaborador pode reduzir o n\u00famero de altera\u00e7\u00f5es conflitantes. Fazer confirma\u00e7\u00f5es semanais de trabalho corre o risco de entrar em conflito com outras funcionalidades e pode ser muito dif\u00edcil de resolver. Conflitos iniciais e pequenos em uma \u00e1rea do sistema fazem com que os membros da equipe se comuniquem sobre a altera\u00e7\u00e3o que est\u00e3o fazendo.\" No esp\u00edrito da transpar\u00eancia e da comunica\u00e7\u00e3o frequente em uma equipe de desenvolvimento, incentivamos os desenvolvedores a confirmar o c\u00f3digo diariamente. Essa abordagem fornece visibilidade ao progresso das funcionalidades e acelera a programa\u00e7\u00e3o em pares em toda a equipe. Aqui est\u00e3o alguns princ\u00edpios a serem considerados: Todos confirmam no reposit\u00f3rio git todos os dias No final do dia, o c\u00f3digo confirmado deve conter testes unit\u00e1rios no m\u00ednimo. Execute a compila\u00e7\u00e3o localmente antes de confirmar para evitar a satura\u00e7\u00e3o do pipeline de Integra\u00e7\u00e3o Cont\u00ednua. Voc\u00ea deve verificar o que causou o erro e tentar resolv\u00ea-lo o mais r\u00e1pido poss\u00edvel, em vez de confirmar o c\u00f3digo. Incentivamos os desenvolvedores a seguir princ\u00edpios de Desenvolvimento Lean . Isolar o trabalho em pequenos peda\u00e7os que se relacionam diretamente com o valor comercial e refatorar incrementalmente. Ambientes Isolados Um dos principais objetivos da valida\u00e7\u00e3o de compila\u00e7\u00e3o \u00e9 isolar e identificar falhas em ambientes de prepara\u00e7\u00e3o e minimizar qualquer interrup\u00e7\u00e3o no tr\u00e1fego de produ\u00e7\u00e3o ao vivo. Nossos testes automatizados de ponta a ponta devem ser executados em um ambiente que reproduza nosso ambiente de produ\u00e7\u00e3o (o m\u00e1ximo poss\u00edvel). Isso inclui vers\u00f5es de software consistent es, SO, simula\u00e7\u00f5es de volume de dados de teste, paridade de tr\u00e1fego de rede com produ\u00e7\u00e3o, etc. Teste em um clone da produ\u00e7\u00e3o O ambiente de produ\u00e7\u00e3o deve ser duplicado em um ambiente de prepara\u00e7\u00e3o (QA e/ou Pr\u00e9-Produ\u00e7\u00e3o) no m\u00ednimo. Atualiza\u00e7\u00f5es de solicita\u00e7\u00e3o de pull acionam lan\u00e7amentos em est\u00e1gios Novas confirma\u00e7\u00f5es relacionadas a uma solicita\u00e7\u00e3o de pull devem acionar uma compila\u00e7\u00e3o/libera\u00e7\u00e3o em um ambiente de integra\u00e7\u00e3o. O ambiente de produ\u00e7\u00e3o deve ser totalmente isolado desse processo. Promover altera\u00e7\u00f5es de infraestrutura em ambientes fixos Altera\u00e7\u00f5es de infraestrutura como c\u00f3digo devem ser testadas em um ambiente de integra\u00e7\u00e3o e promovidas para todos os ambientes de prepara\u00e7\u00e3o, depois migradas para produ\u00e7\u00e3o sem tempo de inatividade para os usu\u00e1rios do sistema. Testando em produ\u00e7\u00e3o Existem v\u00e1rias abordagens para realizar testes automatizados para implanta\u00e7\u00f5es em produ\u00e7\u00e3o com seguran\u00e7a. Algumas dessas abordagens podem incluir: Sinaliza\u00e7\u00e3o de recursos Teste A/B Deslocamento de tr\u00e1fego Acesso do Desenvolvedor aos \u00daltimos Artefatos de Lan\u00e7amento Nosso fluxo de trabalho de DevOps deve permitir que os desenvolvedores obtenham, instalem e executem o execut\u00e1vel do sistema mais recente. Os execut\u00e1veis de lan\u00e7amento devem ser gerados automaticamente como parte de nossos pipelines de CI/CD. Os desenvolvedores podem acessar o execut\u00e1vel mais recente O execut\u00e1vel do sistema mais recente est\u00e1 dispon\u00edvel para todos os desenvolvedores da equipe. Deve haver um local conhecido onde os desenvolvedores possam consultar o artefato de lan\u00e7amento. O artefato de lan\u00e7amento \u00e9 publicado para cada solicita\u00e7\u00e3o de pull ou mesclagem na ramifica\u00e7\u00e3o principal Observabilidade da Integra\u00e7\u00e3o As mudan\u00e7as de estado aplicadas \u00e0 compila\u00e7\u00e3o principal devem estar dispon\u00edveis e ser comunicadas em toda a equipe. Centralizar logs e status de falhas de pipeline de compila\u00e7\u00e3o e lan\u00e7amento \u00e9 essencial para desenvolvedores que investigam compila\u00e7\u00f5es quebradas. Recomendamos integrar Teams ou Slack com as execu\u00e7\u00f5es de pipeline de CI/CD, o que ajuda a manter a equipe constantemente informada sobre falhas e status de candidatos \u00e0 compila\u00e7\u00e3o. Painel de n\u00edvel superior de Integra\u00e7\u00e3o Cont\u00ednua Os provedores modernos de CI t\u00eam a capacidade de consolidar e relatar status de compila\u00e7\u00e3o em um painel espec\u00edfico. Seu painel de CI deve ser capaz de correlacionar uma falha de compila\u00e7\u00e3o com um commit do Git. Emblema de status de compila\u00e7\u00e3o no README do projeto Deve haver um emblema de status de compila\u00e7\u00e3o inclu\u00eddo no README raiz do projeto. Notifica\u00e7\u00f5es de compila\u00e7\u00e3o Seu processo de CI deve ser configurado para enviar notifica\u00e7\u00f5es para plataformas de mensagens como Teams/Slack assim que a compila\u00e7\u00e3o for conclu\u00edda. Recomendamos criar um canal separado para ajudar a consolidar e isolar essas notifica\u00e7\u00f5es. Recursos Melhores Pr\u00e1ticas de Integra\u00e7\u00e3o Cont\u00ednua de Martin Fowler Guia R\u00e1pido de In\u00edcio do Bedrock Guia R\u00e1pido do Cobalt Provedor Azure DevOps do Terraform Pipelines de V\u00e1rios Est\u00e1gios do Azure DevOps Conceitos Chave do Azure Pipeline Ambientes do Azure Pipeline Artefatos no Azure Pipelines Permiss\u00f5es e Fun\u00e7\u00f5es de Seguran\u00e7a do Azure Pipeline Aprova\u00e7\u00f5es e Verifica\u00e7\u00f5es de Ambiente do Azure Guia de In\u00edcio R\u00e1pido do Terraform com Azure Configura\u00e7\u00e3o Remota do Estado do Terraform no Azure Terratest - Framework de Infraestrutura de Testes Unit\u00e1rios e de Integra\u00e7\u00e3o","title":"Valida\u00e7\u00e3o"},{"location":"continuous-integration/CICD/","text":"Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua A Integra\u00e7\u00e3o Cont\u00ednua \u00e9 a pr\u00e1tica de engenharia de frequentemente enviar c\u00f3digo para um reposit\u00f3rio compartilhado, idealmente v\u00e1rias vezes ao dia, e realizar uma compila\u00e7\u00e3o automatizada desse c\u00f3digo. Essas mudan\u00e7as s\u00e3o compiladas junto com outras altera\u00e7\u00f5es simult\u00e2neas no sistema, o que permite a detec\u00e7\u00e3o precoce de problemas de integra\u00e7\u00e3o entre v\u00e1rios desenvolvedores que trabalham em um projeto. Quebras na compila\u00e7\u00e3o devido a falhas de integra\u00e7\u00e3o s\u00e3o tratadas como a quest\u00e3o de maior prioridade para todos os desenvolvedores de uma equipe, e geralmente o trabalho para at\u00e9 que sejam corrigidas. Associada a uma abordagem de teste automatizado, a integra\u00e7\u00e3o cont\u00ednua tamb\u00e9m nos permite testar a compila\u00e7\u00e3o integrada de forma a verificar n\u00e3o apenas se a base de c\u00f3digo ainda \u00e9 compilada corretamente, mas tamb\u00e9m se ainda \u00e9 funcionalmente correta. Isso tamb\u00e9m \u00e9 uma pr\u00e1tica recomendada para a constru\u00e7\u00e3o de sistemas de software robustos e flex\u00edveis. A Entrega Cont\u00ednua leva o conceito de Integra\u00e7\u00e3o Cont\u00ednua ainda mais longe, testando tamb\u00e9m implanta\u00e7\u00f5es da base de c\u00f3digo integrada em uma r\u00e9plica do ambiente em que ser\u00e1 finalmente implantada. Isso nos permite aprender antecipadamente sobre quaisquer problemas operacionais n\u00e3o previstos que surgem de nossas altera\u00e7\u00f5es o mais r\u00e1pido poss\u00edvel e tamb\u00e9m aprender sobre lacunas em nossa cobertura de teste. O objetivo de tudo isso \u00e9 garantir que o branch principal (main) esteja sempre pronto para ser entregue, ou seja, significa que poder\u00edamos, se necess\u00e1rio, pegar uma compila\u00e7\u00e3o do branch principal de nossa base de c\u00f3digo e implant\u00e1-la na produ\u00e7\u00e3o. Se esses conceitos s\u00e3o desconhecidos para voc\u00ea, reserve alguns minutos para ler Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua . Nossa expectativa \u00e9 que a IC/CD deve ser usada em todos os projetos de engenharia que fazemos com nossos clientes e que estamos construindo, testando e implantando cada altera\u00e7\u00e3o que fazemos em qualquer sistema de software que estamos desenvolvendo. Para uma compreens\u00e3o mais profunda de todos esses conceitos, os livros Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua fornecem um conhecimento abrangente. Ferramentas Azure Pipelines Nossa ferramenta na Microsoft tornou f\u00e1cil configurar sistemas de integra\u00e7\u00e3o e entrega como este. Se voc\u00ea n\u00e3o est\u00e1 familiarizado com ela, reserve alguns momentos agora para ler sobre Azure Pipelines (anteriormente VSTS). Para um exemplo pr\u00e1tico de como isso funciona na pr\u00e1tica, voc\u00ea pode ler IC/CD no Kubernetes com VSTS . Jenkins O Jenkins \u00e9 uma das ferramentas mais comumente usadas na comunidade de c\u00f3digo aberto. \u00c9 bem conhecido e possui centenas de plugins para atender a todos os requisitos de compila\u00e7\u00e3o. O Jenkins \u00e9 gratuito, mas requer um servidor dedicado. Voc\u00ea pode criar facilmente uma m\u00e1quina virtual Jenkins usando este modelo . Travis CI O Travis CI pode ser usado gratuitamente em projetos de c\u00f3digo aberto, mas os desenvolvedores devem adquirir um plano empresarial para projetos privados. Este servi\u00e7o \u00e9 ideal para valida\u00e7\u00e3o de PRs no GitHub, pois \u00e9 leve e f\u00e1cil de configurar, sem a necessidade de configura\u00e7\u00e3o de servidor dedicado. Ele tamb\u00e9m suporta uma caracter\u00edstica de matriz de compila\u00e7\u00e3o que permite acelerar o processo de compila\u00e7\u00e3o e teste dividindo-o em partes. CircleCI O CircleCI \u00e9 um servi\u00e7o gratuito para projetos de c\u00f3digo aberto, sem a necessidade de servidor dedicado. Tamb\u00e9m \u00e9 ideal para valida\u00e7\u00e3o de PRs no GitHub. O CircleCI tamb\u00e9m permite fluxos de trabalho, paralelismo e a divis\u00e3o de seus testes em qualquer n\u00famero de cont\u00eaineres com uma ampla variedade de pacotes pr\u00e9-instalados nos cont\u00eaineres de compila\u00e7\u00e3o. AppVeyor O AppVeyor \u00e9 outro servi\u00e7o de IC gratuito para projetos de c\u00f3digo aberto que tamb\u00e9m suporta compila\u00e7\u00f5es baseadas no Windows.","title":"Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua"},{"location":"continuous-integration/CICD/#integracao-continua-e-entrega-continua","text":"A Integra\u00e7\u00e3o Cont\u00ednua \u00e9 a pr\u00e1tica de engenharia de frequentemente enviar c\u00f3digo para um reposit\u00f3rio compartilhado, idealmente v\u00e1rias vezes ao dia, e realizar uma compila\u00e7\u00e3o automatizada desse c\u00f3digo. Essas mudan\u00e7as s\u00e3o compiladas junto com outras altera\u00e7\u00f5es simult\u00e2neas no sistema, o que permite a detec\u00e7\u00e3o precoce de problemas de integra\u00e7\u00e3o entre v\u00e1rios desenvolvedores que trabalham em um projeto. Quebras na compila\u00e7\u00e3o devido a falhas de integra\u00e7\u00e3o s\u00e3o tratadas como a quest\u00e3o de maior prioridade para todos os desenvolvedores de uma equipe, e geralmente o trabalho para at\u00e9 que sejam corrigidas. Associada a uma abordagem de teste automatizado, a integra\u00e7\u00e3o cont\u00ednua tamb\u00e9m nos permite testar a compila\u00e7\u00e3o integrada de forma a verificar n\u00e3o apenas se a base de c\u00f3digo ainda \u00e9 compilada corretamente, mas tamb\u00e9m se ainda \u00e9 funcionalmente correta. Isso tamb\u00e9m \u00e9 uma pr\u00e1tica recomendada para a constru\u00e7\u00e3o de sistemas de software robustos e flex\u00edveis. A Entrega Cont\u00ednua leva o conceito de Integra\u00e7\u00e3o Cont\u00ednua ainda mais longe, testando tamb\u00e9m implanta\u00e7\u00f5es da base de c\u00f3digo integrada em uma r\u00e9plica do ambiente em que ser\u00e1 finalmente implantada. Isso nos permite aprender antecipadamente sobre quaisquer problemas operacionais n\u00e3o previstos que surgem de nossas altera\u00e7\u00f5es o mais r\u00e1pido poss\u00edvel e tamb\u00e9m aprender sobre lacunas em nossa cobertura de teste. O objetivo de tudo isso \u00e9 garantir que o branch principal (main) esteja sempre pronto para ser entregue, ou seja, significa que poder\u00edamos, se necess\u00e1rio, pegar uma compila\u00e7\u00e3o do branch principal de nossa base de c\u00f3digo e implant\u00e1-la na produ\u00e7\u00e3o. Se esses conceitos s\u00e3o desconhecidos para voc\u00ea, reserve alguns minutos para ler Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua . Nossa expectativa \u00e9 que a IC/CD deve ser usada em todos os projetos de engenharia que fazemos com nossos clientes e que estamos construindo, testando e implantando cada altera\u00e7\u00e3o que fazemos em qualquer sistema de software que estamos desenvolvendo. Para uma compreens\u00e3o mais profunda de todos esses conceitos, os livros Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua fornecem um conhecimento abrangente.","title":"Integra\u00e7\u00e3o Cont\u00ednua e Entrega Cont\u00ednua"},{"location":"continuous-integration/CICD/#ferramentas","text":"","title":"Ferramentas"},{"location":"continuous-integration/CICD/#azure-pipelines","text":"Nossa ferramenta na Microsoft tornou f\u00e1cil configurar sistemas de integra\u00e7\u00e3o e entrega como este. Se voc\u00ea n\u00e3o est\u00e1 familiarizado com ela, reserve alguns momentos agora para ler sobre Azure Pipelines (anteriormente VSTS). Para um exemplo pr\u00e1tico de como isso funciona na pr\u00e1tica, voc\u00ea pode ler IC/CD no Kubernetes com VSTS .","title":"Azure Pipelines"},{"location":"continuous-integration/CICD/#jenkins","text":"O Jenkins \u00e9 uma das ferramentas mais comumente usadas na comunidade de c\u00f3digo aberto. \u00c9 bem conhecido e possui centenas de plugins para atender a todos os requisitos de compila\u00e7\u00e3o. O Jenkins \u00e9 gratuito, mas requer um servidor dedicado. Voc\u00ea pode criar facilmente uma m\u00e1quina virtual Jenkins usando este modelo .","title":"Jenkins"},{"location":"continuous-integration/CICD/#travis-ci","text":"O Travis CI pode ser usado gratuitamente em projetos de c\u00f3digo aberto, mas os desenvolvedores devem adquirir um plano empresarial para projetos privados. Este servi\u00e7o \u00e9 ideal para valida\u00e7\u00e3o de PRs no GitHub, pois \u00e9 leve e f\u00e1cil de configurar, sem a necessidade de configura\u00e7\u00e3o de servidor dedicado. Ele tamb\u00e9m suporta uma caracter\u00edstica de matriz de compila\u00e7\u00e3o que permite acelerar o processo de compila\u00e7\u00e3o e teste dividindo-o em partes.","title":"Travis CI"},{"location":"continuous-integration/CICD/#circleci","text":"O CircleCI \u00e9 um servi\u00e7o gratuito para projetos de c\u00f3digo aberto, sem a necessidade de servidor dedicado. Tamb\u00e9m \u00e9 ideal para valida\u00e7\u00e3o de PRs no GitHub. O CircleCI tamb\u00e9m permite fluxos de trabalho, paralelismo e a divis\u00e3o de seus testes em qualquer n\u00famero de cont\u00eaineres com uma ampla variedade de pacotes pr\u00e9-instalados nos cont\u00eaineres de compila\u00e7\u00e3o.","title":"CircleCI"},{"location":"continuous-integration/CICD/#appveyor","text":"O AppVeyor \u00e9 outro servi\u00e7o de IC gratuito para projetos de c\u00f3digo aberto que tamb\u00e9m suporta compila\u00e7\u00f5es baseadas no Windows.","title":"AppVeyor"},{"location":"continuous-integration/inclusive-linting/","text":"Inclus\u00e3o de Linting Como profissionais de software, devemos nos esfor\u00e7ar para promover um ambiente de trabalho inclusivo, o que naturalmente se estende ao c\u00f3digo e \u00e0 documenta\u00e7\u00e3o que escrevemos. \u00c9 importante manter o uso de linguagem inclusiva consistente em todo o projeto ou reposit\u00f3rio. Para alcan\u00e7ar isso, recomendamos o uso de uma ferramenta de an\u00e1lise de texto, como um linter inclusivo, e inclu\u00ed-lo como uma etapa em seus pipelines de Integra\u00e7\u00e3o Cont\u00ednua (CI). O que verificar com o Linter O objetivo principal de um inclusive linter \u00e9 identificar qualquer ocorr\u00eancia de linguagem n\u00e3o inclusiva no c\u00f3digo-fonte (e opcionalmente sugerir algumas alternativas). Palavras ou frases n\u00e3o inclusivas em um projeto podem ser encontradas em qualquer lugar, desde coment\u00e1rios e documenta\u00e7\u00e3o at\u00e9 nomes de vari\u00e1veis. Um inclusive linter pode incluir seu pr\u00f3prio dicion\u00e1rio de palavras e frases n\u00e3o inclusivas \"padr\u00e3o\" para verificar como um bom ponto de partida. Essas ferramentas tamb\u00e9m podem ser personaliz\u00e1veis, oferecendo frequentemente a capacidade de omitir alguns termos e/ou adicionar os seus pr\u00f3prios. A capacidade de adicionar termos adicionais ao seu linter tem o benef\u00edcio adicional de permitir a verifica\u00e7\u00e3o de linguagem sens\u00edvel, al\u00e9m da verifica\u00e7\u00e3o inclusiva. Isso pode evitar que coisas como nomes de clientes ou outras informa\u00e7\u00f5es n\u00e3o p\u00fablicas entrem em seu hist\u00f3rico do Git, por exemplo. Como Come\u00e7ar com um Inclusive Linter woke Um inclusive linter que recomendamos \u00e9 o woke . \u00c9 uma ferramenta CLI agn\u00f3stica a linguagens que detecta linguagem n\u00e3o inclusiva em seu c\u00f3digo-fonte e sugere alternativas. Embora o woke aplique automaticamente um conjunto de regras padr\u00e3o com termos n\u00e3o inclusivos para verificar, voc\u00ea tamb\u00e9m pode aplicar uma configura\u00e7\u00e3o de regra personalizada (por meio de um arquivo YAML) com termos adicionais para verificar. Veja example.yaml para um exemplo de adi\u00e7\u00e3o de regras personalizadas. Executar a ferramenta localmente em um arquivo ou diret\u00f3rio \u00e9 relativamente simples: $ woke test.txt test.txt:2:2-6: ` guys ` pode ser insens\u00edvel, use ` pessoas ` , ` indiv\u00edduos ` em vez disso ( aviso ) * guys ^ woke pode ser executado localmente em sua m\u00e1quina ou sistema CI/CD por meio da CLI e tamb\u00e9m est\u00e1 dispon\u00edvel como duas a\u00e7\u00f5es no GitHub: Executar woke Executar woke com o Reviewdog Para usar a a\u00e7\u00e3o padr\u00e3o \"Run woke\" do GitHub com o conjunto de regras padr\u00e3o em um pipeline de CI: Adicione a a\u00e7\u00e3o woke como uma etapa no arquivo YAML do pipeline de CI do seu projeto: name : ci on : - pull_request jobs : woke : name : woke runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 - name : woke uses : get-woke/woke-action@v0 with : # Faz com que a verifica\u00e7\u00e3o falhe em qualquer regra quebrada fail-on-error : true Execute seu pipeline Veja a sa\u00edda na guia \"A\u00e7\u00f5es\" na visualiza\u00e7\u00e3o principal do reposit\u00f3rio Para obter mais informa\u00e7\u00f5es sobre configura\u00e7\u00e3o adicional e uso, consulte a documenta\u00e7\u00e3o oficial .","title":"Inclus\u00e3o de Linting"},{"location":"continuous-integration/inclusive-linting/#inclusao-de-linting","text":"Como profissionais de software, devemos nos esfor\u00e7ar para promover um ambiente de trabalho inclusivo, o que naturalmente se estende ao c\u00f3digo e \u00e0 documenta\u00e7\u00e3o que escrevemos. \u00c9 importante manter o uso de linguagem inclusiva consistente em todo o projeto ou reposit\u00f3rio. Para alcan\u00e7ar isso, recomendamos o uso de uma ferramenta de an\u00e1lise de texto, como um linter inclusivo, e inclu\u00ed-lo como uma etapa em seus pipelines de Integra\u00e7\u00e3o Cont\u00ednua (CI).","title":"Inclus\u00e3o de Linting"},{"location":"continuous-integration/inclusive-linting/#o-que-verificar-com-o-linter","text":"O objetivo principal de um inclusive linter \u00e9 identificar qualquer ocorr\u00eancia de linguagem n\u00e3o inclusiva no c\u00f3digo-fonte (e opcionalmente sugerir algumas alternativas). Palavras ou frases n\u00e3o inclusivas em um projeto podem ser encontradas em qualquer lugar, desde coment\u00e1rios e documenta\u00e7\u00e3o at\u00e9 nomes de vari\u00e1veis. Um inclusive linter pode incluir seu pr\u00f3prio dicion\u00e1rio de palavras e frases n\u00e3o inclusivas \"padr\u00e3o\" para verificar como um bom ponto de partida. Essas ferramentas tamb\u00e9m podem ser personaliz\u00e1veis, oferecendo frequentemente a capacidade de omitir alguns termos e/ou adicionar os seus pr\u00f3prios. A capacidade de adicionar termos adicionais ao seu linter tem o benef\u00edcio adicional de permitir a verifica\u00e7\u00e3o de linguagem sens\u00edvel, al\u00e9m da verifica\u00e7\u00e3o inclusiva. Isso pode evitar que coisas como nomes de clientes ou outras informa\u00e7\u00f5es n\u00e3o p\u00fablicas entrem em seu hist\u00f3rico do Git, por exemplo.","title":"O que verificar com o Linter"},{"location":"continuous-integration/inclusive-linting/#como-comecar-com-um-inclusive-linter","text":"woke Um inclusive linter que recomendamos \u00e9 o woke . \u00c9 uma ferramenta CLI agn\u00f3stica a linguagens que detecta linguagem n\u00e3o inclusiva em seu c\u00f3digo-fonte e sugere alternativas. Embora o woke aplique automaticamente um conjunto de regras padr\u00e3o com termos n\u00e3o inclusivos para verificar, voc\u00ea tamb\u00e9m pode aplicar uma configura\u00e7\u00e3o de regra personalizada (por meio de um arquivo YAML) com termos adicionais para verificar. Veja example.yaml para um exemplo de adi\u00e7\u00e3o de regras personalizadas. Executar a ferramenta localmente em um arquivo ou diret\u00f3rio \u00e9 relativamente simples: $ woke test.txt test.txt:2:2-6: ` guys ` pode ser insens\u00edvel, use ` pessoas ` , ` indiv\u00edduos ` em vez disso ( aviso ) * guys ^ woke pode ser executado localmente em sua m\u00e1quina ou sistema CI/CD por meio da CLI e tamb\u00e9m est\u00e1 dispon\u00edvel como duas a\u00e7\u00f5es no GitHub: Executar woke Executar woke com o Reviewdog Para usar a a\u00e7\u00e3o padr\u00e3o \"Run woke\" do GitHub com o conjunto de regras padr\u00e3o em um pipeline de CI: Adicione a a\u00e7\u00e3o woke como uma etapa no arquivo YAML do pipeline de CI do seu projeto: name : ci on : - pull_request jobs : woke : name : woke runs-on : ubuntu-latest steps : - name : Checkout uses : actions/checkout@v2 - name : woke uses : get-woke/woke-action@v0 with : # Faz com que a verifica\u00e7\u00e3o falhe em qualquer regra quebrada fail-on-error : true Execute seu pipeline Veja a sa\u00edda na guia \"A\u00e7\u00f5es\" na visualiza\u00e7\u00e3o principal do reposit\u00f3rio Para obter mais informa\u00e7\u00f5es sobre configura\u00e7\u00e3o adicional e uso, consulte a documenta\u00e7\u00e3o oficial .","title":"Como Come\u00e7ar com um Inclusive Linter"},{"location":"continuous-integration/ci-in-data-science/working-with-notebooks/","text":"Data Science Pipeline As Azure DevOps doesn't allow code reviewers to comment directly in Jupyter Notebooks, Data Scientists(DSs) have to convert the notebooks to scripts before they commit and push these files to the repository. This document aims to automate this process in Azure DevOps, so the DSs don't need to execute anything locally. Problem statement A Data Science repository has this folder structure: . \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 00 .ipynb \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 01 .ipynb \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 02 .ipynb \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 03 .ipynb \u2514\u2500\u2500 scripts \u251c\u2500\u2500 Machine Learning Experiments - 00 .py \u251c\u2500\u2500 Machine Learning Experiments - 01 .py \u251c\u2500\u2500 Machine Learning Experiments - 02 .py \u2514\u2500\u2500 Machine Learning Experiments - 03 .py The python files are needed to allow Pull Request reviewers to add comments to the notebooks, they can add comments to the Python scripts and we apply these comments to the notebooks. Since we have to run this process manually before we add files to a commit, this manual process is error prone, e.g. If we create a notebook, generate the script from it, but later make some changes and forget to generate a new script for the changes. Solution One way to avoid this is to create the scripts in the repository from the commit. This document will describe this process. We can add a pipeline with the following steps to the repository to run in ipynb files: Go to the Project Settings -> Repositories -> Security -> User Permissions Add the Build Service in Users the permission to Contribute Create a new pipeline. In the newly created pipeline we add: Trigger to run on ipynb files: trigger: paths: include: - '*.ipynb' - '**/*.ipynb' Select the pool as Linux: pool: vmImage: ubuntu-latest Set the directory where we want to store the scripts: variables: REPO_URL: # Azure DevOps URL in the format: dev.azure.com/<Organization>/<Project>/_git/<RepoName> Now we will start the core of the pipeline: 1. Upgrade pip - script: | python -m pip install --upgrade pip displayName: 'Upgrade pip' 1. Install nbconvert and ipython : - script: | pip install nbconvert ipython displayName: 'install nbconvert & ipython' 1. Install pandoc : - script: | sudo apt install -y pandoc displayName: \"Install pandoc\" 1. Find the notebook files ( ipynb ) in the last commit to the repo and convert it to scripts ( py ): - task: Bash@3 inputs: targetType: 'inline' script: | IPYNB_PATH=($(git diff-tree --no-commit-id --name-only -r $(Build.SourceVersion) | grep '[.]ipynb$')) echo $IPYNB_PATH [ -z \"$IPYNB_PATH\" ] && echo \"Nothing to convert\" || jupyter nbconvert --to script $IPYNB_PATH displayName: \"Convert Notebook to script\" 1. Commit these changes to the repository: - bash: | git config --global user.email \"build@dev.azure.com\" git config --global user.name \"build\" git add . git commit -m 'Convert Jupyter notebooks' || echo \"No changes to commit\" && NO_CHANGES=1 [ -z \"$NO_CHANGES\" ] || git push https://$(System.AccessToken)@$(REPO_URL) HEAD:$(Build.SourceBranchName) displayName: \"Commit notebook to repository\" Now we have a pipeline that will generate the scripts as we commit our notebooks.","title":"Data Science Pipeline"},{"location":"continuous-integration/ci-in-data-science/working-with-notebooks/#data-science-pipeline","text":"As Azure DevOps doesn't allow code reviewers to comment directly in Jupyter Notebooks, Data Scientists(DSs) have to convert the notebooks to scripts before they commit and push these files to the repository. This document aims to automate this process in Azure DevOps, so the DSs don't need to execute anything locally.","title":"Data Science Pipeline"},{"location":"continuous-integration/ci-in-data-science/working-with-notebooks/#problem-statement","text":"A Data Science repository has this folder structure: . \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 00 .ipynb \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 01 .ipynb \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 02 .ipynb \u2502 \u251c\u2500\u2500 Machine Learning Experiments - 03 .ipynb \u2514\u2500\u2500 scripts \u251c\u2500\u2500 Machine Learning Experiments - 00 .py \u251c\u2500\u2500 Machine Learning Experiments - 01 .py \u251c\u2500\u2500 Machine Learning Experiments - 02 .py \u2514\u2500\u2500 Machine Learning Experiments - 03 .py The python files are needed to allow Pull Request reviewers to add comments to the notebooks, they can add comments to the Python scripts and we apply these comments to the notebooks. Since we have to run this process manually before we add files to a commit, this manual process is error prone, e.g. If we create a notebook, generate the script from it, but later make some changes and forget to generate a new script for the changes.","title":"Problem statement"},{"location":"continuous-integration/ci-in-data-science/working-with-notebooks/#solution","text":"One way to avoid this is to create the scripts in the repository from the commit. This document will describe this process. We can add a pipeline with the following steps to the repository to run in ipynb files: Go to the Project Settings -> Repositories -> Security -> User Permissions Add the Build Service in Users the permission to Contribute Create a new pipeline. In the newly created pipeline we add: Trigger to run on ipynb files: trigger: paths: include: - '*.ipynb' - '**/*.ipynb' Select the pool as Linux: pool: vmImage: ubuntu-latest Set the directory where we want to store the scripts: variables: REPO_URL: # Azure DevOps URL in the format: dev.azure.com/<Organization>/<Project>/_git/<RepoName> Now we will start the core of the pipeline: 1. Upgrade pip - script: | python -m pip install --upgrade pip displayName: 'Upgrade pip' 1. Install nbconvert and ipython : - script: | pip install nbconvert ipython displayName: 'install nbconvert & ipython' 1. Install pandoc : - script: | sudo apt install -y pandoc displayName: \"Install pandoc\" 1. Find the notebook files ( ipynb ) in the last commit to the repo and convert it to scripts ( py ): - task: Bash@3 inputs: targetType: 'inline' script: | IPYNB_PATH=($(git diff-tree --no-commit-id --name-only -r $(Build.SourceVersion) | grep '[.]ipynb$')) echo $IPYNB_PATH [ -z \"$IPYNB_PATH\" ] && echo \"Nothing to convert\" || jupyter nbconvert --to script $IPYNB_PATH displayName: \"Convert Notebook to script\" 1. Commit these changes to the repository: - bash: | git config --global user.email \"build@dev.azure.com\" git config --global user.name \"build\" git add . git commit -m 'Convert Jupyter notebooks' || echo \"No changes to commit\" && NO_CHANGES=1 [ -z \"$NO_CHANGES\" ] || git push https://$(System.AccessToken)@$(REPO_URL) HEAD:$(Build.SourceBranchName) displayName: \"Commit notebook to repository\" Now we have a pipeline that will generate the scripts as we commit our notebooks.","title":"Solution"},{"location":"continuous-integration/dev-sec-ops/","text":"DevSecOps The concept of DevSecOps DevSecOps or DevOps security is about introducing security earlier in the life cycle of application development (a.k.a shift-left), thus minimizing the impact of vulnerabilities and bringing security closer to development team. Why By embracing shift-left mentality, DevSecOps encourages organizations to bridge the gap that often exists between development and security teams to the point where many of the security processes are automated and are effectively handled by the development team. DevSecOps Practices This section covers different tools, frameworks and resources allowing introduction of DevSecOps best practices to your project at early stages of development. Topics covered: Credential Scanning - automatically inspecting a project to ensure that no secrets are included in the project's source code. Secrets Rotation - automated process by which the secret, used by the application, is refreshed and replaced by a new secret. Static Code Analysis - analyze source code or compiled versions of code to help find security flaws. Penetration Testing - a simulated attack against your application to check for exploitable vulnerabilities. Container Dependencies Scanning - search for vulnerabilities in container operating systems, language packages and application dependencies.","title":"DevSecOps"},{"location":"continuous-integration/dev-sec-ops/#devsecops","text":"","title":"DevSecOps"},{"location":"continuous-integration/dev-sec-ops/#the-concept-of-devsecops","text":"DevSecOps or DevOps security is about introducing security earlier in the life cycle of application development (a.k.a shift-left), thus minimizing the impact of vulnerabilities and bringing security closer to development team.","title":"The concept of DevSecOps"},{"location":"continuous-integration/dev-sec-ops/#why","text":"By embracing shift-left mentality, DevSecOps encourages organizations to bridge the gap that often exists between development and security teams to the point where many of the security processes are automated and are effectively handled by the development team.","title":"Why"},{"location":"continuous-integration/dev-sec-ops/#devsecops-practices","text":"This section covers different tools, frameworks and resources allowing introduction of DevSecOps best practices to your project at early stages of development. Topics covered: Credential Scanning - automatically inspecting a project to ensure that no secrets are included in the project's source code. Secrets Rotation - automated process by which the secret, used by the application, is refreshed and replaced by a new secret. Static Code Analysis - analyze source code or compiled versions of code to help find security flaws. Penetration Testing - a simulated attack against your application to check for exploitable vulnerabilities. Container Dependencies Scanning - search for vulnerabilities in container operating systems, language packages and application dependencies.","title":"DevSecOps Practices"},{"location":"continuous-integration/dev-sec-ops/azure-devops/service-connection-security/","text":"Azure DevOps Service Connection Security Service Connections are used in Azure DevOps Pipelines to connect to external services, like Azure, GitHub, Docker, Kubernetes, and many other services. Service Connections can be used to authenticate to these external services and to invoke diverse types of commands, like create and update resources in Azure, upload container images to Docker, or deploy applications to Kubernetes. To be able to invoke these commands, Service Connections need to have the right permissions to do so, for most types of Service Connections the permissions can be scoped to a subset of resources to limit the access they have. To improve the principle of least privilege, it's often very common to have separate Service Connections for different environments like Dev/Test/QA/Prod. Secure Service Connection Securing Service Connections can be achieved by using several methods. User permissions can be configured to ensure only the correct users can create, view, use, and manage the Service Connection. Pipeline-level permissions can be configured to ensure only approved YAML pipelines are able to use the Service Connection. Project permissions can be configured to ensure only certain Azure DevOps projects are able to use the Service Connection. After using the above methods, what is secured is who can use the Service Connections. What still isn't secured however, is what can be done with the Service Connections. Because Service Connections have all the necessary permissions in the external services, it is crucial to secure Service Connections so they cannot be misused by accident or by malicious users. An example of this is a Azure DevOps Pipeline that uses a Service Connection to an Azure Resource Group (or entire subscription) to list all resources and then delete those resources. Without the correct security in place, it could be possible to execute this Pipeline, without any validation or reviews being done. pool : vmImage : ubuntu-latest steps : - task : AzureCLI@2 inputs : azureSubscription : 'Production Service Connection' scriptType : 'pscore' scriptLocation : 'inlineScript' inlineScript : | $resources = az resource list foreach ($resource in $resources) { az resource delete --ids $resource.id } Pipeline Security caveat YAML pipelines can be triggered without the need for a pull request, this introduces a security risk. In good practice, Pull Requests and Code Reviews should be used to ensure the code that is being deployed, is being reviewed by a second person and potentially automatically being checked for vulnerabilities and other security issues. However, YAML Pipelines can be executed without the need for a Pull Request and Code Reviews. This allows the (malicious) user to make changes using the Service Connection which would normally require a reviewer. The configuration of when a pipeline should be triggered is specified in the YAML Pipeline itself and therefore a pipeline can be configured to execute on changes in a temporary branch. In this temporary branch, any changes made to the pipeline itself will be executed without being reviewed. If the given pipeline has been granted Pipeline-level permissions to use a specific Service Connection, any command can be executed using that Service Connection, without anyone reviewing the command. Since Service Connections can have a lot of permissions in the external service, executing any pipeline without review could potentially have big consequences. Service Connection Checks To prevent accidental mis-use of Service Connections there are several checks that can be configured. These checks are configured on the Service Connection itself and therefore can only be configured by the owner or administrator of that Service Connection. A user of a certain YAML Pipeline cannot modify these checks since the checks are not defined in the YAML file itself. Configuration can be done in the Approvals and Checks menu on the Service Connection. Branch Control By configuring Branch Control on a Service Connection, you can control that the Service Connection can only be used in a YAML Pipeline if the pipeline is running from a specific branch. By configuring Branch Control to only allow the main branch (and potentially release branches) you can ensure a YAML Pipeline can only use the Service Connection after any changes to that pipeline have been merged into the main branch, and therefore has passed any Pull Requests checks and Code Reviews. As an additional check, Branch Control can verify if Branch Protections (like required Pull Requests and Code Reviews) are actually configured on the allowed branches. With Branch Control in place, in combination with Branch Protections, it is not possible anymore to run any commands against a Service Connection without having multiple persons review the commands. Therefore accidental, or malicious, mis-use of the permissions a Service Connection has is not possible anymore. * Note: When setting a wildcard for the Allowed Branches, anyone could still create a branch matching that wildcard and would be able to use the Service Connection. Using git permissions it can be configured so only administrators are allowed to create certain branches, like release branches.","title":"Azure DevOps Service Connection Security"},{"location":"continuous-integration/dev-sec-ops/azure-devops/service-connection-security/#azure-devops-service-connection-security","text":"Service Connections are used in Azure DevOps Pipelines to connect to external services, like Azure, GitHub, Docker, Kubernetes, and many other services. Service Connections can be used to authenticate to these external services and to invoke diverse types of commands, like create and update resources in Azure, upload container images to Docker, or deploy applications to Kubernetes. To be able to invoke these commands, Service Connections need to have the right permissions to do so, for most types of Service Connections the permissions can be scoped to a subset of resources to limit the access they have. To improve the principle of least privilege, it's often very common to have separate Service Connections for different environments like Dev/Test/QA/Prod.","title":"Azure DevOps Service Connection Security"},{"location":"continuous-integration/dev-sec-ops/azure-devops/service-connection-security/#secure-service-connection","text":"Securing Service Connections can be achieved by using several methods. User permissions can be configured to ensure only the correct users can create, view, use, and manage the Service Connection. Pipeline-level permissions can be configured to ensure only approved YAML pipelines are able to use the Service Connection. Project permissions can be configured to ensure only certain Azure DevOps projects are able to use the Service Connection. After using the above methods, what is secured is who can use the Service Connections. What still isn't secured however, is what can be done with the Service Connections. Because Service Connections have all the necessary permissions in the external services, it is crucial to secure Service Connections so they cannot be misused by accident or by malicious users. An example of this is a Azure DevOps Pipeline that uses a Service Connection to an Azure Resource Group (or entire subscription) to list all resources and then delete those resources. Without the correct security in place, it could be possible to execute this Pipeline, without any validation or reviews being done. pool : vmImage : ubuntu-latest steps : - task : AzureCLI@2 inputs : azureSubscription : 'Production Service Connection' scriptType : 'pscore' scriptLocation : 'inlineScript' inlineScript : | $resources = az resource list foreach ($resource in $resources) { az resource delete --ids $resource.id }","title":"Secure Service Connection"},{"location":"continuous-integration/dev-sec-ops/azure-devops/service-connection-security/#pipeline-security-caveat","text":"YAML pipelines can be triggered without the need for a pull request, this introduces a security risk. In good practice, Pull Requests and Code Reviews should be used to ensure the code that is being deployed, is being reviewed by a second person and potentially automatically being checked for vulnerabilities and other security issues. However, YAML Pipelines can be executed without the need for a Pull Request and Code Reviews. This allows the (malicious) user to make changes using the Service Connection which would normally require a reviewer. The configuration of when a pipeline should be triggered is specified in the YAML Pipeline itself and therefore a pipeline can be configured to execute on changes in a temporary branch. In this temporary branch, any changes made to the pipeline itself will be executed without being reviewed. If the given pipeline has been granted Pipeline-level permissions to use a specific Service Connection, any command can be executed using that Service Connection, without anyone reviewing the command. Since Service Connections can have a lot of permissions in the external service, executing any pipeline without review could potentially have big consequences.","title":"Pipeline Security caveat"},{"location":"continuous-integration/dev-sec-ops/azure-devops/service-connection-security/#service-connection-checks","text":"To prevent accidental mis-use of Service Connections there are several checks that can be configured. These checks are configured on the Service Connection itself and therefore can only be configured by the owner or administrator of that Service Connection. A user of a certain YAML Pipeline cannot modify these checks since the checks are not defined in the YAML file itself. Configuration can be done in the Approvals and Checks menu on the Service Connection.","title":"Service Connection Checks"},{"location":"continuous-integration/dev-sec-ops/azure-devops/service-connection-security/#branch-control","text":"By configuring Branch Control on a Service Connection, you can control that the Service Connection can only be used in a YAML Pipeline if the pipeline is running from a specific branch. By configuring Branch Control to only allow the main branch (and potentially release branches) you can ensure a YAML Pipeline can only use the Service Connection after any changes to that pipeline have been merged into the main branch, and therefore has passed any Pull Requests checks and Code Reviews. As an additional check, Branch Control can verify if Branch Protections (like required Pull Requests and Code Reviews) are actually configured on the allowed branches. With Branch Control in place, in combination with Branch Protections, it is not possible anymore to run any commands against a Service Connection without having multiple persons review the commands. Therefore accidental, or malicious, mis-use of the permissions a Service Connection has is not possible anymore. * Note: When setting a wildcard for the Allowed Branches, anyone could still create a branch matching that wildcard and would be able to use the Service Connection. Using git permissions it can be configured so only administrators are allowed to create certain branches, like release branches.","title":"Branch Control"},{"location":"continuous-integration/dev-sec-ops/dependency-container-scanning/dependency_container_scanning/","text":"Dependency and Container Scanning Dependency and Container scanning is performed in order to search for vulnerabilities in operating systems, language and application packages. Why Dependency and Container Scanning Container images are standard application delivery format in cloud-native environments. Having a broad selection of images from the community, we often choose a community base image, and then add packages that we need to it, which might also come from community sources. Those arbitrary dependencies might introduce vulnerabilities to our image and application. Applying Dependency and Container Scanning Images that contain software with security vulnerabilities become exploitable at runtime. When building an image in your CI pipeline, image scanning must be a requirement for a build to pass. Images that did not pass scanning should never be pushed to your production-accessible container registry. Dependency and Container scanning best practices: Base Image - if your image is built on top of a third-party base image, validate the following: The image comes from a well-known company or open-source group. It is hosted on a reputable registry. The Dockerfile is available, and check for dependencies installed in it. The image is frequently updated - old images might not contain the latest security updates. Remove Non-Essential Software - Start with a minimal base image and install only the tools, libraries and configuration files that are required by your application. Avoid installing the following tools or remove them if present: - Network tools and clients: e.g., wget, curl, netcat, ssh. - Shells: e.g. sh, bash. Note that removing shells also prevents the use of shell scripts at runtime. Instead, use an executable when possible. - Compilers and debuggers. These should be used only in build and development containers, but never in production containers. Container images should be immutable - download and include all the required dependencies during the image build. Scan for vulnerabilities in software dependencies - today there is likely no software project without some form of external libraries, dependencies or open source. While it allows the development team to focus on their application code, the dependency brings forth an expected downside where the security posture of the real application is now resting on it. To detect vulnerabilities contained within a project\u2019s dependencies use container scanning tools which as part of their analysis scan the software dependencies (see \"Dependency and Container Scanning Frameworks and Tools\"). Dependency and Container Scanning Frameworks and Tools Trivy - a simple and comprehensive vulnerability scanner for containers (doesn't support Windows containers) Aqua - dependency and container scanning for applications running on AKS, ACI and Windows Containers. Has an integration with AzDO pipelines. Dependency-Check Plugin for SonarQube - OnPrem dependency scanning Mend (previously WhiteSource) - Open Source Scanning Software Conclusion A powerful technology such as containers should be used carefully. Install the minimal requirements needed for your application, be aware of the software dependencies your application is using and make sure to maintain it over time by using container and dependencies scanning tools.","title":"Dependency and Container Scanning"},{"location":"continuous-integration/dev-sec-ops/dependency-container-scanning/dependency_container_scanning/#dependency-and-container-scanning","text":"Dependency and Container scanning is performed in order to search for vulnerabilities in operating systems, language and application packages.","title":"Dependency and Container Scanning"},{"location":"continuous-integration/dev-sec-ops/dependency-container-scanning/dependency_container_scanning/#why-dependency-and-container-scanning","text":"Container images are standard application delivery format in cloud-native environments. Having a broad selection of images from the community, we often choose a community base image, and then add packages that we need to it, which might also come from community sources. Those arbitrary dependencies might introduce vulnerabilities to our image and application.","title":"Why Dependency and Container Scanning"},{"location":"continuous-integration/dev-sec-ops/dependency-container-scanning/dependency_container_scanning/#applying-dependency-and-container-scanning","text":"Images that contain software with security vulnerabilities become exploitable at runtime. When building an image in your CI pipeline, image scanning must be a requirement for a build to pass. Images that did not pass scanning should never be pushed to your production-accessible container registry. Dependency and Container scanning best practices: Base Image - if your image is built on top of a third-party base image, validate the following: The image comes from a well-known company or open-source group. It is hosted on a reputable registry. The Dockerfile is available, and check for dependencies installed in it. The image is frequently updated - old images might not contain the latest security updates. Remove Non-Essential Software - Start with a minimal base image and install only the tools, libraries and configuration files that are required by your application. Avoid installing the following tools or remove them if present: - Network tools and clients: e.g., wget, curl, netcat, ssh. - Shells: e.g. sh, bash. Note that removing shells also prevents the use of shell scripts at runtime. Instead, use an executable when possible. - Compilers and debuggers. These should be used only in build and development containers, but never in production containers. Container images should be immutable - download and include all the required dependencies during the image build. Scan for vulnerabilities in software dependencies - today there is likely no software project without some form of external libraries, dependencies or open source. While it allows the development team to focus on their application code, the dependency brings forth an expected downside where the security posture of the real application is now resting on it. To detect vulnerabilities contained within a project\u2019s dependencies use container scanning tools which as part of their analysis scan the software dependencies (see \"Dependency and Container Scanning Frameworks and Tools\").","title":"Applying Dependency and Container Scanning"},{"location":"continuous-integration/dev-sec-ops/dependency-container-scanning/dependency_container_scanning/#dependency-and-container-scanning-frameworks-and-tools","text":"Trivy - a simple and comprehensive vulnerability scanner for containers (doesn't support Windows containers) Aqua - dependency and container scanning for applications running on AKS, ACI and Windows Containers. Has an integration with AzDO pipelines. Dependency-Check Plugin for SonarQube - OnPrem dependency scanning Mend (previously WhiteSource) - Open Source Scanning Software","title":"Dependency and Container Scanning Frameworks and Tools"},{"location":"continuous-integration/dev-sec-ops/dependency-container-scanning/dependency_container_scanning/#conclusion","text":"A powerful technology such as containers should be used carefully. Install the minimal requirements needed for your application, be aware of the software dependencies your application is using and make sure to maintain it over time by using container and dependencies scanning tools.","title":"Conclusion"},{"location":"continuous-integration/dev-sec-ops/penetration-testing/penetration_testing/","text":"Penetration Testing A penetration test is a simulated attack against your application to check for exploitable security issues. Why Penetration Testing Penetration testing performed on a running application. As such, it tests the application E2E with all of its layers. It's output is a real simulated attack on the application that succeeded, therefore it is a critical issue in your application and should be addressed as soon as possible. Applying Penetration Testing Many organizations perform manual penetration testing. But new vulnerabilities found every day. Therefore, it is a good practice to have an automated penetration testing performed. To achieve this automation use penetration testing tools to uncover vulnerabilities, such as unsanitized inputs that are susceptible to code injection attacks. Insights provided by the penetration test can then be used to fine-tune your WAF security policies and patch detected vulnerabilities. Penetration Testing Frameworks and Tools OWASP Zed Attack Proxy (ZAP) - OWASP penetration testing tool for web applications. Conclusion Penetration testing is essential to check for vulnerabilities in your application and protect it from simulated attacks. Insights provided by Penetration testing can identify weak spots in an organization's security posture, as well as measure the compliance of its security policy, test the staff's awareness of security issues and determine whether -- and how -- the organization would be subject to security disasters.","title":"Penetration Testing"},{"location":"continuous-integration/dev-sec-ops/penetration-testing/penetration_testing/#penetration-testing","text":"A penetration test is a simulated attack against your application to check for exploitable security issues.","title":"Penetration Testing"},{"location":"continuous-integration/dev-sec-ops/penetration-testing/penetration_testing/#why-penetration-testing","text":"Penetration testing performed on a running application. As such, it tests the application E2E with all of its layers. It's output is a real simulated attack on the application that succeeded, therefore it is a critical issue in your application and should be addressed as soon as possible.","title":"Why Penetration Testing"},{"location":"continuous-integration/dev-sec-ops/penetration-testing/penetration_testing/#applying-penetration-testing","text":"Many organizations perform manual penetration testing. But new vulnerabilities found every day. Therefore, it is a good practice to have an automated penetration testing performed. To achieve this automation use penetration testing tools to uncover vulnerabilities, such as unsanitized inputs that are susceptible to code injection attacks. Insights provided by the penetration test can then be used to fine-tune your WAF security policies and patch detected vulnerabilities.","title":"Applying Penetration Testing"},{"location":"continuous-integration/dev-sec-ops/penetration-testing/penetration_testing/#penetration-testing-frameworks-and-tools","text":"OWASP Zed Attack Proxy (ZAP) - OWASP penetration testing tool for web applications.","title":"Penetration Testing Frameworks and Tools"},{"location":"continuous-integration/dev-sec-ops/penetration-testing/penetration_testing/#conclusion","text":"Penetration testing is essential to check for vulnerabilities in your application and protect it from simulated attacks. Insights provided by Penetration testing can identify weak spots in an organization's security posture, as well as measure the compliance of its security policy, test the staff's awareness of security issues and determine whether -- and how -- the organization would be subject to security disasters.","title":"Conclusion"},{"location":"continuous-integration/dev-sec-ops/secret-management/credential_scanning/","text":"Credential Scanning Credential scanning is the practice of automatically inspecting a project to ensure that no secrets are included in the project's source code. Secrets include database passwords, storage connection strings, admin logins, service principals, etc. Why Credential scanning Including secrets in a project's source code is a significant risk, as it might make those secrets available to unwanted parties. Even if it seems that the source code is accessible to the same people who are privy to the secrets, this situation is likely to change as the project grows. Spreading secrets in different places makes them harder to manage, access control, and revoke efficiently. Secrets that are committed to source control are also harder to discard of, since they will persist in the source's history. Another consideration is that coupling the project's code to its infrastructure and deployment specifics is limiting and considered a bad practice. From a software design perspective, the code should be independent of the runtime configuration that will be used to run it, and that runtime configuration includes secrets. As such, there should be a clear boundary between code and secrets: secrets should be managed outside of the source code (read more here ) and credential scanning should be employed to ensure that this boundary is never violated. Applying Credential Scanning Ideally, credential scanning should be run as part of a developer's workflow (e.g. via a git pre-commit hook ), however, to protect against developer error, credential scanning must also be enforced as part of the continuous integration process to ensure that no credentials ever get merged to a project's main branch. To implement credential scanning for a project, consider the following: Store secrets in an external secure store that is meant to store sensitive information Use secrets scanning tools to asses your repositories current state by scanning it's full history for secrets Incorporate an automated secrets scanning tool into your CI pipeline to detect unintentional committing of secrets Avoid git add . commands on git Add sensitive files to .gitignore Credential Scanning Frameworks and Tools Recipes and Scenarios- detect-secrets is an aptly named module for detecting secrets within a code base. Use detect-secrets inside Azure DevOps Pipeline Microsoft Security Code Analysis extension Additional Tools - CodeQL \u2013 GitHub security. CodeQL lets you query code as if it was data. Write a query to find all variants of a vulnerability Git-secrets - Prevents you from committing passwords and other sensitive information to a git repository. Conclusion Secret management is essential to every project. Storing secrets in external secrets store and incorporating this mindset into your workflow will improve your security posture and will result in cleaner code.","title":"Credential Scanning"},{"location":"continuous-integration/dev-sec-ops/secret-management/credential_scanning/#credential-scanning","text":"Credential scanning is the practice of automatically inspecting a project to ensure that no secrets are included in the project's source code. Secrets include database passwords, storage connection strings, admin logins, service principals, etc.","title":"Credential Scanning"},{"location":"continuous-integration/dev-sec-ops/secret-management/credential_scanning/#why-credential-scanning","text":"Including secrets in a project's source code is a significant risk, as it might make those secrets available to unwanted parties. Even if it seems that the source code is accessible to the same people who are privy to the secrets, this situation is likely to change as the project grows. Spreading secrets in different places makes them harder to manage, access control, and revoke efficiently. Secrets that are committed to source control are also harder to discard of, since they will persist in the source's history. Another consideration is that coupling the project's code to its infrastructure and deployment specifics is limiting and considered a bad practice. From a software design perspective, the code should be independent of the runtime configuration that will be used to run it, and that runtime configuration includes secrets. As such, there should be a clear boundary between code and secrets: secrets should be managed outside of the source code (read more here ) and credential scanning should be employed to ensure that this boundary is never violated.","title":"Why Credential scanning"},{"location":"continuous-integration/dev-sec-ops/secret-management/credential_scanning/#applying-credential-scanning","text":"Ideally, credential scanning should be run as part of a developer's workflow (e.g. via a git pre-commit hook ), however, to protect against developer error, credential scanning must also be enforced as part of the continuous integration process to ensure that no credentials ever get merged to a project's main branch. To implement credential scanning for a project, consider the following: Store secrets in an external secure store that is meant to store sensitive information Use secrets scanning tools to asses your repositories current state by scanning it's full history for secrets Incorporate an automated secrets scanning tool into your CI pipeline to detect unintentional committing of secrets Avoid git add . commands on git Add sensitive files to .gitignore","title":"Applying Credential Scanning"},{"location":"continuous-integration/dev-sec-ops/secret-management/credential_scanning/#credential-scanning-frameworks-and-tools","text":"Recipes and Scenarios- detect-secrets is an aptly named module for detecting secrets within a code base. Use detect-secrets inside Azure DevOps Pipeline Microsoft Security Code Analysis extension Additional Tools - CodeQL \u2013 GitHub security. CodeQL lets you query code as if it was data. Write a query to find all variants of a vulnerability Git-secrets - Prevents you from committing passwords and other sensitive information to a git repository.","title":"Credential Scanning Frameworks and Tools"},{"location":"continuous-integration/dev-sec-ops/secret-management/credential_scanning/#conclusion","text":"Secret management is essential to every project. Storing secrets in external secrets store and incorporating this mindset into your workflow will improve your security posture and will result in cleaner code.","title":"Conclusion"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/","text":"Secrets Rotation Secret rotation is the process of refreshing the secrets that are used by the application. The best way to authenticate to Azure services is by using a managed identity, but there are some scenarios where that isn't an option. In those cases, access keys or secrets are used. You should periodically rotate access keys or secrets. Why Secrets Rotation Secrets are an asset and as such have a potential to be leaked or stolen. By rotating the secrets, we are revoking any secrets that may have been compromised. Therefore, secrets should be rotated frequently. Managed Identity Azure Managed identities are automatically issues by Azure in order to identify individual resources, and can be used for authentication in place of secrets and passwords. The appeal in using Managed Identities is the elimination of management of secrets and credentials. They are not required on developers machines or checked into source control, and they don't need to be rotated. Managed identities are considered safer than the alternatives and is the recommended choice. Applying Secrets Rotation If Azure Managed Identity can't be used. This and the following sections will explain how rotation of secrets can be achieved: To promote frequent rotation of a secret - define an automated periodic secret rotation process. The secret rotation process might result in a downtime when the application is restarted to introduce the new secret. A common solution for that is to have two versions of secret available, also referred to as Blue/Green Secret rotation. By having a second secret at hand, we can start a second instance of the application with that secret before the previous secret is revoked, thus avoiding any downtime. Secrets Rotation Frameworks and Tools For rotation of a secret for resources that use one set of authentication credentials click here For rotation of a secret for resources that have two sets of authentication credentials click here Conclusion Refreshing secrets is important to ensure that your secret stays a secret without causing downtime to your application.","title":"Secrets Rotation"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/#secrets-rotation","text":"Secret rotation is the process of refreshing the secrets that are used by the application. The best way to authenticate to Azure services is by using a managed identity, but there are some scenarios where that isn't an option. In those cases, access keys or secrets are used. You should periodically rotate access keys or secrets.","title":"Secrets Rotation"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/#why-secrets-rotation","text":"Secrets are an asset and as such have a potential to be leaked or stolen. By rotating the secrets, we are revoking any secrets that may have been compromised. Therefore, secrets should be rotated frequently.","title":"Why Secrets Rotation"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/#managed-identity","text":"Azure Managed identities are automatically issues by Azure in order to identify individual resources, and can be used for authentication in place of secrets and passwords. The appeal in using Managed Identities is the elimination of management of secrets and credentials. They are not required on developers machines or checked into source control, and they don't need to be rotated. Managed identities are considered safer than the alternatives and is the recommended choice.","title":"Managed Identity"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/#applying-secrets-rotation","text":"If Azure Managed Identity can't be used. This and the following sections will explain how rotation of secrets can be achieved: To promote frequent rotation of a secret - define an automated periodic secret rotation process. The secret rotation process might result in a downtime when the application is restarted to introduce the new secret. A common solution for that is to have two versions of secret available, also referred to as Blue/Green Secret rotation. By having a second secret at hand, we can start a second instance of the application with that secret before the previous secret is revoked, thus avoiding any downtime.","title":"Applying Secrets Rotation"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/#secrets-rotation-frameworks-and-tools","text":"For rotation of a secret for resources that use one set of authentication credentials click here For rotation of a secret for resources that have two sets of authentication credentials click here","title":"Secrets Rotation Frameworks and Tools"},{"location":"continuous-integration/dev-sec-ops/secret-management/secrets_rotation/#conclusion","text":"Refreshing secrets is important to ensure that your secret stays a secret without causing downtime to your application.","title":"Conclusion"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets-ado/","text":"Running detect-secrets in Azure DevOps Pipelines Overview In this article, you can find information on how to integrate YELP detect-secrets into your Azure DevOps Pipeline. The proposed code can be part of the classic CI process or (preferred way) build validation for PRs before merging to the main branch. Azure DevOps Pipeline Proposed Azure DevOps Pipeline contains multiple steps described below: Set Python 3 as default Install detect-secrets using pip Run detect-secrets tool Publish results in the Pipeline Artifact NOTE: It's an optional step, but for future investigation .json file with results may be helpful. Analyzing detect-secrets results NOTE: This step does a simple analysis of the .json file. If any secret has been detected, then break the build with exit code 1. NOTE: The below example has 2 jobs: for Linux and Windows agents. You do not have to use both jobs - just adjust the pipeline to your needs. NOTE: Windows example does not use the latest version of detect-secrets. It is related to the bug in the detect-secret tool (see more in Issue#452 ). It is highly recommended to monitor the fix for the issue and use the latest version if possible by removing version tag ==1.0.3 in the pip install command. trigger : - none jobs : - job : ubuntu displayName : \"detect-secrets on Ubuntu Linux agent\" pool : vmImage : ubuntu-latest steps : - task : UsePythonVersion@0 displayName : \"Set Python 3 as default\" inputs : versionSpec : \"3\" addToPath : true architecture : \"x64\" - bash : pip install detect-secrets displayName : \"Install detect-secrets using pip\" - bash : | detect-secrets --version detect-secrets scan --all-files --force-use-all-plugins --exclude-files FETCH_HEAD > $(Pipeline.Workspace)/detect-secrets.json displayName : \"Run detect-secrets tool\" - task : PublishPipelineArtifact@1 displayName : \"Publish results in the Pipeline Artifact\" inputs : targetPath : \"$(Pipeline.Workspace)/detect-secrets.json\" artifact : \"detect-secrets-ubuntu\" publishLocation : \"pipeline\" - bash : | dsjson=$(cat $(Pipeline.Workspace)/detect-secrets.json) echo \"${dsjson}\" count=$(echo \"${dsjson}\" | jq -c -r '.results | length') if [ $count -gt 0 ]; then msg=\"Secrets were detected in code. ${count} file(s) affected.\" echo \"##vso[task.logissue type=error]${msg}\" echo \"##vso[task.complete result=Failed;]${msg}.\" else echo \"##vso[task.complete result=Succeeded;]No secrets detected.\" fi displayName : \"Analyzing detect-secrets results\" - job : windows displayName : \"detect-secrets on Windows agent\" pool : vmImage : windows-latest steps : - task : UsePythonVersion@0 displayName : \"Set Python 3 as default\" inputs : versionSpec : \"3\" addToPath : true architecture : \"x64\" - script : pip install detect-secrets==1.0.3 displayName : \"Install detect-secrets using pip\" - script : | detect-secrets --version detect-secrets scan --all-files --force-use-all-plugins > $(Pipeline.Workspace)/detect-secrets.json displayName : \"Run detect-secrets tool\" - task : PublishPipelineArtifact@1 displayName : \"Publish results in the Pipeline Artifact\" inputs : targetPath : \"$(Pipeline.Workspace)/detect-secrets.json\" artifact : \"detect-secrets-windows\" publishLocation : \"pipeline\" - pwsh : | $dsjson = Get-Content $(Pipeline.Workspace)/detect-secrets.json Write-Output $dsjson $dsObj = $dsjson | ConvertFrom-Json $count = ($dsObj.results | Get-Member -MemberType NoteProperty).Count if ($count -gt 0) { $msg = \"Secrets were detected in code. $count file(s) affected. \" Write-Host \"##vso[task.logissue type=error]$msg\" Write-Host \"##vso[task.complete result=Failed;]$msg\" } else { Write-Host \"##vso[task.complete result=Succeeded;]No secrets detected.\" } displayName : \"Analyzing detect-secrets results\"","title":"Running detect-secrets in Azure DevOps Pipelines"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets-ado/#running-detect-secrets-in-azure-devops-pipelines","text":"","title":"Running detect-secrets in Azure DevOps Pipelines"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets-ado/#overview","text":"In this article, you can find information on how to integrate YELP detect-secrets into your Azure DevOps Pipeline. The proposed code can be part of the classic CI process or (preferred way) build validation for PRs before merging to the main branch.","title":"Overview"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets-ado/#azure-devops-pipeline","text":"Proposed Azure DevOps Pipeline contains multiple steps described below: Set Python 3 as default Install detect-secrets using pip Run detect-secrets tool Publish results in the Pipeline Artifact NOTE: It's an optional step, but for future investigation .json file with results may be helpful. Analyzing detect-secrets results NOTE: This step does a simple analysis of the .json file. If any secret has been detected, then break the build with exit code 1. NOTE: The below example has 2 jobs: for Linux and Windows agents. You do not have to use both jobs - just adjust the pipeline to your needs. NOTE: Windows example does not use the latest version of detect-secrets. It is related to the bug in the detect-secret tool (see more in Issue#452 ). It is highly recommended to monitor the fix for the issue and use the latest version if possible by removing version tag ==1.0.3 in the pip install command. trigger : - none jobs : - job : ubuntu displayName : \"detect-secrets on Ubuntu Linux agent\" pool : vmImage : ubuntu-latest steps : - task : UsePythonVersion@0 displayName : \"Set Python 3 as default\" inputs : versionSpec : \"3\" addToPath : true architecture : \"x64\" - bash : pip install detect-secrets displayName : \"Install detect-secrets using pip\" - bash : | detect-secrets --version detect-secrets scan --all-files --force-use-all-plugins --exclude-files FETCH_HEAD > $(Pipeline.Workspace)/detect-secrets.json displayName : \"Run detect-secrets tool\" - task : PublishPipelineArtifact@1 displayName : \"Publish results in the Pipeline Artifact\" inputs : targetPath : \"$(Pipeline.Workspace)/detect-secrets.json\" artifact : \"detect-secrets-ubuntu\" publishLocation : \"pipeline\" - bash : | dsjson=$(cat $(Pipeline.Workspace)/detect-secrets.json) echo \"${dsjson}\" count=$(echo \"${dsjson}\" | jq -c -r '.results | length') if [ $count -gt 0 ]; then msg=\"Secrets were detected in code. ${count} file(s) affected.\" echo \"##vso[task.logissue type=error]${msg}\" echo \"##vso[task.complete result=Failed;]${msg}.\" else echo \"##vso[task.complete result=Succeeded;]No secrets detected.\" fi displayName : \"Analyzing detect-secrets results\" - job : windows displayName : \"detect-secrets on Windows agent\" pool : vmImage : windows-latest steps : - task : UsePythonVersion@0 displayName : \"Set Python 3 as default\" inputs : versionSpec : \"3\" addToPath : true architecture : \"x64\" - script : pip install detect-secrets==1.0.3 displayName : \"Install detect-secrets using pip\" - script : | detect-secrets --version detect-secrets scan --all-files --force-use-all-plugins > $(Pipeline.Workspace)/detect-secrets.json displayName : \"Run detect-secrets tool\" - task : PublishPipelineArtifact@1 displayName : \"Publish results in the Pipeline Artifact\" inputs : targetPath : \"$(Pipeline.Workspace)/detect-secrets.json\" artifact : \"detect-secrets-windows\" publishLocation : \"pipeline\" - pwsh : | $dsjson = Get-Content $(Pipeline.Workspace)/detect-secrets.json Write-Output $dsjson $dsObj = $dsjson | ConvertFrom-Json $count = ($dsObj.results | Get-Member -MemberType NoteProperty).Count if ($count -gt 0) { $msg = \"Secrets were detected in code. $count file(s) affected. \" Write-Host \"##vso[task.logissue type=error]$msg\" Write-Host \"##vso[task.complete result=Failed;]$msg\" } else { Write-Host \"##vso[task.complete result=Succeeded;]No secrets detected.\" } displayName : \"Analyzing detect-secrets results\"","title":"Azure DevOps Pipeline"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets/","text":"Credential Scanning Tool: detect-secrets Background The detect-secrets tool is an open source project that uses heuristics and rules to scan for a wide range of secrets. We can extend the tool with custom rules and heuristics via a simple Python plugin API . Unlike other credential scanning tools, detect-secrets does not attempt to check a project's entire git history when invoked, but instead scans the project's current state. This means that the tool runs quickly which makes it ideal for use in continuous integration pipelines. detect-secrets employs the concept of a \"baseline file\", i.e. a list of known secrets already present in the repository, and we can configure it to ignore any of these pre-existing secrets when running. This makes it easy to gradually introduce the tool into a pre-existing project. The baseline file also provides a simple and convenient way of handling false positives. We can white-list the false positive in the baseline file to ignore it on future invocations of the tool. Setup # install system dependencies: diff, jq, python3 (if on Linux-based OS) apt-get install -y diffutils jq python3 python3-pip # install system dependencies: diff, jq, python3 (if on Windows) winget install Python.Python.3 choco install diffutils jq -y # install the detect-secrets tool python3 -m pip install detect-secrets # run the tool to establish a list of known secrets # review this file thoroughly and check it into the repository detect-secrets scan > .secrets.baseline Pre-commit hook It is recommended to use detect-secrets in your development environment as a Git pre-commit hook. First, follow the pre-commit installation instructions to install the tool in your development environment. Then, add the following to your .pre-commit-config.yaml : repos : - repo : https://github.com/Yelp/detect-secrets rev : v1.4.0 hooks : - id : detect-secrets args : [ '--baseline' , '.secrets.baseline' ] Usage in CI pipelines # backup the list of known secrets cp .secrets.baseline .secrets.new # find all the secrets in the repository detect-secrets scan --baseline .secrets.new $( find . -type f ! -name '.secrets.*' ! -path '*/.git*' ) # if there is any difference between the known and newly detected secrets, break the build list_secrets () { jq -r '.results | keys[] as $key | \"\\($key),\\(.[$key] | .[] | .hashed_secret)\"' \" $1 \" | sort ; } if ! diff < ( list_secrets .secrets.baseline ) < ( list_secrets .secrets.new ) > & 2 ; then echo \"Detected new secrets in the repo\" > & 2 exit 1 fi","title":"Credential Scanning Tool: detect-secrets"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets/#credential-scanning-tool-detect-secrets","text":"","title":"Credential Scanning Tool: detect-secrets"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets/#background","text":"The detect-secrets tool is an open source project that uses heuristics and rules to scan for a wide range of secrets. We can extend the tool with custom rules and heuristics via a simple Python plugin API . Unlike other credential scanning tools, detect-secrets does not attempt to check a project's entire git history when invoked, but instead scans the project's current state. This means that the tool runs quickly which makes it ideal for use in continuous integration pipelines. detect-secrets employs the concept of a \"baseline file\", i.e. a list of known secrets already present in the repository, and we can configure it to ignore any of these pre-existing secrets when running. This makes it easy to gradually introduce the tool into a pre-existing project. The baseline file also provides a simple and convenient way of handling false positives. We can white-list the false positive in the baseline file to ignore it on future invocations of the tool.","title":"Background"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets/#setup","text":"# install system dependencies: diff, jq, python3 (if on Linux-based OS) apt-get install -y diffutils jq python3 python3-pip # install system dependencies: diff, jq, python3 (if on Windows) winget install Python.Python.3 choco install diffutils jq -y # install the detect-secrets tool python3 -m pip install detect-secrets # run the tool to establish a list of known secrets # review this file thoroughly and check it into the repository detect-secrets scan > .secrets.baseline","title":"Setup"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets/#pre-commit-hook","text":"It is recommended to use detect-secrets in your development environment as a Git pre-commit hook. First, follow the pre-commit installation instructions to install the tool in your development environment. Then, add the following to your .pre-commit-config.yaml : repos : - repo : https://github.com/Yelp/detect-secrets rev : v1.4.0 hooks : - id : detect-secrets args : [ '--baseline' , '.secrets.baseline' ]","title":"Pre-commit hook"},{"location":"continuous-integration/dev-sec-ops/secret-management/recipes/detect-secrets/#usage-in-ci-pipelines","text":"# backup the list of known secrets cp .secrets.baseline .secrets.new # find all the secrets in the repository detect-secrets scan --baseline .secrets.new $( find . -type f ! -name '.secrets.*' ! -path '*/.git*' ) # if there is any difference between the known and newly detected secrets, break the build list_secrets () { jq -r '.results | keys[] as $key | \"\\($key),\\(.[$key] | .[] | .hashed_secret)\"' \" $1 \" | sort ; } if ! diff < ( list_secrets .secrets.baseline ) < ( list_secrets .secrets.new ) > & 2 ; then echo \"Detected new secrets in the repo\" > & 2 exit 1 fi","title":"Usage in CI pipelines"},{"location":"continuous-integration/dev-sec-ops/static-code-analysis/static_code_analysis/","text":"Static Code Analysis Static code analysis is a method of detecting security issues by examining the source code of the application. Why Static Code Analysis Compared to code reviews, Static code analysis tools are more fast, accurate and through. As it operates on the source code itself, it is a very early indicator for issues, and coding errors found earlier are less costly to fix. Applying Static Code Analysis Static Code Analysis should be integrated in your build process. There are many tools available for Static Code Analysis, choose the ones that meet your programming language and development techniques. Static Code Analysis Frameworks and Tools SonarCloud - static code analysis with cloud-based software as a service product. OWASP Source code Analysis - OWASP recommendations for source code analysis tools Conclusion Static code analysis is essential to identify potential problems and security issues in the code. It allows you to detect bugs and security issues at an early stage.","title":"Static Code Analysis"},{"location":"continuous-integration/dev-sec-ops/static-code-analysis/static_code_analysis/#static-code-analysis","text":"Static code analysis is a method of detecting security issues by examining the source code of the application.","title":"Static Code Analysis"},{"location":"continuous-integration/dev-sec-ops/static-code-analysis/static_code_analysis/#why-static-code-analysis","text":"Compared to code reviews, Static code analysis tools are more fast, accurate and through. As it operates on the source code itself, it is a very early indicator for issues, and coding errors found earlier are less costly to fix.","title":"Why Static Code Analysis"},{"location":"continuous-integration/dev-sec-ops/static-code-analysis/static_code_analysis/#applying-static-code-analysis","text":"Static Code Analysis should be integrated in your build process. There are many tools available for Static Code Analysis, choose the ones that meet your programming language and development techniques.","title":"Applying Static Code Analysis"},{"location":"continuous-integration/dev-sec-ops/static-code-analysis/static_code_analysis/#static-code-analysis-frameworks-and-tools","text":"SonarCloud - static code analysis with cloud-based software as a service product. OWASP Source code Analysis - OWASP recommendations for source code analysis tools","title":"Static Code Analysis Frameworks and Tools"},{"location":"continuous-integration/dev-sec-ops/static-code-analysis/static_code_analysis/#conclusion","text":"Static code analysis is essential to identify potential problems and security issues in the code. It allows you to detect bugs and security issues at an early stage.","title":"Conclusion"},{"location":"continuous-integration/devcontainers/","text":"Reusing dev containers within a pipeline Given a repository with a local development container aka dev container that contains all the tooling required for development, would it make sense to reuse that container for running the tooling in the Continuous Integration pipelines? Options for building devcontainers within pipeline There are three ways to build devcontainers within pipeline: With GitHub - devcontainers/ci builds the container with the devcontainer.json . Example here: devcontainers/ci \u00b7 Getting Started . With GitHub - devcontainers/cli , which is the same as the above, but using the underlying CLI directly without tasks. Building the DockerFile with docker build . This option excludes all configuration/features specified within the devcontainer.json . Considered Options Run CI pipelines in native environment Run CI pipelines in the dev container via building image locally Run CI pipelines in the dev container with a container registry Here are below pros and cons for both approaches: Run CI pipelines in native environment Pros Cons Can use any pipeline tasks available Need to keep two sets of tooling and their versions in sync No container registry Can take some time to start, based on tools/dependencies required Agent will always be up to date with security patches The dev container should always be built within each run of the CI pipeline, to verify the changes within the branch haven't broken anything Run CI pipelines in the dev container without image caching Pros Cons Utilities scripts will work out of the box Need to rebuild the container for each run, given that there may be changes within the branch being built Rules used (for linting or unit tests) will be the same on the CI Not everything in the container is needed for the CI pipeline\u00b9 No surprise for the developers, local outputs (of linting for instance) will be the same in the CI Some pipeline tasks will not be available All tooling and their versions defined in a single place Building the image for each pipeline run is slow\u00b2 Tools/dependencies are already present The dev container is being tested to include all new tooling in addition to not being broken \u00b9: container size can be reduces by exporting the layer that contains only the tooling needed for the CI pipeline \u00b2: could be mitigated via adding image caching without using a container registry Run CI pipelines in the dev container with image registry Pros Cons Utilities scripts will work out of the box Need to rebuild the container for each run, given that there may be changes within the branch being built No surprise for the developers, local outputs (of linting for instance) will be the same in the CI Not everything in the container is needed for the CI pipeline\u00b9 Rules used (for linting or unit tests) will be the same on the CI Some pipeline tasks will not be available \u00b2 All tooling and their versions defined in a single place Require access to a container registry to host the container within the pipeline\u00b3 Tools/dependencies are already present The dev container is being tested to include all new tooling in addition to not being broken Publishing the container built from devcontainer.json allows you to reference it in the cacheFrom in devcontainer.json (see docs ). By doing this, VS Code will use the published image as a layer cache when building \u00b9: container size can be reduces by exporting the layer that contains only the tooling needed for the CI pipeline. This would require building the image without tasks \u00b2: using container jobs in AzDO you can use all tasks (as far as I can tell). Reference: Dockerizing DevOps V2 - AzDO container jobs - DEV Community \u00b3: within GH actions, the default Github Actions token can be used for accessing GHCR without setting up separate registry, see the example below. NOTE: This does not build the Dockerfile together with the devcontainer.json - uses : whoan/docker-build-with-cache-action@v5 id : cache with : username : $GITHUB_ACTOR password : \"${{ secrets.GITHUB_TOKEN }}\" registry : docker.pkg.github.com image_name : devcontainer dockerfile : .devcontainer/Dockerfile","title":"Reusing dev containers within a pipeline"},{"location":"continuous-integration/devcontainers/#reusing-dev-containers-within-a-pipeline","text":"Given a repository with a local development container aka dev container that contains all the tooling required for development, would it make sense to reuse that container for running the tooling in the Continuous Integration pipelines?","title":"Reusing dev containers within a pipeline"},{"location":"continuous-integration/devcontainers/#options-for-building-devcontainers-within-pipeline","text":"There are three ways to build devcontainers within pipeline: With GitHub - devcontainers/ci builds the container with the devcontainer.json . Example here: devcontainers/ci \u00b7 Getting Started . With GitHub - devcontainers/cli , which is the same as the above, but using the underlying CLI directly without tasks. Building the DockerFile with docker build . This option excludes all configuration/features specified within the devcontainer.json .","title":"Options for building devcontainers within pipeline"},{"location":"continuous-integration/devcontainers/#considered-options","text":"Run CI pipelines in native environment Run CI pipelines in the dev container via building image locally Run CI pipelines in the dev container with a container registry Here are below pros and cons for both approaches:","title":"Considered Options"},{"location":"continuous-integration/devcontainers/#run-ci-pipelines-in-native-environment","text":"Pros Cons Can use any pipeline tasks available Need to keep two sets of tooling and their versions in sync No container registry Can take some time to start, based on tools/dependencies required Agent will always be up to date with security patches The dev container should always be built within each run of the CI pipeline, to verify the changes within the branch haven't broken anything","title":"Run CI pipelines in native environment"},{"location":"continuous-integration/devcontainers/#run-ci-pipelines-in-the-dev-container-without-image-caching","text":"Pros Cons Utilities scripts will work out of the box Need to rebuild the container for each run, given that there may be changes within the branch being built Rules used (for linting or unit tests) will be the same on the CI Not everything in the container is needed for the CI pipeline\u00b9 No surprise for the developers, local outputs (of linting for instance) will be the same in the CI Some pipeline tasks will not be available All tooling and their versions defined in a single place Building the image for each pipeline run is slow\u00b2 Tools/dependencies are already present The dev container is being tested to include all new tooling in addition to not being broken \u00b9: container size can be reduces by exporting the layer that contains only the tooling needed for the CI pipeline \u00b2: could be mitigated via adding image caching without using a container registry","title":"Run CI pipelines in the dev container without image caching"},{"location":"continuous-integration/devcontainers/#run-ci-pipelines-in-the-dev-container-with-image-registry","text":"Pros Cons Utilities scripts will work out of the box Need to rebuild the container for each run, given that there may be changes within the branch being built No surprise for the developers, local outputs (of linting for instance) will be the same in the CI Not everything in the container is needed for the CI pipeline\u00b9 Rules used (for linting or unit tests) will be the same on the CI Some pipeline tasks will not be available \u00b2 All tooling and their versions defined in a single place Require access to a container registry to host the container within the pipeline\u00b3 Tools/dependencies are already present The dev container is being tested to include all new tooling in addition to not being broken Publishing the container built from devcontainer.json allows you to reference it in the cacheFrom in devcontainer.json (see docs ). By doing this, VS Code will use the published image as a layer cache when building \u00b9: container size can be reduces by exporting the layer that contains only the tooling needed for the CI pipeline. This would require building the image without tasks \u00b2: using container jobs in AzDO you can use all tasks (as far as I can tell). Reference: Dockerizing DevOps V2 - AzDO container jobs - DEV Community \u00b3: within GH actions, the default Github Actions token can be used for accessing GHCR without setting up separate registry, see the example below. NOTE: This does not build the Dockerfile together with the devcontainer.json - uses : whoan/docker-build-with-cache-action@v5 id : cache with : username : $GITHUB_ACTOR password : \"${{ secrets.GITHUB_TOKEN }}\" registry : docker.pkg.github.com image_name : devcontainer dockerfile : .devcontainer/Dockerfile","title":"Run CI pipelines in the dev container with image registry"},{"location":"continuous-integration/markdown-linting/","text":"CI Pipeline for better documentation Introduction Most projects start with spikes, where developers and analysts produce lots of documentation. Sometimes, these documents don't have a standard and each team member writes them accordingly with their preference. Add to that the time a reviewer will spend confirming grammar, searching for typos or non-inclusive language. This pipeline helps address that! The Pipeline The pipeline uses the following npm modules: markdownlint : add standardization using rules markdown-link-check : check the links in the documentation and report broken ones write-good : linter for English prose We have been using this pipeline for more than one year in different engagements and always received great feedback from the customers! How does it work To start using this pipeline: Download the files from this repository Unzip the folders and files to your repository root if the repository is empty - if it's not brand new, copy the files and make the required adjustments: - check .azdo so it matches your repository standard - check package.json so you don't overwrite one you already have in the process. Also update the file if you changed the name of the .azdo folder. Create the pipeline in Azure DevOps or GitHub References Markdown Code Reviews in the Code With Engineering Playbook","title":"CI Pipeline for better documentation"},{"location":"continuous-integration/markdown-linting/#ci-pipeline-for-better-documentation","text":"","title":"CI Pipeline for better documentation"},{"location":"continuous-integration/markdown-linting/#introduction","text":"Most projects start with spikes, where developers and analysts produce lots of documentation. Sometimes, these documents don't have a standard and each team member writes them accordingly with their preference. Add to that the time a reviewer will spend confirming grammar, searching for typos or non-inclusive language. This pipeline helps address that!","title":"Introduction"},{"location":"continuous-integration/markdown-linting/#the-pipeline","text":"The pipeline uses the following npm modules: markdownlint : add standardization using rules markdown-link-check : check the links in the documentation and report broken ones write-good : linter for English prose We have been using this pipeline for more than one year in different engagements and always received great feedback from the customers!","title":"The Pipeline"},{"location":"continuous-integration/markdown-linting/#how-does-it-work","text":"To start using this pipeline: Download the files from this repository Unzip the folders and files to your repository root if the repository is empty - if it's not brand new, copy the files and make the required adjustments: - check .azdo so it matches your repository standard - check package.json so you don't overwrite one you already have in the process. Also update the file if you changed the name of the .azdo folder. Create the pipeline in Azure DevOps or GitHub","title":"How does it work"},{"location":"continuous-integration/markdown-linting/#references","text":"Markdown Code Reviews in the Code With Engineering Playbook","title":"References"},{"location":"design/readme/","text":"Design Projetar software de forma eficaz \u00e9 desafiador. A ISE coletou uma s\u00e9rie de pr\u00e1ticas que consideramos \u00fateis no processo de design. Isso abrange n\u00e3o apenas o design t\u00e9cnico de software, mas tamb\u00e9m o design de arquitetura e a coleta de requisitos n\u00e3o funcionais para novos projetos. Objetivos (Metas) Fornecer recomenda\u00e7\u00f5es sobre como projetar software para manutenibilidade, facilidade de extens\u00e3o, conformidade com as melhores pr\u00e1ticas e sustentabilidade. Referenciar ou definir processos ou listas de verifica\u00e7\u00e3o para ajudar a garantir software bem projetado. Consolidar e apontar para fontes de refer\u00eancia (guias, reposit\u00f3rios, artigos) que podem acelerar o processo de aprendizado. Se\u00e7\u00f5es (Se\u00e7\u00f5es) Tipos de Diagrama Padr\u00f5es de Design Revis\u00f5es de Design Orienta\u00e7\u00e3o de Requisitos N\u00e3o Funcionais Engenharia de Software Sustent\u00e1vel Receitas (Receitas) Receitas de Design Exemplos de C\u00f3digo (Exemplos de C\u00f3digo) Estrutura de Pasta Estrutura de Pasta para Reposit\u00f3rio Python Modelos de Projeto Rust Atix Web, Diesel ORM, Test Containers, Arquitetura de Cebola Python Flask, SQLAlchemy ORM, Test Containers, Arquitetura de Cebola","title":"Design"},{"location":"design/readme/#design","text":"Projetar software de forma eficaz \u00e9 desafiador. A ISE coletou uma s\u00e9rie de pr\u00e1ticas que consideramos \u00fateis no processo de design. Isso abrange n\u00e3o apenas o design t\u00e9cnico de software, mas tamb\u00e9m o design de arquitetura e a coleta de requisitos n\u00e3o funcionais para novos projetos.","title":"Design"},{"location":"design/readme/#objetivos-metas","text":"Fornecer recomenda\u00e7\u00f5es sobre como projetar software para manutenibilidade, facilidade de extens\u00e3o, conformidade com as melhores pr\u00e1ticas e sustentabilidade. Referenciar ou definir processos ou listas de verifica\u00e7\u00e3o para ajudar a garantir software bem projetado. Consolidar e apontar para fontes de refer\u00eancia (guias, reposit\u00f3rios, artigos) que podem acelerar o processo de aprendizado.","title":"Objetivos (Metas)"},{"location":"design/readme/#secoes-secoes","text":"Tipos de Diagrama Padr\u00f5es de Design Revis\u00f5es de Design Orienta\u00e7\u00e3o de Requisitos N\u00e3o Funcionais Engenharia de Software Sustent\u00e1vel","title":"Se\u00e7\u00f5es (Se\u00e7\u00f5es)"},{"location":"design/readme/#receitas-receitas","text":"Receitas de Design","title":"Receitas (Receitas)"},{"location":"design/readme/#exemplos-de-codigo-exemplos-de-codigo","text":"Estrutura de Pasta Estrutura de Pasta para Reposit\u00f3rio Python Modelos de Projeto Rust Atix Web, Diesel ORM, Test Containers, Arquitetura de Cebola Python Flask, SQLAlchemy ORM, Test Containers, Arquitetura de Cebola","title":"Exemplos de C\u00f3digo (Exemplos de C\u00f3digo)"},{"location":"design/design-patterns/","text":"Padr\u00f5es de Design (Design Patterns) A se\u00e7\u00e3o de padr\u00f5es de design recomenda padr\u00f5es de design de software e arquitetura. Esta se\u00e7\u00e3o fornece uma lista selecionada de padr\u00f5es comumente usados de fontes confi\u00e1veis. Em vez de duplicar ou substituir as fontes citadas, esta se\u00e7\u00e3o tem como objetivo complement\u00e1-las com sugest\u00f5es, orienta\u00e7\u00f5es e aprendizados com base em experi\u00eancias em primeira m\u00e3o. Subse\u00e7\u00f5es Orienta\u00e7\u00e3o para Design de Dados Pesados Refer\u00eancia de Design Orientado a Objetos Refer\u00eancia para Design de Sistemas Distribu\u00eddos Orienta\u00e7\u00e3o para Design de API REST Orienta\u00e7\u00e3o para Design de Recursos de Nuvem Orienta\u00e7\u00e3o para Arquitetura de Rede para Azure Orienta\u00e7\u00e3o para Arquitetura de Rede H\u00edbrida","title":"Padr\u00f5es de Design (Design Patterns)"},{"location":"design/design-patterns/#padroes-de-design-design-patterns","text":"A se\u00e7\u00e3o de padr\u00f5es de design recomenda padr\u00f5es de design de software e arquitetura. Esta se\u00e7\u00e3o fornece uma lista selecionada de padr\u00f5es comumente usados de fontes confi\u00e1veis. Em vez de duplicar ou substituir as fontes citadas, esta se\u00e7\u00e3o tem como objetivo complement\u00e1-las com sugest\u00f5es, orienta\u00e7\u00f5es e aprendizados com base em experi\u00eancias em primeira m\u00e3o.","title":"Padr\u00f5es de Design (Design Patterns)"},{"location":"design/design-patterns/#subsecoes","text":"Orienta\u00e7\u00e3o para Design de Dados Pesados Refer\u00eancia de Design Orientado a Objetos Refer\u00eancia para Design de Sistemas Distribu\u00eddos Orienta\u00e7\u00e3o para Design de API REST Orienta\u00e7\u00e3o para Design de Recursos de Nuvem Orienta\u00e7\u00e3o para Arquitetura de Rede para Azure Orienta\u00e7\u00e3o para Arquitetura de Rede H\u00edbrida","title":"Subse\u00e7\u00f5es"},{"location":"design/design-patterns/cloud-resource-design-guidance/","text":"Orienta\u00e7\u00e3o para Design de Recursos na Nuvem \u00c0 medida que o uso de nuvem aumenta, considera\u00e7\u00f5es sobre o design de assinaturas, grupos de gerenciamento e conven\u00e7\u00f5es de nomea\u00e7\u00e3o/marca\u00e7\u00e3o de recursos t\u00eam um impacto na governan\u00e7a, na gest\u00e3o de opera\u00e7\u00f5es e nos padr\u00f5es de ado\u00e7\u00e3o. NOTA: Sempre trabalhe com as partes interessadas relevantes para garantir que a introdu\u00e7\u00e3o de novos padr\u00f5es proporcione o valor pretendido. Ao trabalhar em um ambiente de nuvem existente, \u00e9 importante entender quaisquer padr\u00f5es atuais e como eles s\u00e3o usados antes de fazer uma altera\u00e7\u00e3o neles. Refer\u00eancias As seguintes refer\u00eancias podem ser usadas para entender as melhores pr\u00e1ticas mais recentes na organiza\u00e7\u00e3o de recursos na nuvem: Organiza\u00e7\u00e3o de Assinaturas Guia de Decis\u00e3o para Marca\u00e7\u00e3o de Recursos Conven\u00e7\u00f5es de Nomea\u00e7\u00e3o de Recursos Abrevia\u00e7\u00f5es Recomendadas para Recursos Azure Organiza\u00e7\u00e3o de Cargas de Trabalho de Desenvolvimento/Teste/Produ\u00e7\u00e3o Ferramentas Ferramenta de Nomenclatura de Recursos do Azure","title":"Orienta\u00e7\u00e3o para Design de Recursos na Nuvem"},{"location":"design/design-patterns/cloud-resource-design-guidance/#orientacao-para-design-de-recursos-na-nuvem","text":"\u00c0 medida que o uso de nuvem aumenta, considera\u00e7\u00f5es sobre o design de assinaturas, grupos de gerenciamento e conven\u00e7\u00f5es de nomea\u00e7\u00e3o/marca\u00e7\u00e3o de recursos t\u00eam um impacto na governan\u00e7a, na gest\u00e3o de opera\u00e7\u00f5es e nos padr\u00f5es de ado\u00e7\u00e3o. NOTA: Sempre trabalhe com as partes interessadas relevantes para garantir que a introdu\u00e7\u00e3o de novos padr\u00f5es proporcione o valor pretendido. Ao trabalhar em um ambiente de nuvem existente, \u00e9 importante entender quaisquer padr\u00f5es atuais e como eles s\u00e3o usados antes de fazer uma altera\u00e7\u00e3o neles.","title":"Orienta\u00e7\u00e3o para Design de Recursos na Nuvem"},{"location":"design/design-patterns/cloud-resource-design-guidance/#referencias","text":"As seguintes refer\u00eancias podem ser usadas para entender as melhores pr\u00e1ticas mais recentes na organiza\u00e7\u00e3o de recursos na nuvem: Organiza\u00e7\u00e3o de Assinaturas Guia de Decis\u00e3o para Marca\u00e7\u00e3o de Recursos Conven\u00e7\u00f5es de Nomea\u00e7\u00e3o de Recursos Abrevia\u00e7\u00f5es Recomendadas para Recursos Azure Organiza\u00e7\u00e3o de Cargas de Trabalho de Desenvolvimento/Teste/Produ\u00e7\u00e3o","title":"Refer\u00eancias"},{"location":"design/design-patterns/cloud-resource-design-guidance/#ferramentas","text":"Ferramenta de Nomenclatura de Recursos do Azure","title":"Ferramentas"},{"location":"design/design-patterns/data-heavy-design-guidance/","text":"Fundamentos de Dados e DataOps A maioria dos projetos envolve algum tipo de armazenamento de dados, processamento de dados e DataOps. Para esses projetos, assim como para todos os projetos, seguimos as diretrizes gerais apresentadas em outras se\u00e7\u00f5es sobre seguran\u00e7a, testes, observabilidade, CI/CD etc. Objetivo O objetivo desta se\u00e7\u00e3o \u00e9 descrever brevemente como aplicar os fundamentos a projetos de dados pesados ou a partes do projeto. Isolamento Por favor, tenha cuidado com os n\u00edveis de isolamento que voc\u00ea est\u00e1 usando. Mesmo com um banco de dados que oferece serializabilidade, \u00e9 poss\u00edvel que, dentro de uma transa\u00e7\u00e3o ou conex\u00e3o, voc\u00ea esteja usando um n\u00edvel de isolamento mais baixo do que o banco de dados oferece. Em particular, a leitura n\u00e3o confirmada (ou consist\u00eancia eventual) pode ter muitos efeitos colaterais imprevis\u00edveis e introduzir bugs dif\u00edceis de entender. Sistemas eventualmente consistentes devem ser tratados como \u00faltimo recurso para atender aos requisitos de escalabilidade; o uso de lotes, fragmenta\u00e7\u00e3o e armazenamento em cache s\u00e3o todas solu\u00e7\u00f5es recomendadas para aumentar a escalabilidade. Se nenhuma dessas op\u00e7\u00f5es for vi\u00e1vel, considere avaliar os bancos de dados \"New SQL\" como CockroachDB ou TiDB, antes de utilizar uma op\u00e7\u00e3o que dependa da consist\u00eancia eventual. Existem outros n\u00edveis de isolamento, fora dos n\u00edveis de isolamento mencionados no link acima. Alguns deles t\u00eam nuances diferentes dos 4 principais n\u00edveis e podem ser dif\u00edceis de comparar. Isolamento de Snapshot, serializa\u00e7\u00e3o estrita, \"ler o pr\u00f3prio escrito\", leituras monot\u00f4nicas, staleness limitada, consist\u00eancia causal e lineariza\u00e7\u00e3o s\u00e3o todos outros termos que voc\u00ea pode explorar para aprender mais sobre o assunto. Controle de Concorr\u00eancia Seus sistemas devem (quase sempre) aproveitar alguma forma de controle de concorr\u00eancia, para garantir a corre\u00e7\u00e3o entre solicita\u00e7\u00f5es concorrentes e evitar corridas de dados. As duas formas de controle de concorr\u00eancia s\u00e3o pessimista e otimista . Uma transa\u00e7\u00e3o pessimista envolve uma primeira solicita\u00e7\u00e3o para \"bloquear os dados\" e uma segunda solicita\u00e7\u00e3o para escrever os dados. Entre essas solicita\u00e7\u00f5es, nenhuma outra solicita\u00e7\u00e3o que acesse esses dados ter\u00e1 sucesso. Consulte 2 Phase Locking (tamb\u00e9m conhecido como 2 Phase Commit) para obter mais informa\u00e7\u00f5es. A abordagem (mais) recomendada \u00e9 a concorr\u00eancia otimista , onde um usu\u00e1rio pode ler o objeto em uma vers\u00e3o espec\u00edfica e atualizar o objeto apenas se ele n\u00e3o tiver sido alterado. Isso \u00e9 normalmente feito via Cabe\u00e7alho Etag . Uma maneira simples de fazer isso no lado do banco de dados \u00e9 incrementar um n\u00famero de vers\u00e3o em cada atualiza\u00e7\u00e3o. Isso pode ser feito em uma \u00fanica instru\u00e7\u00e3o executada da seguinte forma: AVISO: o c\u00f3digo abaixo n\u00e3o funcionar\u00e1 quando estiver usando um n\u00edvel de isolamento igual ou inferior ao \"read uncommitted\" (consist\u00eancia eventual). -- Trate isso como c\u00f3digo fict\u00edcio e ajuste conforme necess\u00e1rio. UPDATE < nome_da_tabela > SET campo1 = valor1 , ..., campoN = valorN , versao = $ nova_versao WHERE ID = $ id AND versao = $ versao Camadas de Dados (Qualidade de Dados) Desenvolva um entendimento comum da qualidade de seus conjuntos de dados, para que todos entendam a qualidade dos dados, os casos de uso esperados e as limita\u00e7\u00f5es. Um modelo comum de qualidade de dados \u00e9 Bronze , Silver , Gold Bronze: Esta \u00e9 uma \u00e1rea de desembarque para seus conjuntos de dados brutos com pouca ou nenhuma transforma\u00e7\u00e3o de dados aplicada, e, portanto, s\u00e3o otimizados para grava\u00e7\u00f5es / ingest\u00e3o. Trate esses conjuntos de dados como um armazenamento imut\u00e1vel, apenas para anexar. Silver: S\u00e3o conjuntos de dados limpos e semi-processados. Eles se conformam a um esquema conhecido e a invariantes de dados predefinidos e podem ter mais augmenta\u00e7\u00e3o de dados aplicada. Normalmente, s\u00e3o usados por cientistas de dados. Gold: S\u00e3o conjuntos de dados altamente processados e altamente otimizados para leitura, principalmente para o consumo de usu\u00e1rios de neg\u00f3cios. Normalmente, s\u00e3o estruturados em suas tabelas padr\u00e3o de fatos e dimens\u00f5es. Divida seu data lake em tr\u00eas grandes \u00e1reas contendo seus conjuntos de dados Bronze, Silver e Gold. Nota: \u00c1reas de armazenamento adicionais para dados malformados, dados intermedi\u00e1rios (sandbox) e bibliotecas/pacotes/bin\u00e1rios tamb\u00e9m s\u00e3o \u00fateis ao projetar a organiza\u00e7\u00e3o do armazenamento. Valida\u00e7\u00e3o de Dados Valide os dados no in\u00edcio do seu pipeline Adicione valida\u00e7\u00e3o de dados entre os conjuntos de dados Bronze e Silver. Validando no in\u00edcio do seu pipeline, voc\u00ea pode garantir que todos os conjuntos de dados estejam em conformidade com um esquema espec\u00edfico e invariantes de dados conhecidos. Isso tamb\u00e9m pode potencialmente evitar falhas no pipeline de dados em caso de altera\u00e7\u00f5es inesperadas nos dados de entrada. Os dados que n\u00e3o passam por esta etapa de valida\u00e7\u00e3o podem ser encaminhados para um registro dedicado de dados malformados para fins de diagn\u00f3stico. Pode ser tentador adicionar valida\u00e7\u00e3o antes de desembarcar na \u00e1rea Bronze do seu data lake. Isso geralmente n\u00e3o \u00e9 recomendado. Os conjuntos de dados Bronze existem para garantir que voc\u00ea tenha uma c\u00f3pia o mais pr\u00f3xima poss\u00edvel dos dados do sistema de origem. Isso pode ser usado para repetir o pipeline de dados tanto para testes (ou seja, testar a l\u00f3gica de valida\u00e7\u00e3o de dados) quanto para fins de recupera\u00e7\u00e3o de dados (ou seja, a corrup\u00e7\u00e3o de dados \u00e9 introduzida devido a um erro no c\u00f3digo de transforma\u00e7\u00e3o de dados e, portanto, o pipeline precisa ser repetido). Pipelines de Dados Idempotentes Torne seus pipelines de dados reutiliz\u00e1veis e idempotentes Conjuntos de dados Silver e Gold podem ser corrompidos por v\u00e1rios motivos, como bugs n\u00e3o intencionais, altera\u00e7\u00f5es inesperadas nos dados de entrada e outros. Ao tornar os pipelines de dados reutiliz\u00e1veis e idempotentes, voc\u00ea pode se recuperar desse estado por meio da implanta\u00e7\u00e3o de corre\u00e7\u00f5es de c\u00f3digo e repeti\u00e7\u00e3o dos pipelines de dados. - A idempot\u00eancia tamb\u00e9m garante que a duplica\u00e7\u00e3o de dados seja mitigada ao repetir seus pipelines de dados. Testes Garanta que o c\u00f3digo de transforma\u00e7\u00e3o de dados seja test\u00e1vel Abstrair o c\u00f3digo de transforma\u00e7\u00e3o de dados do c\u00f3digo de acesso aos dados \u00e9 fundamental para garantir que testes unit\u00e1rios possam ser escritos contra a l\u00f3gica de transforma\u00e7\u00e3o de dados. Um exemplo disso \u00e9 mover o c\u00f3digo de transforma\u00e7\u00e3o de dados de cadernos para pacotes. Embora seja poss\u00edvel executar testes em cadernos, ao extrair o c\u00f3digo para pacotes, voc\u00ea aumenta a produtividade do desenvolvedor, aumentando a velocidade do ciclo de feedback. CI/CD, Controle de Origem e Revis\u00f5es de C\u00f3digo Todos os artefatos necess\u00e1rios para construir o pipeline de dados do zero devem estar sob controle de origem. Isso inclui artefatos de infraestrutura como c\u00f3digo, objetos de banco de dados (defini\u00e7\u00f5es de esquema, fun\u00e7\u00f5es, procedimentos armazenados etc.), dados de refer\u00eancia/aplica\u00e7\u00e3o, defini\u00e7\u00f5es de pipeline de dados e l\u00f3gica de valida\u00e7\u00e3o e transforma\u00e7\u00e3o de dados. Quaisquer novos artefatos (c\u00f3digo) introduzidos no reposit\u00f3rio devem passar por revis\u00f5es de c\u00f3digo, tanto autom\u00e1ticas (verifica\u00e7\u00e3o de lint, verifica\u00e7\u00e3o de credenciais etc.) quanto revis\u00f5es por pares. Deve haver um processo seguro e repet\u00edvel (CI/CD) para mover as altera\u00e7\u00f5es por meio de desenvolvimento, teste e, finalmente, produ\u00e7\u00e3o. Seguran\u00e7a e Configura\u00e7\u00e3o Mantenha um local central e seguro para configura\u00e7\u00f5es sens\u00edveis, como strings de conex\u00e3o de banco de dados, que podem ser acessadas pelos servi\u00e7os apropriados dentro do ambiente espec\u00edfico. No Azure, isso geralmente \u00e9 resolvido por meio da seguran\u00e7a de segredos em um Key Vault por ambiente e, em seguida, os servi\u00e7os relevantes consultam o KeyVault para obter a configura\u00e7\u00e3o. Observabilidade Monitore infraestrutura, pipelines e dados Uma solu\u00e7\u00e3o de monitoramento adequada deve estar em vigor para garantir que as falhas sejam identificadas, diagnosticadas e abordadas de forma oportuna. Al\u00e9m da infraestrutura base e das execu\u00e7\u00f5es de pipelines, os dados tamb\u00e9m devem ser monitorados. Uma \u00e1rea comum que deve ter monitoramento de dados \u00e9 o registro de dados malformados. Amostras de Tecnologia de Ponta a Ponta e Azure O reposit\u00f3rio DataOps for the Modern Data Warehouse cont\u00e9m amostras de tecnologia espec\u00edficas e de ponta a ponta sobre como implementar o DataOps no Azure. Imagem: CI/CD para pipelines de dados no Azure - do reposit\u00f3rio DataOps para o Modern Data Warehouse","title":"Fundamentos de Dados e DataOps"},{"location":"design/design-patterns/data-heavy-design-guidance/#fundamentos-de-dados-e-dataops","text":"A maioria dos projetos envolve algum tipo de armazenamento de dados, processamento de dados e DataOps. Para esses projetos, assim como para todos os projetos, seguimos as diretrizes gerais apresentadas em outras se\u00e7\u00f5es sobre seguran\u00e7a, testes, observabilidade, CI/CD etc.","title":"Fundamentos de Dados e DataOps"},{"location":"design/design-patterns/data-heavy-design-guidance/#objetivo","text":"O objetivo desta se\u00e7\u00e3o \u00e9 descrever brevemente como aplicar os fundamentos a projetos de dados pesados ou a partes do projeto.","title":"Objetivo"},{"location":"design/design-patterns/data-heavy-design-guidance/#isolamento","text":"Por favor, tenha cuidado com os n\u00edveis de isolamento que voc\u00ea est\u00e1 usando. Mesmo com um banco de dados que oferece serializabilidade, \u00e9 poss\u00edvel que, dentro de uma transa\u00e7\u00e3o ou conex\u00e3o, voc\u00ea esteja usando um n\u00edvel de isolamento mais baixo do que o banco de dados oferece. Em particular, a leitura n\u00e3o confirmada (ou consist\u00eancia eventual) pode ter muitos efeitos colaterais imprevis\u00edveis e introduzir bugs dif\u00edceis de entender. Sistemas eventualmente consistentes devem ser tratados como \u00faltimo recurso para atender aos requisitos de escalabilidade; o uso de lotes, fragmenta\u00e7\u00e3o e armazenamento em cache s\u00e3o todas solu\u00e7\u00f5es recomendadas para aumentar a escalabilidade. Se nenhuma dessas op\u00e7\u00f5es for vi\u00e1vel, considere avaliar os bancos de dados \"New SQL\" como CockroachDB ou TiDB, antes de utilizar uma op\u00e7\u00e3o que dependa da consist\u00eancia eventual. Existem outros n\u00edveis de isolamento, fora dos n\u00edveis de isolamento mencionados no link acima. Alguns deles t\u00eam nuances diferentes dos 4 principais n\u00edveis e podem ser dif\u00edceis de comparar. Isolamento de Snapshot, serializa\u00e7\u00e3o estrita, \"ler o pr\u00f3prio escrito\", leituras monot\u00f4nicas, staleness limitada, consist\u00eancia causal e lineariza\u00e7\u00e3o s\u00e3o todos outros termos que voc\u00ea pode explorar para aprender mais sobre o assunto.","title":"Isolamento"},{"location":"design/design-patterns/data-heavy-design-guidance/#controle-de-concorrencia","text":"Seus sistemas devem (quase sempre) aproveitar alguma forma de controle de concorr\u00eancia, para garantir a corre\u00e7\u00e3o entre solicita\u00e7\u00f5es concorrentes e evitar corridas de dados. As duas formas de controle de concorr\u00eancia s\u00e3o pessimista e otimista . Uma transa\u00e7\u00e3o pessimista envolve uma primeira solicita\u00e7\u00e3o para \"bloquear os dados\" e uma segunda solicita\u00e7\u00e3o para escrever os dados. Entre essas solicita\u00e7\u00f5es, nenhuma outra solicita\u00e7\u00e3o que acesse esses dados ter\u00e1 sucesso. Consulte 2 Phase Locking (tamb\u00e9m conhecido como 2 Phase Commit) para obter mais informa\u00e7\u00f5es. A abordagem (mais) recomendada \u00e9 a concorr\u00eancia otimista , onde um usu\u00e1rio pode ler o objeto em uma vers\u00e3o espec\u00edfica e atualizar o objeto apenas se ele n\u00e3o tiver sido alterado. Isso \u00e9 normalmente feito via Cabe\u00e7alho Etag . Uma maneira simples de fazer isso no lado do banco de dados \u00e9 incrementar um n\u00famero de vers\u00e3o em cada atualiza\u00e7\u00e3o. Isso pode ser feito em uma \u00fanica instru\u00e7\u00e3o executada da seguinte forma: AVISO: o c\u00f3digo abaixo n\u00e3o funcionar\u00e1 quando estiver usando um n\u00edvel de isolamento igual ou inferior ao \"read uncommitted\" (consist\u00eancia eventual). -- Trate isso como c\u00f3digo fict\u00edcio e ajuste conforme necess\u00e1rio. UPDATE < nome_da_tabela > SET campo1 = valor1 , ..., campoN = valorN , versao = $ nova_versao WHERE ID = $ id AND versao = $ versao","title":"Controle de Concorr\u00eancia"},{"location":"design/design-patterns/data-heavy-design-guidance/#camadas-de-dados-qualidade-de-dados","text":"Desenvolva um entendimento comum da qualidade de seus conjuntos de dados, para que todos entendam a qualidade dos dados, os casos de uso esperados e as limita\u00e7\u00f5es. Um modelo comum de qualidade de dados \u00e9 Bronze , Silver , Gold Bronze: Esta \u00e9 uma \u00e1rea de desembarque para seus conjuntos de dados brutos com pouca ou nenhuma transforma\u00e7\u00e3o de dados aplicada, e, portanto, s\u00e3o otimizados para grava\u00e7\u00f5es / ingest\u00e3o. Trate esses conjuntos de dados como um armazenamento imut\u00e1vel, apenas para anexar. Silver: S\u00e3o conjuntos de dados limpos e semi-processados. Eles se conformam a um esquema conhecido e a invariantes de dados predefinidos e podem ter mais augmenta\u00e7\u00e3o de dados aplicada. Normalmente, s\u00e3o usados por cientistas de dados. Gold: S\u00e3o conjuntos de dados altamente processados e altamente otimizados para leitura, principalmente para o consumo de usu\u00e1rios de neg\u00f3cios. Normalmente, s\u00e3o estruturados em suas tabelas padr\u00e3o de fatos e dimens\u00f5es. Divida seu data lake em tr\u00eas grandes \u00e1reas contendo seus conjuntos de dados Bronze, Silver e Gold. Nota: \u00c1reas de armazenamento adicionais para dados malformados, dados intermedi\u00e1rios (sandbox) e bibliotecas/pacotes/bin\u00e1rios tamb\u00e9m s\u00e3o \u00fateis ao projetar a organiza\u00e7\u00e3o do armazenamento.","title":"Camadas de Dados (Qualidade de Dados)"},{"location":"design/design-patterns/data-heavy-design-guidance/#validacao-de-dados","text":"Valide os dados no in\u00edcio do seu pipeline Adicione valida\u00e7\u00e3o de dados entre os conjuntos de dados Bronze e Silver. Validando no in\u00edcio do seu pipeline, voc\u00ea pode garantir que todos os conjuntos de dados estejam em conformidade com um esquema espec\u00edfico e invariantes de dados conhecidos. Isso tamb\u00e9m pode potencialmente evitar falhas no pipeline de dados em caso de altera\u00e7\u00f5es inesperadas nos dados de entrada. Os dados que n\u00e3o passam por esta etapa de valida\u00e7\u00e3o podem ser encaminhados para um registro dedicado de dados malformados para fins de diagn\u00f3stico. Pode ser tentador adicionar valida\u00e7\u00e3o antes de desembarcar na \u00e1rea Bronze do seu data lake. Isso geralmente n\u00e3o \u00e9 recomendado. Os conjuntos de dados Bronze existem para garantir que voc\u00ea tenha uma c\u00f3pia o mais pr\u00f3xima poss\u00edvel dos dados do sistema de origem. Isso pode ser usado para repetir o pipeline de dados tanto para testes (ou seja, testar a l\u00f3gica de valida\u00e7\u00e3o de dados) quanto para fins de recupera\u00e7\u00e3o de dados (ou seja, a corrup\u00e7\u00e3o de dados \u00e9 introduzida devido a um erro no c\u00f3digo de transforma\u00e7\u00e3o de dados e, portanto, o pipeline precisa ser repetido).","title":"Valida\u00e7\u00e3o de Dados"},{"location":"design/design-patterns/data-heavy-design-guidance/#pipelines-de-dados-idempotentes","text":"Torne seus pipelines de dados reutiliz\u00e1veis e idempotentes Conjuntos de dados Silver e Gold podem ser corrompidos por v\u00e1rios motivos, como bugs n\u00e3o intencionais, altera\u00e7\u00f5es inesperadas nos dados de entrada e outros. Ao tornar os pipelines de dados reutiliz\u00e1veis e idempotentes, voc\u00ea pode se recuperar desse estado por meio da implanta\u00e7\u00e3o de corre\u00e7\u00f5es de c\u00f3digo e repeti\u00e7\u00e3o dos pipelines de dados. - A idempot\u00eancia tamb\u00e9m garante que a duplica\u00e7\u00e3o de dados seja mitigada ao repetir seus pipelines de dados.","title":"Pipelines de Dados Idempotentes"},{"location":"design/design-patterns/data-heavy-design-guidance/#testes","text":"Garanta que o c\u00f3digo de transforma\u00e7\u00e3o de dados seja test\u00e1vel Abstrair o c\u00f3digo de transforma\u00e7\u00e3o de dados do c\u00f3digo de acesso aos dados \u00e9 fundamental para garantir que testes unit\u00e1rios possam ser escritos contra a l\u00f3gica de transforma\u00e7\u00e3o de dados. Um exemplo disso \u00e9 mover o c\u00f3digo de transforma\u00e7\u00e3o de dados de cadernos para pacotes. Embora seja poss\u00edvel executar testes em cadernos, ao extrair o c\u00f3digo para pacotes, voc\u00ea aumenta a produtividade do desenvolvedor, aumentando a velocidade do ciclo de feedback.","title":"Testes"},{"location":"design/design-patterns/data-heavy-design-guidance/#cicd-controle-de-origem-e-revisoes-de-codigo","text":"Todos os artefatos necess\u00e1rios para construir o pipeline de dados do zero devem estar sob controle de origem. Isso inclui artefatos de infraestrutura como c\u00f3digo, objetos de banco de dados (defini\u00e7\u00f5es de esquema, fun\u00e7\u00f5es, procedimentos armazenados etc.), dados de refer\u00eancia/aplica\u00e7\u00e3o, defini\u00e7\u00f5es de pipeline de dados e l\u00f3gica de valida\u00e7\u00e3o e transforma\u00e7\u00e3o de dados. Quaisquer novos artefatos (c\u00f3digo) introduzidos no reposit\u00f3rio devem passar por revis\u00f5es de c\u00f3digo, tanto autom\u00e1ticas (verifica\u00e7\u00e3o de lint, verifica\u00e7\u00e3o de credenciais etc.) quanto revis\u00f5es por pares. Deve haver um processo seguro e repet\u00edvel (CI/CD) para mover as altera\u00e7\u00f5es por meio de desenvolvimento, teste e, finalmente, produ\u00e7\u00e3o.","title":"CI/CD, Controle de Origem e Revis\u00f5es de C\u00f3digo"},{"location":"design/design-patterns/data-heavy-design-guidance/#seguranca-e-configuracao","text":"Mantenha um local central e seguro para configura\u00e7\u00f5es sens\u00edveis, como strings de conex\u00e3o de banco de dados, que podem ser acessadas pelos servi\u00e7os apropriados dentro do ambiente espec\u00edfico. No Azure, isso geralmente \u00e9 resolvido por meio da seguran\u00e7a de segredos em um Key Vault por ambiente e, em seguida, os servi\u00e7os relevantes consultam o KeyVault para obter a configura\u00e7\u00e3o.","title":"Seguran\u00e7a e Configura\u00e7\u00e3o"},{"location":"design/design-patterns/data-heavy-design-guidance/#observabilidade","text":"Monitore infraestrutura, pipelines e dados Uma solu\u00e7\u00e3o de monitoramento adequada deve estar em vigor para garantir que as falhas sejam identificadas, diagnosticadas e abordadas de forma oportuna. Al\u00e9m da infraestrutura base e das execu\u00e7\u00f5es de pipelines, os dados tamb\u00e9m devem ser monitorados. Uma \u00e1rea comum que deve ter monitoramento de dados \u00e9 o registro de dados malformados.","title":"Observabilidade"},{"location":"design/design-patterns/data-heavy-design-guidance/#amostras-de-tecnologia-de-ponta-a-ponta-e-azure","text":"O reposit\u00f3rio DataOps for the Modern Data Warehouse cont\u00e9m amostras de tecnologia espec\u00edficas e de ponta a ponta sobre como implementar o DataOps no Azure. Imagem: CI/CD para pipelines de dados no Azure - do reposit\u00f3rio DataOps para o Modern Data Warehouse","title":"Amostras de Tecnologia de Ponta a Ponta e Azure"},{"location":"design/design-patterns/distributed-system-design-reference/","text":"Refer\u00eancia de Design de Sistemas Distribu\u00eddos Sistemas distribu\u00eddos introduzem problemas novos e interessantes que precisam ser abordados. A engenharia de software como campo lidou com esses problemas por anos, e existem recursos fenomenais dispon\u00edveis para refer\u00eancia ao criar um novo sistema distribu\u00eddo. Alguns que recomendamos s\u00e3o os seguintes: Padr\u00f5es de Sistemas Distribu\u00eddos de Martin Fowler microservices.io Padr\u00f5es de Design de Nuvem da Azure","title":"Refer\u00eancia de Design de Sistemas Distribu\u00eddos"},{"location":"design/design-patterns/distributed-system-design-reference/#referencia-de-design-de-sistemas-distribuidos","text":"Sistemas distribu\u00eddos introduzem problemas novos e interessantes que precisam ser abordados. A engenharia de software como campo lidou com esses problemas por anos, e existem recursos fenomenais dispon\u00edveis para refer\u00eancia ao criar um novo sistema distribu\u00eddo. Alguns que recomendamos s\u00e3o os seguintes: Padr\u00f5es de Sistemas Distribu\u00eddos de Martin Fowler microservices.io Padr\u00f5es de Design de Nuvem da Azure","title":"Refer\u00eancia de Design de Sistemas Distribu\u00eddos"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/","text":"Orienta\u00e7\u00f5es de Arquitetura de Rede para o Azure As seguintes s\u00e3o algumas das melhores pr\u00e1ticas ao configurar e trabalhar com recursos de rede em ambientes de nuvem do Azure. NOTA: Ao trabalhar em um ambiente de nuvem existente, \u00e9 importante entender quaisquer padr\u00f5es atuais e como eles s\u00e3o usados antes de fazer altera\u00e7\u00f5es neles. Voc\u00ea tamb\u00e9m deve trabalhar com as partes interessadas relevantes para garantir que quaisquer novos padr\u00f5es que voc\u00ea introduza proporcionem valor suficiente para justificar a mudan\u00e7a. Configura\u00e7\u00e3o de Rede e VNet Topologia de Concentrador e Filial A topologia de rede de concentrador e filial \u00e9 um padr\u00e3o de arquitetura comum usado no Azure para organizar e gerenciar recursos de rede. Baseia-se no conceito de um concentrador central que se conecta a v\u00e1rias redes de filiais. Esse modelo \u00e9 particularmente \u00fatil para organizar recursos, manter a seguran\u00e7a e simplificar o gerenciamento de rede. O modelo de concentrador e filial \u00e9 implementado usando Redes Virtuais (VNet) e interconex\u00e3o de VNets (VNet peering). O concentrador: A VNet central age como um concentrador, fornecendo servi\u00e7os compartilhados como seguran\u00e7a de rede, monitoramento e conectividade com ambientes locais ou outras nuvens. Componentes comuns no concentrador incluem Dispositivos Virtuais de Rede (NVA), Firewall do Azure, Gateway VPN e Gateway ExpressRoute. As filiais: As VNets de filial representam unidades separadas ou aplicativos dentro de uma organiza\u00e7\u00e3o, cada um com seu pr\u00f3prio conjunto de recursos e servi\u00e7os. Elas se conectam ao concentrador por meio de interconex\u00e3o de VNets (VNet peering), o que permite a comunica\u00e7\u00e3o entre as VNets do concentrador e da filial. A implementa\u00e7\u00e3o de um modelo de concentrador e filial no Azure oferece v\u00e1rias vantagens: Isolamento e segmenta\u00e7\u00e3o: Ao dividir recursos em VNets de filiais separadas, voc\u00ea pode isolar e segmentar cargas de trabalho, impedindo que poss\u00edveis problemas ou riscos de seguran\u00e7a afetem outras partes da rede. Gerenciamento centralizado: A VNet do concentrador atua como um ponto \u00fanico de gerenciamento para servi\u00e7os compartilhados, facilitando a manuten\u00e7\u00e3o, o monitoramento e a aplica\u00e7\u00e3o de pol\u00edticas em toda a rede. Conectividade simplificada: A interconex\u00e3o de VNets (VNet peering) permite a comunica\u00e7\u00e3o sem problemas entre as VNets do concentrador e da filial, sem a necessidade de roteamento complexo ou gateways adicionais, reduzindo a lat\u00eancia e a sobrecarga de gerenciamento. Escalabilidade: O modelo de concentrador e filial pode ser facilmente dimensionado para acomodar filiais adicionais \u00e0 medida que a organiza\u00e7\u00e3o cresce ou \u00e0 medida que novos aplicativos e servi\u00e7os s\u00e3o introduzidos. Economia de custos: Centralizando servi\u00e7os compartilhados no concentrador, as organiza\u00e7\u00f5es podem reduzir os custos associados \u00e0 implanta\u00e7\u00e3o e ao gerenciamento de v\u00e1rias inst\u00e2ncias dos mesmos servi\u00e7os em diferentes VNets. Saiba mais sobre topologia de concentrador e filial Ao implantar um modelo de concentrador/filial, \u00e9 recomend\u00e1vel faz\u00ea-lo em conjunto com zonas de pouso (landing zones) . Isso garante consist\u00eancia em todos os ambientes, bem como salvaguardas para garantir um alto n\u00edvel de seguran\u00e7a, ao mesmo tempo em que oferece liberdade aos desenvolvedores nos ambientes de desenvolvimento. Firewall e Seguran\u00e7a Ao usar uma topologia de concentrador e filial, \u00e9 poss\u00edvel implantar um firewall centralizado no Hub que controle todo o tr\u00e1fego de sa\u00edda ou o tr\u00e1fego de/para determinadas VNets. Isso permite prote\u00e7\u00e3o centralizada contra amea\u00e7as, minimizando os custos. DNS As melhores pr\u00e1ticas para o gerenciamento de DNS no Azure e em ambientes de nuvem em geral incluem o uso de servi\u00e7os de DNS gerenciados. Alguns dos benef\u00edcios de usar servi\u00e7os de DNS gerenciados s\u00e3o que os recursos s\u00e3o projetados para serem seguros, f\u00e1ceis de implantar e configurar. Encaminhamento de DNS: Configure o encaminhamento de DNS entre seus servidores de DNS locais e os servidores de DNS do Azure para resolu\u00e7\u00e3o de nomes em diferentes ambientes. Use zonas DNS Privadas do Azure para recursos do Azure: Configure zonas DNS Privadas do Azure para seus recursos do Azure para garantir que a resolu\u00e7\u00e3o de nomes seja mantida dentro da rede virtual. Saiba mais sobre infraestrutura de DNS h\u00edbrido/multi-cloud e infraestrutura de DNS do Azure Aloca\u00e7\u00e3o de IP Ao alocar espa\u00e7os de endere\u00e7o IP para Redes Virtuais do Azure (VNets), \u00e9 essencial seguir as melhores pr\u00e1ticas para um gerenciamento adequado e escalabilidade. Aqui est\u00e3o algumas recomenda\u00e7\u00f5es para aloca\u00e7\u00e3o de IP para VNets: Reserve endere\u00e7os IP: Reserve endere\u00e7os IP em seu espa\u00e7o de endere\u00e7o para recursos ou servi\u00e7os cr\u00edticos. Aloca\u00e7\u00e3o de IP p\u00fablica: Minimize o uso de endere\u00e7os IP p\u00fablicos e use o Azure Private Link sempre que poss\u00edvel para acessar servi\u00e7os por meio de uma conex\u00e3o privada. Gerenciamento de endere\u00e7os IP (IPAM): Use solu\u00e7\u00f5es de IPAM para gerenciar e acompanhar a aloca\u00e7\u00e3o de endere\u00e7os IP em todo o ambiente h\u00edbrido. Planeje seu espa\u00e7o de endere\u00e7o: Escolha um espa\u00e7o de endere\u00e7o IP privado apropriado (a partir do RFC 1918) para suas VNets que seja grande o suficiente para acomodar o crescimento futuro. Evite sobreposi\u00e7\u00e3o com redes locais ou de outras nuvens. Use nota\u00e7\u00e3o CIDR: Use a nota\u00e7\u00e3o CIDR (Classless Inter-Domain Routing) para definir o espa\u00e7o de endere\u00e7o da VNet, o que permite uma aloca\u00e7\u00e3o mais eficiente e impede o desperd\u00edcio de endere\u00e7os IP. Use sub-redes: Divida suas VNets em sub-redes menores com base em requisitos de seguran\u00e7a, aplica\u00e7\u00e3o ou ambiente. Isso permite um melhor gerenciamento e seguran\u00e7a de rede. Considere deixar um buffer entre as VNets: Embora n\u00e3o seja estritamente necess\u00e1rio, deixar um buffer entre as VNets pode ser ben\u00e9fico em alguns casos, especialmente quando voc\u00ea antecipa crescimento futuro ou a possibilidade de mesclar VNets. Isso pode ajudar a evitar conflitos de reendere\u00e7amento ao expandir ou mesclar redes. Reserve endere\u00e7os IP: Reserve uma faixa de endere\u00e7os IP dentro do espa\u00e7o de endere\u00e7o da sua VNet para recursos ou servi\u00e7os cr\u00edticos. Isso garante que eles tenham um endere\u00e7o IP est\u00e1tico, essencial para servi\u00e7os ou aplicativos espec\u00edficos. Planeje para cen\u00e1rios h\u00edbridos: Se voc\u00ea estiver trabalhando em um ambiente h\u00edbrido com redes locais ou multi-cloud, certifique-se de planejar a aloca\u00e7\u00e3o de endere\u00e7os IP em todos os ambientes. Isso inclui evitar sobreposi\u00e7\u00e3o de espa\u00e7os de endere\u00e7o e reservar endere\u00e7os IP para recursos espec\u00edficos, como gateways VPN ou circuitos ExpressRoute. Saiba mais em azure-best-practices/plan-for-ip-addressing Aloca\u00e7\u00e3o de Recursos Para aloca\u00e7\u00e3o de recursos, as melhores pr\u00e1ticas do Guia de Design de Recursos de Nuvem devem ser seguidas.","title":"Orienta\u00e7\u00f5es de Arquitetura de Rede para o Azure"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#orientacoes-de-arquitetura-de-rede-para-o-azure","text":"As seguintes s\u00e3o algumas das melhores pr\u00e1ticas ao configurar e trabalhar com recursos de rede em ambientes de nuvem do Azure. NOTA: Ao trabalhar em um ambiente de nuvem existente, \u00e9 importante entender quaisquer padr\u00f5es atuais e como eles s\u00e3o usados antes de fazer altera\u00e7\u00f5es neles. Voc\u00ea tamb\u00e9m deve trabalhar com as partes interessadas relevantes para garantir que quaisquer novos padr\u00f5es que voc\u00ea introduza proporcionem valor suficiente para justificar a mudan\u00e7a.","title":"Orienta\u00e7\u00f5es de Arquitetura de Rede para o Azure"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#configuracao-de-rede-e-vnet","text":"","title":"Configura\u00e7\u00e3o de Rede e VNet"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#topologia-de-concentrador-e-filial","text":"A topologia de rede de concentrador e filial \u00e9 um padr\u00e3o de arquitetura comum usado no Azure para organizar e gerenciar recursos de rede. Baseia-se no conceito de um concentrador central que se conecta a v\u00e1rias redes de filiais. Esse modelo \u00e9 particularmente \u00fatil para organizar recursos, manter a seguran\u00e7a e simplificar o gerenciamento de rede. O modelo de concentrador e filial \u00e9 implementado usando Redes Virtuais (VNet) e interconex\u00e3o de VNets (VNet peering). O concentrador: A VNet central age como um concentrador, fornecendo servi\u00e7os compartilhados como seguran\u00e7a de rede, monitoramento e conectividade com ambientes locais ou outras nuvens. Componentes comuns no concentrador incluem Dispositivos Virtuais de Rede (NVA), Firewall do Azure, Gateway VPN e Gateway ExpressRoute. As filiais: As VNets de filial representam unidades separadas ou aplicativos dentro de uma organiza\u00e7\u00e3o, cada um com seu pr\u00f3prio conjunto de recursos e servi\u00e7os. Elas se conectam ao concentrador por meio de interconex\u00e3o de VNets (VNet peering), o que permite a comunica\u00e7\u00e3o entre as VNets do concentrador e da filial. A implementa\u00e7\u00e3o de um modelo de concentrador e filial no Azure oferece v\u00e1rias vantagens: Isolamento e segmenta\u00e7\u00e3o: Ao dividir recursos em VNets de filiais separadas, voc\u00ea pode isolar e segmentar cargas de trabalho, impedindo que poss\u00edveis problemas ou riscos de seguran\u00e7a afetem outras partes da rede. Gerenciamento centralizado: A VNet do concentrador atua como um ponto \u00fanico de gerenciamento para servi\u00e7os compartilhados, facilitando a manuten\u00e7\u00e3o, o monitoramento e a aplica\u00e7\u00e3o de pol\u00edticas em toda a rede. Conectividade simplificada: A interconex\u00e3o de VNets (VNet peering) permite a comunica\u00e7\u00e3o sem problemas entre as VNets do concentrador e da filial, sem a necessidade de roteamento complexo ou gateways adicionais, reduzindo a lat\u00eancia e a sobrecarga de gerenciamento. Escalabilidade: O modelo de concentrador e filial pode ser facilmente dimensionado para acomodar filiais adicionais \u00e0 medida que a organiza\u00e7\u00e3o cresce ou \u00e0 medida que novos aplicativos e servi\u00e7os s\u00e3o introduzidos. Economia de custos: Centralizando servi\u00e7os compartilhados no concentrador, as organiza\u00e7\u00f5es podem reduzir os custos associados \u00e0 implanta\u00e7\u00e3o e ao gerenciamento de v\u00e1rias inst\u00e2ncias dos mesmos servi\u00e7os em diferentes VNets. Saiba mais sobre topologia de concentrador e filial Ao implantar um modelo de concentrador/filial, \u00e9 recomend\u00e1vel faz\u00ea-lo em conjunto com zonas de pouso (landing zones) . Isso garante consist\u00eancia em todos os ambientes, bem como salvaguardas para garantir um alto n\u00edvel de seguran\u00e7a, ao mesmo tempo em que oferece liberdade aos desenvolvedores nos ambientes de desenvolvimento.","title":"Topologia de Concentrador e Filial"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#firewall-e-seguranca","text":"Ao usar uma topologia de concentrador e filial, \u00e9 poss\u00edvel implantar um firewall centralizado no Hub que controle todo o tr\u00e1fego de sa\u00edda ou o tr\u00e1fego de/para determinadas VNets. Isso permite prote\u00e7\u00e3o centralizada contra amea\u00e7as, minimizando os custos.","title":"Firewall e Seguran\u00e7a"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#dns","text":"As melhores pr\u00e1ticas para o gerenciamento de DNS no Azure e em ambientes de nuvem em geral incluem o uso de servi\u00e7os de DNS gerenciados. Alguns dos benef\u00edcios de usar servi\u00e7os de DNS gerenciados s\u00e3o que os recursos s\u00e3o projetados para serem seguros, f\u00e1ceis de implantar e configurar. Encaminhamento de DNS: Configure o encaminhamento de DNS entre seus servidores de DNS locais e os servidores de DNS do Azure para resolu\u00e7\u00e3o de nomes em diferentes ambientes. Use zonas DNS Privadas do Azure para recursos do Azure: Configure zonas DNS Privadas do Azure para seus recursos do Azure para garantir que a resolu\u00e7\u00e3o de nomes seja mantida dentro da rede virtual. Saiba mais sobre infraestrutura de DNS h\u00edbrido/multi-cloud e infraestrutura de DNS do Azure","title":"DNS"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#alocacao-de-ip","text":"Ao alocar espa\u00e7os de endere\u00e7o IP para Redes Virtuais do Azure (VNets), \u00e9 essencial seguir as melhores pr\u00e1ticas para um gerenciamento adequado e escalabilidade. Aqui est\u00e3o algumas recomenda\u00e7\u00f5es para aloca\u00e7\u00e3o de IP para VNets: Reserve endere\u00e7os IP: Reserve endere\u00e7os IP em seu espa\u00e7o de endere\u00e7o para recursos ou servi\u00e7os cr\u00edticos. Aloca\u00e7\u00e3o de IP p\u00fablica: Minimize o uso de endere\u00e7os IP p\u00fablicos e use o Azure Private Link sempre que poss\u00edvel para acessar servi\u00e7os por meio de uma conex\u00e3o privada. Gerenciamento de endere\u00e7os IP (IPAM): Use solu\u00e7\u00f5es de IPAM para gerenciar e acompanhar a aloca\u00e7\u00e3o de endere\u00e7os IP em todo o ambiente h\u00edbrido. Planeje seu espa\u00e7o de endere\u00e7o: Escolha um espa\u00e7o de endere\u00e7o IP privado apropriado (a partir do RFC 1918) para suas VNets que seja grande o suficiente para acomodar o crescimento futuro. Evite sobreposi\u00e7\u00e3o com redes locais ou de outras nuvens. Use nota\u00e7\u00e3o CIDR: Use a nota\u00e7\u00e3o CIDR (Classless Inter-Domain Routing) para definir o espa\u00e7o de endere\u00e7o da VNet, o que permite uma aloca\u00e7\u00e3o mais eficiente e impede o desperd\u00edcio de endere\u00e7os IP. Use sub-redes: Divida suas VNets em sub-redes menores com base em requisitos de seguran\u00e7a, aplica\u00e7\u00e3o ou ambiente. Isso permite um melhor gerenciamento e seguran\u00e7a de rede. Considere deixar um buffer entre as VNets: Embora n\u00e3o seja estritamente necess\u00e1rio, deixar um buffer entre as VNets pode ser ben\u00e9fico em alguns casos, especialmente quando voc\u00ea antecipa crescimento futuro ou a possibilidade de mesclar VNets. Isso pode ajudar a evitar conflitos de reendere\u00e7amento ao expandir ou mesclar redes. Reserve endere\u00e7os IP: Reserve uma faixa de endere\u00e7os IP dentro do espa\u00e7o de endere\u00e7o da sua VNet para recursos ou servi\u00e7os cr\u00edticos. Isso garante que eles tenham um endere\u00e7o IP est\u00e1tico, essencial para servi\u00e7os ou aplicativos espec\u00edficos. Planeje para cen\u00e1rios h\u00edbridos: Se voc\u00ea estiver trabalhando em um ambiente h\u00edbrido com redes locais ou multi-cloud, certifique-se de planejar a aloca\u00e7\u00e3o de endere\u00e7os IP em todos os ambientes. Isso inclui evitar sobreposi\u00e7\u00e3o de espa\u00e7os de endere\u00e7o e reservar endere\u00e7os IP para recursos espec\u00edficos, como gateways VPN ou circuitos ExpressRoute. Saiba mais em azure-best-practices/plan-for-ip-addressing","title":"Aloca\u00e7\u00e3o de IP"},{"location":"design/design-patterns/network-architecture-guidance-for-azure/#alocacao-de-recursos","text":"Para aloca\u00e7\u00e3o de recursos, as melhores pr\u00e1ticas do Guia de Design de Recursos de Nuvem devem ser seguidas.","title":"Aloca\u00e7\u00e3o de Recursos"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/","text":"Orienta\u00e7\u00f5es de Arquitetura de Rede para Ambientes H\u00edbridos As seguintes s\u00e3o as melhores pr\u00e1ticas sobre como projetar e configurar recursos usados em ambientes h\u00edbridos e multi-cloud. NOTA: Ao trabalhar em um ambiente h\u00edbrido existente, \u00e9 importante entender quaisquer padr\u00f5es atuais e como eles s\u00e3o usados antes de fazer qualquer altera\u00e7\u00e3o. Topologia de Concentrador e Filial A topologia de concentrador e filial n\u00e3o muda muito ao usar nuvem/h\u00edbrido se configurada corretamente. A principal diferen\u00e7a \u00e9 que a VNet do concentrador est\u00e1 interconectada com a rede local por meio de um ExpressRoute e que todo o tr\u00e1fego do Azure pode sair via ExpressRoute e a conex\u00e3o com a Internet local. As melhores pr\u00e1ticas gerais est\u00e3o em Orienta\u00e7\u00f5es de Arquitetura de Rede para Azure#Topologia de Concentrador e Filial Aloca\u00e7\u00e3o de IP Ao trabalhar com implanta\u00e7\u00f5es h\u00edbridas, tome cuidado extra ao planejar a aloca\u00e7\u00e3o de IPs, pois existe um risco muito maior de sobreposi\u00e7\u00e3o de intervalos de rede. As melhores pr\u00e1ticas gerais est\u00e3o dispon\u00edveis em Orienta\u00e7\u00f5es de Arquitetura de Rede para Azure#Aloca\u00e7\u00e3o de IP Saiba mais sobre isso em Melhores Pr\u00e1ticas do Azure para Planejamento de Endere\u00e7amento IP ExpressRoute Ambientes que usam o ExpressRoute frequentemente direcionam todo o tr\u00e1fego do Azure por meio de uma conex\u00e3o privada (ExpressRoute) para um local local. Isso imp\u00f5e alguns problemas ao trabalhar com ofertas de PAAS, pois nem todas elas se conectam por meio de seu respectivo ponto de extremidade privado e, em vez disso, usam um IP externo para conex\u00f5es de sa\u00edda, ou algum tr\u00e1fego de PAAS para PAAS ocorre internamente no Azure e n\u00e3o funcionar\u00e1 com redes p\u00fablicas desativadas. Dois servi\u00e7os not\u00e1veis aqui s\u00e3o c\u00f3pias dos planos de dados de contas de armazenamento e muitos dos servi\u00e7os n\u00e3o suportam pontos de extremidade privados. Escolha o circuito ExpressRoute certo: selecione um SKU (Padr\u00e3o ou Premium) e largura de banda apropriados com base nos requisitos da sua organiza\u00e7\u00e3o. Redund\u00e2ncia: garanta redund\u00e2ncia provisionando dois circuitos ExpressRoute em locais de interconex\u00e3o diferentes. Monitoramento: use o Azure Monitor e o Network Performance Monitor (NPM) para monitorar a sa\u00fade e o desempenho de seus circuitos ExpressRoute. DNS As melhores pr\u00e1ticas gerais est\u00e3o dispon\u00edveis em Orienta\u00e7\u00f5es de Arquitetura de Rede para Azure#DNS Ao usar o Azure DNS em um ambiente h\u00edbrido ou multi-cloud, \u00e9 importante garantir uma configura\u00e7\u00e3o de DNS e encaminhamento consistente que garanta que os registros sejam atualizados automaticamente e que todos os servidores DNS estejam cientes uns dos outros e saibam qual servidor \u00e9 o autorizado para os diferentes registros. Saiba mais sobre Infraestrutura de DNS H\u00edbrida/Multi-Cloud Aloca\u00e7\u00e3o de Recursos Para aloca\u00e7\u00e3o de recursos, as melhores pr\u00e1ticas do Guia de Design de Recursos de Nuvem devem ser seguidas.","title":"Orienta\u00e7\u00f5es de Arquitetura de Rede para Ambientes H\u00edbridos"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/#orientacoes-de-arquitetura-de-rede-para-ambientes-hibridos","text":"As seguintes s\u00e3o as melhores pr\u00e1ticas sobre como projetar e configurar recursos usados em ambientes h\u00edbridos e multi-cloud. NOTA: Ao trabalhar em um ambiente h\u00edbrido existente, \u00e9 importante entender quaisquer padr\u00f5es atuais e como eles s\u00e3o usados antes de fazer qualquer altera\u00e7\u00e3o.","title":"Orienta\u00e7\u00f5es de Arquitetura de Rede para Ambientes H\u00edbridos"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/#topologia-de-concentrador-e-filial","text":"A topologia de concentrador e filial n\u00e3o muda muito ao usar nuvem/h\u00edbrido se configurada corretamente. A principal diferen\u00e7a \u00e9 que a VNet do concentrador est\u00e1 interconectada com a rede local por meio de um ExpressRoute e que todo o tr\u00e1fego do Azure pode sair via ExpressRoute e a conex\u00e3o com a Internet local. As melhores pr\u00e1ticas gerais est\u00e3o em Orienta\u00e7\u00f5es de Arquitetura de Rede para Azure#Topologia de Concentrador e Filial","title":"Topologia de Concentrador e Filial"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/#alocacao-de-ip","text":"Ao trabalhar com implanta\u00e7\u00f5es h\u00edbridas, tome cuidado extra ao planejar a aloca\u00e7\u00e3o de IPs, pois existe um risco muito maior de sobreposi\u00e7\u00e3o de intervalos de rede. As melhores pr\u00e1ticas gerais est\u00e3o dispon\u00edveis em Orienta\u00e7\u00f5es de Arquitetura de Rede para Azure#Aloca\u00e7\u00e3o de IP Saiba mais sobre isso em Melhores Pr\u00e1ticas do Azure para Planejamento de Endere\u00e7amento IP","title":"Aloca\u00e7\u00e3o de IP"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/#expressroute","text":"Ambientes que usam o ExpressRoute frequentemente direcionam todo o tr\u00e1fego do Azure por meio de uma conex\u00e3o privada (ExpressRoute) para um local local. Isso imp\u00f5e alguns problemas ao trabalhar com ofertas de PAAS, pois nem todas elas se conectam por meio de seu respectivo ponto de extremidade privado e, em vez disso, usam um IP externo para conex\u00f5es de sa\u00edda, ou algum tr\u00e1fego de PAAS para PAAS ocorre internamente no Azure e n\u00e3o funcionar\u00e1 com redes p\u00fablicas desativadas. Dois servi\u00e7os not\u00e1veis aqui s\u00e3o c\u00f3pias dos planos de dados de contas de armazenamento e muitos dos servi\u00e7os n\u00e3o suportam pontos de extremidade privados. Escolha o circuito ExpressRoute certo: selecione um SKU (Padr\u00e3o ou Premium) e largura de banda apropriados com base nos requisitos da sua organiza\u00e7\u00e3o. Redund\u00e2ncia: garanta redund\u00e2ncia provisionando dois circuitos ExpressRoute em locais de interconex\u00e3o diferentes. Monitoramento: use o Azure Monitor e o Network Performance Monitor (NPM) para monitorar a sa\u00fade e o desempenho de seus circuitos ExpressRoute.","title":"ExpressRoute"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/#dns","text":"As melhores pr\u00e1ticas gerais est\u00e3o dispon\u00edveis em Orienta\u00e7\u00f5es de Arquitetura de Rede para Azure#DNS Ao usar o Azure DNS em um ambiente h\u00edbrido ou multi-cloud, \u00e9 importante garantir uma configura\u00e7\u00e3o de DNS e encaminhamento consistente que garanta que os registros sejam atualizados automaticamente e que todos os servidores DNS estejam cientes uns dos outros e saibam qual servidor \u00e9 o autorizado para os diferentes registros. Saiba mais sobre Infraestrutura de DNS H\u00edbrida/Multi-Cloud","title":"DNS"},{"location":"design/design-patterns/network-architecture-guidance-for-hybrid/#alocacao-de-recursos","text":"Para aloca\u00e7\u00e3o de recursos, as melhores pr\u00e1ticas do Guia de Design de Recursos de Nuvem devem ser seguidas.","title":"Aloca\u00e7\u00e3o de Recursos"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/","text":"Captura de Requisitos N\u00e3o Funcionais Objetivos Em projetos de engenharia de software, caracter\u00edsticas importantes do sistema, como testabilidade, confiabilidade, escalabilidade, observabilidade, seguran\u00e7a, gerenciabilidade, entre outras, devem ser consideradas como requisitos n\u00e3o funcionais de primeira classe no processo de levantamento de requisitos. Ao definir esses requisitos n\u00e3o funcionais em detalhes no in\u00edcio do projeto, eles podem ser adequadamente avaliados quando o custo de seu impacto nas decis\u00f5es de design subsequentes \u00e9 comparativamente baixo. Para apoiar o processo de captura de requisitos n\u00e3o funcionais completos de um projeto, este documento oferece uma taxonomia para requisitos n\u00e3o funcionais e fornece um framework para sua identifica\u00e7\u00e3o, explora\u00e7\u00e3o, atribui\u00e7\u00e3o aos stakeholders do cliente e, finalmente, codifica\u00e7\u00e3o em requisitos de engenharia formais como entrada para o subsequente design da solu\u00e7\u00e3o. \u00c1reas de Investiga\u00e7\u00e3o Seguran\u00e7a Empresarial Privacidade PII (Informa\u00e7\u00f5es Pessoalmente Identific\u00e1veis) HIPAA Criptografia Mobilidade de Dados em repouso em tr\u00e2nsito em processo/mem\u00f3ria Gerenciamento de Chaves responsabilidade plataforma BYOK (Traga sua pr\u00f3pria chave) CMK (Chave de Gerenciamento de Cliente) Regulamenta\u00e7\u00f5es/normas de INFOSEC (Seguran\u00e7a da Informa\u00e7\u00e3o) por exemplo, FIPS-140-2 N\u00edvel 2 N\u00edvel 3 S\u00e9rie ISO 27000 NIST (Instituto Nacional de Padr\u00f5es e Tecnologia) Outros Seguran\u00e7a de Rede Limites/fluxo de tr\u00e1fego f\u00edsico/l\u00f3gico/topologia Azure <-- --> On-premises (Local) P\u00fablico <-- --> Azure VNET PIP (Endere\u00e7o IP P\u00fablico) Firewalls VPN (Rede Virtual Privada) ExpressRoute Topologia Seguran\u00e7a Certificados Emissor CA (Autoridade de Certifica\u00e7\u00e3o) Autoassinado Rota\u00e7\u00e3o/expira\u00e7\u00e3o Resposta a Incidentes de INFOSEC Processo Pessoas Responsabilidades Sistemas Jur\u00eddico/regulat\u00f3rio/conformidade Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o Empresariais Usu\u00e1rios Servi\u00e7os Autoridades/diret\u00f3rios Mecanismos/apertos de m\u00e3os (handshakes) Active Directory SAML (Linguagem de Marca\u00e7\u00e3o de Seguran\u00e7a) OAuth Outros Controle de Acesso Baseado em Fun\u00e7\u00f5es (RBAC - Role-Based Access Control) Modelo de heran\u00e7a de permiss\u00f5es Monitoramento/Opera\u00e7\u00f5es Empresariais Registro (Logging) Opera\u00e7\u00f5es Relat\u00f3rios Auditoria Monitoramento Diagn\u00f3stico/Alertas Opera\u00e7\u00f5es Alta disponibilidade/Recupera\u00e7\u00e3o de Desastres Redund\u00e2ncia Recupera\u00e7\u00e3o/Mitiga\u00e7\u00e3o Pr\u00e1ticas Princ\u00edpio do m\u00ednimo privil\u00e9gio Princ\u00edpio da separa\u00e7\u00e3o de responsabilidades Outras tecnologias/pr\u00e1ticas empresariais padr\u00e3o Ecossistema de Desenvolvedores Plataforma/Sistema Operacional Refor\u00e7ado Imagens base aprovadas Reposit\u00f3rio de imagens Ferramentas, linguagens Processo de aprova\u00e7\u00e3o Reposit\u00f3rios de c\u00f3digo Padr\u00f5es de gerenciamento de segredos Vari\u00e1veis de ambiente Arquivo(s) de configura\u00e7\u00e3o API de recupera\u00e7\u00e3o de segredos Origens de gerenciadores de pacotes Privadas P\u00fablicas Aprovadas/Confi\u00e1veis CI/CD (Integra\u00e7\u00e3o Cont\u00ednua/Entrega Cont\u00ednua) Reposit\u00f3rios de artefatos Ecossistema de Produ\u00e7\u00e3o Plataforma/Sistema Operacional Refor\u00e7ado Imagens base aprovadas Reposit\u00f3rio de imagens Longevidade/volatilidade da implanta\u00e7\u00e3o Automa\u00e7\u00e3o Reprodutibilidade IaC (Infraestrutura como C\u00f3digo) Scripting Outros Outras \u00e1reas/t\u00f3picos n\u00e3o abordados acima (requer entrada do cliente para enumerar de forma abrangente) Processo de Investiga\u00e7\u00e3o Identifique/brainstorm \u00e1reas/t\u00f3picos prov\u00e1veis que requerem investiga\u00e7\u00e3o/defini\u00e7\u00e3o adicional. Identifique os stakeholders do cliente respons\u00e1veis por cada \u00e1rea/t\u00f3pico identificado. Ag ende sess\u00f5es de defini\u00e7\u00e3o de requisitos/debrief com cada stakeholder conforme necess\u00e1rio para alcan\u00e7ar uma compreens\u00e3o suficiente do impacto prov\u00e1vel de cada requisito no projeto, tanto no marco atual/inicial quanto no roadmap de longo prazo. 1. Documente os requisitos/depend\u00eancias identificados e as restri\u00e7\u00f5es de design relacionadas. 1. Avalie os marcos atuais/near-term planejados atrav\u00e9s da lente dos requisitos/constrangimentos identificados. - Categorize cada requisito como afetando os marcos imediatos/near-termos ou como aplic\u00e1vel apenas ao roadmap de longo prazo/subsequentes marcos. 1. Adapte os planos para os marcos atuais/near-termos para acomodar os requisitos categorizados como imediatos/near-termos. Estrutura do Esbo\u00e7o/Atribui\u00e7\u00e3o do Stakeholder Respons\u00e1vel No esbo\u00e7o a seguir, atribua o nome/email do 'stakeholder respons\u00e1vel' para cada elemento ap\u00f3s o n\u00edvel apropriado na hierarquia do esbo\u00e7o. Assuma o modelo de atribui\u00e7\u00e3o de responsabilidade por heran\u00e7a: o stakeholder em qualquer n\u00edvel ancestral (pai) tamb\u00e9m \u00e9 respons\u00e1vel pelos elementos descendentes (filhos), a menos que seja substitu\u00eddo no n\u00edvel descendente. Exemplo: Pai1 [Susan/susan@dominio.com] filho1 filho2 [John/john@dominio.com] neto1 filho3 Pai2 [Sam/sam@dominio.com] filho1 filho2 No exemplo anterior, 'Susan' \u00e9 respons\u00e1vel por Pai1 e todos os seus descendentes, exceto por Pai1/filho2 e Pai1/filho2/neto1 (para os quais 'John' \u00e9 o stakeholder). 'Sam' \u00e9 respons\u00e1vel por Pai2 e todos os seus descendentes. Essa abordagem permite a reten\u00e7\u00e3o da hierarquia l\u00f3gica dos elementos em si, ao mesmo tempo em que intercala de forma flex\u00edvel as identifica\u00e7\u00f5es de 'stakeholder' dentro da hierarquia de t\u00f3picos, se e quando elas precisarem divergir devido a nuances organizacionais do cliente.","title":"Captura de Requisitos N\u00e3o Funcionais"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#captura-de-requisitos-nao-funcionais","text":"","title":"Captura de Requisitos N\u00e3o Funcionais"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#objetivos","text":"Em projetos de engenharia de software, caracter\u00edsticas importantes do sistema, como testabilidade, confiabilidade, escalabilidade, observabilidade, seguran\u00e7a, gerenciabilidade, entre outras, devem ser consideradas como requisitos n\u00e3o funcionais de primeira classe no processo de levantamento de requisitos. Ao definir esses requisitos n\u00e3o funcionais em detalhes no in\u00edcio do projeto, eles podem ser adequadamente avaliados quando o custo de seu impacto nas decis\u00f5es de design subsequentes \u00e9 comparativamente baixo. Para apoiar o processo de captura de requisitos n\u00e3o funcionais completos de um projeto, este documento oferece uma taxonomia para requisitos n\u00e3o funcionais e fornece um framework para sua identifica\u00e7\u00e3o, explora\u00e7\u00e3o, atribui\u00e7\u00e3o aos stakeholders do cliente e, finalmente, codifica\u00e7\u00e3o em requisitos de engenharia formais como entrada para o subsequente design da solu\u00e7\u00e3o.","title":"Objetivos"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#areas-de-investigacao","text":"","title":"\u00c1reas de Investiga\u00e7\u00e3o"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#seguranca-empresarial","text":"Privacidade PII (Informa\u00e7\u00f5es Pessoalmente Identific\u00e1veis) HIPAA Criptografia Mobilidade de Dados em repouso em tr\u00e2nsito em processo/mem\u00f3ria Gerenciamento de Chaves responsabilidade plataforma BYOK (Traga sua pr\u00f3pria chave) CMK (Chave de Gerenciamento de Cliente) Regulamenta\u00e7\u00f5es/normas de INFOSEC (Seguran\u00e7a da Informa\u00e7\u00e3o) por exemplo, FIPS-140-2 N\u00edvel 2 N\u00edvel 3 S\u00e9rie ISO 27000 NIST (Instituto Nacional de Padr\u00f5es e Tecnologia) Outros Seguran\u00e7a de Rede Limites/fluxo de tr\u00e1fego f\u00edsico/l\u00f3gico/topologia Azure <-- --> On-premises (Local) P\u00fablico <-- --> Azure VNET PIP (Endere\u00e7o IP P\u00fablico) Firewalls VPN (Rede Virtual Privada) ExpressRoute Topologia Seguran\u00e7a Certificados Emissor CA (Autoridade de Certifica\u00e7\u00e3o) Autoassinado Rota\u00e7\u00e3o/expira\u00e7\u00e3o Resposta a Incidentes de INFOSEC Processo Pessoas Responsabilidades Sistemas Jur\u00eddico/regulat\u00f3rio/conformidade","title":"Seguran\u00e7a Empresarial"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#autenticacao-e-autorizacao-empresariais","text":"Usu\u00e1rios Servi\u00e7os Autoridades/diret\u00f3rios Mecanismos/apertos de m\u00e3os (handshakes) Active Directory SAML (Linguagem de Marca\u00e7\u00e3o de Seguran\u00e7a) OAuth Outros Controle de Acesso Baseado em Fun\u00e7\u00f5es (RBAC - Role-Based Access Control) Modelo de heran\u00e7a de permiss\u00f5es","title":"Autentica\u00e7\u00e3o e Autoriza\u00e7\u00e3o Empresariais"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#monitoramentooperacoes-empresariais","text":"Registro (Logging) Opera\u00e7\u00f5es Relat\u00f3rios Auditoria Monitoramento Diagn\u00f3stico/Alertas Opera\u00e7\u00f5es Alta disponibilidade/Recupera\u00e7\u00e3o de Desastres Redund\u00e2ncia Recupera\u00e7\u00e3o/Mitiga\u00e7\u00e3o Pr\u00e1ticas Princ\u00edpio do m\u00ednimo privil\u00e9gio Princ\u00edpio da separa\u00e7\u00e3o de responsabilidades","title":"Monitoramento/Opera\u00e7\u00f5es Empresariais"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#outras-tecnologiaspraticas-empresariais-padrao","text":"Ecossistema de Desenvolvedores Plataforma/Sistema Operacional Refor\u00e7ado Imagens base aprovadas Reposit\u00f3rio de imagens Ferramentas, linguagens Processo de aprova\u00e7\u00e3o Reposit\u00f3rios de c\u00f3digo Padr\u00f5es de gerenciamento de segredos Vari\u00e1veis de ambiente Arquivo(s) de configura\u00e7\u00e3o API de recupera\u00e7\u00e3o de segredos Origens de gerenciadores de pacotes Privadas P\u00fablicas Aprovadas/Confi\u00e1veis CI/CD (Integra\u00e7\u00e3o Cont\u00ednua/Entrega Cont\u00ednua) Reposit\u00f3rios de artefatos","title":"Outras tecnologias/pr\u00e1ticas empresariais padr\u00e3o"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#ecossistema-de-producao","text":"Plataforma/Sistema Operacional Refor\u00e7ado Imagens base aprovadas Reposit\u00f3rio de imagens Longevidade/volatilidade da implanta\u00e7\u00e3o Automa\u00e7\u00e3o Reprodutibilidade IaC (Infraestrutura como C\u00f3digo) Scripting Outros","title":"Ecossistema de Produ\u00e7\u00e3o"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#outras-areastopicos-nao-abordados-acima-requer-entrada-do-cliente-para-enumerar-de-forma-abrangente","text":"","title":"Outras \u00e1reas/t\u00f3picos n\u00e3o abordados acima (requer entrada do cliente para enumerar de forma abrangente)"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#processo-de-investigacao","text":"Identifique/brainstorm \u00e1reas/t\u00f3picos prov\u00e1veis que requerem investiga\u00e7\u00e3o/defini\u00e7\u00e3o adicional. Identifique os stakeholders do cliente respons\u00e1veis por cada \u00e1rea/t\u00f3pico identificado. Ag ende sess\u00f5es de defini\u00e7\u00e3o de requisitos/debrief com cada stakeholder conforme necess\u00e1rio para alcan\u00e7ar uma compreens\u00e3o suficiente do impacto prov\u00e1vel de cada requisito no projeto, tanto no marco atual/inicial quanto no roadmap de longo prazo. 1. Documente os requisitos/depend\u00eancias identificados e as restri\u00e7\u00f5es de design relacionadas. 1. Avalie os marcos atuais/near-term planejados atrav\u00e9s da lente dos requisitos/constrangimentos identificados. - Categorize cada requisito como afetando os marcos imediatos/near-termos ou como aplic\u00e1vel apenas ao roadmap de longo prazo/subsequentes marcos. 1. Adapte os planos para os marcos atuais/near-termos para acomodar os requisitos categorizados como imediatos/near-termos.","title":"Processo de Investiga\u00e7\u00e3o"},{"location":"design/design-patterns/non-functional-requirements-capture-guide/#estrutura-do-esbocoatribuicao-do-stakeholder-responsavel","text":"No esbo\u00e7o a seguir, atribua o nome/email do 'stakeholder respons\u00e1vel' para cada elemento ap\u00f3s o n\u00edvel apropriado na hierarquia do esbo\u00e7o. Assuma o modelo de atribui\u00e7\u00e3o de responsabilidade por heran\u00e7a: o stakeholder em qualquer n\u00edvel ancestral (pai) tamb\u00e9m \u00e9 respons\u00e1vel pelos elementos descendentes (filhos), a menos que seja substitu\u00eddo no n\u00edvel descendente. Exemplo: Pai1 [Susan/susan@dominio.com] filho1 filho2 [John/john@dominio.com] neto1 filho3 Pai2 [Sam/sam@dominio.com] filho1 filho2 No exemplo anterior, 'Susan' \u00e9 respons\u00e1vel por Pai1 e todos os seus descendentes, exceto por Pai1/filho2 e Pai1/filho2/neto1 (para os quais 'John' \u00e9 o stakeholder). 'Sam' \u00e9 respons\u00e1vel por Pai2 e todos os seus descendentes. Essa abordagem permite a reten\u00e7\u00e3o da hierarquia l\u00f3gica dos elementos em si, ao mesmo tempo em que intercala de forma flex\u00edvel as identifica\u00e7\u00f5es de 'stakeholder' dentro da hierarquia de t\u00f3picos, se e quando elas precisarem divergir devido a nuances organizacionais do cliente.","title":"Estrutura do Esbo\u00e7o/Atribui\u00e7\u00e3o do Stakeholder Respons\u00e1vel"},{"location":"design/design-patterns/object-oriented-design-reference/","text":"Refer\u00eancia de Design Orientado a Objetos Ao escrever software para projetos de grande porte, a parte mais desafiadora geralmente \u00e9 a comunica\u00e7\u00e3o e a manuten\u00e7\u00e3o. Seguir padr\u00f5es de design comprovados pode otimizar a manuten\u00e7\u00e3o, a legibilidade e a facilidade de extens\u00e3o. Em particular, os padr\u00f5es de design orientado a objetos s\u00e3o amplamente reconhecidos na ind\u00fastria. Por favor, consulte os seguintes recursos para criar designs orientados a objetos robustos: Wikipedia de Padr\u00f5es de Design Site de Design Orientado a Objetos","title":"Refer\u00eancia de Design Orientado a Objetos"},{"location":"design/design-patterns/object-oriented-design-reference/#referencia-de-design-orientado-a-objetos","text":"Ao escrever software para projetos de grande porte, a parte mais desafiadora geralmente \u00e9 a comunica\u00e7\u00e3o e a manuten\u00e7\u00e3o. Seguir padr\u00f5es de design comprovados pode otimizar a manuten\u00e7\u00e3o, a legibilidade e a facilidade de extens\u00e3o. Em particular, os padr\u00f5es de design orientado a objetos s\u00e3o amplamente reconhecidos na ind\u00fastria. Por favor, consulte os seguintes recursos para criar designs orientados a objetos robustos: Wikipedia de Padr\u00f5es de Design Site de Design Orientado a Objetos","title":"Refer\u00eancia de Design Orientado a Objetos"},{"location":"design/design-patterns/rest-api-design-guidance/","text":"Orienta\u00e7\u00f5es de Design de REST API Objetivos Elevar as diretrizes de design de REST API publicadas pela Microsoft . Destacar decis\u00f5es de design comuns e fatores a serem considerados ao projetar. Fornecer recursos adicionais para informar o design de API em \u00e1reas n\u00e3o abordadas diretamente pelas diretrizes da Microsoft. Decis\u00f5es Comuns de Design de API As diretrizes da Microsoft para REST API fornecem orienta\u00e7\u00f5es de design que abrangem uma variedade de casos de uso. As seguintes se\u00e7\u00f5es s\u00e3o um bom ponto de partida, pois s\u00e3o considera\u00e7\u00f5es provavelmente necess\u00e1rias em qualquer design de REST API: Estrutura de URL M\u00e9todos HTTP C\u00f3digos de Status HTTP Cole\u00e7\u00f5es Padroniza\u00e7\u00f5es JSON Versionamento Nomenclatura Criando Contratos de API \u00c0 medida que diferentes equipes de desenvolvimento exp\u00f5em APIs para acessar v\u00e1rios servi\u00e7os baseados em REST, \u00e9 importante ter um contrato de API para compartilhar entre os produtores e consumidores de APIs. O formato Open API \u00e9 um dos formatos de descri\u00e7\u00e3o de API mais populares. Este documento Open API pode ser produzido de duas maneiras: Abordagem Design-First - A equipe come\u00e7a a desenvolver APIs descrevendo primeiro os designs da API como um documento Open API e posteriormente gera o c\u00f3digo de boilerplate do lado do servidor com a ajuda deste documento. Abordagem Code-First - A equipe come\u00e7a escrevendo o c\u00f3digo da interface da API do lado do servidor, como controladores, DTOs, etc., e posteriormente gera um documento Open API a partir dele. Abordagem Design-First Uma abordagem Design-First significa que as APIs s\u00e3o tratadas como \"cidad\u00e3os de primeira classe\" e tudo em torno de um projeto gira em torno da ideia de que, no final, essas APIs ser\u00e3o consumidas por clientes. Com base nos requisitos de neg\u00f3cios, a equipe de desenvolvimento de API come\u00e7a descrevendo primeiro os designs da API como um documento Open API e colabora com as partes interessadas para obter feedback. Essa abordagem \u00e9 bastante \u00fatil se um projeto envolver o desenvolvimento de um conjunto de APIs externamente expostas que ser\u00e3o consumidas por parceiros. Nessa abordagem, concordamos primeiro com um contrato de API (documento Open API), criando expectativas claras tanto para o produtor quanto para o consumidor da API, para que ambas as equipes possam come\u00e7ar a trabalhar em paralelo de acordo com o design da API pr\u00e9-acordado. Principais benef\u00edcios desta abordagem: Feedback precoce sobre o design da API. Expectativas claramente estabelecidas tanto para o consumidor quanto para o produtor, j\u00e1 que ambos concordaram com um contrato de API. As equipes de desenvolvimento podem trabalhar em paralelo. A equipe de testes pode usar os contratos de API para escrever testes antecipados, mesmo antes que a l\u00f3gica de neg\u00f3cios esteja implementada. Ao examinar modelos, caminhos, atributos e outros aspectos da API, os testadores podem fornecer seu feedback, o que pode ser muito valioso. Durante um ciclo de desenvolvimento \u00e1gil, as defini\u00e7\u00f5es de API n\u00e3o s\u00e3o impactadas por altera\u00e7\u00f5es incrementais. O design da API n\u00e3o \u00e9 influenciado por limita\u00e7\u00f5es de implementa\u00e7\u00e3o real e estrutura de c\u00f3digo. O c\u00f3digo de boilerplate do lado do servidor, como controladores, DTOs, etc., pode ser gerado automaticamente a partir dos contratos de API. Pode melhorar a colabora\u00e7\u00e3o entre as equipes de produtor e consumidor da API. Planejando um Desenvolvimento Design-First: Identifique casos de uso e servi\u00e7os-chave que a API deve oferecer. Identifique as principais partes interessadas da API e tente inclu\u00ed-las na fase de design da API para obter feedback cont\u00ednuo. Escreva defini\u00e7\u00f5es de contrato de API. Mantenha um estilo consistente para c\u00f3digos de status da API, versionamento, respostas de erro, etc. Incentive revis\u00f5es por pares por meio de solicita\u00e7\u00f5es de pull. Gere o c\u00f3digo de boilerplate do lado do servidor e os SDKs do cliente a partir das defini\u00e7\u00f5es de contrato de API. Pontos importantes a considerar: Se os requisitos da API mudarem com frequ\u00eancia durante a fase inicial de desenvolvimento, a abordagem Design-First pode n\u00e3o ser adequada, pois isso introduzir\u00e1 uma sobrecarga adicional, exigindo atualiza\u00e7\u00f5es e manuten\u00e7\u00e3o repetidas das defini\u00e7\u00f5es de contrato da API. Pode ser \u00fatil primeiro experimentar o gerador de c\u00f3digo espec\u00edfico da plataforma e avaliar quanto trabalho adicional ser\u00e1 necess\u00e1rio para atender aos requisitos e diretrizes de codifica\u00e7\u00e3o do projeto, pois \u00e9 poss\u00edvel que um gerador de c\u00f3digo espec\u00edfico da plataforma n\u00e3o consiga gerar uma implementa\u00e7\u00e3o flex\u00edvel e mantida do c\u00f3digo real. Por exemplo, se o seu framework web exigir que anota\u00e7\u00f5es estejam presentes em suas classes de controlador (por exemplo, para versionamento de API ou autentica\u00e7\u00e3o), certifique-se de que a ferramenta de gera\u00e7\u00e3o de c\u00f3digo que voc\u00ea usa as suporta totalmente. Microsoft TypeSpec \u00e9 uma ferramenta valiosa para desenvolvedores que trabalham com APIs complexas. Fornecendo padr\u00f5es reutiliz\u00e1veis, ele pode simplificar o desenvolvimento de APIs e promover as melhores pr\u00e1ticas. Criamos alguns exemplos de como aplicar uma abordagem de desenvolvimento Design-First em um pipeline de CI/CD do GitHub para ajudar a acelerar sua ado\u00e7\u00e3o em um Desenvolvimento Design-First. Abordagem Code-First Uma abordagem Code-First significa que as equipes de desenvolvimento primeiro implementam o c\u00f3digo da interface da API do lado do servidor, como controladores, DTOs, etc., e depois geram as defini\u00e7\u00f5es de contrato de API a partir dele. Nos tempos atuais, essa abordagem \u00e9 mais amplamente popular na comunidade de desenvolvedores do que a Abordagem Design-First. Essa abordagem tem a vantagem de permitir que a equipe implemente rapidamente as APIs e tamb\u00e9m fornece a flexibilidade de reagir muito rapidamente a quaisquer mudan\u00e7as inesperadas nos requisitos da API. Principais benef\u00edcios desta abordagem: Desenvolvimento r\u00e1pido de APIs, pois a equipe de desenvolvimento pode come\u00e7ar a implementar as APIs muito mais rapidamente ap\u00f3s entender os requisitos e casos de uso-chave. A equipe de desenvolvimento tem melhor controle e flexibilidade para implementar interfaces de API do lado do servidor da maneira que melhor se adapte \u00e0 estrutura do projeto. Mais popular entre as equipes de desenvolvimento, tornando mais f\u00e1cil obter consenso sobre t\u00f3picos relacionados e tamb\u00e9m possui mais exemplos de c\u00f3digo prontos para uso dispon\u00edveis em v\u00e1rios blogs ou f\u00f3runs de desenvolvedores sobre como gerar defini\u00e7\u00f5es Open API a partir do c\u00f3digo real. Pontos importantes a considerar: Uma defini\u00e7\u00e3o Open API gerada pode ficar desatualizada, portanto, \u00e9 importante ter verifica\u00e7\u00f5es automatizadas para evitar isso, caso contr\u00e1rio, os SDKs de cliente gerados estar\u00e3o desatualizados e podem causar problemas para os consumidores da API. Com o desenvolvimento \u00e1gil, \u00e9 dif\u00edcil garantir que as defini\u00e7\u00f5es incorporadas no c\u00f3digo em tempo de execu\u00e7\u00e3o permane\u00e7am est\u00e1veis, especialmente em rodadas de refatora\u00e7\u00e3o e ao atender v\u00e1rias vers\u00f5es concorrentes da API. Pode ser \u00fatil gerar regularmente a defini\u00e7\u00e3o Open API e armazen\u00e1-la em um sistema de controle de vers\u00e3o; caso contr\u00e1rio, gerar a defini\u00e7\u00e3o Open API em tempo de execu\u00e7\u00e3o pode tornar mais complexo em cen\u00e1rios em que essa defini\u00e7\u00e3o \u00e9 necess\u00e1ria durante o desenvolvimento/tempo de CI. Como Interpretar e Aplicar as Diretrizes O documento de diretrizes de API inclui uma se\u00e7\u00e3o sobre como aplicar as diretrizes , dependendo se a API \u00e9 nova ou existente. Em particular, ao trabalhar em um ecossistema de API existente, certifique-se de alinhar com as partes interessadas uma defini\u00e7\u00e3o do que constitui uma mudan\u00e7a quebra para entender o impacto da implementa\u00e7\u00e3o de determinadas melhores pr\u00e1ticas. N\u00e3o recomendamos fazer uma mudan\u00e7a quebra em um servi\u00e7o que antecede estas diretrizes simplesmente para cumprir. Recursos Adicionais Lista de Leitura Recomendada da Microsoft para REST APIs Documenta\u00e7\u00e3o - Orienta\u00e7\u00e3o - REST APIs Defini\u00e7\u00f5es detalhadas de c\u00f3digos de status HTTP Versionamento Sem\u00e2ntico Outras Diretrizes P\u00fablicas de API Pr\u00e1ticas de Design OpenAPI Microsoft TypeSpec Exemplos de Fluxo de Trabalho do GitHub Microsoft TypeSpec","title":"Orienta\u00e7\u00f5es de Design de REST API"},{"location":"design/design-patterns/rest-api-design-guidance/#orientacoes-de-design-de-rest-api","text":"","title":"Orienta\u00e7\u00f5es de Design de REST API"},{"location":"design/design-patterns/rest-api-design-guidance/#objetivos","text":"Elevar as diretrizes de design de REST API publicadas pela Microsoft . Destacar decis\u00f5es de design comuns e fatores a serem considerados ao projetar. Fornecer recursos adicionais para informar o design de API em \u00e1reas n\u00e3o abordadas diretamente pelas diretrizes da Microsoft.","title":"Objetivos"},{"location":"design/design-patterns/rest-api-design-guidance/#decisoes-comuns-de-design-de-api","text":"As diretrizes da Microsoft para REST API fornecem orienta\u00e7\u00f5es de design que abrangem uma variedade de casos de uso. As seguintes se\u00e7\u00f5es s\u00e3o um bom ponto de partida, pois s\u00e3o considera\u00e7\u00f5es provavelmente necess\u00e1rias em qualquer design de REST API: Estrutura de URL M\u00e9todos HTTP C\u00f3digos de Status HTTP Cole\u00e7\u00f5es Padroniza\u00e7\u00f5es JSON Versionamento Nomenclatura","title":"Decis\u00f5es Comuns de Design de API"},{"location":"design/design-patterns/rest-api-design-guidance/#criando-contratos-de-api","text":"\u00c0 medida que diferentes equipes de desenvolvimento exp\u00f5em APIs para acessar v\u00e1rios servi\u00e7os baseados em REST, \u00e9 importante ter um contrato de API para compartilhar entre os produtores e consumidores de APIs. O formato Open API \u00e9 um dos formatos de descri\u00e7\u00e3o de API mais populares. Este documento Open API pode ser produzido de duas maneiras: Abordagem Design-First - A equipe come\u00e7a a desenvolver APIs descrevendo primeiro os designs da API como um documento Open API e posteriormente gera o c\u00f3digo de boilerplate do lado do servidor com a ajuda deste documento. Abordagem Code-First - A equipe come\u00e7a escrevendo o c\u00f3digo da interface da API do lado do servidor, como controladores, DTOs, etc., e posteriormente gera um documento Open API a partir dele.","title":"Criando Contratos de API"},{"location":"design/design-patterns/rest-api-design-guidance/#abordagem-design-first","text":"Uma abordagem Design-First significa que as APIs s\u00e3o tratadas como \"cidad\u00e3os de primeira classe\" e tudo em torno de um projeto gira em torno da ideia de que, no final, essas APIs ser\u00e3o consumidas por clientes. Com base nos requisitos de neg\u00f3cios, a equipe de desenvolvimento de API come\u00e7a descrevendo primeiro os designs da API como um documento Open API e colabora com as partes interessadas para obter feedback. Essa abordagem \u00e9 bastante \u00fatil se um projeto envolver o desenvolvimento de um conjunto de APIs externamente expostas que ser\u00e3o consumidas por parceiros. Nessa abordagem, concordamos primeiro com um contrato de API (documento Open API), criando expectativas claras tanto para o produtor quanto para o consumidor da API, para que ambas as equipes possam come\u00e7ar a trabalhar em paralelo de acordo com o design da API pr\u00e9-acordado. Principais benef\u00edcios desta abordagem: Feedback precoce sobre o design da API. Expectativas claramente estabelecidas tanto para o consumidor quanto para o produtor, j\u00e1 que ambos concordaram com um contrato de API. As equipes de desenvolvimento podem trabalhar em paralelo. A equipe de testes pode usar os contratos de API para escrever testes antecipados, mesmo antes que a l\u00f3gica de neg\u00f3cios esteja implementada. Ao examinar modelos, caminhos, atributos e outros aspectos da API, os testadores podem fornecer seu feedback, o que pode ser muito valioso. Durante um ciclo de desenvolvimento \u00e1gil, as defini\u00e7\u00f5es de API n\u00e3o s\u00e3o impactadas por altera\u00e7\u00f5es incrementais. O design da API n\u00e3o \u00e9 influenciado por limita\u00e7\u00f5es de implementa\u00e7\u00e3o real e estrutura de c\u00f3digo. O c\u00f3digo de boilerplate do lado do servidor, como controladores, DTOs, etc., pode ser gerado automaticamente a partir dos contratos de API. Pode melhorar a colabora\u00e7\u00e3o entre as equipes de produtor e consumidor da API. Planejando um Desenvolvimento Design-First: Identifique casos de uso e servi\u00e7os-chave que a API deve oferecer. Identifique as principais partes interessadas da API e tente inclu\u00ed-las na fase de design da API para obter feedback cont\u00ednuo. Escreva defini\u00e7\u00f5es de contrato de API. Mantenha um estilo consistente para c\u00f3digos de status da API, versionamento, respostas de erro, etc. Incentive revis\u00f5es por pares por meio de solicita\u00e7\u00f5es de pull. Gere o c\u00f3digo de boilerplate do lado do servidor e os SDKs do cliente a partir das defini\u00e7\u00f5es de contrato de API. Pontos importantes a considerar: Se os requisitos da API mudarem com frequ\u00eancia durante a fase inicial de desenvolvimento, a abordagem Design-First pode n\u00e3o ser adequada, pois isso introduzir\u00e1 uma sobrecarga adicional, exigindo atualiza\u00e7\u00f5es e manuten\u00e7\u00e3o repetidas das defini\u00e7\u00f5es de contrato da API. Pode ser \u00fatil primeiro experimentar o gerador de c\u00f3digo espec\u00edfico da plataforma e avaliar quanto trabalho adicional ser\u00e1 necess\u00e1rio para atender aos requisitos e diretrizes de codifica\u00e7\u00e3o do projeto, pois \u00e9 poss\u00edvel que um gerador de c\u00f3digo espec\u00edfico da plataforma n\u00e3o consiga gerar uma implementa\u00e7\u00e3o flex\u00edvel e mantida do c\u00f3digo real. Por exemplo, se o seu framework web exigir que anota\u00e7\u00f5es estejam presentes em suas classes de controlador (por exemplo, para versionamento de API ou autentica\u00e7\u00e3o), certifique-se de que a ferramenta de gera\u00e7\u00e3o de c\u00f3digo que voc\u00ea usa as suporta totalmente. Microsoft TypeSpec \u00e9 uma ferramenta valiosa para desenvolvedores que trabalham com APIs complexas. Fornecendo padr\u00f5es reutiliz\u00e1veis, ele pode simplificar o desenvolvimento de APIs e promover as melhores pr\u00e1ticas. Criamos alguns exemplos de como aplicar uma abordagem de desenvolvimento Design-First em um pipeline de CI/CD do GitHub para ajudar a acelerar sua ado\u00e7\u00e3o em um Desenvolvimento Design-First.","title":"Abordagem Design-First"},{"location":"design/design-patterns/rest-api-design-guidance/#abordagem-code-first","text":"Uma abordagem Code-First significa que as equipes de desenvolvimento primeiro implementam o c\u00f3digo da interface da API do lado do servidor, como controladores, DTOs, etc., e depois geram as defini\u00e7\u00f5es de contrato de API a partir dele. Nos tempos atuais, essa abordagem \u00e9 mais amplamente popular na comunidade de desenvolvedores do que a Abordagem Design-First. Essa abordagem tem a vantagem de permitir que a equipe implemente rapidamente as APIs e tamb\u00e9m fornece a flexibilidade de reagir muito rapidamente a quaisquer mudan\u00e7as inesperadas nos requisitos da API. Principais benef\u00edcios desta abordagem: Desenvolvimento r\u00e1pido de APIs, pois a equipe de desenvolvimento pode come\u00e7ar a implementar as APIs muito mais rapidamente ap\u00f3s entender os requisitos e casos de uso-chave. A equipe de desenvolvimento tem melhor controle e flexibilidade para implementar interfaces de API do lado do servidor da maneira que melhor se adapte \u00e0 estrutura do projeto. Mais popular entre as equipes de desenvolvimento, tornando mais f\u00e1cil obter consenso sobre t\u00f3picos relacionados e tamb\u00e9m possui mais exemplos de c\u00f3digo prontos para uso dispon\u00edveis em v\u00e1rios blogs ou f\u00f3runs de desenvolvedores sobre como gerar defini\u00e7\u00f5es Open API a partir do c\u00f3digo real. Pontos importantes a considerar: Uma defini\u00e7\u00e3o Open API gerada pode ficar desatualizada, portanto, \u00e9 importante ter verifica\u00e7\u00f5es automatizadas para evitar isso, caso contr\u00e1rio, os SDKs de cliente gerados estar\u00e3o desatualizados e podem causar problemas para os consumidores da API. Com o desenvolvimento \u00e1gil, \u00e9 dif\u00edcil garantir que as defini\u00e7\u00f5es incorporadas no c\u00f3digo em tempo de execu\u00e7\u00e3o permane\u00e7am est\u00e1veis, especialmente em rodadas de refatora\u00e7\u00e3o e ao atender v\u00e1rias vers\u00f5es concorrentes da API. Pode ser \u00fatil gerar regularmente a defini\u00e7\u00e3o Open API e armazen\u00e1-la em um sistema de controle de vers\u00e3o; caso contr\u00e1rio, gerar a defini\u00e7\u00e3o Open API em tempo de execu\u00e7\u00e3o pode tornar mais complexo em cen\u00e1rios em que essa defini\u00e7\u00e3o \u00e9 necess\u00e1ria durante o desenvolvimento/tempo de CI.","title":"Abordagem Code-First"},{"location":"design/design-patterns/rest-api-design-guidance/#como-interpretar-e-aplicar-as-diretrizes","text":"O documento de diretrizes de API inclui uma se\u00e7\u00e3o sobre como aplicar as diretrizes , dependendo se a API \u00e9 nova ou existente. Em particular, ao trabalhar em um ecossistema de API existente, certifique-se de alinhar com as partes interessadas uma defini\u00e7\u00e3o do que constitui uma mudan\u00e7a quebra para entender o impacto da implementa\u00e7\u00e3o de determinadas melhores pr\u00e1ticas. N\u00e3o recomendamos fazer uma mudan\u00e7a quebra em um servi\u00e7o que antecede estas diretrizes simplesmente para cumprir.","title":"Como Interpretar e Aplicar as Diretrizes"},{"location":"design/design-patterns/rest-api-design-guidance/#recursos-adicionais","text":"Lista de Leitura Recomendada da Microsoft para REST APIs Documenta\u00e7\u00e3o - Orienta\u00e7\u00e3o - REST APIs Defini\u00e7\u00f5es detalhadas de c\u00f3digos de status HTTP Versionamento Sem\u00e2ntico Outras Diretrizes P\u00fablicas de API Pr\u00e1ticas de Design OpenAPI Microsoft TypeSpec Exemplos de Fluxo de Trabalho do GitHub Microsoft TypeSpec","title":"Recursos Adicionais"},{"location":"design/design-reviews/","text":"Revis\u00f5es de Design Sum\u00e1rio Objetivos Medidas Impacto Participa\u00e7\u00e3o Orienta\u00e7\u00e3o para Facilita\u00e7\u00e3o Avalia\u00e7\u00e3o T\u00e9cnica Objetivos Reduzir a d\u00edvida t\u00e9cnica para nossos clientes. Continuar a iterar no design ap\u00f3s a revis\u00e3o do Plano de Jogo. Gerar artefatos t\u00e9cnicos \u00fateis que possam ser referenciados pela Microsoft e pelos clientes. Medidas Custo da Mudan\u00e7a Ao incorporar revis\u00f5es de design como parte do processo de engenharia, as decis\u00f5es s\u00e3o tomadas antecipadamente antes do in\u00edcio da implementa\u00e7\u00e3o. Tomar a decis\u00e3o de usar o Azure Kubernetes Service em vez dos Servi\u00e7os de Aplicativos na fase de design provavelmente requer apenas a atualiza\u00e7\u00e3o da documenta\u00e7\u00e3o. No entanto, fazer essa mudan\u00e7a ap\u00f3s o in\u00edcio da implementa\u00e7\u00e3o ou ap\u00f3s a solu\u00e7\u00e3o estar em uso \u00e9 muito mais custoso. Essas mudan\u00e7as est\u00e3o ocorrendo antes ou depois da implementa\u00e7\u00e3o? Qual \u00e9 o esfor\u00e7o normalmente envolvido? Participa\u00e7\u00e3o dos Revisores Quantas pessoas participam das revis\u00f5es dos designs criados? Cumulativamente, se esse n\u00famero for maior, isso indicaria uma maior contribui\u00e7\u00e3o de ideias e perspectivas. Um n\u00famero menor (ou seja, as mesmas 2 pessoas apenas em cada revis\u00e3o) pode indicar um conjunto limitado de perspectivas. Algu\u00e9m est\u00e1 participando de fora da equipe central de desenvolvimento? Tempo para Solu\u00e7\u00f5es Potenciais Quanto tempo normalmente leva para ir dos requisitos \u00e0s op\u00e7\u00f5es de solu\u00e7\u00e3o (m\u00faltiplas)? H\u00e1 um equil\u00edbrio saud\u00e1vel entre gastar muito ou muito pouco tempo avaliando diferentes solu\u00e7\u00f5es potenciais. Muito pouco tempo aumenta o risco de mudan\u00e7as custosas necess\u00e1rias ap\u00f3s a implementa\u00e7\u00e3o. Muito tempo atrasa a entrega do valor-alvo e das funcionalidades subsequentes na fila. No entanto, quanto mais r\u00e1pido a equipe puder identificar as informa\u00e7\u00f5es mais cr\u00edticas necess\u00e1rias para tomar uma decis\u00e3o informada , mais r\u00e1pido o valor pode ser entregue com menor risco de mudan\u00e7as custosas no futuro. Tempo para Decis\u00f5es Quanto tempo leva para tomar uma decis\u00e3o sobre qual solu\u00e7\u00e3o implementar? Tamb\u00e9m h\u00e1 um equil\u00edbrio saud\u00e1vel em apoiar um debate saud\u00e1vel sem prejudicar a entrega da equipe. O caso ideal \u00e9 que a equipe assimile rapidamente as op\u00e7\u00f5es de solu\u00e7\u00e3o apresentadas, fa\u00e7a perguntas e debata antes de finalmente alcan\u00e7ar um consenso sobre uma abordagem espec\u00edfica. Nos casos em que n\u00e3o houver consenso, a pessoa com mais contexto sobre o problema (geralmente o propriet\u00e1rio da hist\u00f3ria) deve tomar a decis\u00e3o final. Priorize a entrega de valor e aprendizado. Discordem e comprometam-se! Impacto As solu\u00e7\u00f5es podem ser rapidamente implementadas no ambiente de produ\u00e7\u00e3o do cliente. \u00c9 mais f\u00e1cil para outras equipes de desenvolvimento aproveitar o trabalho de sua equipe. \u00c9 mais f\u00e1cil para os engenheiros se envolverem em projetos. Aumento da velocidade da equipe ao antecipar mudan\u00e7as e decis\u00f5es quando elas custam menos. Maior engajamento e transpar\u00eancia da equipe ao solicitar ampla participa\u00e7\u00e3o dos revisores. Participa\u00e7\u00e3o Equipe de Desenvolvimento A equipe de desenvolvimento deve sempre participar de todas as sess\u00f5es de revis\u00e3o de design. Engenharia do ISE (Intelligent Security Engineering) Engenharia de Clientes Especialistas em Dom\u00ednio Os especialistas em dom\u00ednio devem participar das sess\u00f5es de revis\u00e3o de design conforme necess\u00e1rio. Dom\u00ednios T\u00e9cnicos do ISE Especialistas em assuntos do cliente (SME - Subject Matter Experts) Lideran\u00e7a S\u00eanior Orienta\u00e7\u00e3o para Facilita\u00e7\u00e3o Receitas Consulte nossas Receitas de Revis\u00e3o de Design para orienta\u00e7\u00f5es sobre o processo de design. Sincroniza\u00e7\u00e3o de Revis\u00f5es de Design via Reuni\u00f5es Presenciais/Virtuais Reuni\u00f5es conjuntas com a equipe de desenvolvimento, especialistas em dom\u00ednio e engenheiros do cliente. Revis\u00f5es de Design Ass\u00edncronas via Pull Requests Consulte a receita de revis\u00e3o de design ass\u00edncrona para orienta\u00e7\u00f5es sobre a facilita\u00e7\u00e3o de revis\u00f5es de design ass\u00edncronas. Isso pode ser \u00fatil para equipes que est\u00e3o geograficamente distribu\u00eddas em diferentes fusos hor\u00e1rios. Avalia\u00e7\u00e3o T\u00e9cnica Um spike t\u00e9cnico \u00e9 mais frequentemente usado para avaliar o impacto que uma nova tecnologia tem na implementa\u00e7\u00e3o atual. Leia mais aqui . Documenta\u00e7\u00e3o de Design Documentar e atualizar o design de arquitetura na documenta\u00e7\u00e3o de design do projeto. Rastrear e documentar decis\u00f5es de design em um registro de decis\u00f5es . Documentar o processo de decis\u00e3o em estudos de troca quando v\u00e1rias solu\u00e7\u00f5es existem para o problema dado. No in\u00edcio das colabora\u00e7\u00f5es, a equipe deve decidir onde armazenar os artefatos gerados pelas revis\u00f5es de design. Normalmente, nos encontramos com o cliente onde eles preferem (por exemplo, usando sua inst\u00e2ncia Confluence para armazenar a documenta\u00e7\u00e3o, se essa for a prefer\u00eancia deles). No entanto, semelhante ao armazenamento de registros de decis\u00f5es, estudos de troca, etc., no reposit\u00f3rio de desenvolvimento, tamb\u00e9m existem grandes benef\u00edcios em manter os artefatos de revis\u00e3o de design no pr\u00f3prio reposit\u00f3rio. Normalmente, esses artefatos podem ser adicionados ao diret\u00f3rio de documenta\u00e7\u00e3o de n\u00edvel superior ou at\u00e9 mesmo \u00e0 raiz do projeto correspondente, se o reposit\u00f3rio for monol\u00edtico. Ao adicion\u00e1-los ao reposit\u00f3rio do projeto, esses artefatos devem ser revisados em Pull Requests (normalmente precedendo, mas \u00e0s vezes acompanhando a implementa\u00e7\u00e3o), o que permite a revis\u00e3o/discuss\u00e3o ass\u00edncrona. Al\u00e9m disso, os artefatos podem ser facilmente vinculados a outras se\u00e7\u00f5es do reposit\u00f3rio e a arquivos de c\u00f3digo-fonte (por meio de links em Markdown ).","title":"Revis\u00f5es de Design"},{"location":"design/design-reviews/#revisoes-de-design","text":"","title":"Revis\u00f5es de Design"},{"location":"design/design-reviews/#sumario","text":"Objetivos Medidas Impacto Participa\u00e7\u00e3o Orienta\u00e7\u00e3o para Facilita\u00e7\u00e3o Avalia\u00e7\u00e3o T\u00e9cnica","title":"Sum\u00e1rio"},{"location":"design/design-reviews/#objetivos","text":"Reduzir a d\u00edvida t\u00e9cnica para nossos clientes. Continuar a iterar no design ap\u00f3s a revis\u00e3o do Plano de Jogo. Gerar artefatos t\u00e9cnicos \u00fateis que possam ser referenciados pela Microsoft e pelos clientes.","title":"Objetivos"},{"location":"design/design-reviews/#medidas","text":"","title":"Medidas"},{"location":"design/design-reviews/#custo-da-mudanca","text":"Ao incorporar revis\u00f5es de design como parte do processo de engenharia, as decis\u00f5es s\u00e3o tomadas antecipadamente antes do in\u00edcio da implementa\u00e7\u00e3o. Tomar a decis\u00e3o de usar o Azure Kubernetes Service em vez dos Servi\u00e7os de Aplicativos na fase de design provavelmente requer apenas a atualiza\u00e7\u00e3o da documenta\u00e7\u00e3o. No entanto, fazer essa mudan\u00e7a ap\u00f3s o in\u00edcio da implementa\u00e7\u00e3o ou ap\u00f3s a solu\u00e7\u00e3o estar em uso \u00e9 muito mais custoso. Essas mudan\u00e7as est\u00e3o ocorrendo antes ou depois da implementa\u00e7\u00e3o? Qual \u00e9 o esfor\u00e7o normalmente envolvido?","title":"Custo da Mudan\u00e7a"},{"location":"design/design-reviews/#participacao-dos-revisores","text":"Quantas pessoas participam das revis\u00f5es dos designs criados? Cumulativamente, se esse n\u00famero for maior, isso indicaria uma maior contribui\u00e7\u00e3o de ideias e perspectivas. Um n\u00famero menor (ou seja, as mesmas 2 pessoas apenas em cada revis\u00e3o) pode indicar um conjunto limitado de perspectivas. Algu\u00e9m est\u00e1 participando de fora da equipe central de desenvolvimento?","title":"Participa\u00e7\u00e3o dos Revisores"},{"location":"design/design-reviews/#tempo-para-solucoes-potenciais","text":"Quanto tempo normalmente leva para ir dos requisitos \u00e0s op\u00e7\u00f5es de solu\u00e7\u00e3o (m\u00faltiplas)? H\u00e1 um equil\u00edbrio saud\u00e1vel entre gastar muito ou muito pouco tempo avaliando diferentes solu\u00e7\u00f5es potenciais. Muito pouco tempo aumenta o risco de mudan\u00e7as custosas necess\u00e1rias ap\u00f3s a implementa\u00e7\u00e3o. Muito tempo atrasa a entrega do valor-alvo e das funcionalidades subsequentes na fila. No entanto, quanto mais r\u00e1pido a equipe puder identificar as informa\u00e7\u00f5es mais cr\u00edticas necess\u00e1rias para tomar uma decis\u00e3o informada , mais r\u00e1pido o valor pode ser entregue com menor risco de mudan\u00e7as custosas no futuro.","title":"Tempo para Solu\u00e7\u00f5es Potenciais"},{"location":"design/design-reviews/#tempo-para-decisoes","text":"Quanto tempo leva para tomar uma decis\u00e3o sobre qual solu\u00e7\u00e3o implementar? Tamb\u00e9m h\u00e1 um equil\u00edbrio saud\u00e1vel em apoiar um debate saud\u00e1vel sem prejudicar a entrega da equipe. O caso ideal \u00e9 que a equipe assimile rapidamente as op\u00e7\u00f5es de solu\u00e7\u00e3o apresentadas, fa\u00e7a perguntas e debata antes de finalmente alcan\u00e7ar um consenso sobre uma abordagem espec\u00edfica. Nos casos em que n\u00e3o houver consenso, a pessoa com mais contexto sobre o problema (geralmente o propriet\u00e1rio da hist\u00f3ria) deve tomar a decis\u00e3o final. Priorize a entrega de valor e aprendizado. Discordem e comprometam-se!","title":"Tempo para Decis\u00f5es"},{"location":"design/design-reviews/#impacto","text":"As solu\u00e7\u00f5es podem ser rapidamente implementadas no ambiente de produ\u00e7\u00e3o do cliente. \u00c9 mais f\u00e1cil para outras equipes de desenvolvimento aproveitar o trabalho de sua equipe. \u00c9 mais f\u00e1cil para os engenheiros se envolverem em projetos. Aumento da velocidade da equipe ao antecipar mudan\u00e7as e decis\u00f5es quando elas custam menos. Maior engajamento e transpar\u00eancia da equipe ao solicitar ampla participa\u00e7\u00e3o dos revisores.","title":"Impacto"},{"location":"design/design-reviews/#participacao","text":"","title":"Participa\u00e7\u00e3o"},{"location":"design/design-reviews/#equipe-de-desenvolvimento","text":"A equipe de desenvolvimento deve sempre participar de todas as sess\u00f5es de revis\u00e3o de design. Engenharia do ISE (Intelligent Security Engineering) Engenharia de Clientes","title":"Equipe de Desenvolvimento"},{"location":"design/design-reviews/#especialistas-em-dominio","text":"Os especialistas em dom\u00ednio devem participar das sess\u00f5es de revis\u00e3o de design conforme necess\u00e1rio. Dom\u00ednios T\u00e9cnicos do ISE Especialistas em assuntos do cliente (SME - Subject Matter Experts) Lideran\u00e7a S\u00eanior","title":"Especialistas em Dom\u00ednio"},{"location":"design/design-reviews/#orientacao-para-facilitacao","text":"","title":"Orienta\u00e7\u00e3o para Facilita\u00e7\u00e3o"},{"location":"design/design-reviews/#receitas","text":"Consulte nossas Receitas de Revis\u00e3o de Design para orienta\u00e7\u00f5es sobre o processo de design.","title":"Receitas"},{"location":"design/design-reviews/#sincronizacao-de-revisoes-de-design-via-reunioes-presenciaisvirtuais","text":"Reuni\u00f5es conjuntas com a equipe de desenvolvimento, especialistas em dom\u00ednio e engenheiros do cliente.","title":"Sincroniza\u00e7\u00e3o de Revis\u00f5es de Design via Reuni\u00f5es Presenciais/Virtuais"},{"location":"design/design-reviews/#revisoes-de-design-assincronas-via-pull-requests","text":"Consulte a receita de revis\u00e3o de design ass\u00edncrona para orienta\u00e7\u00f5es sobre a facilita\u00e7\u00e3o de revis\u00f5es de design ass\u00edncronas. Isso pode ser \u00fatil para equipes que est\u00e3o geograficamente distribu\u00eddas em diferentes fusos hor\u00e1rios.","title":"Revis\u00f5es de Design Ass\u00edncronas via Pull Requests"},{"location":"design/design-reviews/#avaliacao-tecnica","text":"Um spike t\u00e9cnico \u00e9 mais frequentemente usado para avaliar o impacto que uma nova tecnologia tem na implementa\u00e7\u00e3o atual. Leia mais aqui .","title":"Avalia\u00e7\u00e3o T\u00e9cnica"},{"location":"design/design-reviews/#documentacao-de-design","text":"Documentar e atualizar o design de arquitetura na documenta\u00e7\u00e3o de design do projeto. Rastrear e documentar decis\u00f5es de design em um registro de decis\u00f5es . Documentar o processo de decis\u00e3o em estudos de troca quando v\u00e1rias solu\u00e7\u00f5es existem para o problema dado. No in\u00edcio das colabora\u00e7\u00f5es, a equipe deve decidir onde armazenar os artefatos gerados pelas revis\u00f5es de design. Normalmente, nos encontramos com o cliente onde eles preferem (por exemplo, usando sua inst\u00e2ncia Confluence para armazenar a documenta\u00e7\u00e3o, se essa for a prefer\u00eancia deles). No entanto, semelhante ao armazenamento de registros de decis\u00f5es, estudos de troca, etc., no reposit\u00f3rio de desenvolvimento, tamb\u00e9m existem grandes benef\u00edcios em manter os artefatos de revis\u00e3o de design no pr\u00f3prio reposit\u00f3rio. Normalmente, esses artefatos podem ser adicionados ao diret\u00f3rio de documenta\u00e7\u00e3o de n\u00edvel superior ou at\u00e9 mesmo \u00e0 raiz do projeto correspondente, se o reposit\u00f3rio for monol\u00edtico. Ao adicion\u00e1-los ao reposit\u00f3rio do projeto, esses artefatos devem ser revisados em Pull Requests (normalmente precedendo, mas \u00e0s vezes acompanhando a implementa\u00e7\u00e3o), o que permite a revis\u00e3o/discuss\u00e3o ass\u00edncrona. Al\u00e9m disso, os artefatos podem ser facilmente vinculados a outras se\u00e7\u00f5es do reposit\u00f3rio e a arquivos de c\u00f3digo-fonte (por meio de links em Markdown ).","title":"Documenta\u00e7\u00e3o de Design"},{"location":"design/design-reviews/decision-log/","text":"Registro de Decis\u00f5es de Design Nem todos os requisitos podem ser capturados no in\u00edcio de um projeto \u00e1gil durante uma ou mais sess\u00f5es de design. O design inicial da arquitetura pode evoluir ou mudar durante o projeto, especialmente se houver v\u00e1rias escolhas tecnol\u00f3gicas poss\u00edveis. Acompanhar essas mudan\u00e7as em um documento extenso geralmente n\u00e3o \u00e9 o ideal, pois voc\u00ea pode perder a vis\u00e3o geral das mudan\u00e7as de design feitas em qual ponto no tempo. Ter que percorrer um documento grande para encontrar um conte\u00fado espec\u00edfico leva tempo e, na maioria dos casos, as consequ\u00eancias de uma decis\u00e3o n\u00e3o s\u00e3o documentadas. Por que \u00e9 importante rastrear decis\u00f5es de design Rastrear uma decis\u00e3o de design de arquitetura pode ter muitas vantagens: Os desenvolvedores e partes interessadas do projeto podem ver o registro de decis\u00f5es e acompanhar as altera\u00e7\u00f5es, mesmo quando a composi\u00e7\u00e3o da equipe muda ao longo do tempo. O registro \u00e9 mantido atualizado. O contexto de uma decis\u00e3o, incluindo as consequ\u00eancias para a equipe, \u00e9 documentado junto com a decis\u00e3o. \u00c9 mais f\u00e1cil encontrar a decis\u00e3o de design em um registro do que ter que ler um documento grande. Qual \u00e9 o formato recomendado para rastrear decis\u00f5es Al\u00e9m de incorporar uma decis\u00e3o de design como uma atualiza\u00e7\u00e3o na documenta\u00e7\u00e3o de design geral do projeto, as decis\u00f5es podem ser rastreadas como Registros de Decis\u00f5es de Arquitetura conforme Michael Nygard prop\u00f4s em seu blog. O esfor\u00e7o investido em revis\u00f5es e discuss\u00f5es de design pode ser diferente ao longo do projeto. \u00c0s vezes, decis\u00f5es s\u00e3o tomadas rapidamente sem a necessidade de fazer uma compara\u00e7\u00e3o detalhada entre tecnologias concorrentes. Em alguns casos, \u00e9 necess\u00e1rio realizar um estudo mais elaborado das vantagens e desvantagens, conforme descrito na documenta\u00e7\u00e3o dos Estudos de Troca . Em outros casos, pode ser \u00fatil realizar Spikes de Viabilidade de Engenharia . Um ADR pode incorporar cada uma dessas abordagens diferentes. Registro de Decis\u00e3o de Arquitetura (ADR) Um registro de decis\u00e3o de arquitetura tem a estrutura [N\u00famero Crescente]. [T\u00edtulo da decis\u00e3o] O t\u00edtulo deve fornecer ao leitor informa\u00e7\u00f5es sobre o que foi decidido. Exemplo: 001. Registro de log no n\u00edvel do aplicativo com Serilog e Application Insights Data: A data em que a decis\u00e3o foi tomada. Status: Proposto/Aceito/Descontinuado/Substitu\u00eddo Um design proposto pode ser revisado pela equipe de desenvolvimento antes de ser aceito. Uma decis\u00e3o anterior pode ser substitu\u00edda por uma nova ou o registro ADR pode ser marcado como descontinuado caso n\u00e3o seja mais v\u00e1lido. Contexto: O texto deve fornecer ao leitor uma compreens\u00e3o do problema ou, como Michael Nygard coloca, uma descri\u00e7\u00e3o [objetiva] e neutra em valor das for\u00e7as em jogo. Exemplo: Devido ao design de microsservi\u00e7os da plataforma, precisamos garantir a consist\u00eancia do registro em cada servi\u00e7o para que o rastreamento de uso, desempenho, erros etc. possa ser realizado de ponta a ponta. Deve ser usado um \u00fanico framework de registro/monitoramento, onde poss\u00edvel, para alcan\u00e7ar isso, permitindo ao mesmo tempo a flexibilidade para integra\u00e7\u00e3o/exporta\u00e7\u00e3o em outras ferramentas em uma etapa posterior. Os desenvolvedores devem ter uma interface simples para registrar mensagens e m\u00e9tricas. Se a equipe de desenvolvimento adotou uma abordagem baseada em dados para apoiar a decis\u00e3o, ou seja, um estudo que avalia as escolhas potenciais em rela\u00e7\u00e3o a um conjunto de crit\u00e9rios objetivos seguindo a orienta\u00e7\u00e3o em Estudos de Troca , o estudo deve ser mencionado nesta se\u00e7\u00e3o. Decis\u00e3o: A decis\u00e3o tomada, deve come\u00e7ar com 'Vamos...' ou 'Concordamos em...'. Exemplo: Concordamos em utilizar o Serilog como o framework de registro do Dotnet de escolha no n\u00edvel do aplicativo, com integra\u00e7\u00e3o ao Log Analytics e Application Insights para an\u00e1lise. Consequ\u00eancias: O contexto resultante ap\u00f3s a aplica\u00e7\u00e3o da decis\u00e3o. Exemplo: > *A amostragem precisar\u00e1 ser configurada no Application Insights para que ela n\u00e3o fique excessivamente cara ao receber milh\u00f5es de mensagens, mas tamb\u00e9m n\u00e3o impe\u00e7a a captura de informa\u00e7\u00f5es essenciais. A equipe precisar\u00e1 registrar apenas o que foi acordado como essencial para monitoramento durante as revis\u00f5es de design, a fim de reduzir o ru\u00eddo e os n\u00edveis desnecess\u00e1rios de amostragem.* Onde armazenar ADRs ADRs podem ser armazenados e rastreados em qualquer sistema de controle de vers\u00e3o, como o Git. Como pr\u00e1tica recomendada, ADRs podem ser adicionados como pull requests no status proposto para serem discutidos pela equipe at\u00e9 que sejam atualizados para aceitos e mesclados com o ramo principal. Eles geralmente s\u00e3o armazenados em uma estrutura de pasta doc/adr ou doc/arch . Al\u00e9m disso, pode ser \u00fatil rastrear ADRs em um decision-log.md para fornecer metadados \u00fateis em um formato \u00f3bvio. Registros de Decis\u00e3o Um registro de decis\u00e3o \u00e9 um arquivo Markdown que cont\u00e9m uma tabela que fornece resumos executivos das decis\u00f5es contidas nos ADRs, bem como alguns outros metadados. Voc\u00ea pode ver um modelo de tabela em doc/decision-log.md . Quando rastrear ADRs As decis\u00f5es de design de arquitetura geralmente s\u00e3o rastreadas sempre que decis\u00f5es significativas s\u00e3o tomadas que afetam a estrutura e as caracter\u00edsticas da solu\u00e7\u00e3o ou framework que estamos construindo. ADRs tamb\u00e9m podem ser usados para documentar resultados de spikes ao avaliar diferentes escolhas tecnol\u00f3gicas. Exemplos de ADRs O primeiro ADR poderia ser a decis\u00e3o de usar ADRs para rastrear decis\u00f5es de design, 0001-registrar-decisoes-arquitetura.md , seguido por decis\u00f5es reais no engajamento, como no exemplo usado acima, 0002-registro-log-nivel-aplicativo.md .","title":"Registro de Decis\u00f5es de Design"},{"location":"design/design-reviews/decision-log/#registro-de-decisoes-de-design","text":"Nem todos os requisitos podem ser capturados no in\u00edcio de um projeto \u00e1gil durante uma ou mais sess\u00f5es de design. O design inicial da arquitetura pode evoluir ou mudar durante o projeto, especialmente se houver v\u00e1rias escolhas tecnol\u00f3gicas poss\u00edveis. Acompanhar essas mudan\u00e7as em um documento extenso geralmente n\u00e3o \u00e9 o ideal, pois voc\u00ea pode perder a vis\u00e3o geral das mudan\u00e7as de design feitas em qual ponto no tempo. Ter que percorrer um documento grande para encontrar um conte\u00fado espec\u00edfico leva tempo e, na maioria dos casos, as consequ\u00eancias de uma decis\u00e3o n\u00e3o s\u00e3o documentadas.","title":"Registro de Decis\u00f5es de Design"},{"location":"design/design-reviews/decision-log/#por-que-e-importante-rastrear-decisoes-de-design","text":"Rastrear uma decis\u00e3o de design de arquitetura pode ter muitas vantagens: Os desenvolvedores e partes interessadas do projeto podem ver o registro de decis\u00f5es e acompanhar as altera\u00e7\u00f5es, mesmo quando a composi\u00e7\u00e3o da equipe muda ao longo do tempo. O registro \u00e9 mantido atualizado. O contexto de uma decis\u00e3o, incluindo as consequ\u00eancias para a equipe, \u00e9 documentado junto com a decis\u00e3o. \u00c9 mais f\u00e1cil encontrar a decis\u00e3o de design em um registro do que ter que ler um documento grande.","title":"Por que \u00e9 importante rastrear decis\u00f5es de design"},{"location":"design/design-reviews/decision-log/#qual-e-o-formato-recomendado-para-rastrear-decisoes","text":"Al\u00e9m de incorporar uma decis\u00e3o de design como uma atualiza\u00e7\u00e3o na documenta\u00e7\u00e3o de design geral do projeto, as decis\u00f5es podem ser rastreadas como Registros de Decis\u00f5es de Arquitetura conforme Michael Nygard prop\u00f4s em seu blog. O esfor\u00e7o investido em revis\u00f5es e discuss\u00f5es de design pode ser diferente ao longo do projeto. \u00c0s vezes, decis\u00f5es s\u00e3o tomadas rapidamente sem a necessidade de fazer uma compara\u00e7\u00e3o detalhada entre tecnologias concorrentes. Em alguns casos, \u00e9 necess\u00e1rio realizar um estudo mais elaborado das vantagens e desvantagens, conforme descrito na documenta\u00e7\u00e3o dos Estudos de Troca . Em outros casos, pode ser \u00fatil realizar Spikes de Viabilidade de Engenharia . Um ADR pode incorporar cada uma dessas abordagens diferentes.","title":"Qual \u00e9 o formato recomendado para rastrear decis\u00f5es"},{"location":"design/design-reviews/decision-log/#registro-de-decisao-de-arquitetura-adr","text":"Um registro de decis\u00e3o de arquitetura tem a estrutura [N\u00famero Crescente]. [T\u00edtulo da decis\u00e3o] O t\u00edtulo deve fornecer ao leitor informa\u00e7\u00f5es sobre o que foi decidido. Exemplo: 001. Registro de log no n\u00edvel do aplicativo com Serilog e Application Insights Data: A data em que a decis\u00e3o foi tomada. Status: Proposto/Aceito/Descontinuado/Substitu\u00eddo Um design proposto pode ser revisado pela equipe de desenvolvimento antes de ser aceito. Uma decis\u00e3o anterior pode ser substitu\u00edda por uma nova ou o registro ADR pode ser marcado como descontinuado caso n\u00e3o seja mais v\u00e1lido. Contexto: O texto deve fornecer ao leitor uma compreens\u00e3o do problema ou, como Michael Nygard coloca, uma descri\u00e7\u00e3o [objetiva] e neutra em valor das for\u00e7as em jogo. Exemplo: Devido ao design de microsservi\u00e7os da plataforma, precisamos garantir a consist\u00eancia do registro em cada servi\u00e7o para que o rastreamento de uso, desempenho, erros etc. possa ser realizado de ponta a ponta. Deve ser usado um \u00fanico framework de registro/monitoramento, onde poss\u00edvel, para alcan\u00e7ar isso, permitindo ao mesmo tempo a flexibilidade para integra\u00e7\u00e3o/exporta\u00e7\u00e3o em outras ferramentas em uma etapa posterior. Os desenvolvedores devem ter uma interface simples para registrar mensagens e m\u00e9tricas. Se a equipe de desenvolvimento adotou uma abordagem baseada em dados para apoiar a decis\u00e3o, ou seja, um estudo que avalia as escolhas potenciais em rela\u00e7\u00e3o a um conjunto de crit\u00e9rios objetivos seguindo a orienta\u00e7\u00e3o em Estudos de Troca , o estudo deve ser mencionado nesta se\u00e7\u00e3o. Decis\u00e3o: A decis\u00e3o tomada, deve come\u00e7ar com 'Vamos...' ou 'Concordamos em...'. Exemplo: Concordamos em utilizar o Serilog como o framework de registro do Dotnet de escolha no n\u00edvel do aplicativo, com integra\u00e7\u00e3o ao Log Analytics e Application Insights para an\u00e1lise. Consequ\u00eancias: O contexto resultante ap\u00f3s a aplica\u00e7\u00e3o da decis\u00e3o. Exemplo: > *A amostragem precisar\u00e1 ser configurada no Application Insights para que ela n\u00e3o fique excessivamente cara ao receber milh\u00f5es de mensagens, mas tamb\u00e9m n\u00e3o impe\u00e7a a captura de informa\u00e7\u00f5es essenciais. A equipe precisar\u00e1 registrar apenas o que foi acordado como essencial para monitoramento durante as revis\u00f5es de design, a fim de reduzir o ru\u00eddo e os n\u00edveis desnecess\u00e1rios de amostragem.*","title":"Registro de Decis\u00e3o de Arquitetura (ADR)"},{"location":"design/design-reviews/decision-log/#onde-armazenar-adrs","text":"ADRs podem ser armazenados e rastreados em qualquer sistema de controle de vers\u00e3o, como o Git. Como pr\u00e1tica recomendada, ADRs podem ser adicionados como pull requests no status proposto para serem discutidos pela equipe at\u00e9 que sejam atualizados para aceitos e mesclados com o ramo principal. Eles geralmente s\u00e3o armazenados em uma estrutura de pasta doc/adr ou doc/arch . Al\u00e9m disso, pode ser \u00fatil rastrear ADRs em um decision-log.md para fornecer metadados \u00fateis em um formato \u00f3bvio.","title":"Onde armazenar ADRs"},{"location":"design/design-reviews/decision-log/#registros-de-decisao","text":"Um registro de decis\u00e3o \u00e9 um arquivo Markdown que cont\u00e9m uma tabela que fornece resumos executivos das decis\u00f5es contidas nos ADRs, bem como alguns outros metadados. Voc\u00ea pode ver um modelo de tabela em doc/decision-log.md .","title":"Registros de Decis\u00e3o"},{"location":"design/design-reviews/decision-log/#quando-rastrear-adrs","text":"As decis\u00f5es de design de arquitetura geralmente s\u00e3o rastreadas sempre que decis\u00f5es significativas s\u00e3o tomadas que afetam a estrutura e as caracter\u00edsticas da solu\u00e7\u00e3o ou framework que estamos construindo. ADRs tamb\u00e9m podem ser usados para documentar resultados de spikes ao avaliar diferentes escolhas tecnol\u00f3gicas.","title":"Quando rastrear ADRs"},{"location":"design/design-reviews/decision-log/#exemplos-de-adrs","text":"O primeiro ADR poderia ser a decis\u00e3o de usar ADRs para rastrear decis\u00f5es de design, 0001-registrar-decisoes-arquitetura.md , seguido por decis\u00f5es reais no engajamento, como no exemplo usado acima, 0002-registro-log-nivel-aplicativo.md .","title":"Exemplos de ADRs"},{"location":"design/design-reviews/decision-log/doc/decision-log/","text":"Decision Log This document is used to track key decisions that are made during the course of the project. This can be used at a later stage to understand why decisions were made and by whom. Decision Date Alternatives Considered Reasoning Detailed doc Made By Work Required A one-sentence summary of the decision made. Date the decision was made. A list of the other approaches considered. A two to three sentence summary of why the decision was made. A link to the ADR with the format [Title] DR. Who made this decision? A link to the work item for the linked ADR.","title":"Decision Log"},{"location":"design/design-reviews/decision-log/doc/decision-log/#decision-log","text":"This document is used to track key decisions that are made during the course of the project. This can be used at a later stage to understand why decisions were made and by whom. Decision Date Alternatives Considered Reasoning Detailed doc Made By Work Required A one-sentence summary of the decision made. Date the decision was made. A list of the other approaches considered. A two to three sentence summary of why the decision was made. A link to the ADR with the format [Title] DR. Who made this decision? A link to the work item for the linked ADR.","title":"Decision Log"},{"location":"design/design-reviews/decision-log/doc/adr/0001-record-architecture-decisions/","text":"1. Record architecture decisions Date: 2020-03-20 Status Accepted Context We need to record the architectural decisions made on this project. Decision We will use Architecture Decision Records, as described by Michael Nygard . Consequences See Michael Nygard's article, linked above. For a lightweight ADR tool set, see Nat Pryce's adr-tools .","title":"1. Record architecture decisions"},{"location":"design/design-reviews/decision-log/doc/adr/0001-record-architecture-decisions/#1-record-architecture-decisions","text":"Date: 2020-03-20","title":"1. Record architecture decisions"},{"location":"design/design-reviews/decision-log/doc/adr/0001-record-architecture-decisions/#status","text":"Accepted","title":"Status"},{"location":"design/design-reviews/decision-log/doc/adr/0001-record-architecture-decisions/#context","text":"We need to record the architectural decisions made on this project.","title":"Context"},{"location":"design/design-reviews/decision-log/doc/adr/0001-record-architecture-decisions/#decision","text":"We will use Architecture Decision Records, as described by Michael Nygard .","title":"Decision"},{"location":"design/design-reviews/decision-log/doc/adr/0001-record-architecture-decisions/#consequences","text":"See Michael Nygard's article, linked above. For a lightweight ADR tool set, see Nat Pryce's adr-tools .","title":"Consequences"},{"location":"design/design-reviews/decision-log/doc/adr/0002-app-level-logging/","text":"2. App-level Logging with Serilog and Application Insights Date: 2020-04-08 Status Accepted Context Due to the microservices design of the platform, we need to ensure consistency of logging throughout each service so tracking of usage, performance, errors etc. can be performed end-to-end. A single logging/monitoring framework should be used where possible to achieve this, whilst allowing the flexibility for integration/export into other tools at a later stage. The developers should be equipped with a simple interface to log messages and metrics. Decision We have agreed to utilize Serilog as the Dotnet Logging framework of choice at the application level, with integration into Log Analytics and Application Insights for analysis. Consequences Sampling will need to be configured in Application Insights so that it does not become overly-expensive when ingesting millions of messages, but also does not prevent capture of essential information. The team will need to only log what is agreed to be essential for monitoring as part of design reviews, to reduce noise and unnecessary levels of sampling.","title":"2. App-level Logging with Serilog and Application Insights"},{"location":"design/design-reviews/decision-log/doc/adr/0002-app-level-logging/#2-app-level-logging-with-serilog-and-application-insights","text":"Date: 2020-04-08","title":"2. App-level Logging with Serilog and Application Insights"},{"location":"design/design-reviews/decision-log/doc/adr/0002-app-level-logging/#status","text":"Accepted","title":"Status"},{"location":"design/design-reviews/decision-log/doc/adr/0002-app-level-logging/#context","text":"Due to the microservices design of the platform, we need to ensure consistency of logging throughout each service so tracking of usage, performance, errors etc. can be performed end-to-end. A single logging/monitoring framework should be used where possible to achieve this, whilst allowing the flexibility for integration/export into other tools at a later stage. The developers should be equipped with a simple interface to log messages and metrics.","title":"Context"},{"location":"design/design-reviews/decision-log/doc/adr/0002-app-level-logging/#decision","text":"We have agreed to utilize Serilog as the Dotnet Logging framework of choice at the application level, with integration into Log Analytics and Application Insights for analysis.","title":"Decision"},{"location":"design/design-reviews/decision-log/doc/adr/0002-app-level-logging/#consequences","text":"Sampling will need to be configured in Application Insights so that it does not become overly-expensive when ingesting millions of messages, but also does not prevent capture of essential information. The team will need to only log what is agreed to be essential for monitoring as part of design reviews, to reduce noise and unnecessary levels of sampling.","title":"Consequences"},{"location":"design/design-reviews/decision-log/examples/memory/","text":"Memory These examples were taken from the Memory project, an internal tool for tracking an individual's accomplishments. The main example here is the Decision Log . Since this log was used from the start, the decisions are mostly based on technology choices made in the start of the project. All line items have a link out to the trade studies done for each technology choice.","title":"Memory"},{"location":"design/design-reviews/decision-log/examples/memory/#memory","text":"These examples were taken from the Memory project, an internal tool for tracking an individual's accomplishments. The main example here is the Decision Log . Since this log was used from the start, the decisions are mostly based on technology choices made in the start of the project. All line items have a link out to the trade studies done for each technology choice.","title":"Memory"},{"location":"design/design-reviews/decision-log/examples/memory/Decision-Log/","text":"Decision Log This document is used to track key decisions that are made during the course of the project. This can be used at a later stage to understand why decisions were made and by whom. Decision Date Alternatives Considered Reasoning Detailed doc Made By Work Required Use Architecture Decision Records 01/25/2021 Standard Design Docs An easy and low cost solution of tracking architecture decisions over the lifetime of a project Record Architecture Decisions Dev Team #21654 Use ArgoCD 01/26/2021 FluxCD ArgoCD is more feature rich, will support more scenarios, and will be a better tool to put in our tool belts. So we have decided at this point to go with ArgoCD GitOps Trade Study Dev Team #21672 Use Helm 01/28/2021 Kustomize, Kubes, Gitkube, Draft Platform maturity, templating, ArgoCD support K8s Package Manager Trade Study Dev Team #21674 Use CosmosDB 01/29/2021 Blob Storage, CosmosDB, SQL Server, Neo4j, JanusGraph, ArangoDB CosmosDB has better Azure integration, managed identity, and the Gremlin API is powerful. Graph Storage Trade Study and Decision Dev Team #21650 Use Azure Traffic Manager 02/02/2021 Azure Front Door A lightweight solution to route traffic between multiple k8s regional clusters Routing Trade Study Dev Team #21673 Use Linkerd + Contour 02/02/2021 Istio, Consul, Ambassador, Traefik A CNCF backed cloud native k8s stack to deliver service mesh, API gateway and ingress Routing Trade Study Dev Team #21673 Use ARM Templates 02/02/2021 Terraform, Pulumi, Az CLI Azure Native, Az Monitoring and incremental updates support Automated Deployment Trade Study Dev Team #21651 Use 99designs/gqlgen 02/04/2021 graphql, graphql-go, thunder Type safety, auto-registration and code generation GraphQL Golang Trade Study Dev Team #21775 Create normalized role data model 03/25/2021 Career Stage Profiles (CSP), Microsoft Role Library Requires a data model that support the data requirements of both role systems Role Data Model Schema Dev Team #22035 Design for edges and vertices 03/25/2021 N/A N/A Data Model Dev Team #21976 Use grammes 03/29/2021 Gremlin, gremgo, gremcos Balance of documentation and maturity Gremlin API library Trade Study Dev Team #21870 Design for Gremlin implementation 04/02/2021 N/A N/A Gremlin Dev Team #21980 Design for Gremlin implementation 04/02/2021 N/A N/A Gremlin Dev Team #21980 Expose 1:1 data model from API to DB 04/02/2021 Exposing a minified version of data model contract Team decided that there were no pieces of data that we can rule out as being useful. Will update if data model becomes too complex API README Dev Team #21658 Deprecate SonarCloud 04/05/2021 Checkstyle, PMD, FindBugs Requires paid plan to use in a private repo Code Quality & Security Dev Team #22090 Adopted Stable Tagging Strategy 04/08/2021 N/A Team aligned on the proposed docker container tagging strategy Tagging Strategy Dev Team #22005","title":"Decision Log"},{"location":"design/design-reviews/decision-log/examples/memory/Decision-Log/#decision-log","text":"This document is used to track key decisions that are made during the course of the project. This can be used at a later stage to understand why decisions were made and by whom. Decision Date Alternatives Considered Reasoning Detailed doc Made By Work Required Use Architecture Decision Records 01/25/2021 Standard Design Docs An easy and low cost solution of tracking architecture decisions over the lifetime of a project Record Architecture Decisions Dev Team #21654 Use ArgoCD 01/26/2021 FluxCD ArgoCD is more feature rich, will support more scenarios, and will be a better tool to put in our tool belts. So we have decided at this point to go with ArgoCD GitOps Trade Study Dev Team #21672 Use Helm 01/28/2021 Kustomize, Kubes, Gitkube, Draft Platform maturity, templating, ArgoCD support K8s Package Manager Trade Study Dev Team #21674 Use CosmosDB 01/29/2021 Blob Storage, CosmosDB, SQL Server, Neo4j, JanusGraph, ArangoDB CosmosDB has better Azure integration, managed identity, and the Gremlin API is powerful. Graph Storage Trade Study and Decision Dev Team #21650 Use Azure Traffic Manager 02/02/2021 Azure Front Door A lightweight solution to route traffic between multiple k8s regional clusters Routing Trade Study Dev Team #21673 Use Linkerd + Contour 02/02/2021 Istio, Consul, Ambassador, Traefik A CNCF backed cloud native k8s stack to deliver service mesh, API gateway and ingress Routing Trade Study Dev Team #21673 Use ARM Templates 02/02/2021 Terraform, Pulumi, Az CLI Azure Native, Az Monitoring and incremental updates support Automated Deployment Trade Study Dev Team #21651 Use 99designs/gqlgen 02/04/2021 graphql, graphql-go, thunder Type safety, auto-registration and code generation GraphQL Golang Trade Study Dev Team #21775 Create normalized role data model 03/25/2021 Career Stage Profiles (CSP), Microsoft Role Library Requires a data model that support the data requirements of both role systems Role Data Model Schema Dev Team #22035 Design for edges and vertices 03/25/2021 N/A N/A Data Model Dev Team #21976 Use grammes 03/29/2021 Gremlin, gremgo, gremcos Balance of documentation and maturity Gremlin API library Trade Study Dev Team #21870 Design for Gremlin implementation 04/02/2021 N/A N/A Gremlin Dev Team #21980 Design for Gremlin implementation 04/02/2021 N/A N/A Gremlin Dev Team #21980 Expose 1:1 data model from API to DB 04/02/2021 Exposing a minified version of data model contract Team decided that there were no pieces of data that we can rule out as being useful. Will update if data model becomes too complex API README Dev Team #21658 Deprecate SonarCloud 04/05/2021 Checkstyle, PMD, FindBugs Requires paid plan to use in a private repo Code Quality & Security Dev Team #22090 Adopted Stable Tagging Strategy 04/08/2021 N/A Team aligned on the proposed docker container tagging strategy Tagging Strategy Dev Team #22005","title":"Decision Log"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/","text":"Data Model Table of Contents Graph vertices and edges Graph Properties Vertex Descriptions Full Role JSON Example Graph Model Graph Vertices and Edges The set of vertices (entities) and edges (relationships) of the graph model Vertex (Source) Edge Type Relationship Type Vertex (Target) Notes Required Profession Applies 1:many Discipline Top most level of categorization * Discipline Defines 1:many Role Groups of related roles within a profession * AppliedBy 1:1 Profession 1 Role Requires 1:many Responsibility Individual role mapped to an employee 1+ Requires 1:many Competency 1+ RequiredBy 1:1 Discipline 1 Succeeds 1:1 Role Supports career progression between roles 1 Precedes 1:1 Role Supports career progression between roles 1 AssignedTo 1:many User Profile * Responsibility Expects 1:many Key Result A group of expected outcomes and key results for employees within a role 1+ ExpectedBy 1:1 Role 1 Competency Describes 1:many Behavior A set of behaviors that contribute to success 1+ DescribedBy 1:1 Role 1 Key Result ExpectedBy 1:1 Responsibility The expected outcome of performing a responsibility 1 Behavior ContributesTo 1:1 Competency The way in which one acts or conducts oneself 1 User Profile Fulfills many:1 Role 1+ Authors 1:many Entry * Reads many:many Entry * Entry SharedWith many:many User Profile Business logic should add manager to this list by default. These users should only have read access. * Demonstrates many:many Competency * Demonstrates many:many Behavior * Demonstrates many:many Responsibility * Demonstrates many:many Result * AuthoredBy many:1 UserProfile 1+ DiscussedBy 1:many Commentary * References many:many Artifact * Competency DemonstratedBy many:many Entry * Behavior DemonstratedBy many:many Entry * Responsibility DemonstratedBy many:many Entry * Result DemonstratedBy many:many Entry * Commentary Discusses many:1 Entry * Artifact ReferencedBy many:many Entry 1+ Graph Properties The full set of data properties available on each vertex and edge Vertex/Edge Property Data Type Notes Required (Any) ID guid 1 Profession Title String 1 Description String 0 Discipline Title String 1 Description String 0 Role Title String 1 Description String 0 Level Band String SDE, SDE II, Senior, etc 1 Responsibility Title String 1 Description String 0 Competency Title String 1 Description String 0 Key Result Description String 1 Behavior Description String 1 User Profile Theme selection string there are only 2: dark, light 1 PersonaId guid[] there are only 2: User, Admin 1+ UserId guid Points to AAD object 1 DeploymentRing string[] Is used to deploy new versions 1 Project string[] list of user created projects * Entry Title string 1 DateCreated date 1 ReadyToShare boolean false if draft 1 AreaOfImpact string[] 3 options: self, contribute to others, leverage others * Commentary Data string 1 DateCreated date 1 Artifact Data string 1 DateCreated date 1 ArtifactType string describes the artifact type: markdown, blob link 1 Vertex Descriptions Profession Top most level of categorization { \"title\" : \"Software Engineering\" , \"description\" : \"Description of profession\" , \"disciplines\" : [] } Discipline Groups of related roles within a profession { \"title\" : \"Site Reliability Engineering\" , \"description\" : \"Description of discipline\" , \"roles\" : [] } Role Individual role mapped to an employee { \"title\" : \"Site Reliability Engineering IC2\" , \"description\" : \"Detailed description of role\" , \"responsibilities\" : [], \"competencies\" : [] } Responsibility A group of expected outcomes and key results for employees within a role { \"title\" : \"Technical Knowledge and Domain Specific Expertise\" , \"results\" : [] } Competency A set of behaviors that contribute to success { \"title\" : \"Adaptability\" , \"behaviors\" : [] } Key Result The expected outcome of performing a responsibility { \"description\" : \"Develops a foundational understanding of distributed systems design...\" } Behavior The way in which one acts or conducts oneself { \"description\" : \"Actively seeks information and tests assumptions.\" } User The user object refers to whom a person is. We do not store our own rather use Azure OIDs. User Profile The user profile contains any user settings and edges specific to Memory. Persona A user may hold multiple personas. Entry The same entry object can hold many kinds of data, and at this stage of the project we decide that we will not store external data, so it's up to the user to provide a link to the data for a reader to click into and get redirected to a new tab to open. Note: This means that in the web app, we will need to ensure links are opened in new tabs. Project Projects are just string fields to represent what a user wants to group their entries under. Area of Impact This refers to the 3 areas of impact in the venn-style diagram in the HR tool. The options are: self, contributing to impact of others, building on others' work. Commentary A comment is essentially a piece of text. However, anyone that an entry is shared with can add commentary on an entry. Artifact The artifact object contains the relevant data as markdown, or a link to the relevant data. Full Role JSON Example { \"id\" : \"abc123\" , \"title\" : \"Site Reliability Engineering IC2\" , \"description\" : \"Detailed description of role\" , \"responsibilities\" : [ { \"id\" : \"abc123\" , \"title\" : \"Technical Knowledge and Domain Specific Expertise\" , \"results\" : [ { \"description\" : \"Develops a foundational understanding of distributed systems design...\" }, { \"description\" : \"Develops an understanding of the code, features, and operations of specific products...\" } ] }, { \"id\" : \"abc123\" , \"title\" : \"Contributions to Development and Design\" , \"results\" : [ { \"description\" : \"Develops and tests basic changes to optimize code...\" }, { \"description\" : \"Supports ongoing engagements with product engineering teams...\" } ] } ], \"competencies\" : [ { \"id\" : \"abc123\" , \"title\" : \"Adaptability\" , \"behaviors\" : [ { \"description\" : \"Actively seeks information and tests assumptions.\" }, { \"description\" : \"Shifts his or her approach in response to the demands of a changing situation.\" } ] }, { \"id\" : \"abc123\" , \"title\" : \"Collaboration\" , \"behaviors\" : [ { \"description\" : \"Removes barriers by working with others around a shared need or customer benefit.\" }, { \"description\" : \" Incorporates diverse perspectives to thoroughly address complex business issues.\" } ] } ] } API Data Model Because there is no internal edges or vertices that need to be hidden from API consumers, the API will expose a 1:1 mapping of the current data model for consumption. This is subject to change if our data model becomes too complex for downstream users.","title":"Data Model"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#data-model","text":"","title":"Data Model"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#table-of-contents","text":"Graph vertices and edges Graph Properties Vertex Descriptions Full Role JSON Example","title":"Table of Contents"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#graph-model","text":"","title":"Graph Model"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#graph-vertices-and-edges","text":"The set of vertices (entities) and edges (relationships) of the graph model Vertex (Source) Edge Type Relationship Type Vertex (Target) Notes Required Profession Applies 1:many Discipline Top most level of categorization * Discipline Defines 1:many Role Groups of related roles within a profession * AppliedBy 1:1 Profession 1 Role Requires 1:many Responsibility Individual role mapped to an employee 1+ Requires 1:many Competency 1+ RequiredBy 1:1 Discipline 1 Succeeds 1:1 Role Supports career progression between roles 1 Precedes 1:1 Role Supports career progression between roles 1 AssignedTo 1:many User Profile * Responsibility Expects 1:many Key Result A group of expected outcomes and key results for employees within a role 1+ ExpectedBy 1:1 Role 1 Competency Describes 1:many Behavior A set of behaviors that contribute to success 1+ DescribedBy 1:1 Role 1 Key Result ExpectedBy 1:1 Responsibility The expected outcome of performing a responsibility 1 Behavior ContributesTo 1:1 Competency The way in which one acts or conducts oneself 1 User Profile Fulfills many:1 Role 1+ Authors 1:many Entry * Reads many:many Entry * Entry SharedWith many:many User Profile Business logic should add manager to this list by default. These users should only have read access. * Demonstrates many:many Competency * Demonstrates many:many Behavior * Demonstrates many:many Responsibility * Demonstrates many:many Result * AuthoredBy many:1 UserProfile 1+ DiscussedBy 1:many Commentary * References many:many Artifact * Competency DemonstratedBy many:many Entry * Behavior DemonstratedBy many:many Entry * Responsibility DemonstratedBy many:many Entry * Result DemonstratedBy many:many Entry * Commentary Discusses many:1 Entry * Artifact ReferencedBy many:many Entry 1+","title":"Graph Vertices and Edges"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#graph-properties","text":"The full set of data properties available on each vertex and edge Vertex/Edge Property Data Type Notes Required (Any) ID guid 1 Profession Title String 1 Description String 0 Discipline Title String 1 Description String 0 Role Title String 1 Description String 0 Level Band String SDE, SDE II, Senior, etc 1 Responsibility Title String 1 Description String 0 Competency Title String 1 Description String 0 Key Result Description String 1 Behavior Description String 1 User Profile Theme selection string there are only 2: dark, light 1 PersonaId guid[] there are only 2: User, Admin 1+ UserId guid Points to AAD object 1 DeploymentRing string[] Is used to deploy new versions 1 Project string[] list of user created projects * Entry Title string 1 DateCreated date 1 ReadyToShare boolean false if draft 1 AreaOfImpact string[] 3 options: self, contribute to others, leverage others * Commentary Data string 1 DateCreated date 1 Artifact Data string 1 DateCreated date 1 ArtifactType string describes the artifact type: markdown, blob link 1","title":"Graph Properties"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#vertex-descriptions","text":"","title":"Vertex Descriptions"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#profession","text":"Top most level of categorization { \"title\" : \"Software Engineering\" , \"description\" : \"Description of profession\" , \"disciplines\" : [] }","title":"Profession"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#discipline","text":"Groups of related roles within a profession { \"title\" : \"Site Reliability Engineering\" , \"description\" : \"Description of discipline\" , \"roles\" : [] }","title":"Discipline"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#role","text":"Individual role mapped to an employee { \"title\" : \"Site Reliability Engineering IC2\" , \"description\" : \"Detailed description of role\" , \"responsibilities\" : [], \"competencies\" : [] }","title":"Role"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#responsibility","text":"A group of expected outcomes and key results for employees within a role { \"title\" : \"Technical Knowledge and Domain Specific Expertise\" , \"results\" : [] }","title":"Responsibility"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#competency","text":"A set of behaviors that contribute to success { \"title\" : \"Adaptability\" , \"behaviors\" : [] }","title":"Competency"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#key-result","text":"The expected outcome of performing a responsibility { \"description\" : \"Develops a foundational understanding of distributed systems design...\" }","title":"Key Result"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#behavior","text":"The way in which one acts or conducts oneself { \"description\" : \"Actively seeks information and tests assumptions.\" }","title":"Behavior"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#user","text":"The user object refers to whom a person is. We do not store our own rather use Azure OIDs.","title":"User"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#user-profile","text":"The user profile contains any user settings and edges specific to Memory.","title":"User Profile"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#persona","text":"A user may hold multiple personas.","title":"Persona"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#entry","text":"The same entry object can hold many kinds of data, and at this stage of the project we decide that we will not store external data, so it's up to the user to provide a link to the data for a reader to click into and get redirected to a new tab to open. Note: This means that in the web app, we will need to ensure links are opened in new tabs.","title":"Entry"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#project","text":"Projects are just string fields to represent what a user wants to group their entries under.","title":"Project"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#area-of-impact","text":"This refers to the 3 areas of impact in the venn-style diagram in the HR tool. The options are: self, contributing to impact of others, building on others' work.","title":"Area of Impact"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#commentary","text":"A comment is essentially a piece of text. However, anyone that an entry is shared with can add commentary on an entry.","title":"Commentary"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#artifact","text":"The artifact object contains the relevant data as markdown, or a link to the relevant data.","title":"Artifact"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#full-role-json-example","text":"{ \"id\" : \"abc123\" , \"title\" : \"Site Reliability Engineering IC2\" , \"description\" : \"Detailed description of role\" , \"responsibilities\" : [ { \"id\" : \"abc123\" , \"title\" : \"Technical Knowledge and Domain Specific Expertise\" , \"results\" : [ { \"description\" : \"Develops a foundational understanding of distributed systems design...\" }, { \"description\" : \"Develops an understanding of the code, features, and operations of specific products...\" } ] }, { \"id\" : \"abc123\" , \"title\" : \"Contributions to Development and Design\" , \"results\" : [ { \"description\" : \"Develops and tests basic changes to optimize code...\" }, { \"description\" : \"Supports ongoing engagements with product engineering teams...\" } ] } ], \"competencies\" : [ { \"id\" : \"abc123\" , \"title\" : \"Adaptability\" , \"behaviors\" : [ { \"description\" : \"Actively seeks information and tests assumptions.\" }, { \"description\" : \"Shifts his or her approach in response to the demands of a changing situation.\" } ] }, { \"id\" : \"abc123\" , \"title\" : \"Collaboration\" , \"behaviors\" : [ { \"description\" : \"Removes barriers by working with others around a shared need or customer benefit.\" }, { \"description\" : \" Incorporates diverse perspectives to thoroughly address complex business issues.\" } ] } ] }","title":"Full Role JSON Example"},{"location":"design/design-reviews/decision-log/examples/memory/Architecture/Data-Model/#api-data-model","text":"Because there is no internal edges or vertices that need to be hidden from API consumers, the API will expose a 1:1 mapping of the current data model for consumption. This is subject to change if our data model becomes too complex for downstream users.","title":"API Data Model"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/","text":"Application Deployment The Memory application leverages Azure DevOps for work item tracking as well as continuous integration (CI) and continuous deployment (CD). Environments The Memory project uses multiple environments to isolate and test changes before promoting releases to the global user base. New environment rollouts are automatically triggered based upon a successful deployment of the previous stage /environment. The development , staging and production environments leverage slot deployment during an environment rollout. After a new release is deployed to a staging slot, it is validated through a series of functional integration tests. Upon a 100% pass rate of all tests the staging & production slots are swapped effectively making updates to the environment available. Any errors or failed tests halt the deployment in the current stage and prevent changes to further environments. Each deployed environment is completely isolated and does not share any components. They each have unique resource instances of Azure Traffic Manager, Cosmos DB, etc. Deployment Dependencies Development Staging Production CI Quality Gates Development Staging Manual Approval Local The local environment is used by individual software engineers during the development of new features and components. Engineers leverage some components from the deployed development environment that are not available on certain platforms or are unable to run locally. CosmosDB Emulator only exists for Windows The local environment also does not use Azure Traffic Manager. The frontend web app directly communicates to the backend REST API typically running on a separate localhost port mapping. Development The development environment is used as the first quality gate. All code that is checked into the main branch is automatically deployed to this environment after all CI quality gates have passed. Dev Regions West US (westus) Staging The staging environment is used to validate new features, components and other changes prior to production rollout. This environment is primarily used by developers, QA and other company stakeholders. Staging Regions West US (westus) East US (eastus) Production The production environment is used by the worldwide user base. Changes to this environment are gated by manual approval by your product's leadership team in addition to other automatic quality gates. Production Regions West US (westus) Central US (centralus) East US (eastus) Environment Variable Group Infrastructure Setup (memory-common) appName businessUnit serviceConnection subscriptionId Development Setup (memory-dev) environmentName (placeholder) Staging Setup (memory-staging) environmentName (placeholder) Production Setup (memory-prod) environmentName (placeholder)","title":"Application Deployment"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#application-deployment","text":"The Memory application leverages Azure DevOps for work item tracking as well as continuous integration (CI) and continuous deployment (CD).","title":"Application Deployment"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#environments","text":"The Memory project uses multiple environments to isolate and test changes before promoting releases to the global user base. New environment rollouts are automatically triggered based upon a successful deployment of the previous stage /environment. The development , staging and production environments leverage slot deployment during an environment rollout. After a new release is deployed to a staging slot, it is validated through a series of functional integration tests. Upon a 100% pass rate of all tests the staging & production slots are swapped effectively making updates to the environment available. Any errors or failed tests halt the deployment in the current stage and prevent changes to further environments. Each deployed environment is completely isolated and does not share any components. They each have unique resource instances of Azure Traffic Manager, Cosmos DB, etc.","title":"Environments"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#deployment-dependencies","text":"Development Staging Production CI Quality Gates Development Staging Manual Approval","title":"Deployment Dependencies"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#local","text":"The local environment is used by individual software engineers during the development of new features and components. Engineers leverage some components from the deployed development environment that are not available on certain platforms or are unable to run locally. CosmosDB Emulator only exists for Windows The local environment also does not use Azure Traffic Manager. The frontend web app directly communicates to the backend REST API typically running on a separate localhost port mapping.","title":"Local"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#development","text":"The development environment is used as the first quality gate. All code that is checked into the main branch is automatically deployed to this environment after all CI quality gates have passed.","title":"Development"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#dev-regions","text":"West US (westus)","title":"Dev Regions"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#staging","text":"The staging environment is used to validate new features, components and other changes prior to production rollout. This environment is primarily used by developers, QA and other company stakeholders.","title":"Staging"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#staging-regions","text":"West US (westus) East US (eastus)","title":"Staging Regions"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#production","text":"The production environment is used by the worldwide user base. Changes to this environment are gated by manual approval by your product's leadership team in addition to other automatic quality gates.","title":"Production"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#production-regions","text":"West US (westus) Central US (centralus) East US (eastus)","title":"Production Regions"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#environment-variable-group","text":"","title":"Environment Variable Group"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#infrastructure-setup-memory-common","text":"appName businessUnit serviceConnection subscriptionId","title":"Infrastructure Setup (memory-common)"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#development-setup-memory-dev","text":"environmentName (placeholder)","title":"Development Setup (memory-dev)"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#staging-setup-memory-staging","text":"environmentName (placeholder)","title":"Staging Setup (memory-staging)"},{"location":"design/design-reviews/decision-log/examples/memory/Deployment/Environments/#production-setup-memory-prod","text":"environmentName (placeholder)","title":"Production Setup (memory-prod)"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/","text":"Trade Study: GitOps Conducted by: Tess and Jeff Backlog Work Item: #21672 Decision Makers: Wallace, whole team Overview For Memory, we will be creating a cloud native application with infrastructure as code. We will use GitOps for Continuous Deployment through pull requests infrastructure changes to be reflected. Overall, between our two options, one is more simple and targeted in a way that we believe would meet the requirements for this project. The other does the same, with additional features that may or may not be worth the extra configuration and setup. Evaluation Criteria Repo style: mono versus multi Policy Enforcement Deployment Methods Deployment Monitoring Admission Control Azure Documentation availability Maintainability Maturity User Interface Solutions Flux Flux is a tool created by Waveworks and is built on top of Kubernetes' API extension system, supports multi-tenancy, and integrates seamlessly with popular tools like Prometheus. Flux Acceptance Criteria Evaluation Repo style: mono versus multi Flux supports both as of v2 Policy Enforcement Azure Policy is in Preview Deployment Methods Define a Helm release using Helm Controllers Kustomization describes deployments Deployment Monitoring Flux works with Prometheus for deployment monitoring as well as Grafana dashboards Admission Control Flux uses RBAC from Kubernetes to lock down sync permissions. Uses the service account to access image pull secrets Azure Documentation availability Great, better when using Helm Operators Maintainability Manage via YAML files in git repo Maturity v2 is published under Apache license in GitHub , it works with Helm v3, and has PR commits from as recently as today 945 stars, 94 forks User Interface CLI, the simplest lightweight option Other features to call out (see more on website) Flux only supports Pull-based deployments which means it must be paired with an operator Flux can send notifications and receive webhooks for syncing Health assessments Dependency management Automatic deployment Garbage collection Deploy on commit Variations Controllers Both Controller options are optional. The Helm Controller additionally fetches helm artifacts to publish, see below diagram. The Kustomize Controller manages state and continuous deployment. We will not decide between the controller to use here, as that's a separate trade study, however we will note that Helm is more widely documented within Flux documentation. Flux v1 Flux v1 is only in maintenance mode and should not be used anymore. So this section does not consider the v1 option a valid option. GitOps Toolkit Flux v2 is built on top of the GitOps Toolkit , however we do not evaluate using the GitOps Toolkit alone as that is for when you want to make your own CD system, which is not what we want. ArgoCD with Helm Charts ArgoCD is a declarative, GitOps-based Continuous Delivery (CD) tool for Kubernetes. ArgoCD with Helm Acceptance Criteria Evaluation Repo style: mono versus multi ArgoCD supports both Policy Enforcement Azure Policy is in Preview Deployment Methods Deploy with Helm Chart Use Kustomize to apply some post-rendering to the Helm release templates Deployment Monitoring Argo CD expose two sets of Prometheus metrics (application metrics and API server metrics) for deployment monitoring. Admission Control ArgoCD use RBAC feature. RBAC requires SSO configuration or one or more local users setup. Once SSO or local users are configured, additional RBAC roles can be defined Argo CD does not have its own user management system and has only one built-in user admin. The admin user is a superuser, and it has unrestricted access to the system Authorization is handled via JWT tokens and checking group claims in them Azure Documentation availability Argo has documentation on Azure AD Maturity Has PR commits from as recently as today 5,000 stars, 1,100 forks Maintainability Can use GitOps to manage it User Interface ArgoCD has a GUI and can be used across clusters Other features to call out (see more on website) ArgoCD support both pull model and push model for continuous delivery Argo can send notifications, but you need a separate tool for it Argo can receive webhooks Health assessments Potentially much more useful multi-tenancy tools. Manages multiple projects, maps them to teams, etc. SSO Integration Garbage collection Results This section should contain a table that has each solution rated against each of the evaluation criteria: Solution Repo style Policy Enforcement Deployment Methods Deployment Monitoring Admission Control Azure Doc Maintainability Maturity UI Flux mono, multi Azure Policy, preview Helm, Kustomize Prometheus, Grafana RBAC Yes on Azure YAML in git repo 945 stars, 94 forks, currently maintained CLI ArgoCD mono, multi Azure Policy, preview Helm, Kustomize, KSonnet, ... Prometheus, Grafana RBAC Only in their own docs manifests in git repo 5,000 stars, 1,100 forks GUI, multiple clusters in same GUI Decision ArgoCD is more feature rich, will support more scenarios, and will be a better tool to put in our tool belts. So we have decided at this point to go with ArgoCD. References GitOps Enforcement Monitoring Policies Deployment Push with ArgoCD in Azure DevOps","title":"Trade Study: GitOps"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#trade-study-gitops","text":"Conducted by: Tess and Jeff Backlog Work Item: #21672 Decision Makers: Wallace, whole team","title":"Trade Study: GitOps"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#overview","text":"For Memory, we will be creating a cloud native application with infrastructure as code. We will use GitOps for Continuous Deployment through pull requests infrastructure changes to be reflected. Overall, between our two options, one is more simple and targeted in a way that we believe would meet the requirements for this project. The other does the same, with additional features that may or may not be worth the extra configuration and setup.","title":"Overview"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#evaluation-criteria","text":"Repo style: mono versus multi Policy Enforcement Deployment Methods Deployment Monitoring Admission Control Azure Documentation availability Maintainability Maturity User Interface","title":"Evaluation Criteria"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#solutions","text":"","title":"Solutions"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#flux","text":"Flux is a tool created by Waveworks and is built on top of Kubernetes' API extension system, supports multi-tenancy, and integrates seamlessly with popular tools like Prometheus.","title":"Flux"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#flux-acceptance-criteria-evaluation","text":"Repo style: mono versus multi Flux supports both as of v2 Policy Enforcement Azure Policy is in Preview Deployment Methods Define a Helm release using Helm Controllers Kustomization describes deployments Deployment Monitoring Flux works with Prometheus for deployment monitoring as well as Grafana dashboards Admission Control Flux uses RBAC from Kubernetes to lock down sync permissions. Uses the service account to access image pull secrets Azure Documentation availability Great, better when using Helm Operators Maintainability Manage via YAML files in git repo Maturity v2 is published under Apache license in GitHub , it works with Helm v3, and has PR commits from as recently as today 945 stars, 94 forks User Interface CLI, the simplest lightweight option Other features to call out (see more on website) Flux only supports Pull-based deployments which means it must be paired with an operator Flux can send notifications and receive webhooks for syncing Health assessments Dependency management Automatic deployment Garbage collection Deploy on commit","title":"Flux Acceptance Criteria Evaluation"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#variations","text":"","title":"Variations"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#controllers","text":"Both Controller options are optional. The Helm Controller additionally fetches helm artifacts to publish, see below diagram. The Kustomize Controller manages state and continuous deployment. We will not decide between the controller to use here, as that's a separate trade study, however we will note that Helm is more widely documented within Flux documentation.","title":"Controllers"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#flux-v1","text":"Flux v1 is only in maintenance mode and should not be used anymore. So this section does not consider the v1 option a valid option.","title":"Flux v1"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#gitops-toolkit","text":"Flux v2 is built on top of the GitOps Toolkit , however we do not evaluate using the GitOps Toolkit alone as that is for when you want to make your own CD system, which is not what we want.","title":"GitOps Toolkit"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#argocd-with-helm-charts","text":"ArgoCD is a declarative, GitOps-based Continuous Delivery (CD) tool for Kubernetes.","title":"ArgoCD with Helm Charts"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#argocd-with-helm-acceptance-criteria-evaluation","text":"Repo style: mono versus multi ArgoCD supports both Policy Enforcement Azure Policy is in Preview Deployment Methods Deploy with Helm Chart Use Kustomize to apply some post-rendering to the Helm release templates Deployment Monitoring Argo CD expose two sets of Prometheus metrics (application metrics and API server metrics) for deployment monitoring. Admission Control ArgoCD use RBAC feature. RBAC requires SSO configuration or one or more local users setup. Once SSO or local users are configured, additional RBAC roles can be defined Argo CD does not have its own user management system and has only one built-in user admin. The admin user is a superuser, and it has unrestricted access to the system Authorization is handled via JWT tokens and checking group claims in them Azure Documentation availability Argo has documentation on Azure AD Maturity Has PR commits from as recently as today 5,000 stars, 1,100 forks Maintainability Can use GitOps to manage it User Interface ArgoCD has a GUI and can be used across clusters Other features to call out (see more on website) ArgoCD support both pull model and push model for continuous delivery Argo can send notifications, but you need a separate tool for it Argo can receive webhooks Health assessments Potentially much more useful multi-tenancy tools. Manages multiple projects, maps them to teams, etc. SSO Integration Garbage collection","title":"ArgoCD with Helm Acceptance Criteria Evaluation"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#results","text":"This section should contain a table that has each solution rated against each of the evaluation criteria: Solution Repo style Policy Enforcement Deployment Methods Deployment Monitoring Admission Control Azure Doc Maintainability Maturity UI Flux mono, multi Azure Policy, preview Helm, Kustomize Prometheus, Grafana RBAC Yes on Azure YAML in git repo 945 stars, 94 forks, currently maintained CLI ArgoCD mono, multi Azure Policy, preview Helm, Kustomize, KSonnet, ... Prometheus, Grafana RBAC Only in their own docs manifests in git repo 5,000 stars, 1,100 forks GUI, multiple clusters in same GUI","title":"Results"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#decision","text":"ArgoCD is more feature rich, will support more scenarios, and will be a better tool to put in our tool belts. So we have decided at this point to go with ArgoCD.","title":"Decision"},{"location":"design/design-reviews/decision-log/examples/memory/Trade-Studies/GitOps/#references","text":"GitOps Enforcement Monitoring Policies Deployment Push with ArgoCD in Azure DevOps","title":"References"},{"location":"design/design-reviews/recipes/","text":"Design Review Recipes Design reviews come in all shapes and sizes. There are also different items to consider when creating a design at different stages during an engagement Design Review Process Incorporate design reviews throughout the lifetime of an engagement Design Review Templates Game Plan The same template already in use today High level architecture and design Includes technologies, languages & products to complete engagement objective Milestone / Epic Design Review Should be considered when an engagement contains multiple milestones or epics Design should be more detailed than game plan May require unique deployment, security and/or privacy characteristics from other milestones Feature/story design review Design for complex features or stories Will reuse deployment, security and other characteristics defined within game plan or milestone May require new libraries, OSS or patterns to accomplish goals Task design review Highly detailed design for a complex tasks with many unknowns Will integrate into higher level feature/component designs","title":"Design Review Recipes"},{"location":"design/design-reviews/recipes/#design-review-recipes","text":"Design reviews come in all shapes and sizes. There are also different items to consider when creating a design at different stages during an engagement","title":"Design Review Recipes"},{"location":"design/design-reviews/recipes/#design-review-process","text":"Incorporate design reviews throughout the lifetime of an engagement","title":"Design Review Process"},{"location":"design/design-reviews/recipes/#design-review-templates","text":"","title":"Design Review Templates"},{"location":"design/design-reviews/recipes/#game-plan","text":"The same template already in use today High level architecture and design Includes technologies, languages & products to complete engagement objective","title":"Game Plan"},{"location":"design/design-reviews/recipes/#milestone-epic-design-review","text":"Should be considered when an engagement contains multiple milestones or epics Design should be more detailed than game plan May require unique deployment, security and/or privacy characteristics from other milestones","title":"Milestone / Epic Design Review"},{"location":"design/design-reviews/recipes/#featurestory-design-review","text":"Design for complex features or stories Will reuse deployment, security and other characteristics defined within game plan or milestone May require new libraries, OSS or patterns to accomplish goals","title":"Feature/story design review"},{"location":"design/design-reviews/recipes/#task-design-review","text":"Highly detailed design for a complex tasks with many unknowns Will integrate into higher level feature/component designs","title":"Task design review"},{"location":"design/design-reviews/recipes/async-design-reviews/","text":"Async Design Reviews Goals Allow team members to review designs as their work schedule allows. Impact This in turn results in the following benefits: Higher Participation & Accessibility . They do not need to be online and available at the same time as others to review. Reduced Time Constraint . Reviewers can spend longer than the duration of a single meeting to think through the approach and provide feedback. Measures The metrics and/or KPIs used for design reviews overall would still apply. See design reviews for measures guidance. Participation The participation should be same as any design review. See design reviews for participation guidance. Facilitation Guidance The concept is to have the design follow the same workflow as any code changes to implement story or task. Rather than code however, the artifacts being added or changed are Markdown documents as well as any other supporting artifacts (prototypes, code samples, diagrams, etc). Prerequisites Source Controlled Design Docs Design documentation must live in a source control repository that supports pull requests (i.e. git). The following guidelines can be used to determine what repository houses the docs Keeping docs in the same repo as the affected code allows for the docs to be updated atomically alongside code within the same pull request. If the documentation represents code that lives in many different repositories, it may make more sense to keep the docs in their own repository. Place the docs so that they do not trigger CI builds for the affected code (assuming the documentation was the only change). This can be done by placing them in an isolated directory should they live alongside the code they represent. See directory structure example below. -root --src --docs <-- exclude from ci build trigger --design Workflow The designer branches the repo with the documentation. The designer works on adding or updating documentation relevant to the design. The designer submits pull request and requests specific team members to review. Reviewers provide feedback to Designer who incorporates the feedback. (OPTIONAL) Design review meeting might be held to give deeper explanation of design to reviewers. Design is approved/accepted and merged to main branch. Tips for Faster Review Cycles To make sure a design is reviewed in a timely manner, it's important to directly request reviews from team members. If team members are assigned without asking, or if no one is assigned it's likely the design will sit for longer without review. Try the following actions: Make it the designer's responsibility to find reviewers for their design The designer should ask a team member directly (face-to-face conversation, async messaging, etc) if they are available to review. Only if they agree, then assign them as a reviewer. Indicate if the design is ready to be merged once approved. Indicate Design Completeness It helps the reviewer to understand if the design is ready to be accepted or if its still a work-in-progress. The level and type of feedback the reviewer provides will likely be different depending on its state. Try the following actions to indicate the design state Mark the PR as a Draft. Some ALM tools support opening a pull request as a Draft such as Azure DevOps. Prefix the title with \"DRAFT\", \"WIP\", or \"work-in-progress\". Set the pull request to automatically merge after approvals and checks have passed. This can indicate to the reviewer the design is complete from the designer's perspective. Practice Inclusive Behaviors The designated reviewers are not the only team members that can provide feedback on the design. If other team members voluntarily committed time to providing feedback or asking questions, be sure to respond. Utilize face-to-face conversation (in person or virtual) to resolve feedback or questions from others as needed. This aids in building team cohesiveness in ensuring everyone understands and is willing to commit to a given design. This practice demonstrates inclusive behavior ; which will promote trust and respect within the team. Respond to all PR comments objectively and respectively irrespective of the authors level, position, or title. After two round trips of question/response, resort to synchronous communication for resolution (i.e. virtual or physical face-to-face conversation).","title":"Async Design Reviews"},{"location":"design/design-reviews/recipes/async-design-reviews/#async-design-reviews","text":"","title":"Async Design Reviews"},{"location":"design/design-reviews/recipes/async-design-reviews/#goals","text":"Allow team members to review designs as their work schedule allows.","title":"Goals"},{"location":"design/design-reviews/recipes/async-design-reviews/#impact","text":"This in turn results in the following benefits: Higher Participation & Accessibility . They do not need to be online and available at the same time as others to review. Reduced Time Constraint . Reviewers can spend longer than the duration of a single meeting to think through the approach and provide feedback.","title":"Impact"},{"location":"design/design-reviews/recipes/async-design-reviews/#measures","text":"The metrics and/or KPIs used for design reviews overall would still apply. See design reviews for measures guidance.","title":"Measures"},{"location":"design/design-reviews/recipes/async-design-reviews/#participation","text":"The participation should be same as any design review. See design reviews for participation guidance.","title":"Participation"},{"location":"design/design-reviews/recipes/async-design-reviews/#facilitation-guidance","text":"The concept is to have the design follow the same workflow as any code changes to implement story or task. Rather than code however, the artifacts being added or changed are Markdown documents as well as any other supporting artifacts (prototypes, code samples, diagrams, etc).","title":"Facilitation Guidance"},{"location":"design/design-reviews/recipes/async-design-reviews/#prerequisites","text":"","title":"Prerequisites"},{"location":"design/design-reviews/recipes/async-design-reviews/#source-controlled-design-docs","text":"Design documentation must live in a source control repository that supports pull requests (i.e. git). The following guidelines can be used to determine what repository houses the docs Keeping docs in the same repo as the affected code allows for the docs to be updated atomically alongside code within the same pull request. If the documentation represents code that lives in many different repositories, it may make more sense to keep the docs in their own repository. Place the docs so that they do not trigger CI builds for the affected code (assuming the documentation was the only change). This can be done by placing them in an isolated directory should they live alongside the code they represent. See directory structure example below. -root --src --docs <-- exclude from ci build trigger --design","title":"Source Controlled Design Docs"},{"location":"design/design-reviews/recipes/async-design-reviews/#workflow","text":"The designer branches the repo with the documentation. The designer works on adding or updating documentation relevant to the design. The designer submits pull request and requests specific team members to review. Reviewers provide feedback to Designer who incorporates the feedback. (OPTIONAL) Design review meeting might be held to give deeper explanation of design to reviewers. Design is approved/accepted and merged to main branch.","title":"Workflow"},{"location":"design/design-reviews/recipes/async-design-reviews/#tips-for-faster-review-cycles","text":"To make sure a design is reviewed in a timely manner, it's important to directly request reviews from team members. If team members are assigned without asking, or if no one is assigned it's likely the design will sit for longer without review. Try the following actions: Make it the designer's responsibility to find reviewers for their design The designer should ask a team member directly (face-to-face conversation, async messaging, etc) if they are available to review. Only if they agree, then assign them as a reviewer. Indicate if the design is ready to be merged once approved.","title":"Tips for Faster Review Cycles"},{"location":"design/design-reviews/recipes/async-design-reviews/#indicate-design-completeness","text":"It helps the reviewer to understand if the design is ready to be accepted or if its still a work-in-progress. The level and type of feedback the reviewer provides will likely be different depending on its state. Try the following actions to indicate the design state Mark the PR as a Draft. Some ALM tools support opening a pull request as a Draft such as Azure DevOps. Prefix the title with \"DRAFT\", \"WIP\", or \"work-in-progress\". Set the pull request to automatically merge after approvals and checks have passed. This can indicate to the reviewer the design is complete from the designer's perspective.","title":"Indicate Design Completeness"},{"location":"design/design-reviews/recipes/async-design-reviews/#practice-inclusive-behaviors","text":"The designated reviewers are not the only team members that can provide feedback on the design. If other team members voluntarily committed time to providing feedback or asking questions, be sure to respond. Utilize face-to-face conversation (in person or virtual) to resolve feedback or questions from others as needed. This aids in building team cohesiveness in ensuring everyone understands and is willing to commit to a given design. This practice demonstrates inclusive behavior ; which will promote trust and respect within the team. Respond to all PR comments objectively and respectively irrespective of the authors level, position, or title. After two round trips of question/response, resort to synchronous communication for resolution (i.e. virtual or physical face-to-face conversation).","title":"Practice Inclusive Behaviors"},{"location":"design/design-reviews/recipes/engagement-process/","text":"Incorporating Design Reviews into an Engagement Introduction Design reviews should not feel like a burden. Design reviews can be easily incorporated into the dev crew process with minimal overhead. Only create design reviews when needed. Not every story or task requires a complete design review. Leverage this guidance to make changes that best fit in with the team. Every team works differently. Leverage Microsoft subject-matter experts (SME) as needed during design reviews. Not every story needs SME or leadership sign-off. Most design reviews can be fully executed within a dev crew. Use diagrams to visualize concepts and architecture. The following guidelines outline how Microsoft and the customer together can incorporate design reviews into their day-to-day agile processes. Envisioning / Architecture Design Session (ADS) Early in an engagement Microsoft works with customers to understand their unique goals and objectives and establish a definition of done. Microsoft dives deep into existing customer infrastructure and architecture to understand potential constraints. Additionally, we seek to understand and uncover specific non-functional requirements that influence the solution. During this time the team uncovers many unknowns, leveraging all new-found information, in order to help generate an impactful design that meets customer goals. After ADS it can be helpful to conduct Engineering Feasibility Spikes to further de-risk technologies being considered for the engagement. Tip : All unknowns have not been addressed at this point. Sprint Planning In many engagements Microsoft works with customers using a SCRUM agile development process which begins with sprint planning. Sprint planning is a great opportunity to dive deep into the next set of high priority work. Some key points to address are the following: Identify stories that require design reviews Separate design from implementation for complex stories Assign an owner to each design story Stories that will benefit from design reviews have one or more of the following in common: There are many unknown or unclear requirements There is a wide distribution of anticipated workload, or story pointing, across the dev crew The developer cannot clearly illustrate all tasks required for the story Tip: After sprint planning is complete the team should consider hosting an initial design review discussion to dive deep in the design requirement of the stories that were identified. This will provide more clarity so that the team can move forward with a design review, synchronously or asynchronously, and complete tasks. Sprint Backlog Refinement If your team is not already hosting a Sprint Backlog Refinement session at least once per week you should consider it. It is a great opportunity to: Keep the backlog clean Re-prioritize work based on shifting business priorities Fill in missing descriptions and acceptance criteria Identify stories that require design reviews The team can follow the same steps from sprint planning to help identify which stories require design reviews. This can often save much time during the actual sprint planning meetings to focus on the task at hand. Sprint Retrospectives Sprint retrospectives are a great time to check in with the dev team, identify what is working or not working, and propose changes to keep improving. It is also a great time to check in on design reviews Did any of the designs change from last sprint? How have design changes impacted the engagement? Have previous design artifacts been updated to reflect new changes? All design artifacts should be treated as a living document. As requirements change or uncover more unknowns the dev crew should retroactively update all design artifacts. Missing this critical step may cause the customer to incur future technical debt. Artifacts that are not up to date are bugs in the design. Tip: Keep your artifacts up to date by adding it to your teams Definition of Done for all user stories. Sync Design Reviews It is often helpful to schedule 1-2 design sessions per sprint as part of the normal aforementioned meeting cadence. Throughout the sprint, folks can add design topics to the meeting agenda and if there is nothing to discuss for a particular meeting occurrence, it can simply be cancelled. While these sessions may not always be used, they help project members align on timing and purpose early on and establish precedence, often encouraging participation so design topics don't slip through the cracks. Oftentimes, it is helpful for those project members intending to present their design to the wider group to distribute documentation on their design prior to the session so that other participants can come prepared with context heading into the session. It should be noted that the necessity of these sessions certainly evolves over the course of the engagement. Early on, or in other times of more ambiguity, these meetings are typically used more often and more fully. Lastly, while it is suggested that sync design reviews are scheduled during the normal sprint cadence, scheduling ad-hoc sessions should not be discouraged - even if these reviews are limited to the participants of a specific workstream. Wrap-up Sprints Wrap-up sprints are a great time to tie up loose ends with the customer and hand-off solution. Customer hand-off becomes a lot easier when there are design artifacts to reference and deliver alongside the completed solution. During your wrap-up sprints the dev crew should consider the following: Are the design artifacts up to date? Are the design artifacts stored in an accessible location?","title":"Incorporating Design Reviews into an Engagement"},{"location":"design/design-reviews/recipes/engagement-process/#incorporating-design-reviews-into-an-engagement","text":"","title":"Incorporating Design Reviews into an Engagement"},{"location":"design/design-reviews/recipes/engagement-process/#introduction","text":"Design reviews should not feel like a burden. Design reviews can be easily incorporated into the dev crew process with minimal overhead. Only create design reviews when needed. Not every story or task requires a complete design review. Leverage this guidance to make changes that best fit in with the team. Every team works differently. Leverage Microsoft subject-matter experts (SME) as needed during design reviews. Not every story needs SME or leadership sign-off. Most design reviews can be fully executed within a dev crew. Use diagrams to visualize concepts and architecture. The following guidelines outline how Microsoft and the customer together can incorporate design reviews into their day-to-day agile processes.","title":"Introduction"},{"location":"design/design-reviews/recipes/engagement-process/#envisioning-architecture-design-session-ads","text":"Early in an engagement Microsoft works with customers to understand their unique goals and objectives and establish a definition of done. Microsoft dives deep into existing customer infrastructure and architecture to understand potential constraints. Additionally, we seek to understand and uncover specific non-functional requirements that influence the solution. During this time the team uncovers many unknowns, leveraging all new-found information, in order to help generate an impactful design that meets customer goals. After ADS it can be helpful to conduct Engineering Feasibility Spikes to further de-risk technologies being considered for the engagement. Tip : All unknowns have not been addressed at this point.","title":"Envisioning / Architecture Design Session (ADS)"},{"location":"design/design-reviews/recipes/engagement-process/#sprint-planning","text":"In many engagements Microsoft works with customers using a SCRUM agile development process which begins with sprint planning. Sprint planning is a great opportunity to dive deep into the next set of high priority work. Some key points to address are the following: Identify stories that require design reviews Separate design from implementation for complex stories Assign an owner to each design story Stories that will benefit from design reviews have one or more of the following in common: There are many unknown or unclear requirements There is a wide distribution of anticipated workload, or story pointing, across the dev crew The developer cannot clearly illustrate all tasks required for the story Tip: After sprint planning is complete the team should consider hosting an initial design review discussion to dive deep in the design requirement of the stories that were identified. This will provide more clarity so that the team can move forward with a design review, synchronously or asynchronously, and complete tasks.","title":"Sprint Planning"},{"location":"design/design-reviews/recipes/engagement-process/#sprint-backlog-refinement","text":"If your team is not already hosting a Sprint Backlog Refinement session at least once per week you should consider it. It is a great opportunity to: Keep the backlog clean Re-prioritize work based on shifting business priorities Fill in missing descriptions and acceptance criteria Identify stories that require design reviews The team can follow the same steps from sprint planning to help identify which stories require design reviews. This can often save much time during the actual sprint planning meetings to focus on the task at hand.","title":"Sprint Backlog Refinement"},{"location":"design/design-reviews/recipes/engagement-process/#sprint-retrospectives","text":"Sprint retrospectives are a great time to check in with the dev team, identify what is working or not working, and propose changes to keep improving. It is also a great time to check in on design reviews Did any of the designs change from last sprint? How have design changes impacted the engagement? Have previous design artifacts been updated to reflect new changes? All design artifacts should be treated as a living document. As requirements change or uncover more unknowns the dev crew should retroactively update all design artifacts. Missing this critical step may cause the customer to incur future technical debt. Artifacts that are not up to date are bugs in the design. Tip: Keep your artifacts up to date by adding it to your teams Definition of Done for all user stories.","title":"Sprint Retrospectives"},{"location":"design/design-reviews/recipes/engagement-process/#sync-design-reviews","text":"It is often helpful to schedule 1-2 design sessions per sprint as part of the normal aforementioned meeting cadence. Throughout the sprint, folks can add design topics to the meeting agenda and if there is nothing to discuss for a particular meeting occurrence, it can simply be cancelled. While these sessions may not always be used, they help project members align on timing and purpose early on and establish precedence, often encouraging participation so design topics don't slip through the cracks. Oftentimes, it is helpful for those project members intending to present their design to the wider group to distribute documentation on their design prior to the session so that other participants can come prepared with context heading into the session. It should be noted that the necessity of these sessions certainly evolves over the course of the engagement. Early on, or in other times of more ambiguity, these meetings are typically used more often and more fully. Lastly, while it is suggested that sync design reviews are scheduled during the normal sprint cadence, scheduling ad-hoc sessions should not be discouraged - even if these reviews are limited to the participants of a specific workstream.","title":"Sync Design Reviews"},{"location":"design/design-reviews/recipes/engagement-process/#wrap-up-sprints","text":"Wrap-up sprints are a great time to tie up loose ends with the customer and hand-off solution. Customer hand-off becomes a lot easier when there are design artifacts to reference and deliver alongside the completed solution. During your wrap-up sprints the dev crew should consider the following: Are the design artifacts up to date? Are the design artifacts stored in an accessible location?","title":"Wrap-up Sprints"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/","text":"Engineering Feasibility Spikes: identifying and mitigating risk Introduction Some engagements require more de-risking than others. Even after Architectural Design Sessions (ADS) an engagement may still have substantial technical unknowns. These types of engagements warrant an exploratory/validation phase where Engineering Feasibility Spikes can be conducted immediately after envisioning/ADS and before engineering sprints. Engineering feasibility spikes Are regimented yet collaborative time-boxed investigatory activities conducted in a feedback loop to capitalize on individual learnings to inform the team. Increase the team\u2019s knowledge and understanding while minimizing engagement risks. The following guidelines outline how Microsoft and the customer can incorporate engineering feasibility spikes into the day-to-day agile processes. Pre-Mortem A good way to gauge what engineering spikes to conduct is to do a pre-mortem . What is a pre-mortem? A 90-minute meeting after envisioning/ADS that includes the entire team (and can also include the customer) which answers \"Imagine the project has failed. What problems and challenges caused this failure?\" Allows the entire team to initially raise concerns and risks early in the engagement. This input is used to decide which risks to pursue as engineering spikes. Sharing Learnings & Current Progress Feedback loop The key element from conducting the engineering feasibility spikes is sharing the outcomes in-flight. The team gets together and shares learning on a weekly basis (or more frequently if needed). The sharing is done via a 30-minute call. Everyone on the Dev Crew joins the call (even if not everyone is assigned an engineering spike story or even if the spike work was underway and not fully completed). The feedback loop is significantly tighter/shorter than in sprint-based agile process. Instead of using the Sprint as the forcing function to adjust/pivot/re-prioritize, the interim sharing sessions were the trigger. Re-prioritizing the next spikes After the team shares current progress, another round of planning is done. This allows the team to Establish a very tight feedback loop. Re-prioritize the next spike(s) because of the outcome from the current engineering feasibility spikes. Adjusting based on context During the sharing call, and when the team believes it has enough information, the team sometimes comes to the realization that the original spike acceptance criteria is no longer valid. The team pivots into another area that provides more value. A decision log can be used to track outcomes. Engineering Feasibility Sprints Diagram The process is depicted in the diagram below. Benefits Creating code samples to prove out ideas It is important to note to be intentional about the spikes not aiming to produce production-level code. The team sometimes must write code to arrive at the technical learning. The team must be cognizant that the code written for the spikes is not going to serve as the code for the final solution. The code written is just enough to drive the investigation forward with greater confidence. For example, supposed the team was exploring the API choreography of creating a Graph client with various Azure Active Directory (AAD) authentication flows and permissions. The code to demonstrate this is implemented in a console app, but it could have been done via an Express server, etc. The fact that it was a console app was not important, but rather the ability of the Graph client to be able to do operations against the Graph API endpoint with the minimal number of permissions is the main learning goal. Targeted conversations By sharing the progress of the spike, the team\u2019s collective knowledge increases. The spikes allow the team to drive succinct conversations with various Product Groups (PGs) and other subject matter experts (SMEs). Rather than speaking at a hypothetical level, the team playbacks project/architecture concerns and concretely points out why something is a showstopper or not a viable way forward. Increased customer trust This process leads to increased customer trust. Using this process, the team Brings the customer along in the decision-making process and guides them how to go forward. Provides answers with confidence and suggests sound architectural designs. Conducting engineering feasibility spikes sets the team and the customer up for success, especially if it highlights technology learnings that help the customer fully understand the feasibility/viability of an engineering solution. Summary of key points A pre-mortem can involve the whole team in surfacing business and technical risks. The key purpose of the engineering feasibility spike is learning. Learning comes from both conducting and sharing insights from spikes. Use new spike infused learnings to revise, refine, re-prioritize, or create the next set of spikes. When spikes are completed, look for new weekly rhythms like adding a \u2018risk\u2019 column to the retro board or raising topics at daily standup to identify emerging risks.","title":"Engineering Feasibility Spikes: identifying and mitigating risk"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#engineering-feasibility-spikes-identifying-and-mitigating-risk","text":"","title":"Engineering Feasibility Spikes: identifying and mitigating risk"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#introduction","text":"Some engagements require more de-risking than others. Even after Architectural Design Sessions (ADS) an engagement may still have substantial technical unknowns. These types of engagements warrant an exploratory/validation phase where Engineering Feasibility Spikes can be conducted immediately after envisioning/ADS and before engineering sprints.","title":"Introduction"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#engineering-feasibility-spikes","text":"Are regimented yet collaborative time-boxed investigatory activities conducted in a feedback loop to capitalize on individual learnings to inform the team. Increase the team\u2019s knowledge and understanding while minimizing engagement risks. The following guidelines outline how Microsoft and the customer can incorporate engineering feasibility spikes into the day-to-day agile processes.","title":"Engineering feasibility spikes"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#pre-mortem","text":"A good way to gauge what engineering spikes to conduct is to do a pre-mortem .","title":"Pre-Mortem"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#what-is-a-pre-mortem","text":"A 90-minute meeting after envisioning/ADS that includes the entire team (and can also include the customer) which answers \"Imagine the project has failed. What problems and challenges caused this failure?\" Allows the entire team to initially raise concerns and risks early in the engagement. This input is used to decide which risks to pursue as engineering spikes.","title":"What is a pre-mortem?"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#sharing-learnings-current-progress","text":"","title":"Sharing Learnings &amp; Current Progress"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#feedback-loop","text":"The key element from conducting the engineering feasibility spikes is sharing the outcomes in-flight. The team gets together and shares learning on a weekly basis (or more frequently if needed). The sharing is done via a 30-minute call. Everyone on the Dev Crew joins the call (even if not everyone is assigned an engineering spike story or even if the spike work was underway and not fully completed). The feedback loop is significantly tighter/shorter than in sprint-based agile process. Instead of using the Sprint as the forcing function to adjust/pivot/re-prioritize, the interim sharing sessions were the trigger.","title":"Feedback loop"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#re-prioritizing-the-next-spikes","text":"After the team shares current progress, another round of planning is done. This allows the team to Establish a very tight feedback loop. Re-prioritize the next spike(s) because of the outcome from the current engineering feasibility spikes.","title":"Re-prioritizing the next spikes"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#adjusting-based-on-context","text":"During the sharing call, and when the team believes it has enough information, the team sometimes comes to the realization that the original spike acceptance criteria is no longer valid. The team pivots into another area that provides more value. A decision log can be used to track outcomes.","title":"Adjusting based on context"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#engineering-feasibility-sprints-diagram","text":"The process is depicted in the diagram below.","title":"Engineering Feasibility Sprints Diagram"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#benefits","text":"","title":"Benefits"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#creating-code-samples-to-prove-out-ideas","text":"It is important to note to be intentional about the spikes not aiming to produce production-level code. The team sometimes must write code to arrive at the technical learning. The team must be cognizant that the code written for the spikes is not going to serve as the code for the final solution. The code written is just enough to drive the investigation forward with greater confidence. For example, supposed the team was exploring the API choreography of creating a Graph client with various Azure Active Directory (AAD) authentication flows and permissions. The code to demonstrate this is implemented in a console app, but it could have been done via an Express server, etc. The fact that it was a console app was not important, but rather the ability of the Graph client to be able to do operations against the Graph API endpoint with the minimal number of permissions is the main learning goal.","title":"Creating code samples to prove out ideas"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#targeted-conversations","text":"By sharing the progress of the spike, the team\u2019s collective knowledge increases. The spikes allow the team to drive succinct conversations with various Product Groups (PGs) and other subject matter experts (SMEs). Rather than speaking at a hypothetical level, the team playbacks project/architecture concerns and concretely points out why something is a showstopper or not a viable way forward.","title":"Targeted conversations"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#increased-customer-trust","text":"This process leads to increased customer trust. Using this process, the team Brings the customer along in the decision-making process and guides them how to go forward. Provides answers with confidence and suggests sound architectural designs. Conducting engineering feasibility spikes sets the team and the customer up for success, especially if it highlights technology learnings that help the customer fully understand the feasibility/viability of an engineering solution.","title":"Increased customer trust"},{"location":"design/design-reviews/recipes/engineering-feasibility-spikes/#summary-of-key-points","text":"A pre-mortem can involve the whole team in surfacing business and technical risks. The key purpose of the engineering feasibility spike is learning. Learning comes from both conducting and sharing insights from spikes. Use new spike infused learnings to revise, refine, re-prioritize, or create the next set of spikes. When spikes are completed, look for new weekly rhythms like adding a \u2018risk\u2019 column to the retro board or raising topics at daily standup to identify emerging risks.","title":"Summary of key points"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/","text":"Your Feature or Story Design Title Here (prefix with DRAFT/WIP to indicate level of completeness) Does the feature re-use or extend existing patterns / interfaces that have already been established for the project? Does the feature expose new patterns or interfaces that will establish a new standard for new future development? Feature/Story Name Engagement: [Engagement] Customer: [Customer] Authors: [Author1, Author2, etc.] Overview/Problem Statement It can also be a link to the work item . Describe the feature/story with a high-level summary. Consider additional background and justification, for posterity and historical context. List any assumptions that were made for this design. Goals/In-Scope List the goals that the feature/story will help us achieve that are most relevant for the design review discussion. This should include acceptance criteria required to meet definition of done . Non-goals / Out-of-Scope List the non-goals for the feature/story. This contains work that is beyond the scope of what the feature/component/service is intended for. Proposed Design Briefly describe the high-level architecture for the feature/story. Relevant diagrams (e.g. sequence, component, context, deployment) should be included here. Technology Describe the relevant OS, Web server, presentation layer, persistence layer, caching, eventing/messaging/jobs, etc. \u2013 whatever is applicable to the overall technology solution and how are they going to be used. Describe the usage of any libraries of OSS components. Briefly list the languages(s) and platform(s) that comprise the stack. Non-Functional Requirements What are the primary performance and scalability concerns for this feature/story? Are there specific latency, availability, and RTO/RPO objectives that must be met? Are there specific bottlenecks or potential problem areas? For example, are operations CPU or I/O (network, disk) bound? How large are the data sets and how fast do they grow? What is the expected usage pattern of the service? For example, will there be peaks and valleys of intense concurrent usage? Are there specific cost constraints? (e.g. $ per transaction/device/user) Dependencies Does this feature/story need to be sequenced after another feature/story assigned to the same team and why? Is the feature/story dependent on another team completing other work? Will the team need to wait for that work to be completed or could the work proceed in parallel? Risks & Mitigation Does the team need assistance from subject-matter experts? What security and privacy concerns does this milestone/epic have? Is all sensitive information and secrets treated in a safe and secure manner? Open Questions List any open questions/concerns here. Additional References List any additional references here including links to backlog items, work items or other documents.","title":"Your Feature or Story Design Title Here (prefix with DRAFT/WIP to indicate level of completeness)"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#your-feature-or-story-design-title-here-prefix-with-draftwip-to-indicate-level-of-completeness","text":"Does the feature re-use or extend existing patterns / interfaces that have already been established for the project? Does the feature expose new patterns or interfaces that will establish a new standard for new future development? Feature/Story Name Engagement: [Engagement] Customer: [Customer] Authors: [Author1, Author2, etc.]","title":"Your Feature or Story Design Title Here (prefix with DRAFT/WIP to indicate level of completeness)"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#overviewproblem-statement","text":"It can also be a link to the work item . Describe the feature/story with a high-level summary. Consider additional background and justification, for posterity and historical context. List any assumptions that were made for this design.","title":"Overview/Problem Statement"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#goalsin-scope","text":"List the goals that the feature/story will help us achieve that are most relevant for the design review discussion. This should include acceptance criteria required to meet definition of done .","title":"Goals/In-Scope"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#non-goals-out-of-scope","text":"List the non-goals for the feature/story. This contains work that is beyond the scope of what the feature/component/service is intended for.","title":"Non-goals / Out-of-Scope"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#proposed-design","text":"Briefly describe the high-level architecture for the feature/story. Relevant diagrams (e.g. sequence, component, context, deployment) should be included here.","title":"Proposed Design"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#technology","text":"Describe the relevant OS, Web server, presentation layer, persistence layer, caching, eventing/messaging/jobs, etc. \u2013 whatever is applicable to the overall technology solution and how are they going to be used. Describe the usage of any libraries of OSS components. Briefly list the languages(s) and platform(s) that comprise the stack.","title":"Technology"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#non-functional-requirements","text":"What are the primary performance and scalability concerns for this feature/story? Are there specific latency, availability, and RTO/RPO objectives that must be met? Are there specific bottlenecks or potential problem areas? For example, are operations CPU or I/O (network, disk) bound? How large are the data sets and how fast do they grow? What is the expected usage pattern of the service? For example, will there be peaks and valleys of intense concurrent usage? Are there specific cost constraints? (e.g. $ per transaction/device/user)","title":"Non-Functional Requirements"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#dependencies","text":"Does this feature/story need to be sequenced after another feature/story assigned to the same team and why? Is the feature/story dependent on another team completing other work? Will the team need to wait for that work to be completed or could the work proceed in parallel?","title":"Dependencies"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#risks-mitigation","text":"Does the team need assistance from subject-matter experts? What security and privacy concerns does this milestone/epic have? Is all sensitive information and secrets treated in a safe and secure manner?","title":"Risks &amp; Mitigation"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#open-questions","text":"List any open questions/concerns here.","title":"Open Questions"},{"location":"design/design-reviews/recipes/feature-story-design-review-template/#additional-references","text":"List any additional references here including links to backlog items, work items or other documents.","title":"Additional References"},{"location":"design/design-reviews/recipes/high-level-design-recipe/","text":"High Level / Game Plan Design Recipe Why is this valuable? Design at macroscopic level shows the interactions between systems and services that will be used to accomplish the project. It is intended to ensure there is high level understanding of the plan for what to build, which off-the-shelf components will be used, and which external components will need to interact with the deliverable. Things to keep in mind As with all other aspects of the project, design reviews must provide a friendly and safe environment so that any team member feels comfortable proposing a design for review and can use the opportunity to grow and learn from the constructive / non-judgemental feedback from peers and subject-matter experts (see Team Agreements ). Attempt to illustrate different personas involved in the use cases and how/which boxes are their entry points. Prefer pictures over paragraphs. The diagrams aren't intended to generate code, so they should be fairly high level. Artifacts should indicate the direction of calls (are they outbound, inbound, or bidirectional?) and call out system boundaries where ports might need to be opened or additional infrastructure work may be needed to allow calls to be made. Sequence diagrams are helpful to show the flow of calls among components + systems. Generic box diagrams depicting data flow or call origination/destination are useful. However, the title should clearly define what the arrows show indicate. In most cases, a diagram will show either data flow or call directions but not both. Visualize the contrasting aspects of the system/diagram for ease of communication. e.g. differing technologies employed, modified vs. untouched components, or internet vs. local cloud components. Colors, grouping boxes, and iconography can be used for differentiating. Prefer ease-of-understanding for communicating ideas over strict UML correctness. Design reviews should be lightweight and should not feel like an additional process overhead. Examples","title":"High Level / Game Plan Design Recipe"},{"location":"design/design-reviews/recipes/high-level-design-recipe/#high-level-game-plan-design-recipe","text":"","title":"High Level / Game Plan Design Recipe"},{"location":"design/design-reviews/recipes/high-level-design-recipe/#why-is-this-valuable","text":"Design at macroscopic level shows the interactions between systems and services that will be used to accomplish the project. It is intended to ensure there is high level understanding of the plan for what to build, which off-the-shelf components will be used, and which external components will need to interact with the deliverable.","title":"Why is this valuable?"},{"location":"design/design-reviews/recipes/high-level-design-recipe/#things-to-keep-in-mind","text":"As with all other aspects of the project, design reviews must provide a friendly and safe environment so that any team member feels comfortable proposing a design for review and can use the opportunity to grow and learn from the constructive / non-judgemental feedback from peers and subject-matter experts (see Team Agreements ). Attempt to illustrate different personas involved in the use cases and how/which boxes are their entry points. Prefer pictures over paragraphs. The diagrams aren't intended to generate code, so they should be fairly high level. Artifacts should indicate the direction of calls (are they outbound, inbound, or bidirectional?) and call out system boundaries where ports might need to be opened or additional infrastructure work may be needed to allow calls to be made. Sequence diagrams are helpful to show the flow of calls among components + systems. Generic box diagrams depicting data flow or call origination/destination are useful. However, the title should clearly define what the arrows show indicate. In most cases, a diagram will show either data flow or call directions but not both. Visualize the contrasting aspects of the system/diagram for ease of communication. e.g. differing technologies employed, modified vs. untouched components, or internet vs. local cloud components. Colors, grouping boxes, and iconography can be used for differentiating. Prefer ease-of-understanding for communicating ideas over strict UML correctness. Design reviews should be lightweight and should not feel like an additional process overhead.","title":"Things to keep in mind"},{"location":"design/design-reviews/recipes/high-level-design-recipe/#examples","text":"","title":"Examples"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-recipe/","text":"Milestone / Epic Design Review Recipe Why is this valuable? Design at epic/milestone level can help the team make better decisions about prioritization by summarizing the value, effort, complexity, risks, and dependencies. This brief document can help the team align on the selected approach and briefly explain the rationale for other teams, subject-matter experts, project advisors, and new team members. Things to keep in mind As with all other aspects of the project, design reviews must provide a friendly and safe environment so that any team member feels comfortable proposing a design for review and can use the opportunity to grow and learn from the constructive / non-judgemental feedback from peers and subject-matter experts (see Team Agreements ). Design reviews should be lightweight and should not feel like an additional process overhead. Dev Lead can usually provide guidance on whether a given epic/milestone needs a design review and can help other team members in preparation. This is not a strict template that must be followed and teams should not be bogged down with polished \"design presentations\". Think of the recipe below as a \"menu of options\" for potential questions to think through in designing this epic. Not all sections are required for every epic. Focus on sections and questions that are most relevant for making the decision and rationalizing the trade-offs. Milestone/epic design is considered high-level design but is usually more detailed than the design included in the Game Plan, but will likely re-use some technologies, non-functional requirements, and constraints mentioned in the Game Plan. As the team learned more about the project and further refined the scope of the epic, they may specifically call out notable changes to the overall approach and, in particular, highlight any unique deployment, security, private, scalability, etc. characteristics of this milestone. Template You can download the Milestone/Epic Design Review Template , copy it into your project, and use it as described in the async design review recipe .","title":"Milestone / Epic Design Review Recipe"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-recipe/#milestone-epic-design-review-recipe","text":"","title":"Milestone / Epic Design Review Recipe"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-recipe/#why-is-this-valuable","text":"Design at epic/milestone level can help the team make better decisions about prioritization by summarizing the value, effort, complexity, risks, and dependencies. This brief document can help the team align on the selected approach and briefly explain the rationale for other teams, subject-matter experts, project advisors, and new team members.","title":"Why is this valuable?"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-recipe/#things-to-keep-in-mind","text":"As with all other aspects of the project, design reviews must provide a friendly and safe environment so that any team member feels comfortable proposing a design for review and can use the opportunity to grow and learn from the constructive / non-judgemental feedback from peers and subject-matter experts (see Team Agreements ). Design reviews should be lightweight and should not feel like an additional process overhead. Dev Lead can usually provide guidance on whether a given epic/milestone needs a design review and can help other team members in preparation. This is not a strict template that must be followed and teams should not be bogged down with polished \"design presentations\". Think of the recipe below as a \"menu of options\" for potential questions to think through in designing this epic. Not all sections are required for every epic. Focus on sections and questions that are most relevant for making the decision and rationalizing the trade-offs. Milestone/epic design is considered high-level design but is usually more detailed than the design included in the Game Plan, but will likely re-use some technologies, non-functional requirements, and constraints mentioned in the Game Plan. As the team learned more about the project and further refined the scope of the epic, they may specifically call out notable changes to the overall approach and, in particular, highlight any unique deployment, security, private, scalability, etc. characteristics of this milestone.","title":"Things to keep in mind"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-recipe/#template","text":"You can download the Milestone/Epic Design Review Template , copy it into your project, and use it as described in the async design review recipe .","title":"Template"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/","text":"Your Milestone/Epic Design Title Here (prefix with DRAFT/WIP to indicate level of completeness) Please refer to https://microsoft.github.io/code-with-engineering-playbook/design/design-reviews/recipes/milestone-epic-design-review-recipe/ for things to keep in mind when using this template. Milestone / Epic: Name Project / Engagement: [Project Engagement] Authors: [Author1, Author2, etc.] Overview / Problem Statement Describe the milestone/epic with a high-level summary and a problem statement. Consider including or linking to any additional background (e.g. Game Plan or Checkpoint docs) if it is useful for historical context. Goals / In-Scope List a few bullet points of goals that this milestone/epic will achieve and that are most relevant for the design review discussion. You may include acceptable criteria required to meet the Definition of Done . Non-goals / Out-of-Scope List a few bullet points of non-goals to clarify the work that is beyond the scope of the design review for this milestone/epic. Proposed Design / Suggested Approach To optimize the time investment, this should be brief since it is likely that details will change as the epic/milestone is further decomposed into features and stories. The goal being to convey the vision and complexity in something that can be understood in a few minutes and can help guide a discussion (either asynchronously via comments or in a meeting). A paragraph to describe the proposed design / suggested approach for this milestone/epic. A diagram (e.g. architecture, sequence, component, deployment, etc.) or pseudo-code snippet to make it easier to talk through the approach. List a few of the alternative approaches that were considered and include the brief key Pros and Cons used to help rationalize the decision. For example: Pros Cons Simple to implement Creates secondary identity system Repeatable pattern/code artifact Deployment requires admin credentials Technology Briefly list the languages(s) and platform(s) that comprise the stack. This may include anything that is needed to understand the overall solution: OS, web server, presentation layer, persistence layer, caching, eventing, etc. Non-Functional Requirements What are the primary performance and scalability concerns for this milestone/epic? Are there specific latency, availability, and RTO/RPO objectives that must be met? Are there specific bottlenecks or potential problem areas? For example, are operations CPU or I/O (network, disk) bound? How large are the data sets and how fast do they grow? What is the expected usage pattern of the service? For example, will there be peaks and valleys of intense concurrent usage? Are there specific cost constraints? (e.g. $ per transaction/device/user) Operationalization Are there any specific considerations for the CI/CD setup of milestone/epic? Is there a process (manual or automated) to promote builds from lower environments to higher ones? Does this milestone/epic require zero-downtime deployments, and if so, how are they achieved? Are there mechanisms in place to rollback a deployment? What is the process for monitoring the functionality provided by this milestone/epic? Dependencies Does this milestone/epic need to be sequenced after another epic assigned to the same team and why? Is the milestone/epic dependent on another team completing other work? Will the team need to wait for that work to be completed or could the work proceed in parallel? Risks & Mitigations Does the team need assistance from subject-matter experts? What security and privacy concerns does this milestone/epic have? Is all sensitive information and secrets treated in a safe and secure manner? Open Questions Include any open questions and concerns. Additional References Include any additional references including links to work items or other documents.","title":"Your Milestone/Epic Design Title Here (prefix with DRAFT/WIP to indicate level of completeness)"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#your-milestoneepic-design-title-here-prefix-with-draftwip-to-indicate-level-of-completeness","text":"Please refer to https://microsoft.github.io/code-with-engineering-playbook/design/design-reviews/recipes/milestone-epic-design-review-recipe/ for things to keep in mind when using this template. Milestone / Epic: Name Project / Engagement: [Project Engagement] Authors: [Author1, Author2, etc.]","title":"Your Milestone/Epic Design Title Here (prefix with DRAFT/WIP to indicate level of completeness)"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#overview-problem-statement","text":"Describe the milestone/epic with a high-level summary and a problem statement. Consider including or linking to any additional background (e.g. Game Plan or Checkpoint docs) if it is useful for historical context.","title":"Overview / Problem Statement"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#goals-in-scope","text":"List a few bullet points of goals that this milestone/epic will achieve and that are most relevant for the design review discussion. You may include acceptable criteria required to meet the Definition of Done .","title":"Goals / In-Scope"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#non-goals-out-of-scope","text":"List a few bullet points of non-goals to clarify the work that is beyond the scope of the design review for this milestone/epic.","title":"Non-goals / Out-of-Scope"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#proposed-design-suggested-approach","text":"To optimize the time investment, this should be brief since it is likely that details will change as the epic/milestone is further decomposed into features and stories. The goal being to convey the vision and complexity in something that can be understood in a few minutes and can help guide a discussion (either asynchronously via comments or in a meeting). A paragraph to describe the proposed design / suggested approach for this milestone/epic. A diagram (e.g. architecture, sequence, component, deployment, etc.) or pseudo-code snippet to make it easier to talk through the approach. List a few of the alternative approaches that were considered and include the brief key Pros and Cons used to help rationalize the decision. For example: Pros Cons Simple to implement Creates secondary identity system Repeatable pattern/code artifact Deployment requires admin credentials","title":"Proposed Design / Suggested Approach"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#technology","text":"Briefly list the languages(s) and platform(s) that comprise the stack. This may include anything that is needed to understand the overall solution: OS, web server, presentation layer, persistence layer, caching, eventing, etc.","title":"Technology"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#non-functional-requirements","text":"What are the primary performance and scalability concerns for this milestone/epic? Are there specific latency, availability, and RTO/RPO objectives that must be met? Are there specific bottlenecks or potential problem areas? For example, are operations CPU or I/O (network, disk) bound? How large are the data sets and how fast do they grow? What is the expected usage pattern of the service? For example, will there be peaks and valleys of intense concurrent usage? Are there specific cost constraints? (e.g. $ per transaction/device/user)","title":"Non-Functional Requirements"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#operationalization","text":"Are there any specific considerations for the CI/CD setup of milestone/epic? Is there a process (manual or automated) to promote builds from lower environments to higher ones? Does this milestone/epic require zero-downtime deployments, and if so, how are they achieved? Are there mechanisms in place to rollback a deployment? What is the process for monitoring the functionality provided by this milestone/epic?","title":"Operationalization"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#dependencies","text":"Does this milestone/epic need to be sequenced after another epic assigned to the same team and why? Is the milestone/epic dependent on another team completing other work? Will the team need to wait for that work to be completed or could the work proceed in parallel?","title":"Dependencies"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#risks-mitigations","text":"Does the team need assistance from subject-matter experts? What security and privacy concerns does this milestone/epic have? Is all sensitive information and secrets treated in a safe and secure manner?","title":"Risks &amp; Mitigations"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#open-questions","text":"Include any open questions and concerns.","title":"Open Questions"},{"location":"design/design-reviews/recipes/milestone-epic-design-review-template/#additional-references","text":"Include any additional references including links to work items or other documents.","title":"Additional References"},{"location":"design/design-reviews/recipes/preferred-diagram-tooling/","text":"Preferred Diagram Tooling At each stage in the engagement process, diagrams are a key part of the design review. The preferred tooling for creating and maintaining diagrams is to choose one of the following: Microsoft Visio Microsoft PowerPoint The .drawio.png (or .drawio ) format from diagrams.net (formerly draw.io ) In all cases, we recommend storing the exported PNG images from these diagrams in the repo along with the source files so they can easily be referenced in documentation and more easily reviewed during PRs. The .drawio.png format stores both at once. Microsoft Visio It contains a lot of shapes out of the box, including Azure icons, the desktop app exists on PC, and there's a great Web app. Most diagrams in the Azure Architecture Center are Visio diagrams. Microsoft PowerPoint Diagrams can be easily reused in presentations, a PowerPoint license is pretty common, the desktop app exists on PC and on the Mac, and there's a great Web app. .drawio.png There are different desktop, web apps and VS Code extensions. This tooling can be used like Visio or LucidChart, without the licensing/remote storage concerns. Furthermore, Diagrams.net has a collection of Azure/Office/Microsoft icons, as well as other well-known tech, so it is not only useful for swimlanes and flow diagrams, but also for architecture diagrams. .drawio.png should be preferred over the .drawio format. The .drawio.png format uses the metadata layer within the PNG file-format to hide SVG vector graphics representation, then renders the .png when saving. This clever use of both the meta layer and image layer allows anyone to further edit the PNG file. It also renders like a normal PNG in browsers and other viewers, making it easy to transfer and embed. Furthermore, it can be edited within VSCode very easily using the Draw.io Integration VSCode Extension .","title":"Preferred Diagram Tooling"},{"location":"design/design-reviews/recipes/preferred-diagram-tooling/#preferred-diagram-tooling","text":"At each stage in the engagement process, diagrams are a key part of the design review. The preferred tooling for creating and maintaining diagrams is to choose one of the following: Microsoft Visio Microsoft PowerPoint The .drawio.png (or .drawio ) format from diagrams.net (formerly draw.io ) In all cases, we recommend storing the exported PNG images from these diagrams in the repo along with the source files so they can easily be referenced in documentation and more easily reviewed during PRs. The .drawio.png format stores both at once.","title":"Preferred Diagram Tooling"},{"location":"design/design-reviews/recipes/preferred-diagram-tooling/#microsoft-visio","text":"It contains a lot of shapes out of the box, including Azure icons, the desktop app exists on PC, and there's a great Web app. Most diagrams in the Azure Architecture Center are Visio diagrams.","title":"Microsoft Visio"},{"location":"design/design-reviews/recipes/preferred-diagram-tooling/#microsoft-powerpoint","text":"Diagrams can be easily reused in presentations, a PowerPoint license is pretty common, the desktop app exists on PC and on the Mac, and there's a great Web app.","title":"Microsoft PowerPoint"},{"location":"design/design-reviews/recipes/preferred-diagram-tooling/#drawiopng","text":"There are different desktop, web apps and VS Code extensions. This tooling can be used like Visio or LucidChart, without the licensing/remote storage concerns. Furthermore, Diagrams.net has a collection of Azure/Office/Microsoft icons, as well as other well-known tech, so it is not only useful for swimlanes and flow diagrams, but also for architecture diagrams. .drawio.png should be preferred over the .drawio format. The .drawio.png format uses the metadata layer within the PNG file-format to hide SVG vector graphics representation, then renders the .png when saving. This clever use of both the meta layer and image layer allows anyone to further edit the PNG file. It also renders like a normal PNG in browsers and other viewers, making it easy to transfer and embed. Furthermore, it can be edited within VSCode very easily using the Draw.io Integration VSCode Extension .","title":".drawio.png"},{"location":"design/design-reviews/recipes/sprint-spike-template/","text":"Spike: {Name} Conducted by: {Names and at least one email address for follow-up questions} Backlog Work Item: {Link to the work item to provide more context} Sprint : {Which sprint did the study take place. Include sprint start date} Goal Describe what question(s) the spike intends to answer and why. Method Describe how the team will uncover the answer to the question(s) the spike intends to answer. For example: Build prototype to test. Research existing documents and samples. Discuss with subject matter experts. Evidence Document the evidence collected that informed the conclusions below. Examples may include: Recorded or live demos of a prototype providing the desired capabilities Metrics collected while testing the prototype Documentation that indicates the solution can provided the desired capabilities Conclusions What was the answer to the question(s) outlined at the start of the spike? Capture what was learned that will inform future work. Next Steps What work is expected as an outcome of the learning within this spike. Was there work that was blocked or dependent on the learning within this spike?","title":"Spike: {Name}"},{"location":"design/design-reviews/recipes/sprint-spike-template/#spike-name","text":"Conducted by: {Names and at least one email address for follow-up questions} Backlog Work Item: {Link to the work item to provide more context} Sprint : {Which sprint did the study take place. Include sprint start date}","title":"Spike: {Name}"},{"location":"design/design-reviews/recipes/sprint-spike-template/#goal","text":"Describe what question(s) the spike intends to answer and why.","title":"Goal"},{"location":"design/design-reviews/recipes/sprint-spike-template/#method","text":"Describe how the team will uncover the answer to the question(s) the spike intends to answer. For example: Build prototype to test. Research existing documents and samples. Discuss with subject matter experts.","title":"Method"},{"location":"design/design-reviews/recipes/sprint-spike-template/#evidence","text":"Document the evidence collected that informed the conclusions below. Examples may include: Recorded or live demos of a prototype providing the desired capabilities Metrics collected while testing the prototype Documentation that indicates the solution can provided the desired capabilities","title":"Evidence"},{"location":"design/design-reviews/recipes/sprint-spike-template/#conclusions","text":"What was the answer to the question(s) outlined at the start of the spike? Capture what was learned that will inform future work.","title":"Conclusions"},{"location":"design/design-reviews/recipes/sprint-spike-template/#next-steps","text":"What work is expected as an outcome of the learning within this spike. Was there work that was blocked or dependent on the learning within this spike?","title":"Next Steps"},{"location":"design/design-reviews/recipes/task-design-review-template/","text":"Your Task Design Title Here (prefix with DRAFT/WIP to indicate level of completeness) When developing a design document for a new task, it should contain a detailed design proposal demonstrating how it will solve the goals outlined below. Not all tasks require a design review, but when they do it is likely that there many unknowns, or the solution may be more complex. The design should include diagrams, pseudocode, interface contracts as needed to provide a detailed understanding of the proposal. Task Name Story Name Engagement: [Engagement] Customer: [Customer] Authors: [Author1, Author2, etc.] Overview/Problem Statement It can also be a link to the work item . Describe the task with a high-level summary. Consider additional background and justification, for posterity and historical context. Goals/In-Scope List a few bullet points of what this task will achieve and that are most relevant for the design review discussion. This should include acceptance criteria required to meet the definition of done . Non-goals / Out-of-Scope List a few bullet points of non-goals to clarify the work that is beyond the scope of the design review for this task. Proposed Options Describe the detailed design to accomplish the proposed task. What patterns & practices will be used and why were they chosen. Were any alternate proposals considered? What new components are required to be developed? Are there any existing components that require updates? Relevant diagrams (e.g. sequence, component, context, deployment) should be included here. Technology Choices Describe any libraries and OSS components that will be used to complete the task. Briefly list the languages(s) and platform(s) that comprise the stack. Open Questions List any open questions/concerns here. Additional References List any additional references here including links to backlog items, work items or other documents.","title":"Your Task Design Title Here (prefix with DRAFT/WIP to indicate level of completeness)"},{"location":"design/design-reviews/recipes/task-design-review-template/#your-task-design-title-here-prefix-with-draftwip-to-indicate-level-of-completeness","text":"When developing a design document for a new task, it should contain a detailed design proposal demonstrating how it will solve the goals outlined below. Not all tasks require a design review, but when they do it is likely that there many unknowns, or the solution may be more complex. The design should include diagrams, pseudocode, interface contracts as needed to provide a detailed understanding of the proposal. Task Name Story Name Engagement: [Engagement] Customer: [Customer] Authors: [Author1, Author2, etc.]","title":"Your Task Design Title Here (prefix with DRAFT/WIP to indicate level of completeness)"},{"location":"design/design-reviews/recipes/task-design-review-template/#overviewproblem-statement","text":"It can also be a link to the work item . Describe the task with a high-level summary. Consider additional background and justification, for posterity and historical context.","title":"Overview/Problem Statement"},{"location":"design/design-reviews/recipes/task-design-review-template/#goalsin-scope","text":"List a few bullet points of what this task will achieve and that are most relevant for the design review discussion. This should include acceptance criteria required to meet the definition of done .","title":"Goals/In-Scope"},{"location":"design/design-reviews/recipes/task-design-review-template/#non-goals-out-of-scope","text":"List a few bullet points of non-goals to clarify the work that is beyond the scope of the design review for this task.","title":"Non-goals / Out-of-Scope"},{"location":"design/design-reviews/recipes/task-design-review-template/#proposed-options","text":"Describe the detailed design to accomplish the proposed task. What patterns & practices will be used and why were they chosen. Were any alternate proposals considered? What new components are required to be developed? Are there any existing components that require updates? Relevant diagrams (e.g. sequence, component, context, deployment) should be included here.","title":"Proposed Options"},{"location":"design/design-reviews/recipes/task-design-review-template/#technology-choices","text":"Describe any libraries and OSS components that will be used to complete the task. Briefly list the languages(s) and platform(s) that comprise the stack.","title":"Technology Choices"},{"location":"design/design-reviews/recipes/task-design-review-template/#open-questions","text":"List any open questions/concerns here.","title":"Open Questions"},{"location":"design/design-reviews/recipes/task-design-review-template/#additional-references","text":"List any additional references here including links to backlog items, work items or other documents.","title":"Additional References"},{"location":"design/design-reviews/recipes/technical-spike/","text":"Technical Spike From Wikipedia ... A spike in a sprint can be used in a number of ways: As a way to familiarize the team with new hardware or software To analyze a problem thoroughly and assist in properly dividing work among separate team members. Spike tests can also be used to mitigate future risk, and may uncover additional issues that have escaped notice. A distinction can be made between technical spikes and functional spikes. The technical spike is used more often for evaluating the impact new technology has on the current implementation. A functional spike is used to determine the interaction with a new feature or implementation. Engineering feasibility spikes can also be conducted to de-risk an engagement and increase the team's understanding. Deliverable Generally the deliverable from a Technical Spike should be a document detailing what was evaluated and the outcome of that evaluation. The specifics contained in the document will vary, but there are some general principles that might be helpful. Problem Statement/Goals: Be sure to include a section that clearly details why an evaluation is being done and what the outcome of this evaluation should be. This is helpful to ensure that the technical spike was productive and advanced the overall project in some way. Make sure it is repeatable: Detail the components used, installation instructions, configuration, etc. required to build the environment that was used for evaluation and testing. If any testing is performed, make sure to include the scripts, links to the applications, configuration options, etc. so that testing could be performed again. There are many reasons that the evaluation environment may need to be rebuilt. For example: Another scenario needs to be tested. A new version of the technology has been released. The technology needs to be tested on a new platform. Fact-Finding: The goal of a spike should be fact-finding, not decision-making or recommendation. Ideally, the technology spike digs into a number of technical questions and gets answers so that the broader project team can then come back together and agree on an appropriate course forward. Evidence: Generally you will use sections to summarize the results of testing which do not include the potentially hundreds of detailed results, however, you should include all detailed testing results in an appendix or an attachment. Having full results detailed somewhere will help the team trust the results. In addition, data can be interpreted lots of different ways, and it may be necessary to go back to the original data for a new interpretation. Organization: The technical documentation can be lengthy. It is generally a good idea to organize sections with headers and include a table of contents. Generally sections towards the beginning of the document should summarize data and use one or more appendices for more details.","title":"Technical Spike"},{"location":"design/design-reviews/recipes/technical-spike/#technical-spike","text":"From Wikipedia ... A spike in a sprint can be used in a number of ways: As a way to familiarize the team with new hardware or software To analyze a problem thoroughly and assist in properly dividing work among separate team members. Spike tests can also be used to mitigate future risk, and may uncover additional issues that have escaped notice. A distinction can be made between technical spikes and functional spikes. The technical spike is used more often for evaluating the impact new technology has on the current implementation. A functional spike is used to determine the interaction with a new feature or implementation. Engineering feasibility spikes can also be conducted to de-risk an engagement and increase the team's understanding.","title":"Technical Spike"},{"location":"design/design-reviews/recipes/technical-spike/#deliverable","text":"Generally the deliverable from a Technical Spike should be a document detailing what was evaluated and the outcome of that evaluation. The specifics contained in the document will vary, but there are some general principles that might be helpful. Problem Statement/Goals: Be sure to include a section that clearly details why an evaluation is being done and what the outcome of this evaluation should be. This is helpful to ensure that the technical spike was productive and advanced the overall project in some way. Make sure it is repeatable: Detail the components used, installation instructions, configuration, etc. required to build the environment that was used for evaluation and testing. If any testing is performed, make sure to include the scripts, links to the applications, configuration options, etc. so that testing could be performed again. There are many reasons that the evaluation environment may need to be rebuilt. For example: Another scenario needs to be tested. A new version of the technology has been released. The technology needs to be tested on a new platform. Fact-Finding: The goal of a spike should be fact-finding, not decision-making or recommendation. Ideally, the technology spike digs into a number of technical questions and gets answers so that the broader project team can then come back together and agree on an appropriate course forward. Evidence: Generally you will use sections to summarize the results of testing which do not include the potentially hundreds of detailed results, however, you should include all detailed testing results in an appendix or an attachment. Having full results detailed somewhere will help the team trust the results. In addition, data can be interpreted lots of different ways, and it may be necessary to go back to the original data for a new interpretation. Organization: The technical documentation can be lengthy. It is generally a good idea to organize sections with headers and include a table of contents. Generally sections towards the beginning of the document should summarize data and use one or more appendices for more details.","title":"Deliverable"},{"location":"design/design-reviews/trade-studies/","text":"Trade Studies Trade studies are a tool for selecting the best option out of several possible options for a given problem (for example: compute, storage). They evaluate potential choices against a set of objective criteria/requirements to clearly lay out the benefits and limitations of each solution. Trade studies are a concept from systems engineering that we adapted for software projects. Trade studies have proved to be a critical tool to drive alignment with the stakeholders, earn credibility while doing so and ensure our decisions were backed by data and not bias. When to use the tool Trade studies go hand in hand with high level architecture design. This usually occurs as project requirements are solidifying, before coding begins. Trade studies continue to be useful throughout the project any time there are multiple options that need to be selected from. New decision point could occur from changing requirements, getting results of a research spike, or identifying challenges that were not originally seen. Trade studies should be avoided if there is a clear solution choice. Because they require each solution to be fully thought out, they have the potential to take a lot of time to complete. When there is a clear design, the trade study should be omitted, and an entry should be made in the Decision Log documenting the decision. Why Trade Studies Trade studies are a way of formalizing the design process and leaving a documentation record for why the decision was made. This gives a few advantages: The trade study template guides a user through the design process. This provides structure to the design stage. Having a uniform design process aids splitting work amongst team members. We have had success with engineers pairing to define requirements, evaluation criteria, and brainstorming possible solutions. Then they can each split to review solutions in parallel, before rejoining to make the final decision. The completed trade study document helps drive alignment across the team and decision makers. For presenting results of the study, the document itself can be used to highlight the main points. Alternatively, we have extracted requirements, diagrams for each solution, and the results table into a slide deck to give high level overviews of the results. The completed trade study gets checked into the code repository, providing documentation of the decision process. This leaves a history of the requirements at the time that lead to each decision. Also, the results table gives a quick reference for how the decision would be impacted if requirements change as the project proceeds. Flow of a Trade Study Trade studies can vary widely in scope; however, they follow the common pattern below: Solidify the requirements \u2013 Work with the stakeholders to agree on the requirements for the functionality that you are trying to build. Create evaluation criteria \u2013 This is a set of qualitative and quantitative assessment points that represent the requirements. Taken together, they become an easy to measure stand-in for the potentially abstract requirements. Brainstorm solutions \u2013 Gather a list of possible solutions to the problem. Then, use your best judgement to pick the 2-4 solutions that seem most promising. For assistance narrowing solutions, remember to reach out to subject-matter experts and other teams who may have gone through a similar decision. Evaluate shortlisted solutions \u2013 Dive deep into each solution and measure it against the evaluation criteria. In this stage, time box your research to avoid overly investing in any given area. Compare results and choose solution - Align the decision with the team. If you are unable to decide, then a clear list of action items and owners to drive the final decision must be produced. Template See template.md for an example of how to structure the above information. This template was created to guide a user through conducting a trade study. Once the decision has been made we recommend adding an entry to the Decision Log that has references back to the full text of the trade study.","title":"Trade Studies"},{"location":"design/design-reviews/trade-studies/#trade-studies","text":"Trade studies are a tool for selecting the best option out of several possible options for a given problem (for example: compute, storage). They evaluate potential choices against a set of objective criteria/requirements to clearly lay out the benefits and limitations of each solution. Trade studies are a concept from systems engineering that we adapted for software projects. Trade studies have proved to be a critical tool to drive alignment with the stakeholders, earn credibility while doing so and ensure our decisions were backed by data and not bias.","title":"Trade Studies"},{"location":"design/design-reviews/trade-studies/#when-to-use-the-tool","text":"Trade studies go hand in hand with high level architecture design. This usually occurs as project requirements are solidifying, before coding begins. Trade studies continue to be useful throughout the project any time there are multiple options that need to be selected from. New decision point could occur from changing requirements, getting results of a research spike, or identifying challenges that were not originally seen. Trade studies should be avoided if there is a clear solution choice. Because they require each solution to be fully thought out, they have the potential to take a lot of time to complete. When there is a clear design, the trade study should be omitted, and an entry should be made in the Decision Log documenting the decision.","title":"When to use the tool"},{"location":"design/design-reviews/trade-studies/#why-trade-studies","text":"Trade studies are a way of formalizing the design process and leaving a documentation record for why the decision was made. This gives a few advantages: The trade study template guides a user through the design process. This provides structure to the design stage. Having a uniform design process aids splitting work amongst team members. We have had success with engineers pairing to define requirements, evaluation criteria, and brainstorming possible solutions. Then they can each split to review solutions in parallel, before rejoining to make the final decision. The completed trade study document helps drive alignment across the team and decision makers. For presenting results of the study, the document itself can be used to highlight the main points. Alternatively, we have extracted requirements, diagrams for each solution, and the results table into a slide deck to give high level overviews of the results. The completed trade study gets checked into the code repository, providing documentation of the decision process. This leaves a history of the requirements at the time that lead to each decision. Also, the results table gives a quick reference for how the decision would be impacted if requirements change as the project proceeds.","title":"Why Trade Studies"},{"location":"design/design-reviews/trade-studies/#flow-of-a-trade-study","text":"Trade studies can vary widely in scope; however, they follow the common pattern below: Solidify the requirements \u2013 Work with the stakeholders to agree on the requirements for the functionality that you are trying to build. Create evaluation criteria \u2013 This is a set of qualitative and quantitative assessment points that represent the requirements. Taken together, they become an easy to measure stand-in for the potentially abstract requirements. Brainstorm solutions \u2013 Gather a list of possible solutions to the problem. Then, use your best judgement to pick the 2-4 solutions that seem most promising. For assistance narrowing solutions, remember to reach out to subject-matter experts and other teams who may have gone through a similar decision. Evaluate shortlisted solutions \u2013 Dive deep into each solution and measure it against the evaluation criteria. In this stage, time box your research to avoid overly investing in any given area. Compare results and choose solution - Align the decision with the team. If you are unable to decide, then a clear list of action items and owners to drive the final decision must be produced.","title":"Flow of a Trade Study"},{"location":"design/design-reviews/trade-studies/#template","text":"See template.md for an example of how to structure the above information. This template was created to guide a user through conducting a trade study. Once the decision has been made we recommend adding an entry to the Decision Log that has references back to the full text of the trade study.","title":"Template"},{"location":"design/design-reviews/trade-studies/template/","text":"Trade Study Template This generic template can be used for any situation where we have a set of requirements that can be satisfied by multiple solutions. They can range in scope from choice of which open source package to use, to full architecture designs. Trade Study/Design: {study name goes here} Conducted by: {Names of those that can answer follow-up questions and at least one email address} Backlog Work Item: {Link to the work item to provide more context} Sprint: {Which sprint did the study take place? Include sprint start date} Decision: {Solution chosen to proceed with} Decision Makers: IMPORTANT Designs should be completed within a sprint. Most designs will benefit from brevity. To accomplish this: Narrow the scope of the design. Narrow evaluation to 2 to 3 solutions. Design experiments to collect evidence as fast as possible. Overview Description of the problem we are solving. This should include: Assumptions about the rest of the system Constraints that apply to the system, both business and technical Requirements for the functionality that needs to be implemented, including possible inputs and outputs (optional) A diagram showing the different pieces Desired Outcomes The following section should establish the desired capabilities of the solution for it to be successful. This can be done by answering the following questions either directly or via link to related artifact (i.e. PBI or Feature description). Acceptance: What capabilities should be demonstrable for a stakeholder to accept the solution? Justification: How does this contribute to the broader project objectives? IMPORTANT This is not intended to define outcomes for the design activity itself. It is intended to define the outcomes for the solution being designed. As mentioned in the User Interface section, if the trade study is analyzing an application development solution, make use of the persona stories to derive desired outcomes. For example, if a persona story exemplifies a certain accessibility requirement, the parallel desired outcome may be \"The application must be accessible for people with vision-based disabilities\". Evaluation Criteria The former should be condensed down to a set of \"evaluation criteria\" that we can rate any potential solutions against. Examples of evaluation criteria: Runs on Windows and Linux - Binary response Compute Usage - Could be categories that effectively rank different options: High, Medium, Low Cost of the solution \u2013 An estimated numeric field The results section contains a table evaluating each solution against the evaluation criteria. Key Metrics (Optional) If available, describe any measurable metrics that are important to the success of the solution. Examples include, but are not limited to: Performance & Scale targets such as, Requests/Second, Latency, and Response time (at a given percentile). Azure consumption cost budget. For example, given certain usage, solution expected to cost X dollars per month. Availability uptime of XX% over X time period. Consistency. Writes available for read within X milliseconds. Recovery point objective (RPO) & Recovery time objective (RTO). Constraints (Optional) If applicable, describe the boundaries from which we have to design the solution. This could be thought of as the \"box\" the team has to work within. This box may be defined as: Technologies, services, and languages an organization is comfortable operating/managing. Devices, operating systems, and/or browsers that must be supported. Backward Compatibility. For example, public interfaces consumed by client or third party apps cannot introduce breaking changes. Integrations or dependencies with other systems. For example, push notifications to client apps must be done via existing websockets channel. Accessibility Accessibility is never optional . Microsoft has made a public commitment to always produce accessible applications. For more information visit the official Microsoft accessibility site and read the Accessibility page. Consider the following prompts when determining application accessibility requirements: Does the application meet industry accessibility standards? Are training, support, and documentation resources accessible? Is the application designed to be inclusive for people will a broad range of abilities, languages, and cultures? Solution Hypotheses Enumerate the solutions that are believed to deliver the outcomes defined above. NOTE: Limiting the evaluated solutions to 2 or 3 potential candidates can help manage the time spent on the evaluation. If there are more than 3 candidates, prioritize what the team feels are the top 3. If appropriate, the eliminated candidates can be mentioned to capture why they were eliminated. Additionally, there should be at least two options compared, otherwise you didn't need a trade study. {Solution 1} - Short and easily recognizable name Add a brief description of the solution and how its expected to produce the desired outcomes. If appropriate, illustrations/diagrams can be used to reduce the amount of text explanation required to describe the solution. NOTE: Using present tense language to describe the solution can help avoid confusion between current state and future state. For example, use \"This solution works by doing...\" vs. \"This solution would work by doing...\". Each solution section should contain the following: Description of the solution (optional) A diagram to quickly reference the solution Possible variations - things that are small variations on the main solution can be grouped together Evaluation of the idea based on the evaluation criteria above The depth, detail, and contents of these sections will vary based on the complexity of the functionality being developed. Experiment(s) Describe how the solution will be evaluated to prove or dis-prove that it will produce the desired outcomes. This could take many forms such as building a prototype and researching existing documentation and sample solutions. Additionally, document any assumptions made as part of the experiment. NOTE: Time boxing these experiments can be beneficial to make sure the team is making the best use of the time by focusing on collecting key evidence in the simplest/fastest way possible. Evidence Present the evidence collected during experimentation that supports the hypothesis that this solution will meet the desired outcomes. Examples may include: Recorded or live demos of a prototype providing the desired capabilities Metrics collected while testing the prototype Documentation that indicates the solution can provide the desired capabilities NOTE: Evidence is not required for every capability, metric, or constraint for the design to be considered done. Instead, focus on presenting evidence that is most relevant and impactful towards supporting or eliminating the hypothesis. {Solution 2} ... {Solution N} ... Results This section should contain a table that has each solution rated against each of the evaluation criteria: Solution Evaluation Criteria 1 Evaluation Criteria 2 ... Evaluation Criteria N Solution 1 Solution 2 ... Solution M Note: The formatting of the table can change. In the past, we have had success with qualitative descriptions in the table entries and color coding the cells to represent good, fair, bad. Decision The chosen solution, or a list of questions that need to be answered before the decision can be made. In the latter case, each question needs an action item and an assigned person for answering the question. Once those questions are answered, the document must be updated to reflect the answers, and the final decision. In the first case, describe which solution was chosen and why. Summarize what evidence informed the decision and how that evidence mapped to the desired outcomes. IMPORTANT : Decisions should be made with the understanding that they can change as the team learns more. It's a starting point, not a contract. Next Steps What work is expected once a decision has been reached? Examples include but are not limited to: Creating new PBI's or modifying existing ones Follow up spikes Creating specification for public interfaces and integrations between other work streams. Decision Log Entry","title":"Trade Study Template"},{"location":"design/design-reviews/trade-studies/template/#trade-study-template","text":"This generic template can be used for any situation where we have a set of requirements that can be satisfied by multiple solutions. They can range in scope from choice of which open source package to use, to full architecture designs.","title":"Trade Study Template"},{"location":"design/design-reviews/trade-studies/template/#trade-studydesign-study-name-goes-here","text":"Conducted by: {Names of those that can answer follow-up questions and at least one email address} Backlog Work Item: {Link to the work item to provide more context} Sprint: {Which sprint did the study take place? Include sprint start date} Decision: {Solution chosen to proceed with} Decision Makers: IMPORTANT Designs should be completed within a sprint. Most designs will benefit from brevity. To accomplish this: Narrow the scope of the design. Narrow evaluation to 2 to 3 solutions. Design experiments to collect evidence as fast as possible.","title":"Trade Study/Design: {study name goes here}"},{"location":"design/design-reviews/trade-studies/template/#overview","text":"Description of the problem we are solving. This should include: Assumptions about the rest of the system Constraints that apply to the system, both business and technical Requirements for the functionality that needs to be implemented, including possible inputs and outputs (optional) A diagram showing the different pieces","title":"Overview"},{"location":"design/design-reviews/trade-studies/template/#desired-outcomes","text":"The following section should establish the desired capabilities of the solution for it to be successful. This can be done by answering the following questions either directly or via link to related artifact (i.e. PBI or Feature description). Acceptance: What capabilities should be demonstrable for a stakeholder to accept the solution? Justification: How does this contribute to the broader project objectives? IMPORTANT This is not intended to define outcomes for the design activity itself. It is intended to define the outcomes for the solution being designed. As mentioned in the User Interface section, if the trade study is analyzing an application development solution, make use of the persona stories to derive desired outcomes. For example, if a persona story exemplifies a certain accessibility requirement, the parallel desired outcome may be \"The application must be accessible for people with vision-based disabilities\".","title":"Desired Outcomes"},{"location":"design/design-reviews/trade-studies/template/#evaluation-criteria","text":"The former should be condensed down to a set of \"evaluation criteria\" that we can rate any potential solutions against. Examples of evaluation criteria: Runs on Windows and Linux - Binary response Compute Usage - Could be categories that effectively rank different options: High, Medium, Low Cost of the solution \u2013 An estimated numeric field The results section contains a table evaluating each solution against the evaluation criteria.","title":"Evaluation Criteria"},{"location":"design/design-reviews/trade-studies/template/#key-metrics-optional","text":"If available, describe any measurable metrics that are important to the success of the solution. Examples include, but are not limited to: Performance & Scale targets such as, Requests/Second, Latency, and Response time (at a given percentile). Azure consumption cost budget. For example, given certain usage, solution expected to cost X dollars per month. Availability uptime of XX% over X time period. Consistency. Writes available for read within X milliseconds. Recovery point objective (RPO) & Recovery time objective (RTO).","title":"Key Metrics (Optional)"},{"location":"design/design-reviews/trade-studies/template/#constraints-optional","text":"If applicable, describe the boundaries from which we have to design the solution. This could be thought of as the \"box\" the team has to work within. This box may be defined as: Technologies, services, and languages an organization is comfortable operating/managing. Devices, operating systems, and/or browsers that must be supported. Backward Compatibility. For example, public interfaces consumed by client or third party apps cannot introduce breaking changes. Integrations or dependencies with other systems. For example, push notifications to client apps must be done via existing websockets channel.","title":"Constraints (Optional)"},{"location":"design/design-reviews/trade-studies/template/#accessibility","text":"Accessibility is never optional . Microsoft has made a public commitment to always produce accessible applications. For more information visit the official Microsoft accessibility site and read the Accessibility page. Consider the following prompts when determining application accessibility requirements: Does the application meet industry accessibility standards? Are training, support, and documentation resources accessible? Is the application designed to be inclusive for people will a broad range of abilities, languages, and cultures?","title":"Accessibility"},{"location":"design/design-reviews/trade-studies/template/#solution-hypotheses","text":"Enumerate the solutions that are believed to deliver the outcomes defined above. NOTE: Limiting the evaluated solutions to 2 or 3 potential candidates can help manage the time spent on the evaluation. If there are more than 3 candidates, prioritize what the team feels are the top 3. If appropriate, the eliminated candidates can be mentioned to capture why they were eliminated. Additionally, there should be at least two options compared, otherwise you didn't need a trade study.","title":"Solution Hypotheses"},{"location":"design/design-reviews/trade-studies/template/#solution-1-short-and-easily-recognizable-name","text":"Add a brief description of the solution and how its expected to produce the desired outcomes. If appropriate, illustrations/diagrams can be used to reduce the amount of text explanation required to describe the solution. NOTE: Using present tense language to describe the solution can help avoid confusion between current state and future state. For example, use \"This solution works by doing...\" vs. \"This solution would work by doing...\". Each solution section should contain the following: Description of the solution (optional) A diagram to quickly reference the solution Possible variations - things that are small variations on the main solution can be grouped together Evaluation of the idea based on the evaluation criteria above The depth, detail, and contents of these sections will vary based on the complexity of the functionality being developed.","title":"{Solution 1} - Short and easily recognizable name"},{"location":"design/design-reviews/trade-studies/template/#experiments","text":"Describe how the solution will be evaluated to prove or dis-prove that it will produce the desired outcomes. This could take many forms such as building a prototype and researching existing documentation and sample solutions. Additionally, document any assumptions made as part of the experiment. NOTE: Time boxing these experiments can be beneficial to make sure the team is making the best use of the time by focusing on collecting key evidence in the simplest/fastest way possible.","title":"Experiment(s)"},{"location":"design/design-reviews/trade-studies/template/#evidence","text":"Present the evidence collected during experimentation that supports the hypothesis that this solution will meet the desired outcomes. Examples may include: Recorded or live demos of a prototype providing the desired capabilities Metrics collected while testing the prototype Documentation that indicates the solution can provide the desired capabilities NOTE: Evidence is not required for every capability, metric, or constraint for the design to be considered done. Instead, focus on presenting evidence that is most relevant and impactful towards supporting or eliminating the hypothesis.","title":"Evidence"},{"location":"design/design-reviews/trade-studies/template/#solution-2","text":"...","title":"{Solution 2}"},{"location":"design/design-reviews/trade-studies/template/#solution-n","text":"...","title":"{Solution N}"},{"location":"design/design-reviews/trade-studies/template/#results","text":"This section should contain a table that has each solution rated against each of the evaluation criteria: Solution Evaluation Criteria 1 Evaluation Criteria 2 ... Evaluation Criteria N Solution 1 Solution 2 ... Solution M Note: The formatting of the table can change. In the past, we have had success with qualitative descriptions in the table entries and color coding the cells to represent good, fair, bad.","title":"Results"},{"location":"design/design-reviews/trade-studies/template/#decision","text":"The chosen solution, or a list of questions that need to be answered before the decision can be made. In the latter case, each question needs an action item and an assigned person for answering the question. Once those questions are answered, the document must be updated to reflect the answers, and the final decision. In the first case, describe which solution was chosen and why. Summarize what evidence informed the decision and how that evidence mapped to the desired outcomes. IMPORTANT : Decisions should be made with the understanding that they can change as the team learns more. It's a starting point, not a contract.","title":"Decision"},{"location":"design/design-reviews/trade-studies/template/#next-steps","text":"What work is expected once a decision has been reached? Examples include but are not limited to: Creating new PBI's or modifying existing ones Follow up spikes Creating specification for public interfaces and integrations between other work streams. Decision Log Entry","title":"Next Steps"},{"location":"design/diagram-types/","text":"Diagram Types Creating and maintaining diagrams is a challenge for any team. Common reasons across these challenges include: Not leveraging tools to assist in generating diagrams Uncertainty on what to include in a diagram and when to create one Overcoming these challenges and effectively using design diagrams can amplify a team's ability to execute throughout the entire Software Development Lifecycle, from the design phase when proposing various designs to leveraging it as documentation as part of the maintenance phase. This section will share sample tools for diagram generation, provide a high level overview of the different types of diagrams and provide examples of some of these types. There are two primary classes of diagrams: Structural Behavior Within each of these classes, there are many types of diagrams, each intended to convey specific types of information. When different types of diagrams are effectively used in a solution, system, or repository, one can deliver a cohesive and incrementally detailed design. Sample Design Diagrams This section contains educational material and examples for the following design diagrams: Class Diagrams - Useful to document the structural design of a codebase's relationship between classes, and their corresponding methods Component Diagrams - Useful to document a high level structural overview of all the components and their direct \"touch points\" with other Components Sequence Diagrams - Useful to document a behavior overview of the system, capturing the various \"use cases\" or \"actions\" that triggers the system to perform some business logic Deployment Diagram - Useful in order to document the networking and hosting environments where the system will operate in Supplemental Resources Each of the above types of diagrams will provide specific resources related to its type. Below are the generic resources: Visual Paradigm UML Structural vs Behavior Diagrams PlantUML - requires a generator from code to PlantUML syntax to generate diagrams C# to PlantUML Drawing manually","title":"Diagram Types"},{"location":"design/diagram-types/#diagram-types","text":"Creating and maintaining diagrams is a challenge for any team. Common reasons across these challenges include: Not leveraging tools to assist in generating diagrams Uncertainty on what to include in a diagram and when to create one Overcoming these challenges and effectively using design diagrams can amplify a team's ability to execute throughout the entire Software Development Lifecycle, from the design phase when proposing various designs to leveraging it as documentation as part of the maintenance phase. This section will share sample tools for diagram generation, provide a high level overview of the different types of diagrams and provide examples of some of these types. There are two primary classes of diagrams: Structural Behavior Within each of these classes, there are many types of diagrams, each intended to convey specific types of information. When different types of diagrams are effectively used in a solution, system, or repository, one can deliver a cohesive and incrementally detailed design.","title":"Diagram Types"},{"location":"design/diagram-types/#sample-design-diagrams","text":"This section contains educational material and examples for the following design diagrams: Class Diagrams - Useful to document the structural design of a codebase's relationship between classes, and their corresponding methods Component Diagrams - Useful to document a high level structural overview of all the components and their direct \"touch points\" with other Components Sequence Diagrams - Useful to document a behavior overview of the system, capturing the various \"use cases\" or \"actions\" that triggers the system to perform some business logic Deployment Diagram - Useful in order to document the networking and hosting environments where the system will operate in","title":"Sample Design Diagrams"},{"location":"design/diagram-types/#supplemental-resources","text":"Each of the above types of diagrams will provide specific resources related to its type. Below are the generic resources: Visual Paradigm UML Structural vs Behavior Diagrams PlantUML - requires a generator from code to PlantUML syntax to generate diagrams C# to PlantUML Drawing manually","title":"Supplemental Resources"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/","text":"Class Diagrams Purpose This document is intended to provide a baseline understanding for what, why, and how to incorporate Class Diagrams as part of your engagement. Regarding the how , the section at the bottom will provide tools and plugins to automate as much as possible when generating Class Diagrams through VSCode. Wikipedia defines UML Class Diagrams as: a type of static structure diagram that describes the structure of a system by showing the system's classes, their attributes, operations (or methods), and the relationships among objects. The key terms to make a note of here are: static structure showing the system's classes, attributes, operations, and relationships Class Diagrams are a type of a static structure because it focuses on the properties, and relationships of classes. It is not supposed to inform about the data flow, the caller or callee responsibilities, the request flows, nor any other \"behavior\" related characteristics. Essential Takeaways Each \"Component\" (Stand alone piece of software - think datastores, microservices, serverless functions, user interfaces, etc...) of a Product or System will have it's own Class Diagram. Class Diagrams should tell a \"story\", where each Diagram will require Engineers to really think about: The responsibility / operations of each class. What can (should) the class perform? The class' attributes and properties. What can be set by an implementor of this class? What are all (if any) universally static properties? The visibility or accessibility that a class' operation may have to other classes The relationship between each class or the various instances When to Create? Because Class Diagrams represent one of the more granular depiction of what a \"product\" or \"system\" is composed of, it is recommended to begin the creation of these diagrams at the beginning and throughout the engineering portions of an engagement. This does mean that any code change (new feature, enhancement, code refactor) might involve updating one or many Class Diagrams. Although this might seem like a downside of Class Diagrams, it actually can become a very strong benefit. Because Class Diagrams tell a \"story\" for each Component of a product (see the previous section), it requires a substantial amount of upfront thought and design considerations. This amount of upfront thought ultimately results in making more effective code changes, and may even minimize the level of refactors in future stages of the engagement. Class Diagrams also provides quick \"alert indicators\" when a refactor might be necessary. Reasons could be due to seeing that a particular class might be doing too much, have too many dependencies, or when the codebase might produce a very \"messy\" or \"chaotic\" Class Diagram. If the Class Diagram is unreadable, the code will probably be unreadable Examples One can find many examples online such as at UML Diagrams . Below are some basic examples: Versioning Because Class Diagrams will be changing rapidly, essentially anytime a class is changed in the code, and because it might be very large in size, it's recommended to \"publish\" an image of the generated diagram periodically. The frequency might vary as the engagement proceeds. The below approach can be used to assist the team on how often to update the published version of the diagram: Wait until the engagement progresses (maybe 10-20% completion) before publishing a Class Diagram. It is not worth publishing a Class Diagram from the beginning as it will be changing daily Once the most crucial classes are developed, update the published diagram periodically. Ideally whenever a large refactor or net new class is introduced. If the team uses an IDE plugin to automatically generate the diagram from their development environment, this becomes more of a documentation task rather than a necessity As the engagement approaches its end (90-100% completion), update the published diagram whenever a change to an existing class as part of a feature or story acceptance criteria Depending on the tool being used, automatic versioning might be performed whenever an update to the Diagram is performed. If not, it is recommended to capture distinct versions whenever there is a particular customer need to have a snapshot of the project at a particular point in time. The hard requirement is that the latest diagram should be published and everyone should know how to access it as the customer hand-off approaches. Resources Wikipedia Visual Paradigm VS Code Plugins: C#, Visual Basic, C++ using Class Designer Component TypeScript classdiagram-ts PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax C# to PlantUML Drawing manually","title":"Class Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#class-diagrams","text":"","title":"Class Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#purpose","text":"This document is intended to provide a baseline understanding for what, why, and how to incorporate Class Diagrams as part of your engagement. Regarding the how , the section at the bottom will provide tools and plugins to automate as much as possible when generating Class Diagrams through VSCode. Wikipedia defines UML Class Diagrams as: a type of static structure diagram that describes the structure of a system by showing the system's classes, their attributes, operations (or methods), and the relationships among objects. The key terms to make a note of here are: static structure showing the system's classes, attributes, operations, and relationships Class Diagrams are a type of a static structure because it focuses on the properties, and relationships of classes. It is not supposed to inform about the data flow, the caller or callee responsibilities, the request flows, nor any other \"behavior\" related characteristics.","title":"Purpose"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#essential-takeaways","text":"Each \"Component\" (Stand alone piece of software - think datastores, microservices, serverless functions, user interfaces, etc...) of a Product or System will have it's own Class Diagram. Class Diagrams should tell a \"story\", where each Diagram will require Engineers to really think about: The responsibility / operations of each class. What can (should) the class perform? The class' attributes and properties. What can be set by an implementor of this class? What are all (if any) universally static properties? The visibility or accessibility that a class' operation may have to other classes The relationship between each class or the various instances","title":"Essential Takeaways"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#when-to-create","text":"Because Class Diagrams represent one of the more granular depiction of what a \"product\" or \"system\" is composed of, it is recommended to begin the creation of these diagrams at the beginning and throughout the engineering portions of an engagement. This does mean that any code change (new feature, enhancement, code refactor) might involve updating one or many Class Diagrams. Although this might seem like a downside of Class Diagrams, it actually can become a very strong benefit. Because Class Diagrams tell a \"story\" for each Component of a product (see the previous section), it requires a substantial amount of upfront thought and design considerations. This amount of upfront thought ultimately results in making more effective code changes, and may even minimize the level of refactors in future stages of the engagement. Class Diagrams also provides quick \"alert indicators\" when a refactor might be necessary. Reasons could be due to seeing that a particular class might be doing too much, have too many dependencies, or when the codebase might produce a very \"messy\" or \"chaotic\" Class Diagram. If the Class Diagram is unreadable, the code will probably be unreadable","title":"When to Create?"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#examples","text":"One can find many examples online such as at UML Diagrams . Below are some basic examples:","title":"Examples"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#versioning","text":"Because Class Diagrams will be changing rapidly, essentially anytime a class is changed in the code, and because it might be very large in size, it's recommended to \"publish\" an image of the generated diagram periodically. The frequency might vary as the engagement proceeds. The below approach can be used to assist the team on how often to update the published version of the diagram: Wait until the engagement progresses (maybe 10-20% completion) before publishing a Class Diagram. It is not worth publishing a Class Diagram from the beginning as it will be changing daily Once the most crucial classes are developed, update the published diagram periodically. Ideally whenever a large refactor or net new class is introduced. If the team uses an IDE plugin to automatically generate the diagram from their development environment, this becomes more of a documentation task rather than a necessity As the engagement approaches its end (90-100% completion), update the published diagram whenever a change to an existing class as part of a feature or story acceptance criteria Depending on the tool being used, automatic versioning might be performed whenever an update to the Diagram is performed. If not, it is recommended to capture distinct versions whenever there is a particular customer need to have a snapshot of the project at a particular point in time. The hard requirement is that the latest diagram should be published and everyone should know how to access it as the customer hand-off approaches.","title":"Versioning"},{"location":"design/diagram-types/DesignDiagramsTemplates/classDiagrams/#resources","text":"Wikipedia Visual Paradigm VS Code Plugins: C#, Visual Basic, C++ using Class Designer Component TypeScript classdiagram-ts PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax C# to PlantUML Drawing manually","title":"Resources"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/","text":"Component Diagrams Purpose This document is intended to provide a baseline understanding for what, why, and how to incorporate Component Diagrams as part of your engagement. Regarding the how , the section at the bottom will provide tools and plugins to streamline as much as possible when generating Component Diagrams through VSCode. Wikipedia defines UML Component Diagrams as: a component diagram depicts how components are wired together to form larger components or software systems. Component Diagrams are a type of a static structure because it focuses on the responsibility and relationships between components as part of the overall system or solution. It is not supposed to inform about the data flow, the caller or callee responsibilities, the request flows, nor any other \"behavior\" related characteristics. ...Hold on a second... what is a Component? A Component is a runnable solution that performs a set of operations and can possibly be interfaced through a particular API. One can think of Components as a \"stand alone\" piece of software - think datastores, microservices, serverless functions, user interfaces, etc... Essential Takeaways The primary two takeaways from a Component Diagram should be: A quick view of all the various components (User Interface, Service, Data Storage) involved in the system The immediate \"touch points\" that a particular Component has with other Components, including how that \"touch point\" is accomplished (HTTP, FTP, etc...) Depending on the complexity of the system, a team might decide to create several Component Diagrams. Where there is one diagram per Component (depicting all it's immediate \"touch points\" with other Components). Or if a system is simple, the team might decide to create a single Component Diagram capturing all Components in the diagram. When to Create? Because Component Diagrams represent a high level overview of the entire system from a Component focus, it is recommended to begin the creation of this diagram from the beginning of an engagement, and update it as the various Components are identified, developed, and introduced into the system. Otherwise, if this is left till later, then there is risk that: the team won't be able to identify areas of improvement the team or other necessary stakeholders won't have a full understanding on how the system works as it is being developed Because of the inherent granularity of the system, the Component Diagrams won't have to be updated as often as Class Diagrams . Things that might merit updating a Component Diagram could be: A deletion or addition of a new Component into the system A change to a system Component's interaction APIs A change to a system Component's immediate \"touch points\" with other Components Because Component Diagrams focuses on informing the various \"touch points\" between Components, it requires some upfront thought in order to determine what Components are needed and what interaction mechanisms are most effective per the system requirements. This amount of upfront thought should be approached in a pragmatic manner - as the design may evolve over time, and that is perfectly fine, as long as changes are influenced based on functional requirements and non-functional requirements. Examples Below are some basic examples: Versioning Because Component Diagrams will be changing periodically, it's recommended to \"publish\" an image of the generated diagram periodically. The frequency might vary as the engagement proceeds. The below approach can be used to assist the team on how often to update the published version of the diagram: At the beginning of the engagement, publishing an \"envisioned\" version of the Component Diagram will provide a common visual to all engineers when working on the different parts of the solution Throughout the engagement, update the published diagram periodically. Ideally whenever a new Component is introduced into the system, or whenever a new \"touch point\" occurs between Components Depending on the tool being used, automatic versioning might be performed whenever an update to the Diagram is performed. If not, it is recommended to capture distinct versions whenever there is a particular customer need to have a snapshot of the project at a particular point in time. The hard requirement is that the latest diagram should be published and everyone should know how to access it as the customer hand-off approaches. Resources Wikipedia Visual Paradigm VS Code Plugins: PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax Drawing manually","title":"Component Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#component-diagrams","text":"","title":"Component Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#purpose","text":"This document is intended to provide a baseline understanding for what, why, and how to incorporate Component Diagrams as part of your engagement. Regarding the how , the section at the bottom will provide tools and plugins to streamline as much as possible when generating Component Diagrams through VSCode. Wikipedia defines UML Component Diagrams as: a component diagram depicts how components are wired together to form larger components or software systems. Component Diagrams are a type of a static structure because it focuses on the responsibility and relationships between components as part of the overall system or solution. It is not supposed to inform about the data flow, the caller or callee responsibilities, the request flows, nor any other \"behavior\" related characteristics. ...Hold on a second... what is a Component? A Component is a runnable solution that performs a set of operations and can possibly be interfaced through a particular API. One can think of Components as a \"stand alone\" piece of software - think datastores, microservices, serverless functions, user interfaces, etc...","title":"Purpose"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#essential-takeaways","text":"The primary two takeaways from a Component Diagram should be: A quick view of all the various components (User Interface, Service, Data Storage) involved in the system The immediate \"touch points\" that a particular Component has with other Components, including how that \"touch point\" is accomplished (HTTP, FTP, etc...) Depending on the complexity of the system, a team might decide to create several Component Diagrams. Where there is one diagram per Component (depicting all it's immediate \"touch points\" with other Components). Or if a system is simple, the team might decide to create a single Component Diagram capturing all Components in the diagram.","title":"Essential Takeaways"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#when-to-create","text":"Because Component Diagrams represent a high level overview of the entire system from a Component focus, it is recommended to begin the creation of this diagram from the beginning of an engagement, and update it as the various Components are identified, developed, and introduced into the system. Otherwise, if this is left till later, then there is risk that: the team won't be able to identify areas of improvement the team or other necessary stakeholders won't have a full understanding on how the system works as it is being developed Because of the inherent granularity of the system, the Component Diagrams won't have to be updated as often as Class Diagrams . Things that might merit updating a Component Diagram could be: A deletion or addition of a new Component into the system A change to a system Component's interaction APIs A change to a system Component's immediate \"touch points\" with other Components Because Component Diagrams focuses on informing the various \"touch points\" between Components, it requires some upfront thought in order to determine what Components are needed and what interaction mechanisms are most effective per the system requirements. This amount of upfront thought should be approached in a pragmatic manner - as the design may evolve over time, and that is perfectly fine, as long as changes are influenced based on functional requirements and non-functional requirements.","title":"When to Create?"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#examples","text":"Below are some basic examples:","title":"Examples"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#versioning","text":"Because Component Diagrams will be changing periodically, it's recommended to \"publish\" an image of the generated diagram periodically. The frequency might vary as the engagement proceeds. The below approach can be used to assist the team on how often to update the published version of the diagram: At the beginning of the engagement, publishing an \"envisioned\" version of the Component Diagram will provide a common visual to all engineers when working on the different parts of the solution Throughout the engagement, update the published diagram periodically. Ideally whenever a new Component is introduced into the system, or whenever a new \"touch point\" occurs between Components Depending on the tool being used, automatic versioning might be performed whenever an update to the Diagram is performed. If not, it is recommended to capture distinct versions whenever there is a particular customer need to have a snapshot of the project at a particular point in time. The hard requirement is that the latest diagram should be published and everyone should know how to access it as the customer hand-off approaches.","title":"Versioning"},{"location":"design/diagram-types/DesignDiagramsTemplates/componentDiagrams/#resources","text":"Wikipedia Visual Paradigm VS Code Plugins: PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax Drawing manually","title":"Resources"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/","text":"Deployment Diagrams Purpose This document is intended to provide a baseline understanding for what, why, and how to incorporate Deployment Diagrams as part of your engagement. Wikipedia defines UML Deployment Diagrams as: models the physical deployment of artifacts on nodes Deployment Diagrams are a type of a static structure because it focuses on the infrastructure and hosting where all aspects of the system reside in. It is not supposed to inform about the data flow, the caller or callee responsibilities, the request flows, nor any other \"behavior\" related characteristics. Essential Takeaways The Deployment diagram should contain all Components identified in the Component Diagram(s) , but captured alongside the following elements: Firewalls VNETs and subnets Virtual machines Cloud Services Data Stores Servers (Web, proxy) Load Balancers This diagram should inform the audience: where things are hosted / running in what network boundaries are involved in the system When to Create? Because Deployment Diagrams represent the final \"hosting\" architecture, it's recommended to create the \"final envisioned\" diagram from the beginning of an engagement. This allows the team to have a shared idea on what the team is working towards. Keep in mind that this might change if any non-functional requirement was not considered at the start of the engagement. This is okay, but requires creating the necessary Backlog Items and updating the Deployment diagram in order to capture these changes. It's also worthwhile to create and maintain a Deployment Diagram depicting the \"current\" state of the system. At times, it may be beneficial for there to be a Deployment Diagram per each environment (Dev, QA, Staging, Prod, etc...). However, this adds to the amount of maintenance required and should only be performed if there are substantial differences across environments. The \"current\" Deployment diagram should be updated when: A new element has been introduced or removed in the system (see the \"Essential Takeaways\" section for a list of possible elements) Examples Below are some basic examples: Versioning Because Deployment Diagrams will be changing periodically, it's recommended to \"publish\" an image of the generated diagram periodically. The frequency might vary as the engagement proceeds. The below approach can be used to assist the team on how often to update the published version of the diagram: At the beginning of the engagement, publishing an \"envisioned\" version of the Component Diagram will provide a common visual to all engineers when working on the different parts of the solution Throughout the engagement, update the \"actual / current\" diagram (state represented from the \"main\" branch) periodically. Ideally whenever a new Component is introduced into the system, or whenever a new \"touch point\" occurs between Components. Resources Wikipedia Visual Paradigm PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax Drawing manually","title":"Deployment Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#deployment-diagrams","text":"","title":"Deployment Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#purpose","text":"This document is intended to provide a baseline understanding for what, why, and how to incorporate Deployment Diagrams as part of your engagement. Wikipedia defines UML Deployment Diagrams as: models the physical deployment of artifacts on nodes Deployment Diagrams are a type of a static structure because it focuses on the infrastructure and hosting where all aspects of the system reside in. It is not supposed to inform about the data flow, the caller or callee responsibilities, the request flows, nor any other \"behavior\" related characteristics.","title":"Purpose"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#essential-takeaways","text":"The Deployment diagram should contain all Components identified in the Component Diagram(s) , but captured alongside the following elements: Firewalls VNETs and subnets Virtual machines Cloud Services Data Stores Servers (Web, proxy) Load Balancers This diagram should inform the audience: where things are hosted / running in what network boundaries are involved in the system","title":"Essential Takeaways"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#when-to-create","text":"Because Deployment Diagrams represent the final \"hosting\" architecture, it's recommended to create the \"final envisioned\" diagram from the beginning of an engagement. This allows the team to have a shared idea on what the team is working towards. Keep in mind that this might change if any non-functional requirement was not considered at the start of the engagement. This is okay, but requires creating the necessary Backlog Items and updating the Deployment diagram in order to capture these changes. It's also worthwhile to create and maintain a Deployment Diagram depicting the \"current\" state of the system. At times, it may be beneficial for there to be a Deployment Diagram per each environment (Dev, QA, Staging, Prod, etc...). However, this adds to the amount of maintenance required and should only be performed if there are substantial differences across environments. The \"current\" Deployment diagram should be updated when: A new element has been introduced or removed in the system (see the \"Essential Takeaways\" section for a list of possible elements)","title":"When to Create?"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#examples","text":"Below are some basic examples:","title":"Examples"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#versioning","text":"Because Deployment Diagrams will be changing periodically, it's recommended to \"publish\" an image of the generated diagram periodically. The frequency might vary as the engagement proceeds. The below approach can be used to assist the team on how often to update the published version of the diagram: At the beginning of the engagement, publishing an \"envisioned\" version of the Component Diagram will provide a common visual to all engineers when working on the different parts of the solution Throughout the engagement, update the \"actual / current\" diagram (state represented from the \"main\" branch) periodically. Ideally whenever a new Component is introduced into the system, or whenever a new \"touch point\" occurs between Components.","title":"Versioning"},{"location":"design/diagram-types/DesignDiagramsTemplates/deploymentDiagrams/#resources","text":"Wikipedia Visual Paradigm PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax Drawing manually","title":"Resources"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/","text":"Sequence Diagrams Purpose This document is intended to provide a baseline understanding for what, why, and how to incorporate Sequence Diagrams as part of an engagement. Regarding the how , the section at the bottom will provide tools and plugins to streamline as much as possible when generating Sequence Diagrams through VSCode. Wikipedia defines UML Sequence Diagrams responsible to: depict the objects involved in the scenario and the sequence of messages exchanged between the objects needed to carry out the functionality of the scenario What is a scenario ? It can be: an actual user persona performing an action a system specific trigger (time based, condition based) that results in an action to occur What is a message in this context? It can be: a synchronous or asynchronous request a transfer of any form of data between any objects What is an object in this context? It can be: any specific user persona any service any data store a system (black box composed of unknown services, data stores or other components) an abstract sub-scenario (in order to minimize high complexity of a scenario) Essential Takeaways A Sequence Diagram should: start with a scenario indicate which object or \"actor\" initiated that scenario have the scenario clearly indicate what the \"end\" state is, even if it doesn't necessarily end back with the object that initiated the scenario It is okay for a single Sequence Diagram to have many different scenarios if they have some related context that merits them being grouped. Another important thing to keep in mind, is that the objects involved in a Sequence Diagram should refer to existing Components from a Component Diagram . There are 2 areas where complexity can result in an overly \"crowded\" Sequence Diagram, making it costly to maintain. They are: Large number of objects / components involved in a particular scenario Capturing all the possible \"failure\" situations that a scenario may encounter Large Number of Objects A Sequence Diagram typically starts with an end user persona performing an action, and then shows all the various components and request/data transfers that are involved in that scenario. However, more often than not, the complete end-to-end flow for that scenario may be too complex in order to capture within a single Sequence Diagram. When this level of complexity occurs, consider creating separate sub-scenario Sequence Diagrams , and using it as an object in a particular Sequence Diagram. Examples for this are \"Authentication\" or \"Authorization\". Almost all user persona scenarios will have several objects/components involved in either of these sub-scenarios, but it is not necessary to include them in every Sequence Diagram once the sub-scenarios have a stand-alone Sequence Diagram created. Be sure that when using this approach of sub-scenarios to give it a name that encapsulates what the sub-scenarios is performing, and to determine the appropriate \"actor\" and \"action\" that initiates the sub-scenarios. The combination and story telling between these end user Sequence Diagrams and the sub-scenarios Sequence Diagrams can greatly improve readability by distributing the level of complexity across multiple diagrams and take advantage of reusability of common sub-scenarios. Handling Large Number of Failure Situations Another factor of high complexity is the possible failure situations that a particular scenario may encounter. Each object / component involved in the scenario could have several different \"failure\" situations, which could result in a very crowded and messy Sequence Diagram. In order to make it realistic to manage all these scenarios, try to: Identify the most common failure situations that an \"actor\" may face as part of a scenario. Capturing these in a sequence diagram and documenting the other scenarios without having to manage them in a diagram will accomplish the goal of awareness \"Bubble up\" and \"abstract\" all the vast number of failure situations that can occur downstream in the system, and depict how the object / component closest to the \"actor\" handles all these failures and informs the \"actor\" of them When to Create? Because Sequence Diagrams represent a detailed overview of the behavior of the system, outlining the various messages/requests sent within the system, it is recommended to begin the creation of these diagrams from the beginning of an engagement. While updating it as the various communications between Components are introduced into the system. The risks of not creating Sequence Diagrams early on are that: the team will not create any because of it being perceived more as a \"chore\" instead of adding value the team will be unable to gain insights in time, from visualizing the various messages and requests sent between Components, in order to perform any potential refactoring the team or other necessary stakeholders won't have a complete understanding of the request/message/data flow within the system Because of the inherent granularity of the system, the Sequence Diagrams won't have to be updated as often as Class Diagrams , but may require more maintenance than Component Diagrams . Things that might merit updating a Sequence Diagram could be: A new request/message/data being sent across Components involved in a scenario A change to one or several Components involved in a Sequence Diagram. Such as splitting a component into multiple ones, or consolidating many Components into a single one The introduction of a new Use Case or scenario that the system now supports Examples Place Order Scenario: A \"Member\" user persona places an order, which can be composed of many \"order items\" The \"Member\" user persona can be either of type \"VIP\" or \"Ordinary\" Depending on the \"Member type\", each \"order item\" will be shipped using either a Courier or via Mail If the \"Member\" user persona selected the option to be informed once all \"order items\" have been shipped, then the system will send a notification Facebook User Authentication Scenario: A user persona uses a Web Browser to interact with an \"application\" which tries to access a specific \"Facebook resource\" The \"Facebook Authorization Server\" is involved in order to have the user to authenticate with Facebook The user persona then receives a \"permission form\" in order to authorize the \"application\" access to the \"Facebook resource\" If the \"application\" was not authorized, then the \"application\" returns back an error If the \"application\" was authorized, then the \"application\" retrieves an \"access token\" from the \"Facebook Authorization Server\" and uses it to securely access the \"Facebook resource\" from the \"Facebook Content Server\". Once the content is obtained, the \"application\" sends it to the Web Browser Versioning Because Sequence Diagrams are more expensive to maintain, it's recommended to \"publish\" an image of the generated diagram often, whenever a new \"use case\" or \"scenario\" is identified as part of the system behavior or requirements. The most important element to these diagrams is to ensure that the latest version is accurate . If the latest diagram shows a sequence of communication between components that are no longer valid, then the diagram causes more harm than good. The below approach can be used to assist the team on how often to update the published version of the diagram: At the beginning of the engagement, publishing an \"envisioned\" version of the Sequence Diagram will provide a common visual to all engineers when working on the different parts of the solution (focusing on the data flow and request flow) Throughout the engagement, update the published diagram periodically. Ideally whenever a new \"use case\" or \"scenario\" is identified, or when a Component is introduced or removed in the system, or when a change in data/request flow is made in the system Depending on the tool being used, automatic versioning might be performed whenever an update to the Diagram is performed. If not, it is recommended to capture distinct versions whenever there is a particular customer need to have a snapshot of the project at a particular point in time. The hard requirement is that the latest diagram should be published and everyone should know how to access it as the customer hand-off approaches. Resources Wikipedia Visual Paradigm VS Code Plugins: PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax Drawing manually","title":"Sequence Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#sequence-diagrams","text":"","title":"Sequence Diagrams"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#purpose","text":"This document is intended to provide a baseline understanding for what, why, and how to incorporate Sequence Diagrams as part of an engagement. Regarding the how , the section at the bottom will provide tools and plugins to streamline as much as possible when generating Sequence Diagrams through VSCode. Wikipedia defines UML Sequence Diagrams responsible to: depict the objects involved in the scenario and the sequence of messages exchanged between the objects needed to carry out the functionality of the scenario What is a scenario ? It can be: an actual user persona performing an action a system specific trigger (time based, condition based) that results in an action to occur What is a message in this context? It can be: a synchronous or asynchronous request a transfer of any form of data between any objects What is an object in this context? It can be: any specific user persona any service any data store a system (black box composed of unknown services, data stores or other components) an abstract sub-scenario (in order to minimize high complexity of a scenario)","title":"Purpose"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#essential-takeaways","text":"A Sequence Diagram should: start with a scenario indicate which object or \"actor\" initiated that scenario have the scenario clearly indicate what the \"end\" state is, even if it doesn't necessarily end back with the object that initiated the scenario It is okay for a single Sequence Diagram to have many different scenarios if they have some related context that merits them being grouped. Another important thing to keep in mind, is that the objects involved in a Sequence Diagram should refer to existing Components from a Component Diagram . There are 2 areas where complexity can result in an overly \"crowded\" Sequence Diagram, making it costly to maintain. They are: Large number of objects / components involved in a particular scenario Capturing all the possible \"failure\" situations that a scenario may encounter","title":"Essential Takeaways"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#large-number-of-objects","text":"A Sequence Diagram typically starts with an end user persona performing an action, and then shows all the various components and request/data transfers that are involved in that scenario. However, more often than not, the complete end-to-end flow for that scenario may be too complex in order to capture within a single Sequence Diagram. When this level of complexity occurs, consider creating separate sub-scenario Sequence Diagrams , and using it as an object in a particular Sequence Diagram. Examples for this are \"Authentication\" or \"Authorization\". Almost all user persona scenarios will have several objects/components involved in either of these sub-scenarios, but it is not necessary to include them in every Sequence Diagram once the sub-scenarios have a stand-alone Sequence Diagram created. Be sure that when using this approach of sub-scenarios to give it a name that encapsulates what the sub-scenarios is performing, and to determine the appropriate \"actor\" and \"action\" that initiates the sub-scenarios. The combination and story telling between these end user Sequence Diagrams and the sub-scenarios Sequence Diagrams can greatly improve readability by distributing the level of complexity across multiple diagrams and take advantage of reusability of common sub-scenarios.","title":"Large Number of Objects"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#handling-large-number-of-failure-situations","text":"Another factor of high complexity is the possible failure situations that a particular scenario may encounter. Each object / component involved in the scenario could have several different \"failure\" situations, which could result in a very crowded and messy Sequence Diagram. In order to make it realistic to manage all these scenarios, try to: Identify the most common failure situations that an \"actor\" may face as part of a scenario. Capturing these in a sequence diagram and documenting the other scenarios without having to manage them in a diagram will accomplish the goal of awareness \"Bubble up\" and \"abstract\" all the vast number of failure situations that can occur downstream in the system, and depict how the object / component closest to the \"actor\" handles all these failures and informs the \"actor\" of them","title":"Handling Large Number of Failure Situations"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#when-to-create","text":"Because Sequence Diagrams represent a detailed overview of the behavior of the system, outlining the various messages/requests sent within the system, it is recommended to begin the creation of these diagrams from the beginning of an engagement. While updating it as the various communications between Components are introduced into the system. The risks of not creating Sequence Diagrams early on are that: the team will not create any because of it being perceived more as a \"chore\" instead of adding value the team will be unable to gain insights in time, from visualizing the various messages and requests sent between Components, in order to perform any potential refactoring the team or other necessary stakeholders won't have a complete understanding of the request/message/data flow within the system Because of the inherent granularity of the system, the Sequence Diagrams won't have to be updated as often as Class Diagrams , but may require more maintenance than Component Diagrams . Things that might merit updating a Sequence Diagram could be: A new request/message/data being sent across Components involved in a scenario A change to one or several Components involved in a Sequence Diagram. Such as splitting a component into multiple ones, or consolidating many Components into a single one The introduction of a new Use Case or scenario that the system now supports","title":"When to Create?"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#examples","text":"Place Order Scenario: A \"Member\" user persona places an order, which can be composed of many \"order items\" The \"Member\" user persona can be either of type \"VIP\" or \"Ordinary\" Depending on the \"Member type\", each \"order item\" will be shipped using either a Courier or via Mail If the \"Member\" user persona selected the option to be informed once all \"order items\" have been shipped, then the system will send a notification Facebook User Authentication Scenario: A user persona uses a Web Browser to interact with an \"application\" which tries to access a specific \"Facebook resource\" The \"Facebook Authorization Server\" is involved in order to have the user to authenticate with Facebook The user persona then receives a \"permission form\" in order to authorize the \"application\" access to the \"Facebook resource\" If the \"application\" was not authorized, then the \"application\" returns back an error If the \"application\" was authorized, then the \"application\" retrieves an \"access token\" from the \"Facebook Authorization Server\" and uses it to securely access the \"Facebook resource\" from the \"Facebook Content Server\". Once the content is obtained, the \"application\" sends it to the Web Browser","title":"Examples"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#versioning","text":"Because Sequence Diagrams are more expensive to maintain, it's recommended to \"publish\" an image of the generated diagram often, whenever a new \"use case\" or \"scenario\" is identified as part of the system behavior or requirements. The most important element to these diagrams is to ensure that the latest version is accurate . If the latest diagram shows a sequence of communication between components that are no longer valid, then the diagram causes more harm than good. The below approach can be used to assist the team on how often to update the published version of the diagram: At the beginning of the engagement, publishing an \"envisioned\" version of the Sequence Diagram will provide a common visual to all engineers when working on the different parts of the solution (focusing on the data flow and request flow) Throughout the engagement, update the published diagram periodically. Ideally whenever a new \"use case\" or \"scenario\" is identified, or when a Component is introduced or removed in the system, or when a change in data/request flow is made in the system Depending on the tool being used, automatic versioning might be performed whenever an update to the Diagram is performed. If not, it is recommended to capture distinct versions whenever there is a particular customer need to have a snapshot of the project at a particular point in time. The hard requirement is that the latest diagram should be published and everyone should know how to access it as the customer hand-off approaches.","title":"Versioning"},{"location":"design/diagram-types/DesignDiagramsTemplates/sequenceDiagrams/#resources","text":"Wikipedia Visual Paradigm VS Code Plugins: PlantUML - requires a generator from code to PlantUML syntax to generate diagrams PlantUML Syntax Drawing manually","title":"Resources"},{"location":"design/sustainability/readme/","text":"Sustainable Software Engineering The choices made throughout the engineering process regarding cloud services, software architecture design and automation can have a big impact on the carbon footprint of a solution. Some choices are always beneficial, like turning off unused resources. Other choices require a more nuanced understanding of the business case at hand and its potential carbon impact. Goal One goal of this section is to provide tangible guidance for what sustainable actions you can apply in certain situations and the tools to be able to implement those recommendations. Another goal is to highlight the many resources available to learn about the wider domain of sustainable software. Sustainable Engineering Checklist This checklist should be used to quickly identify scenarios for which common sustainable actions exist. Check the box if the scenario applies to your project, then go through the actions and tools you can use to build more sustainable software for those cases. If there are important nuances to consider, they will be linked in the Disclaimers section. For readability some considerations are blank, indicating that the action applies to the first consideration above it. \u2705 Consideration Action Principle Tools Disclaimers For any running software/services Shutdown unused resources. Electricity Consumption Identify Unassociated Resources Resize physical or virtual machines to improve utilization. Energy Proportionality Azure Advisor Cost Recommendations Understanding Advisor Recommendations For development and testing VMs Configure VMs to shutdown during off-hours Electricity Consumption Start/Stop VMs during off-hours For VMs with attached volumes Limit the amount of attached storage capacity to what you expect to use and expand as necessary Electricity Consumption Expanding storage of active VMs Understanding the energy cost of storage For systems using object storage (Azure Blob Storage, AWS S3, GCP Cloud Storage, etc) Compress infrequently accessed data Electricity Consumption , Embodied Carbon Compressing and extracting files in .NET Understanding the energy cost of storage Delete data when it is no longer needed Electricity Consumption Configuring a lifecycle management policy Understanding the energy cost of storage For systems running in on-premise data centers Migrate to hyperscale cloud provider Embodied Carbon , Electricity Consumption Cloud Adoption Approaches Carbon benefits of cloud computing For systems migrating to a hyperscale cloud provider Consider physically shipping data to the provider Networking Azure Data Box Understanding data shipping tradeoffs For time-flexible workloads Utilize \"Spot VMs\" for compute Demand Shaping How to use Spot VMs For services with varied utilization patterns Configure Autoscaling Energy Proportionality Autoscaling Documentation Use serverless functions Energy Proportionality Serverless Architecture Design For services with geographically co-located users (EG internal employee apps) Select a data center region that is physically close to them Networking Azure products available by region Consider running edge devices to reduce excessive data transfer Networking Azure Stack Edge Understanding edge tradeoffs For systems sending data over the network Use caching policies to keep data on the local machine Networking HTTP caching APIs , Cache Management in .NET Understanding caching tradeoffs Consider caching data close to end users with a CDN Networking Benefits of a CDN Understanding CDN tradeoffs Send only the data that will be used Networking Compress data to reduce the size Networking Compressing and extracting files in .NET When designing for the end user Consider giving users visibility and control over their energy usage Electricity Consumption Demand Shaping Designing for eco-mode Design and test your application to be compatible for a wide variety of devices, especially older devices Embodied Carbon Extending device lifespan Compatibility Testing When selecting a programming language Consider the energy efficiency of languages Electricity Consumption Reasoning about the energy consumption of programming languages , Programming Language Energy Efficiency (PDF) Making informed programming language choices Resources Principles of Green Software Engineering Green Software Foundation Microsoft Cloud for Sustainability Learning Module: Sustainable Software Engineering Tools Carbon-Aware SDK \"Awesome List\" of Green Software Emissions Impact Azure GreenAI Carbon-Intensity API Projects Sustainability through SpotVMs","title":"Sustainable Software Engineering"},{"location":"design/sustainability/readme/#sustainable-software-engineering","text":"The choices made throughout the engineering process regarding cloud services, software architecture design and automation can have a big impact on the carbon footprint of a solution. Some choices are always beneficial, like turning off unused resources. Other choices require a more nuanced understanding of the business case at hand and its potential carbon impact.","title":"Sustainable Software Engineering"},{"location":"design/sustainability/readme/#goal","text":"One goal of this section is to provide tangible guidance for what sustainable actions you can apply in certain situations and the tools to be able to implement those recommendations. Another goal is to highlight the many resources available to learn about the wider domain of sustainable software.","title":"Goal"},{"location":"design/sustainability/readme/#sustainable-engineering-checklist","text":"This checklist should be used to quickly identify scenarios for which common sustainable actions exist. Check the box if the scenario applies to your project, then go through the actions and tools you can use to build more sustainable software for those cases. If there are important nuances to consider, they will be linked in the Disclaimers section. For readability some considerations are blank, indicating that the action applies to the first consideration above it. \u2705 Consideration Action Principle Tools Disclaimers For any running software/services Shutdown unused resources. Electricity Consumption Identify Unassociated Resources Resize physical or virtual machines to improve utilization. Energy Proportionality Azure Advisor Cost Recommendations Understanding Advisor Recommendations For development and testing VMs Configure VMs to shutdown during off-hours Electricity Consumption Start/Stop VMs during off-hours For VMs with attached volumes Limit the amount of attached storage capacity to what you expect to use and expand as necessary Electricity Consumption Expanding storage of active VMs Understanding the energy cost of storage For systems using object storage (Azure Blob Storage, AWS S3, GCP Cloud Storage, etc) Compress infrequently accessed data Electricity Consumption , Embodied Carbon Compressing and extracting files in .NET Understanding the energy cost of storage Delete data when it is no longer needed Electricity Consumption Configuring a lifecycle management policy Understanding the energy cost of storage For systems running in on-premise data centers Migrate to hyperscale cloud provider Embodied Carbon , Electricity Consumption Cloud Adoption Approaches Carbon benefits of cloud computing For systems migrating to a hyperscale cloud provider Consider physically shipping data to the provider Networking Azure Data Box Understanding data shipping tradeoffs For time-flexible workloads Utilize \"Spot VMs\" for compute Demand Shaping How to use Spot VMs For services with varied utilization patterns Configure Autoscaling Energy Proportionality Autoscaling Documentation Use serverless functions Energy Proportionality Serverless Architecture Design For services with geographically co-located users (EG internal employee apps) Select a data center region that is physically close to them Networking Azure products available by region Consider running edge devices to reduce excessive data transfer Networking Azure Stack Edge Understanding edge tradeoffs For systems sending data over the network Use caching policies to keep data on the local machine Networking HTTP caching APIs , Cache Management in .NET Understanding caching tradeoffs Consider caching data close to end users with a CDN Networking Benefits of a CDN Understanding CDN tradeoffs Send only the data that will be used Networking Compress data to reduce the size Networking Compressing and extracting files in .NET When designing for the end user Consider giving users visibility and control over their energy usage Electricity Consumption Demand Shaping Designing for eco-mode Design and test your application to be compatible for a wide variety of devices, especially older devices Embodied Carbon Extending device lifespan Compatibility Testing When selecting a programming language Consider the energy efficiency of languages Electricity Consumption Reasoning about the energy consumption of programming languages , Programming Language Energy Efficiency (PDF) Making informed programming language choices","title":"Sustainable Engineering Checklist"},{"location":"design/sustainability/readme/#resources","text":"Principles of Green Software Engineering Green Software Foundation Microsoft Cloud for Sustainability Learning Module: Sustainable Software Engineering","title":"Resources"},{"location":"design/sustainability/readme/#tools","text":"Carbon-Aware SDK \"Awesome List\" of Green Software Emissions Impact Azure GreenAI Carbon-Intensity API","title":"Tools"},{"location":"design/sustainability/readme/#projects","text":"Sustainability through SpotVMs","title":"Projects"},{"location":"design/sustainability/sustainable-action-disclaimers/","text":"Disclaimers The following disclaimers provide more details about how to consider the impact of particular actions recommended by the Sustainable Engineering Checklist . ACTION: Resize physical or virtual machines to improve utilization Recommendations from cost-savings tools are usually aligned with carbon-reduction, but as sustainability is not the purpose of such tools, carbon-savings are not guaranteed. How a cloud provider or data center manages unused capacity is also a factor in determining how impactful this action may be. For example: The sustainable impact of using smaller VMs in the same family are typically beneficial or neutral. When cores are no longer reserved they can be used by others instead of bringing new servers online. The sustainable impact of changing VM families can be harder to reason about because the underlying hardware and reserved cores may be changing with them. ACTION: Migrate to a hyperscale cloud provider Carbon savings from hyperscale cloud providers are generally attributable to four key features: IT operational efficiency, IT equipment efficiency, data center infrastructure efficiency, and renewable electricity. Microsoft Cloud, for example, is between 22 and 93 percent more energy efficient than traditional enterprise data centers, depending on the specific comparison being made. When taking into account renewable energy purchases, the Microsoft Cloud is between 72 and 98 percent more carbon efficient. Source (PDF) ACTION: Consider running an edge device Running an edge device negates many of the benefits of hyperscale compute facilities, so considering the local energy grid mix and the typical timing of the workloads is important to determine if this is beneficial overall. The larger volume of data that needs to be transmitted, the more this solution becomes appealing. For example, sending large amounts of audio and video content for processing. ACTION: Consider physically shipping data to the provider Shipping physical items has its own carbon impact, depending on the mode of transportation, which needs to be understood before making this decision. The larger the volume of data that needs to be transmitted the more this options may be beneficial. ACTION: Consider the energy efficiency of languages When selecting a programming language, the most energy efficient programming language may not always be the best choice for development speed, maintenance, integration with dependent systems, and other project factors. But when deciding between languages that all meet the project needs, energy efficiency can be a helpful consideration. ACTION: Use caching policies A cache provides temporary storage of resources that have been requested by an application. Caching can improve application performance by reducing the time required to get a requested resource. Caching can also improve sustainability by decreasing the amount of network traffic. While caching provides these benefits, it also increases the risk that the resource returned to the application is stale, meaning that it is not identical to the resource that would have been sent by the server if caching were not in use. This can create poor user experiences when data accuracy is critical. Additionally, caching may allow unauthorized users or processes to read sensitive data. An authenticated response that is cached may be retrieved from the cache without an additional authorization. Due to security concerns like this, caching is not recommended for middle tier scenarios. ACTION: Consider caching data close to end users with a CDN Including CDNs in your network architecture adds many additional servers to your software footprint, each with their own local energy grid mix. The details of CDN hardware and the impact of the power that runs it is important to determine if the carbon emissions from running them is lower than the emissions from sending the data over the wire from a more distant source. The larger the volume of data, distance it needs to travel, and frequency of requests, the more this solution becomes appealing.","title":"Disclaimers"},{"location":"design/sustainability/sustainable-action-disclaimers/#disclaimers","text":"The following disclaimers provide more details about how to consider the impact of particular actions recommended by the Sustainable Engineering Checklist .","title":"Disclaimers"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-resize-physical-or-virtual-machines-to-improve-utilization","text":"Recommendations from cost-savings tools are usually aligned with carbon-reduction, but as sustainability is not the purpose of such tools, carbon-savings are not guaranteed. How a cloud provider or data center manages unused capacity is also a factor in determining how impactful this action may be. For example: The sustainable impact of using smaller VMs in the same family are typically beneficial or neutral. When cores are no longer reserved they can be used by others instead of bringing new servers online. The sustainable impact of changing VM families can be harder to reason about because the underlying hardware and reserved cores may be changing with them.","title":"ACTION: Resize physical or virtual machines to improve utilization"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-migrate-to-a-hyperscale-cloud-provider","text":"Carbon savings from hyperscale cloud providers are generally attributable to four key features: IT operational efficiency, IT equipment efficiency, data center infrastructure efficiency, and renewable electricity. Microsoft Cloud, for example, is between 22 and 93 percent more energy efficient than traditional enterprise data centers, depending on the specific comparison being made. When taking into account renewable energy purchases, the Microsoft Cloud is between 72 and 98 percent more carbon efficient. Source (PDF)","title":"ACTION: Migrate to a hyperscale cloud provider"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-consider-running-an-edge-device","text":"Running an edge device negates many of the benefits of hyperscale compute facilities, so considering the local energy grid mix and the typical timing of the workloads is important to determine if this is beneficial overall. The larger volume of data that needs to be transmitted, the more this solution becomes appealing. For example, sending large amounts of audio and video content for processing.","title":"ACTION: Consider running an edge device"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-consider-physically-shipping-data-to-the-provider","text":"Shipping physical items has its own carbon impact, depending on the mode of transportation, which needs to be understood before making this decision. The larger the volume of data that needs to be transmitted the more this options may be beneficial.","title":"ACTION: Consider physically shipping data to the provider"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-consider-the-energy-efficiency-of-languages","text":"When selecting a programming language, the most energy efficient programming language may not always be the best choice for development speed, maintenance, integration with dependent systems, and other project factors. But when deciding between languages that all meet the project needs, energy efficiency can be a helpful consideration.","title":"ACTION: Consider the energy efficiency of languages"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-use-caching-policies","text":"A cache provides temporary storage of resources that have been requested by an application. Caching can improve application performance by reducing the time required to get a requested resource. Caching can also improve sustainability by decreasing the amount of network traffic. While caching provides these benefits, it also increases the risk that the resource returned to the application is stale, meaning that it is not identical to the resource that would have been sent by the server if caching were not in use. This can create poor user experiences when data accuracy is critical. Additionally, caching may allow unauthorized users or processes to read sensitive data. An authenticated response that is cached may be retrieved from the cache without an additional authorization. Due to security concerns like this, caching is not recommended for middle tier scenarios.","title":"ACTION: Use caching policies"},{"location":"design/sustainability/sustainable-action-disclaimers/#action-consider-caching-data-close-to-end-users-with-a-cdn","text":"Including CDNs in your network architecture adds many additional servers to your software footprint, each with their own local energy grid mix. The details of CDN hardware and the impact of the power that runs it is important to determine if the carbon emissions from running them is lower than the emissions from sending the data over the wire from a more distant source. The larger the volume of data, distance it needs to travel, and frequency of requests, the more this solution becomes appealing.","title":"ACTION: Consider caching data close to end users with a CDN"},{"location":"design/sustainability/sustainable-engineering-principles/","text":"Sustainable Principles The following principle overviews provide the foundations supporting specific actions in the Sustainable Engineering Checklist . More details about each principle can be found by following the links in the headings or visiting the Principles of Green Software Engineering website . Electricity Consumption Most electricity is still produced through the burning of fossil fuels and is responsible for 49% of the carbon emitted into the atmosphere. Software consumes electricity in its execution. Running hardware consumes electricity even at zero percent utilization. Some of the best ways we can reduce electricity consumption and the subsequent emissions of carbon pollution is to make our applications more energy efficient when they are running and limit idle hardware. Energy Proportionality The relationship between power and utilization is not proportional. The more you utilize a computer, the more efficient it becomes at converting electricity to useful computing operations. Running your work on as few servers as possible with the highest utilization rate maximizes their energy efficiency. An idle computer, even running at zero percent utilization, still draws electricity. Embodied Carbon Embodied carbon (otherwise referred to as \"Embedded Carbon\") is the amount of carbon pollution emitted during the creation and disposal of a device. When calculating the total carbon pollution for the computers running your software, account for both the carbon pollution to run the computer and the embodied carbon of the computer. Therefore a great way to reduce embodied carbon is to prevent the need for new devices to be manufactured by extending the usefulness of existing ones. Demand Shaping Demand shaping is a strategy of shaping our demand for resources so it matches the existing supply. If supply is high, increase the demand by doing more in your applications. If the supply is low, decrease demand. This means doing less in your applications or delaying work until supply is higher. Networking A network is a series of switches, routers, and servers. All the computers and network equipment in a network consume electricity and have embedded carbon . The internet is a global network of devices typically run off the standard local grid energy mix. When you send data across the internet, you are sending that data through many devices in the network, each one of those devices consuming electricity. As a result, any data you send or receive over the internet emits carbon. The amount of carbon emitted to send data depends on many factors including: Distance the data travels Number of hops between network devices Energy efficiency of the network devices Carbon intensity of energy used by each device at the time the data is transmitted. Network protocol used to coordinate data transmission - e.g. multiplex, header compression, TLS/Quic Recent networking studies - Cloud Carbon Footprint","title":"Sustainable Principles"},{"location":"design/sustainability/sustainable-engineering-principles/#sustainable-principles","text":"The following principle overviews provide the foundations supporting specific actions in the Sustainable Engineering Checklist . More details about each principle can be found by following the links in the headings or visiting the Principles of Green Software Engineering website .","title":"Sustainable Principles"},{"location":"design/sustainability/sustainable-engineering-principles/#electricity-consumption","text":"Most electricity is still produced through the burning of fossil fuels and is responsible for 49% of the carbon emitted into the atmosphere. Software consumes electricity in its execution. Running hardware consumes electricity even at zero percent utilization. Some of the best ways we can reduce electricity consumption and the subsequent emissions of carbon pollution is to make our applications more energy efficient when they are running and limit idle hardware.","title":"Electricity Consumption"},{"location":"design/sustainability/sustainable-engineering-principles/#energy-proportionality","text":"The relationship between power and utilization is not proportional. The more you utilize a computer, the more efficient it becomes at converting electricity to useful computing operations. Running your work on as few servers as possible with the highest utilization rate maximizes their energy efficiency. An idle computer, even running at zero percent utilization, still draws electricity.","title":"Energy Proportionality"},{"location":"design/sustainability/sustainable-engineering-principles/#embodied-carbon","text":"Embodied carbon (otherwise referred to as \"Embedded Carbon\") is the amount of carbon pollution emitted during the creation and disposal of a device. When calculating the total carbon pollution for the computers running your software, account for both the carbon pollution to run the computer and the embodied carbon of the computer. Therefore a great way to reduce embodied carbon is to prevent the need for new devices to be manufactured by extending the usefulness of existing ones.","title":"Embodied Carbon"},{"location":"design/sustainability/sustainable-engineering-principles/#demand-shaping","text":"Demand shaping is a strategy of shaping our demand for resources so it matches the existing supply. If supply is high, increase the demand by doing more in your applications. If the supply is low, decrease demand. This means doing less in your applications or delaying work until supply is higher.","title":"Demand Shaping"},{"location":"design/sustainability/sustainable-engineering-principles/#networking","text":"A network is a series of switches, routers, and servers. All the computers and network equipment in a network consume electricity and have embedded carbon . The internet is a global network of devices typically run off the standard local grid energy mix. When you send data across the internet, you are sending that data through many devices in the network, each one of those devices consuming electricity. As a result, any data you send or receive over the internet emits carbon. The amount of carbon emitted to send data depends on many factors including: Distance the data travels Number of hops between network devices Energy efficiency of the network devices Carbon intensity of energy used by each device at the time the data is transmitted. Network protocol used to coordinate data transmission - e.g. multiplex, header compression, TLS/Quic Recent networking studies - Cloud Carbon Footprint","title":"Networking"},{"location":"developer-experience/","text":"Developer Experience (DevEx) Developer experience refers to how easy or difficult it is for a developer to perform essential tasks needed to implement a change. A positive developer experience would mean these tasks are relatively easy for the team (see measures below). The essential tasks are identified below. Build - Verify that changes are free of syntax error and compile. Test - Verify that all automated tests pass. Start - Launch end-to-end to simulate execution in a deployed environment. Debug - Attach debugger to started solution, set breakpoints, step through code, and inspect variables. If effort is invested to make these activities as easy as possible, the returns on that effort will increase the longer the project runs, and the larger the team is . Defining End-to-End This document makes several references to running a solution end-to-end (aka E2E). End-to-end for the purposes of this document is scoped to the software that is owned, built, and shipped by the team. Systems owned by other teams or third-party vendors is not within the E2E scope for the purposes of this document. Goals Maximize the amount of time engineers spend on writing code that fulfills story acceptance and done-done criteria. Minimize the amount of time spent manual setup and configuration of tooling Minimize regressions and new defects by making end-to-end testing easy Impact Developer experience can have a significant impact on the efficiency of the day-to-day execution of the team. A positive experience can pay dividends throughout the lifetime of the project; especially as new developers join the team. Increased Velocity - Team spends less time on non-value-add activities such as dev/local environment setup, waiting on remote environments to test, and rework (fixing defects). Improved Quality - When it's easy to debug and test, developers will do more of it. This will translate to fewer defects being introduced. Easier Onboarding & Adoption - When dev essential tasks are automated, there is less documentation to write and, subsequently, less to read to get started! Most importantly, the customer will continue to accrue these benefits long after the code-with engagement. Measures Time to First E2E Result (aka F5 Contract) Assuming a laptop/pc that has never run the solution, how long does it take to set up and run the whole system end-to-end and see a result. Time To First Commit How long does it take to make a change that can be verified/tested locally. A locally verified/tested change is one that passes test cases without introducing regression or breaking changes. Participation Providing a positive developer experience is a team effort. However, certain members can take ownership of different areas to help hold the entire team accountable. Dev Lead - Set the bar The following are examples of how the Dev Lead might set the bar for dev experience Determines development environment (suggested IDE, hosting, etc) Determines source control environment and number of repos required Given development environment and repo structure, sets expectations for team to meet in terms of steps to perform the essential dev tasks Nominates the DevEx Champion IDE choice is NOT intended to mandate that all team members must use the same IDE. However, this choice will direct where tight-integration investment will be prioritized. For example, if Visual Studio Code is the suggested IDE then, the team would focus on integrating VS code tasks and launch configurations over similar integrations for other IDEs. Team members should still feel free to use their preferred IDE as long as it does not negatively impact the team. DevEx Champion - Identify Iterative Improvements The DevEx champion takes ownership in holding the team accountable for providing a positive developer experience. The following outline responsibilities for the DevEx champion. Actively seek opportunities for improving the solution developer experience Work with the Dev Lead to iteratively improve team expectations for developer experience Curate a backlog actionable stories that identify areas for improvement and prioritize with respect to project delivery goals by engaging directly with the Product Owner and Customer. Serve as subject-matter expert for the rest of the team. Help the team determine how to implement DevEx expectations and identify deviations. Team Members - Assert Expectations The team members of the team can also help hold each other accountable for providing a positive developer experience. The following are examples of areas team members can help identify where the team's DevEx expectations are not being met. Pull requests. Try the changes locally to see if they are adhering to the team's DevEx expectations. Design Reviews. Look for proposals that may negatively affect the solution's DevEx. These might include Introduction of new tech whose testability is limited to manual steps in a deployed environment. Addition of new repository New Team Members - Identify Iterative Improvements New team members are uniquely positioned to identify instances of undocumented Collective Wisdom . The following outlines responsibilities of new team members as it relates to DevEx: If you come across missing, incomplete or incorrect documentation while onboarding, you should record the issue as a new defect(s) and assign it to the product owner to triage. If no onboarding documentation exists, note the steps you took in a new user story. Assign the new story to the product owner to triage. Facilitation Guidance The following outline examples of several strategies that can be adopted to promote a positive developer experience. It is expected that each team should define what a positive dev experience means within the context of their project. Additionally, refine that over time via feedback mechanisms such as sprint and project retrospectives. Establish Hotkeys Assign hotkeys to each of the essential tasks. Task Windows Build CTRL+SHIFT+B Test CTRL+R,T Start With Debugging F5 The F5 Contract The F5 contract aims for the ability to run the end-to-end solution with the following steps. Clone - git clone [ my-repo-url-here ] Configure - set any configuration values that need to be unique to the individual (i.e. update a .env file) Press F5 - launch the solution with debugging attached. Most IDEs have some form of a task runner that can be used to automate the build, execute, and attach steps. Try to leverage these such that the steps can all be run with as few manual steps as possible. DevEx Champion Actively Seek Improvements The DevEx champion should actively seek areas where the team has opportunity to improve. For example, do they need to deploy their changes to an environment off their laptop before they can validate if what they did worked. Rather than debugging locally, do they have to do this repetitively to get to a working solution? Does this take several minutes each iteration? Does this block other developers due to the contention on the environment? The following are ceremonies that the DevEx champion can use to find potential opportunities Retrospectives. Is feedback being raised that relates to the essential tasks being difficult or unwieldy? Standup Blockers. Are individuals getting blocked or stumbling on the essential tasks? As opportunities are identified, the DevEx champion can translate these into actionable stories for the product backlog. Make Tasks Cross Platform For essential tasks being standardized during the engagement, ensure that different platforms are accounted for. Team members may have different operating systems and ensuring the tasks are cross-platform will provide an additional opportunity to improve the experience. See the making tasks cross platform recipe for guidance on how tasks can be configured to include different platforms. Create an Onboarding Guide When welcoming new team members to the engagement, there are many areas for them to get adjusted to and bring them up to speed including codebase, coding standards, team agreements, and team culture. By adopting a strong onboarding practice such as an onboarding guide in a centralized location that explains the scope of the project, processes, setup details, and software required, new members can have all the necessary resources for them to be efficient, successful and a valuable team member from the start. See the onboarding guide recipe for guidance on what an onboarding guide may look like. Standardize Essential Tasks Apply a common strategy across solution components for performing the essential tasks Standardize the configuration for solution components Standardize the way tests are run for each component Standardize the way each component is started and stopped locally Standardize how to document the essential tasks for each component This standardization will enable the team to more easily automate these tasks across all components at the solution level. See Solution-level Essential Tasks below. Solution-level Essential Tasks Automate the ability to execute each essential task across all solution components. An example would be mapping the build action in the IDE to run the build task for each component in the solution. More importantly, configure the IDE start action to start all components within the solution. This will provide significant efficiency for the engineering team when dealing with multi-component solutions. When this is not implemented, the engineers must repeat each of the essential tasks manually for each component in the solution. In this situation, the number of steps required to perform each essential task is multiplied by the number of components in the system [Configuration steps + Build steps + Start/Debug steps + Stop steps + Run test steps + Documenting all of the above] * [many solution components] = TOO MANY STEPS VS. [Configuration steps + Build steps + Start/Debug steps + Stop steps + Run test steps + Documenting all of the above] * [1 solution] = MINIMUM NUMBER OF STEPS Observability Observability alleviates unforeseen challenges for the developer in a complex distributed system. It identifies project bottlenecks quicker and with more precision, enhancing performance as the developer seeks to deploy code changes. Adding observability improves the experience when identifying and resolving bugs or broken code. This results in fewer or less severe current and future production failures. There are many observability strategies a developer can use alongside best engineering practices. These resources improve the DevEx by ensuring a shared view of the complex system throughout the entire lifecycle. Observability in code via logging, exception handling and exposing of relevant application metrics for example, promotes the consistent visibility of real time performance. The observability pillars, logging , metrics , and tracing , detail when to enable each of the three specific types of observability. Minimize the Number of Repositories Splitting a solution across multiple repositories can negatively impact the above measures. This can also negatively impact other areas such as Pull Requests, Automated Testing, Continuous Integration, and Continuous Delivery. Similar to the IDE instances, the negative impact is multiplied by the number of repositories. [Clone steps + Branching steps + Commit steps + CI steps + Pull Request reviews & merges ] * [many source code repositories] = TOO MANY STEPS VS. [Clone steps + Branching steps + Commit steps + CI steps + Pull Request reviews & merges ] * [1 source code repository] = MINIMUM NUMBER OF STEPS Atomic Pull Requests When the solution is encapsulated within a single repository, it also allows pull requests to represent a change across multiple layers. This is especially helpful when a change requires changes to a shared contract between multiple components. For example, a story requires that an api endpoint is changed. With this strategy the api and web client could be updated with the same pull request. This avoids the main branch being broken temporarily while waiting on dependent pull requests to merge. Minimize Remote Dependencies for Local Development The fewer dependencies on components that cannot run a developer's machine translate to fewer steps required to get started. Therefore, fewer dependencies will positively impact the measures above. The following strategies can be used to reduce these dependencies Use an Emulator If available, emulators are implementations of technologies that are typically only available in cloud environments. A good example is the CosmosDB emulator . Use DI + Toggle to Mock Remote Dependencies When the solution depends on a technology that cannot be run on a developer's machine, the setup and testing of that solution can be challenging. One strategy that can be employed is to create the ability to swap that dependency for one that can run locally. Abstract the layer that has the remote dependency behind an interface owned by the solution (not the remote dependency). Create an implementation of that interface using a technology that can be run locally. Create a factory that decides which instance to use. This decision could be based on environment configuration (i.e. the toggle). Then, the original class that depends on the remote tech instead should depend on the factory to provide which instance to use. Much of this strategy can be simplified with proper dependency injection technique and/or framework. See example below that swaps Azure Service Bus implementation for RabbitMQ which can be run locally. interface IPublisher { send ( message : string ) : void } class RabbitMQPublisher implements IPublisher { send ( message : string ) { //todo: send the message via RabbitMQ } } class AzureServiceBusPublisher implements IPublisher { send ( message : string ) { //todo: send the message via Azure Service Bus } } interface IPublisherFactory { create () : IPublisher } class PublisherFactory { create () : IPublisher { // use env var value to determine which instance should be used if ( process . env . UseAsb ){ return new AzureServiceBusPublisher (); } else { return new RabbitMqPublisher (); } } } class MyService { //inject the factory constructor ( private readonly publisherFactory : IPublisherFactory ){ } sendAMessage ( message : string ) : void { //use the factory to determine which instance to use const publisher : IPublisher = this . publisherFactory . create (); publisher . send ( message ); } } The recipes section has a more complete discussion on DI as part of a high productivity inner dev loop","title":"Developer Experience (DevEx)"},{"location":"developer-experience/#developer-experience-devex","text":"Developer experience refers to how easy or difficult it is for a developer to perform essential tasks needed to implement a change. A positive developer experience would mean these tasks are relatively easy for the team (see measures below). The essential tasks are identified below. Build - Verify that changes are free of syntax error and compile. Test - Verify that all automated tests pass. Start - Launch end-to-end to simulate execution in a deployed environment. Debug - Attach debugger to started solution, set breakpoints, step through code, and inspect variables. If effort is invested to make these activities as easy as possible, the returns on that effort will increase the longer the project runs, and the larger the team is .","title":"Developer Experience (DevEx)"},{"location":"developer-experience/#defining-end-to-end","text":"This document makes several references to running a solution end-to-end (aka E2E). End-to-end for the purposes of this document is scoped to the software that is owned, built, and shipped by the team. Systems owned by other teams or third-party vendors is not within the E2E scope for the purposes of this document.","title":"Defining End-to-End"},{"location":"developer-experience/#goals","text":"Maximize the amount of time engineers spend on writing code that fulfills story acceptance and done-done criteria. Minimize the amount of time spent manual setup and configuration of tooling Minimize regressions and new defects by making end-to-end testing easy","title":"Goals"},{"location":"developer-experience/#impact","text":"Developer experience can have a significant impact on the efficiency of the day-to-day execution of the team. A positive experience can pay dividends throughout the lifetime of the project; especially as new developers join the team. Increased Velocity - Team spends less time on non-value-add activities such as dev/local environment setup, waiting on remote environments to test, and rework (fixing defects). Improved Quality - When it's easy to debug and test, developers will do more of it. This will translate to fewer defects being introduced. Easier Onboarding & Adoption - When dev essential tasks are automated, there is less documentation to write and, subsequently, less to read to get started! Most importantly, the customer will continue to accrue these benefits long after the code-with engagement.","title":"Impact"},{"location":"developer-experience/#measures","text":"","title":"Measures"},{"location":"developer-experience/#time-to-first-e2e-result-aka-f5-contract","text":"Assuming a laptop/pc that has never run the solution, how long does it take to set up and run the whole system end-to-end and see a result.","title":"Time to First E2E Result (aka F5 Contract)"},{"location":"developer-experience/#time-to-first-commit","text":"How long does it take to make a change that can be verified/tested locally. A locally verified/tested change is one that passes test cases without introducing regression or breaking changes.","title":"Time To First Commit"},{"location":"developer-experience/#participation","text":"Providing a positive developer experience is a team effort. However, certain members can take ownership of different areas to help hold the entire team accountable.","title":"Participation"},{"location":"developer-experience/#dev-lead-set-the-bar","text":"The following are examples of how the Dev Lead might set the bar for dev experience Determines development environment (suggested IDE, hosting, etc) Determines source control environment and number of repos required Given development environment and repo structure, sets expectations for team to meet in terms of steps to perform the essential dev tasks Nominates the DevEx Champion IDE choice is NOT intended to mandate that all team members must use the same IDE. However, this choice will direct where tight-integration investment will be prioritized. For example, if Visual Studio Code is the suggested IDE then, the team would focus on integrating VS code tasks and launch configurations over similar integrations for other IDEs. Team members should still feel free to use their preferred IDE as long as it does not negatively impact the team.","title":"Dev Lead - Set the bar"},{"location":"developer-experience/#devex-champion-identify-iterative-improvements","text":"The DevEx champion takes ownership in holding the team accountable for providing a positive developer experience. The following outline responsibilities for the DevEx champion. Actively seek opportunities for improving the solution developer experience Work with the Dev Lead to iteratively improve team expectations for developer experience Curate a backlog actionable stories that identify areas for improvement and prioritize with respect to project delivery goals by engaging directly with the Product Owner and Customer. Serve as subject-matter expert for the rest of the team. Help the team determine how to implement DevEx expectations and identify deviations.","title":"DevEx Champion - Identify Iterative Improvements"},{"location":"developer-experience/#team-members-assert-expectations","text":"The team members of the team can also help hold each other accountable for providing a positive developer experience. The following are examples of areas team members can help identify where the team's DevEx expectations are not being met. Pull requests. Try the changes locally to see if they are adhering to the team's DevEx expectations. Design Reviews. Look for proposals that may negatively affect the solution's DevEx. These might include Introduction of new tech whose testability is limited to manual steps in a deployed environment. Addition of new repository","title":"Team Members - Assert Expectations"},{"location":"developer-experience/#new-team-members-identify-iterative-improvements","text":"New team members are uniquely positioned to identify instances of undocumented Collective Wisdom . The following outlines responsibilities of new team members as it relates to DevEx: If you come across missing, incomplete or incorrect documentation while onboarding, you should record the issue as a new defect(s) and assign it to the product owner to triage. If no onboarding documentation exists, note the steps you took in a new user story. Assign the new story to the product owner to triage.","title":"New Team Members - Identify Iterative Improvements"},{"location":"developer-experience/#facilitation-guidance","text":"The following outline examples of several strategies that can be adopted to promote a positive developer experience. It is expected that each team should define what a positive dev experience means within the context of their project. Additionally, refine that over time via feedback mechanisms such as sprint and project retrospectives.","title":"Facilitation Guidance"},{"location":"developer-experience/#establish-hotkeys","text":"Assign hotkeys to each of the essential tasks. Task Windows Build CTRL+SHIFT+B Test CTRL+R,T Start With Debugging F5","title":"Establish Hotkeys"},{"location":"developer-experience/#the-f5-contract","text":"The F5 contract aims for the ability to run the end-to-end solution with the following steps. Clone - git clone [ my-repo-url-here ] Configure - set any configuration values that need to be unique to the individual (i.e. update a .env file) Press F5 - launch the solution with debugging attached. Most IDEs have some form of a task runner that can be used to automate the build, execute, and attach steps. Try to leverage these such that the steps can all be run with as few manual steps as possible.","title":"The F5 Contract"},{"location":"developer-experience/#devex-champion-actively-seek-improvements","text":"The DevEx champion should actively seek areas where the team has opportunity to improve. For example, do they need to deploy their changes to an environment off their laptop before they can validate if what they did worked. Rather than debugging locally, do they have to do this repetitively to get to a working solution? Does this take several minutes each iteration? Does this block other developers due to the contention on the environment? The following are ceremonies that the DevEx champion can use to find potential opportunities Retrospectives. Is feedback being raised that relates to the essential tasks being difficult or unwieldy? Standup Blockers. Are individuals getting blocked or stumbling on the essential tasks? As opportunities are identified, the DevEx champion can translate these into actionable stories for the product backlog.","title":"DevEx Champion Actively Seek Improvements"},{"location":"developer-experience/#make-tasks-cross-platform","text":"For essential tasks being standardized during the engagement, ensure that different platforms are accounted for. Team members may have different operating systems and ensuring the tasks are cross-platform will provide an additional opportunity to improve the experience. See the making tasks cross platform recipe for guidance on how tasks can be configured to include different platforms.","title":"Make Tasks Cross Platform"},{"location":"developer-experience/#create-an-onboarding-guide","text":"When welcoming new team members to the engagement, there are many areas for them to get adjusted to and bring them up to speed including codebase, coding standards, team agreements, and team culture. By adopting a strong onboarding practice such as an onboarding guide in a centralized location that explains the scope of the project, processes, setup details, and software required, new members can have all the necessary resources for them to be efficient, successful and a valuable team member from the start. See the onboarding guide recipe for guidance on what an onboarding guide may look like.","title":"Create an Onboarding Guide"},{"location":"developer-experience/#standardize-essential-tasks","text":"Apply a common strategy across solution components for performing the essential tasks Standardize the configuration for solution components Standardize the way tests are run for each component Standardize the way each component is started and stopped locally Standardize how to document the essential tasks for each component This standardization will enable the team to more easily automate these tasks across all components at the solution level. See Solution-level Essential Tasks below.","title":"Standardize Essential Tasks"},{"location":"developer-experience/#solution-level-essential-tasks","text":"Automate the ability to execute each essential task across all solution components. An example would be mapping the build action in the IDE to run the build task for each component in the solution. More importantly, configure the IDE start action to start all components within the solution. This will provide significant efficiency for the engineering team when dealing with multi-component solutions. When this is not implemented, the engineers must repeat each of the essential tasks manually for each component in the solution. In this situation, the number of steps required to perform each essential task is multiplied by the number of components in the system [Configuration steps + Build steps + Start/Debug steps + Stop steps + Run test steps + Documenting all of the above] * [many solution components] = TOO MANY STEPS VS. [Configuration steps + Build steps + Start/Debug steps + Stop steps + Run test steps + Documenting all of the above] * [1 solution] = MINIMUM NUMBER OF STEPS","title":"Solution-level Essential Tasks"},{"location":"developer-experience/#observability","text":"Observability alleviates unforeseen challenges for the developer in a complex distributed system. It identifies project bottlenecks quicker and with more precision, enhancing performance as the developer seeks to deploy code changes. Adding observability improves the experience when identifying and resolving bugs or broken code. This results in fewer or less severe current and future production failures. There are many observability strategies a developer can use alongside best engineering practices. These resources improve the DevEx by ensuring a shared view of the complex system throughout the entire lifecycle. Observability in code via logging, exception handling and exposing of relevant application metrics for example, promotes the consistent visibility of real time performance. The observability pillars, logging , metrics , and tracing , detail when to enable each of the three specific types of observability.","title":"Observability"},{"location":"developer-experience/#minimize-the-number-of-repositories","text":"Splitting a solution across multiple repositories can negatively impact the above measures. This can also negatively impact other areas such as Pull Requests, Automated Testing, Continuous Integration, and Continuous Delivery. Similar to the IDE instances, the negative impact is multiplied by the number of repositories. [Clone steps + Branching steps + Commit steps + CI steps + Pull Request reviews & merges ] * [many source code repositories] = TOO MANY STEPS VS. [Clone steps + Branching steps + Commit steps + CI steps + Pull Request reviews & merges ] * [1 source code repository] = MINIMUM NUMBER OF STEPS","title":"Minimize the Number of Repositories"},{"location":"developer-experience/#atomic-pull-requests","text":"When the solution is encapsulated within a single repository, it also allows pull requests to represent a change across multiple layers. This is especially helpful when a change requires changes to a shared contract between multiple components. For example, a story requires that an api endpoint is changed. With this strategy the api and web client could be updated with the same pull request. This avoids the main branch being broken temporarily while waiting on dependent pull requests to merge.","title":"Atomic Pull Requests"},{"location":"developer-experience/#minimize-remote-dependencies-for-local-development","text":"The fewer dependencies on components that cannot run a developer's machine translate to fewer steps required to get started. Therefore, fewer dependencies will positively impact the measures above. The following strategies can be used to reduce these dependencies","title":"Minimize Remote Dependencies for Local Development"},{"location":"developer-experience/#use-an-emulator","text":"If available, emulators are implementations of technologies that are typically only available in cloud environments. A good example is the CosmosDB emulator .","title":"Use an Emulator"},{"location":"developer-experience/#use-di-toggle-to-mock-remote-dependencies","text":"When the solution depends on a technology that cannot be run on a developer's machine, the setup and testing of that solution can be challenging. One strategy that can be employed is to create the ability to swap that dependency for one that can run locally. Abstract the layer that has the remote dependency behind an interface owned by the solution (not the remote dependency). Create an implementation of that interface using a technology that can be run locally. Create a factory that decides which instance to use. This decision could be based on environment configuration (i.e. the toggle). Then, the original class that depends on the remote tech instead should depend on the factory to provide which instance to use. Much of this strategy can be simplified with proper dependency injection technique and/or framework. See example below that swaps Azure Service Bus implementation for RabbitMQ which can be run locally. interface IPublisher { send ( message : string ) : void } class RabbitMQPublisher implements IPublisher { send ( message : string ) { //todo: send the message via RabbitMQ } } class AzureServiceBusPublisher implements IPublisher { send ( message : string ) { //todo: send the message via Azure Service Bus } } interface IPublisherFactory { create () : IPublisher } class PublisherFactory { create () : IPublisher { // use env var value to determine which instance should be used if ( process . env . UseAsb ){ return new AzureServiceBusPublisher (); } else { return new RabbitMqPublisher (); } } } class MyService { //inject the factory constructor ( private readonly publisherFactory : IPublisherFactory ){ } sendAMessage ( message : string ) : void { //use the factory to determine which instance to use const publisher : IPublisher = this . publisherFactory . create (); publisher . send ( message ); } } The recipes section has a more complete discussion on DI as part of a high productivity inner dev loop","title":"Use DI + Toggle to Mock Remote Dependencies"},{"location":"developer-experience/client-app-inner-loop/","text":"Separating client apps from the services they consume during development Client Apps typically rely on remote services to power their apps. However, development schedules between the client app and the services don't always fully align. For a high velocity inner dev loop, client app development must be decoupled from the backend services while still allowing the app to \"invoke\" the services for local testing. Options Several options exist to decouple client app development from the backend services. The options range from embedding mock implementation of the services into the application, others rely on simplified versions of the services. This document lists several options and discusses trade-offs. Embedded Mocks An embedded mock solution includes classes that implement the service interfaces locally. Interfaces and data classes, also called models or data transfer objects or DTOs, are often generated from the services' API specs using tools like nswag ( RicoSuter/NSwag: The Swagger/OpenAPI toolchain for .NET, ASP.NET Core and TypeScript. (github.com) ) or autorest ( Azure/autorest: OpenAPI (f.k.a Swagger) Specification code generator. Supports C#, PowerShell, Go, Java, Node.js, TypeScript, Python, Ruby (github.com) ). A simple service implementation can return a static response. For RESTful services, the JSON responses for the stubs can be stored as application resources or simply as static strings. public Task < UserProfile > GetUserAsync ( long userId , CancellationToken cancellationToken ) { PetProfile result = Newtonsoft . Json . JsonConvert . DeserializeObject < UserProfile > ( MockUserProfile . UserProfile , new Newtonsoft . Json . JsonSerializerSettings ()); return Task . FromResult ( result ); } More sophisticated can randomly return errors to test the app's resiliency code paths. Mocks can be activated via conditional compilation or dynamically via app configuration. In either case, it is recommended to ensure that mocks, service responses and externalized configurations are not included in the final release to avoid confusing behavior and inclusion of potential vulnerabilities. Sample: Registering Mocks via Dependency Injection Dependency Injection Containers like Unity ( Unity Container Introduction | Unity Container ) make it easy to switch between mock services and real service client implementations. Since both implement the same interface, implementations can be registered with the Unity container. public static void Bootstrap ( IUnityContainer container ) { #if DEBUG container . RegisterSingleton < IUserServiceClient , MockUserService > (); #else container . RegisterSingleton < IUserServiceClient , UserServiceClient > (); #endif } Consuming mocks via Dependency Injection The code consuming the interfaces will not notice the difference. public class UserPageModel { private readonly IUserServiceClient userServiceClient ; public UserPageModel ( IUserServiceClient userServiceClient ) { this . userServiceClient = userServiceClient ; } // ... } Local Services The approach with Locally Running Services is to replace the call in the client from pointing to the actual endpoint (whether dev, QA, prod, etc.) to a local endpoint. This approach also enables injecting traffic capture and shaping proxies like Postman ( Postman API Platform | Sign Up for Free ) or Fiddler ( Fiddler | Web Debugging Proxy and Troubleshooting Solutions (telerik.com) ). The advantage of this approach is that the APIs are decoupled from the client and can be independently updated/modified (e.g. changing response codes, changing data) without requiring changes to the client. This helps to unlock new development scenarios and provides flexibility during the development phase. The challenge with this approach is that it does require setup, configuration, and running of the services locally. There are tools that help to simplify that process (e.g. JsonServer , Postman Mock Server ). High-Fidelity Local Services A local service stub implements the expected APIs. Just like the embedded mock, it can be generated based on existing API contracts (e.g. OpenAPI). A high-fidelity approach packages the real services together with simplified data in docker containers that can be run locally using docker-compose before the client app is started for local debugging and testing. To enable running services fully local the \"local version\" substitutes dependent cloud services with local alternatives, e.g. file storage instead of blobs, locally running SQL Server instead of SQL AzureDB. This approach also enables full fidelity integration testing without spinning up distributed deployments. Stub / Fake Services Lower fidelity approaches run stub services, that could be generated from API specs, or run fake servers like JsonServer ( JsonServer.io: A fake json server API Service for prototyping and testing. ) or Postman. All these services would respond with predetermined and configured JSON messages. How to decide Pros Cons Example when developing for: Example When not to Use Embedded Mocks Simplifies the F5 developer experience Tightly coupled with Client More static type data scenarios Testing (e.g. unit tests, integration tests) No external dependencies to manage Hard coded data Initial integration with services Mocking via Dependency Injection can be a non-trivial effort High-Fidelity Local Services Loosely Coupled from Client Extra tooling required i.e. local infrastructure overhead URL Routes When API contract are not available Easier to independently modify response Extra setup and configuration of services Independent updates to services Can utilize HTTP traffic Easier to replace with real services at a later time Stub/Fake Services Loosely coupled from client Extra tooling required i.e. local infrastructure overhead Response Codes When API Contracts available Easier to independently modify response Extra setup and configuration of services Complex/variable data scenarios When API Contracts are note available Independent updates to services Might not provide full fidelity of expected API Can utilize HTTP traffic Easier to replace with real services at a later time","title":"Separating client apps from the services they consume during development"},{"location":"developer-experience/client-app-inner-loop/#separating-client-apps-from-the-services-they-consume-during-development","text":"Client Apps typically rely on remote services to power their apps. However, development schedules between the client app and the services don't always fully align. For a high velocity inner dev loop, client app development must be decoupled from the backend services while still allowing the app to \"invoke\" the services for local testing.","title":"Separating client apps from the services they consume during development"},{"location":"developer-experience/client-app-inner-loop/#options","text":"Several options exist to decouple client app development from the backend services. The options range from embedding mock implementation of the services into the application, others rely on simplified versions of the services. This document lists several options and discusses trade-offs.","title":"Options"},{"location":"developer-experience/client-app-inner-loop/#embedded-mocks","text":"An embedded mock solution includes classes that implement the service interfaces locally. Interfaces and data classes, also called models or data transfer objects or DTOs, are often generated from the services' API specs using tools like nswag ( RicoSuter/NSwag: The Swagger/OpenAPI toolchain for .NET, ASP.NET Core and TypeScript. (github.com) ) or autorest ( Azure/autorest: OpenAPI (f.k.a Swagger) Specification code generator. Supports C#, PowerShell, Go, Java, Node.js, TypeScript, Python, Ruby (github.com) ). A simple service implementation can return a static response. For RESTful services, the JSON responses for the stubs can be stored as application resources or simply as static strings. public Task < UserProfile > GetUserAsync ( long userId , CancellationToken cancellationToken ) { PetProfile result = Newtonsoft . Json . JsonConvert . DeserializeObject < UserProfile > ( MockUserProfile . UserProfile , new Newtonsoft . Json . JsonSerializerSettings ()); return Task . FromResult ( result ); } More sophisticated can randomly return errors to test the app's resiliency code paths. Mocks can be activated via conditional compilation or dynamically via app configuration. In either case, it is recommended to ensure that mocks, service responses and externalized configurations are not included in the final release to avoid confusing behavior and inclusion of potential vulnerabilities.","title":"Embedded Mocks"},{"location":"developer-experience/client-app-inner-loop/#sample-registering-mocks-via-dependency-injection","text":"Dependency Injection Containers like Unity ( Unity Container Introduction | Unity Container ) make it easy to switch between mock services and real service client implementations. Since both implement the same interface, implementations can be registered with the Unity container. public static void Bootstrap ( IUnityContainer container ) { #if DEBUG container . RegisterSingleton < IUserServiceClient , MockUserService > (); #else container . RegisterSingleton < IUserServiceClient , UserServiceClient > (); #endif }","title":"Sample: Registering Mocks via Dependency Injection"},{"location":"developer-experience/client-app-inner-loop/#consuming-mocks-via-dependency-injection","text":"The code consuming the interfaces will not notice the difference. public class UserPageModel { private readonly IUserServiceClient userServiceClient ; public UserPageModel ( IUserServiceClient userServiceClient ) { this . userServiceClient = userServiceClient ; } // ... }","title":"Consuming mocks via Dependency Injection"},{"location":"developer-experience/client-app-inner-loop/#local-services","text":"The approach with Locally Running Services is to replace the call in the client from pointing to the actual endpoint (whether dev, QA, prod, etc.) to a local endpoint. This approach also enables injecting traffic capture and shaping proxies like Postman ( Postman API Platform | Sign Up for Free ) or Fiddler ( Fiddler | Web Debugging Proxy and Troubleshooting Solutions (telerik.com) ). The advantage of this approach is that the APIs are decoupled from the client and can be independently updated/modified (e.g. changing response codes, changing data) without requiring changes to the client. This helps to unlock new development scenarios and provides flexibility during the development phase. The challenge with this approach is that it does require setup, configuration, and running of the services locally. There are tools that help to simplify that process (e.g. JsonServer , Postman Mock Server ).","title":"Local Services"},{"location":"developer-experience/client-app-inner-loop/#high-fidelity-local-services","text":"A local service stub implements the expected APIs. Just like the embedded mock, it can be generated based on existing API contracts (e.g. OpenAPI). A high-fidelity approach packages the real services together with simplified data in docker containers that can be run locally using docker-compose before the client app is started for local debugging and testing. To enable running services fully local the \"local version\" substitutes dependent cloud services with local alternatives, e.g. file storage instead of blobs, locally running SQL Server instead of SQL AzureDB. This approach also enables full fidelity integration testing without spinning up distributed deployments.","title":"High-Fidelity Local Services"},{"location":"developer-experience/client-app-inner-loop/#stub-fake-services","text":"Lower fidelity approaches run stub services, that could be generated from API specs, or run fake servers like JsonServer ( JsonServer.io: A fake json server API Service for prototyping and testing. ) or Postman. All these services would respond with predetermined and configured JSON messages.","title":"Stub / Fake Services"},{"location":"developer-experience/client-app-inner-loop/#how-to-decide","text":"Pros Cons Example when developing for: Example When not to Use Embedded Mocks Simplifies the F5 developer experience Tightly coupled with Client More static type data scenarios Testing (e.g. unit tests, integration tests) No external dependencies to manage Hard coded data Initial integration with services Mocking via Dependency Injection can be a non-trivial effort High-Fidelity Local Services Loosely Coupled from Client Extra tooling required i.e. local infrastructure overhead URL Routes When API contract are not available Easier to independently modify response Extra setup and configuration of services Independent updates to services Can utilize HTTP traffic Easier to replace with real services at a later time Stub/Fake Services Loosely coupled from client Extra tooling required i.e. local infrastructure overhead Response Codes When API Contracts available Easier to independently modify response Extra setup and configuration of services Complex/variable data scenarios When API Contracts are note available Independent updates to services Might not provide full fidelity of expected API Can utilize HTTP traffic Easier to replace with real services at a later time","title":"How to decide"},{"location":"developer-experience/copilots/","text":"Copilots There are a number of AI tools that can improve the developer experience. This article will discuss tooling that is available as well as advice on when it might be appropriate to use such tooling. GitHub Copilot The current version of GitHub Copilot can provide code completion in many popular IDEs. For instance, the VS Code extension that can be installed from the VS Code Marketplace. It requires a GitHub account to use. For more information about what IDEs are supported, what languages are supported, cost, features, etc., please checkout out the information on Copilot and Copilot for Business . Some example use-cases for GitHub Copilot include: Write Documentation . For example, the above paragraph was written using Copilot. Write Unit Tests . Given that setup and assertions are often consistent across unit tests, Copilot tends to be very accurate. Unblock . It is often hard start writing when staring at a blank page, Copilot can fill the space with something that may or may not be what you ultimately want to do, but it can help get you in the right head space. If you want Copilot to write something useful for you, try writing a comment that describes what your code is going to do - it can often take it from there. GitHub Copilot Labs Copilot has a GitHub Copilot Labs extension that offers additional features that are not yet ready for prime-time. For VS Code, you can install it from the VS Code Marketplace. These features include: Explain . Copilot can explain what the code is doing in natural language. Translate . Copilot can translate code from one language to another. Brushes . You can select code that Copilot then modifies inline based on a \"brush\" you select, for example, to make the code more readable, fix bugs, improve debugging, document, etc. Generate Tests . Copilot can generate unit tests for your code. Though currently this is limited to JavaScript and TypeScript. GitHub Copilot X The next version of Copilot offers a number of new use-cases beyond code completion. These include: Chat . Rather than just providing code completion, Copilot will be able to have a conversation with you about what you want to do. It has context about the code you are working on and can provide suggestions based on that context. Beyond just writing code, consider using chat to: Build SQL Indexes . Given a query, ChatGPT can generate a SQL index that will improve the performance of the query. Write Regular Expressions . These are notoriously difficult to write, but ChatGPT can generate them for you if you give some sample input and describe what you want to extract. Improve and Validate . If you are unsure of the implications of writing code a particular way, you can ask questions about it. For instance, you might ask if there is a way to write the code that is more performant or uses less memory. Once it gives you an opinion, you can ask it to provide documentation validating that assertion. Explain . Copilot can explain what the code is doing in natural language. Write Code . Given prompting by the developer it can write code that you can one-click deploy into existing or new files. Debug . Copilot can analyze your code and propose solutions to fix bugs. It can do most of what Labs can do with \"brushes\" as \"topics\", but whereas Labs changes the code in your file, the chat functionality just shows what it would change in the window. However, there is also an \"inline mode\" for GitHub Copilot Chat that allows you to make changes to your code inline which does not have this same limitation. ChatGPT / Bing Chat For coding, generic AI chat tools such as ChatGPT and Bing Chat are less useful, but they still have their place. GitHub Copilot will only answer \"questions about coding\" and it's interpretation of that rule can be a little restrictive. Some cases for using ChatGPT or Bing Chat include: Write Documentation . Copilot can write documentation, but using ChatGPT or Bing Chat, you can expand your documentation to include business information, use-cases, additional context, etc. Change Perspective . ChatGPT can impersonate a persona or even a system and answer questions from that perspective. For example, you can ask it to explain what a particular piece of code does from the perspective of a user. You might have ChatGPT imagine it is a database administrator and ask it to explain how to improve a particular query. When using Bing Chat, experiment with modes, sometimes changing to Creative Mode can give the results you need. Prompt Engineering Chat AI tools are only as good as the prompts you give them. The quality and appropriateness of the output can vary greatly depending on the prompt. In addition, many of these tools restrict the number of prompts you can send in a given amount of time. To learn more about prompt engineering, you might review some open source documentation here . Considerations It is important when using AI tools to understand how the data (including private or commercial code) might be used by the system. Read more about how GitHub Copilot handles your data and code here .","title":"Copilots"},{"location":"developer-experience/copilots/#copilots","text":"There are a number of AI tools that can improve the developer experience. This article will discuss tooling that is available as well as advice on when it might be appropriate to use such tooling.","title":"Copilots"},{"location":"developer-experience/copilots/#github-copilot","text":"The current version of GitHub Copilot can provide code completion in many popular IDEs. For instance, the VS Code extension that can be installed from the VS Code Marketplace. It requires a GitHub account to use. For more information about what IDEs are supported, what languages are supported, cost, features, etc., please checkout out the information on Copilot and Copilot for Business . Some example use-cases for GitHub Copilot include: Write Documentation . For example, the above paragraph was written using Copilot. Write Unit Tests . Given that setup and assertions are often consistent across unit tests, Copilot tends to be very accurate. Unblock . It is often hard start writing when staring at a blank page, Copilot can fill the space with something that may or may not be what you ultimately want to do, but it can help get you in the right head space. If you want Copilot to write something useful for you, try writing a comment that describes what your code is going to do - it can often take it from there.","title":"GitHub Copilot"},{"location":"developer-experience/copilots/#github-copilot-labs","text":"Copilot has a GitHub Copilot Labs extension that offers additional features that are not yet ready for prime-time. For VS Code, you can install it from the VS Code Marketplace. These features include: Explain . Copilot can explain what the code is doing in natural language. Translate . Copilot can translate code from one language to another. Brushes . You can select code that Copilot then modifies inline based on a \"brush\" you select, for example, to make the code more readable, fix bugs, improve debugging, document, etc. Generate Tests . Copilot can generate unit tests for your code. Though currently this is limited to JavaScript and TypeScript.","title":"GitHub Copilot Labs"},{"location":"developer-experience/copilots/#github-copilot-x","text":"The next version of Copilot offers a number of new use-cases beyond code completion. These include: Chat . Rather than just providing code completion, Copilot will be able to have a conversation with you about what you want to do. It has context about the code you are working on and can provide suggestions based on that context. Beyond just writing code, consider using chat to: Build SQL Indexes . Given a query, ChatGPT can generate a SQL index that will improve the performance of the query. Write Regular Expressions . These are notoriously difficult to write, but ChatGPT can generate them for you if you give some sample input and describe what you want to extract. Improve and Validate . If you are unsure of the implications of writing code a particular way, you can ask questions about it. For instance, you might ask if there is a way to write the code that is more performant or uses less memory. Once it gives you an opinion, you can ask it to provide documentation validating that assertion. Explain . Copilot can explain what the code is doing in natural language. Write Code . Given prompting by the developer it can write code that you can one-click deploy into existing or new files. Debug . Copilot can analyze your code and propose solutions to fix bugs. It can do most of what Labs can do with \"brushes\" as \"topics\", but whereas Labs changes the code in your file, the chat functionality just shows what it would change in the window. However, there is also an \"inline mode\" for GitHub Copilot Chat that allows you to make changes to your code inline which does not have this same limitation.","title":"GitHub Copilot X"},{"location":"developer-experience/copilots/#chatgpt-bing-chat","text":"For coding, generic AI chat tools such as ChatGPT and Bing Chat are less useful, but they still have their place. GitHub Copilot will only answer \"questions about coding\" and it's interpretation of that rule can be a little restrictive. Some cases for using ChatGPT or Bing Chat include: Write Documentation . Copilot can write documentation, but using ChatGPT or Bing Chat, you can expand your documentation to include business information, use-cases, additional context, etc. Change Perspective . ChatGPT can impersonate a persona or even a system and answer questions from that perspective. For example, you can ask it to explain what a particular piece of code does from the perspective of a user. You might have ChatGPT imagine it is a database administrator and ask it to explain how to improve a particular query. When using Bing Chat, experiment with modes, sometimes changing to Creative Mode can give the results you need.","title":"ChatGPT / Bing Chat"},{"location":"developer-experience/copilots/#prompt-engineering","text":"Chat AI tools are only as good as the prompts you give them. The quality and appropriateness of the output can vary greatly depending on the prompt. In addition, many of these tools restrict the number of prompts you can send in a given amount of time. To learn more about prompt engineering, you might review some open source documentation here .","title":"Prompt Engineering"},{"location":"developer-experience/copilots/#considerations","text":"It is important when using AI tools to understand how the data (including private or commercial code) might be used by the system. Read more about how GitHub Copilot handles your data and code here .","title":"Considerations"},{"location":"developer-experience/cross-platform-tasks/","text":"Cross Platform Tasks There are several options to alleviate cross-platform compatibility issues. Running tasks in a container Using the tasks-system in VS Code which provides options to allow commands to be executed specific to an operating system. Docker or Container based Using containers as development machines allows developers to get started with minimal setup and abstracts the development environment from the host OS by having it run in a container. DevContainers can also help in standardizing the local developer experience across the team. The following are some good resources to get started with running tasks in DevContainers Developing inside a container . Tutorial on Development in Containers For samples projects and dev container templates see VS Code Dev Containers Recipe Dev Containers Library Tasks in VS Code Running Node.js The example below offers insight into running Node.js executable as a command with tasks.json and how it can be treated differently on Windows and Linux. { \"label\" : \"Run Node\" , \"type\" : \"process\" , \"windows\" : { \"command\" : \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" }, \"linux\" : { \"command\" : \"/usr/bin/node\" } } In this example, to run Node.js, there is a specific windows command, and a specific linux command. This allows for platform specific properties. When these are defined, they will be used instead of the default properties when the command is executed on the Windows operating system or on Linux. Custom Tasks Not all scripts or tasks can be auto-detected in the workspace. It may be necessary at times to defined your own custom tasks. In this example, we have a script to run in order to set up some environment correctly. The script is stored in a folder inside your workspace and named test.sh for Linux & macOS and test.cmd for Windows. With the tasks.json file, the execution of this script can be made possible with a custom task that defines what to do on different operating systems. { \"version\" : \"2.0.0\" , \"tasks\" : [ { \"label\" : \"Run tests\" , \"type\" : \"shell\" , \"command\" : \"./scripts/test.sh\" , \"windows\" : { \"command\" : \".\\\\scripts\\\\test.cmd\" }, \"group\" : \"test\" , \"presentation\" : { \"reveal\" : \"always\" , \"panel\" : \"new\" } } ] } The command here is a shell command and tells the system to run either the test.sh or test.cmd. By default, it will run test.sh with that given path. This example here also defines Windows specific properties and tells it execute test.cmd instead of the default. References VS Code Docs - operating system specific properties","title":"Cross Platform Tasks"},{"location":"developer-experience/cross-platform-tasks/#cross-platform-tasks","text":"There are several options to alleviate cross-platform compatibility issues. Running tasks in a container Using the tasks-system in VS Code which provides options to allow commands to be executed specific to an operating system.","title":"Cross Platform Tasks"},{"location":"developer-experience/cross-platform-tasks/#docker-or-container-based","text":"Using containers as development machines allows developers to get started with minimal setup and abstracts the development environment from the host OS by having it run in a container. DevContainers can also help in standardizing the local developer experience across the team. The following are some good resources to get started with running tasks in DevContainers Developing inside a container . Tutorial on Development in Containers For samples projects and dev container templates see VS Code Dev Containers Recipe Dev Containers Library","title":"Docker or Container based"},{"location":"developer-experience/cross-platform-tasks/#tasks-in-vs-code","text":"","title":"Tasks in VS Code"},{"location":"developer-experience/cross-platform-tasks/#running-nodejs","text":"The example below offers insight into running Node.js executable as a command with tasks.json and how it can be treated differently on Windows and Linux. { \"label\" : \"Run Node\" , \"type\" : \"process\" , \"windows\" : { \"command\" : \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" }, \"linux\" : { \"command\" : \"/usr/bin/node\" } } In this example, to run Node.js, there is a specific windows command, and a specific linux command. This allows for platform specific properties. When these are defined, they will be used instead of the default properties when the command is executed on the Windows operating system or on Linux.","title":"Running Node.js"},{"location":"developer-experience/cross-platform-tasks/#custom-tasks","text":"Not all scripts or tasks can be auto-detected in the workspace. It may be necessary at times to defined your own custom tasks. In this example, we have a script to run in order to set up some environment correctly. The script is stored in a folder inside your workspace and named test.sh for Linux & macOS and test.cmd for Windows. With the tasks.json file, the execution of this script can be made possible with a custom task that defines what to do on different operating systems. { \"version\" : \"2.0.0\" , \"tasks\" : [ { \"label\" : \"Run tests\" , \"type\" : \"shell\" , \"command\" : \"./scripts/test.sh\" , \"windows\" : { \"command\" : \".\\\\scripts\\\\test.cmd\" }, \"group\" : \"test\" , \"presentation\" : { \"reveal\" : \"always\" , \"panel\" : \"new\" } } ] } The command here is a shell command and tells the system to run either the test.sh or test.cmd. By default, it will run test.sh with that given path. This example here also defines Windows specific properties and tells it execute test.cmd instead of the default.","title":"Custom Tasks"},{"location":"developer-experience/cross-platform-tasks/#references","text":"VS Code Docs - operating system specific properties","title":"References"},{"location":"developer-experience/devcontainers/","text":"Dev Containers: Getting Started If you are a developer and have experience with Visual Studio Code (VS Code) or Docker, then it's probably time you look at development containers (dev containers). This readme is intended to assist developers in the decision-making process needed to build dev containers. The guidance provided should be especially helpful if you are experiencing VS Code dev containers for the first time. Note: This guide is not about setting up a Docker file for deploying a running Python program for CI/CD. Prerequisites Experience with VS Code Experience with Docker What are dev containers? Development containers are a VS Code feature that allows developers to package a local development tool stack into the internals of a Docker container while also bringing the VS Code UI experience with them. Have you ever set a breakpoint inside a Docker container? Maybe not. Dev containers make that possible. This is all made possible through a VS Code extension called the Remote Development Extension Pack that works together with Docker to spin-up a VS Code Server within a Docker container. The VS Code UI component remains local, but your working files are volume mounted into the container. The diagram below, taken directly from the official VS Code docs , illustrates this: If the above diagram is not clear, a basic analogy that might help you intuitively understand dev containers is to think of them as a union between Docker's interactive mode ( docker exec -it 987654e0ff32 ), and the VS Code UI experience that you are used to. To set yourself up for the dev container experience described above, use your VS Code's Extension Marketplace to install the Remote Development Extension Pack . How can dev containers improve project collaboration? VS Code dev containers have improved project collaboration between developers on recent team projects by addressing two very specific problems: Inconsistent local developer experiences within a team. Slow onboarding of developers joining a project. The problems listed above were addressed by configuring and then sharing a dev container definition. Dev containers are defined by their base image, and the artifacts that support that base image. The base image and the artifacts that come with it live in the .devcontainer directory. This directory is where configuration begins. A central artifact to the dev container definition is a configuration file called devcontainer.json . This file orchestrates the artifacts needed to support the base image and the dev container lifecycle. Installation of the Remote Development Extension Pack is required to enable this orchestration within a project repo. All developers on the team are expected to share and use the dev container definition (.devcontainer directory) in order to spin-up a container. This definition provides consistent tooling for locally developing an application across a team. The code snippets below demonstrate the common location of a .devcontainer directory and devcontainer.json file within a project repository. They also highlight the correct way to reference a Docker file. $ tree vs-code-remote-try-python # main repo directory \u2514\u2500\u2500\u2500.devcontainers \u251c\u2500\u2500\u2500Dockerfile \u251c\u2500\u2500\u2500devcontainer.json # devco nta i ner .jso n { \"name\" : \"Python 3\" , \"build\" : { \"dockerfile\" : \"Dockerfile\" , \"context\" : \"..\" , // Update 'VARIANT' to pick a Python version: 3, 3.6, 3.7, 3.8 \"args\" : { \"VARIANT\" : \"3.8\" } }, } For a list of devcontainer.json configuration properties, visit VS Code documentation on dev container properties . How do I decide which dev container is right for my use case? Fortunately, VS Code has a repo gallery of platform specific folders that host dev container definitions (.devcontainer directories) to make getting started with dev containers easier. The code snippet below shows a list of gallery folders that come directly from the VS Code dev container gallery repo : $ tree vs-code-dev-containers # main repo directory \u2514\u2500\u2500\u2500containers \u251c\u2500\u2500\u2500dotnetcore | \u2514\u2500\u2500\u2500.devcontainers # dev container \u251c\u2500\u2500\u2500python-3 | \u2514\u2500\u2500\u2500.devcontainers # dev container \u251c\u2500\u2500\u2500ubuntu | \u2514\u2500\u2500\u2500.devcontainers # dev container \u2514\u2500\u2500\u2500.... Here are the final high-level steps it takes to build a dev container: Decide which platform you'd like to build a local development tool stack around. Browse the VS Code provided dev container gallery of project folders that target your platform and choose the most appropriate one. Inspect the dev container definitions (.devcontainer directory) of a project for the base image, and the artifacts that support that base image. Use what you've discovered to begin setting up the dev container as it is, extending it or building your own from scratch. Going further There are use cases where you would want to go further in configuring your Dev Container. More details here","title":"Dev Containers: Getting Started"},{"location":"developer-experience/devcontainers/#dev-containers-getting-started","text":"If you are a developer and have experience with Visual Studio Code (VS Code) or Docker, then it's probably time you look at development containers (dev containers). This readme is intended to assist developers in the decision-making process needed to build dev containers. The guidance provided should be especially helpful if you are experiencing VS Code dev containers for the first time. Note: This guide is not about setting up a Docker file for deploying a running Python program for CI/CD.","title":"Dev Containers: Getting Started"},{"location":"developer-experience/devcontainers/#prerequisites","text":"Experience with VS Code Experience with Docker","title":"Prerequisites"},{"location":"developer-experience/devcontainers/#what-are-dev-containers","text":"Development containers are a VS Code feature that allows developers to package a local development tool stack into the internals of a Docker container while also bringing the VS Code UI experience with them. Have you ever set a breakpoint inside a Docker container? Maybe not. Dev containers make that possible. This is all made possible through a VS Code extension called the Remote Development Extension Pack that works together with Docker to spin-up a VS Code Server within a Docker container. The VS Code UI component remains local, but your working files are volume mounted into the container. The diagram below, taken directly from the official VS Code docs , illustrates this: If the above diagram is not clear, a basic analogy that might help you intuitively understand dev containers is to think of them as a union between Docker's interactive mode ( docker exec -it 987654e0ff32 ), and the VS Code UI experience that you are used to. To set yourself up for the dev container experience described above, use your VS Code's Extension Marketplace to install the Remote Development Extension Pack .","title":"What are dev containers?"},{"location":"developer-experience/devcontainers/#how-can-dev-containers-improve-project-collaboration","text":"VS Code dev containers have improved project collaboration between developers on recent team projects by addressing two very specific problems: Inconsistent local developer experiences within a team. Slow onboarding of developers joining a project. The problems listed above were addressed by configuring and then sharing a dev container definition. Dev containers are defined by their base image, and the artifacts that support that base image. The base image and the artifacts that come with it live in the .devcontainer directory. This directory is where configuration begins. A central artifact to the dev container definition is a configuration file called devcontainer.json . This file orchestrates the artifacts needed to support the base image and the dev container lifecycle. Installation of the Remote Development Extension Pack is required to enable this orchestration within a project repo. All developers on the team are expected to share and use the dev container definition (.devcontainer directory) in order to spin-up a container. This definition provides consistent tooling for locally developing an application across a team. The code snippets below demonstrate the common location of a .devcontainer directory and devcontainer.json file within a project repository. They also highlight the correct way to reference a Docker file. $ tree vs-code-remote-try-python # main repo directory \u2514\u2500\u2500\u2500.devcontainers \u251c\u2500\u2500\u2500Dockerfile \u251c\u2500\u2500\u2500devcontainer.json # devco nta i ner .jso n { \"name\" : \"Python 3\" , \"build\" : { \"dockerfile\" : \"Dockerfile\" , \"context\" : \"..\" , // Update 'VARIANT' to pick a Python version: 3, 3.6, 3.7, 3.8 \"args\" : { \"VARIANT\" : \"3.8\" } }, } For a list of devcontainer.json configuration properties, visit VS Code documentation on dev container properties .","title":"How can dev containers improve project collaboration?"},{"location":"developer-experience/devcontainers/#how-do-i-decide-which-dev-container-is-right-for-my-use-case","text":"Fortunately, VS Code has a repo gallery of platform specific folders that host dev container definitions (.devcontainer directories) to make getting started with dev containers easier. The code snippet below shows a list of gallery folders that come directly from the VS Code dev container gallery repo : $ tree vs-code-dev-containers # main repo directory \u2514\u2500\u2500\u2500containers \u251c\u2500\u2500\u2500dotnetcore | \u2514\u2500\u2500\u2500.devcontainers # dev container \u251c\u2500\u2500\u2500python-3 | \u2514\u2500\u2500\u2500.devcontainers # dev container \u251c\u2500\u2500\u2500ubuntu | \u2514\u2500\u2500\u2500.devcontainers # dev container \u2514\u2500\u2500\u2500.... Here are the final high-level steps it takes to build a dev container: Decide which platform you'd like to build a local development tool stack around. Browse the VS Code provided dev container gallery of project folders that target your platform and choose the most appropriate one. Inspect the dev container definitions (.devcontainer directory) of a project for the base image, and the artifacts that support that base image. Use what you've discovered to begin setting up the dev container as it is, extending it or building your own from scratch.","title":"How do I decide which dev container is right for my use case?"},{"location":"developer-experience/devcontainers/#going-further","text":"There are use cases where you would want to go further in configuring your Dev Container. More details here","title":"Going further"},{"location":"developer-experience/execute-local-pipeline-with-docker/","text":"Executing pipelines locally Abstract Having the ability to execute pipeline activities locally has been identified as an opportunity to promote positive developer experience. In this document we will explore a solution which will allow us to have the local CI experience to be as similar as possible to the remote process in the CI server. Using the suggested method will allow us to: Build Lint Unit test E2E test Run Solution Be OS and environment agnostic. Enter Docker Compose Docker Compose allows you to build push or run multi-container Docker applications. Method of work Dockerize your application(s), including a build step if possible. Add a step in your docker file to execute unit tests. Add a step in the docker file for linting. Create a new dockerfile, possibly in a different folder, which executes end-to-end tests against the cluster. Make sure the default endpoints are configurable (This will become handy in your remote CI server, where you will be able to test against a live environment, if you choose to). Create a docker-compose file which allows you to choose which of the services to run. The default will run all applications and tests, and an optional parameter can run specific services, for example only the application without the tests. Prerequisites Docker Optional: if you clone the sample app, you need to have dotnet core installed. Step by step with examples For this tutorial we are going to use a sample dotnet core api application . Here is the docker file for the sample app: # https://hub.docker.com/_/microsoft-dotnet FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build WORKDIR /app # copy csproj and restore as distinct layers COPY ./ ./ RUN dotnet restore RUN dotnet test # copy everything else and build app COPY SampleApp/. ./ RUN dotnet publish -c release -o out --no-restore # final stage/image FROM mcr.microsoft.com/dotnet/aspnet:5.0 WORKDIR /app COPY --from = build /app/out . ENTRYPOINT [ \"dotnet\" , \"SampleNetApi.dll\" ] This script restores all dependencies, builds and runs tests. The dotnet app includes stylecop which fails the build in case of linting issues. Next we will also create a dockerfile to perform an end-to-end test. Usually this will look like a set of scripts, or a dedicated app which performs actual HTTP calls to a running application. For the sake of simplicity the dockerfile itself will run a simple curl command: FROM alpine:3.7 RUN apk --no-cache add curl ENTRYPOINT [ \"curl\" , \"0.0.0.0:8080/weatherforecast\" ] Now we are ready to combine both of the dockerfiles in a docker-compose script: version: '3' services: app: image: app:0.01 build: context: . ports: - \"8080:80\" e2e: image: e2e:0.01 build: context: ./E2E The docker-compose script will launch the 2 dockerfiles, and it will build them if they were not built before. The following command will run docker compose: docker-compose up --build -d Once the images are up, you can make calls to the service. The e2e image will perform the set of e2e tests. If you want to skip the tests, you can simply tell compose to run a specific service by appending the name of the service, as follows: docker-compose up --build -d app Now you have a local script which builds and tests you application. The next step would be make your CI run the docker-compose script. Here is an example of a yaml file used by Azure DevOps pipelines: trigger: - master pool: vmImage: 'ubuntu-latest' variables: solution: '**/*.sln' buildPlatform: 'Any CPU' buildConfiguration: 'Release' steps: - task: DockerCompose@0 displayName: Build, Test, E2E inputs: action: Run services dockerComposeFile: docker-compose.yml - script: dotnet restore SampleApp - script: dotnet build --configuration $( buildConfiguration ) SampleApp displayName: 'dotnet build $(buildConfiguration)' In this script the first step is docker-compose, which uses the same file we created the previous steps. The next steps, do the same using scripts, and are here for comparison. By the end of this step, your CI effectively runs the same build and test commands you run locally.","title":"Executing pipelines locally"},{"location":"developer-experience/execute-local-pipeline-with-docker/#executing-pipelines-locally","text":"","title":"Executing pipelines locally"},{"location":"developer-experience/execute-local-pipeline-with-docker/#abstract","text":"Having the ability to execute pipeline activities locally has been identified as an opportunity to promote positive developer experience. In this document we will explore a solution which will allow us to have the local CI experience to be as similar as possible to the remote process in the CI server. Using the suggested method will allow us to: Build Lint Unit test E2E test Run Solution Be OS and environment agnostic.","title":"Abstract"},{"location":"developer-experience/execute-local-pipeline-with-docker/#enter-docker-compose","text":"Docker Compose allows you to build push or run multi-container Docker applications.","title":"Enter Docker Compose"},{"location":"developer-experience/execute-local-pipeline-with-docker/#method-of-work","text":"Dockerize your application(s), including a build step if possible. Add a step in your docker file to execute unit tests. Add a step in the docker file for linting. Create a new dockerfile, possibly in a different folder, which executes end-to-end tests against the cluster. Make sure the default endpoints are configurable (This will become handy in your remote CI server, where you will be able to test against a live environment, if you choose to). Create a docker-compose file which allows you to choose which of the services to run. The default will run all applications and tests, and an optional parameter can run specific services, for example only the application without the tests.","title":"Method of work"},{"location":"developer-experience/execute-local-pipeline-with-docker/#prerequisites","text":"Docker Optional: if you clone the sample app, you need to have dotnet core installed.","title":"Prerequisites"},{"location":"developer-experience/execute-local-pipeline-with-docker/#step-by-step-with-examples","text":"For this tutorial we are going to use a sample dotnet core api application . Here is the docker file for the sample app: # https://hub.docker.com/_/microsoft-dotnet FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build WORKDIR /app # copy csproj and restore as distinct layers COPY ./ ./ RUN dotnet restore RUN dotnet test # copy everything else and build app COPY SampleApp/. ./ RUN dotnet publish -c release -o out --no-restore # final stage/image FROM mcr.microsoft.com/dotnet/aspnet:5.0 WORKDIR /app COPY --from = build /app/out . ENTRYPOINT [ \"dotnet\" , \"SampleNetApi.dll\" ] This script restores all dependencies, builds and runs tests. The dotnet app includes stylecop which fails the build in case of linting issues. Next we will also create a dockerfile to perform an end-to-end test. Usually this will look like a set of scripts, or a dedicated app which performs actual HTTP calls to a running application. For the sake of simplicity the dockerfile itself will run a simple curl command: FROM alpine:3.7 RUN apk --no-cache add curl ENTRYPOINT [ \"curl\" , \"0.0.0.0:8080/weatherforecast\" ] Now we are ready to combine both of the dockerfiles in a docker-compose script: version: '3' services: app: image: app:0.01 build: context: . ports: - \"8080:80\" e2e: image: e2e:0.01 build: context: ./E2E The docker-compose script will launch the 2 dockerfiles, and it will build them if they were not built before. The following command will run docker compose: docker-compose up --build -d Once the images are up, you can make calls to the service. The e2e image will perform the set of e2e tests. If you want to skip the tests, you can simply tell compose to run a specific service by appending the name of the service, as follows: docker-compose up --build -d app Now you have a local script which builds and tests you application. The next step would be make your CI run the docker-compose script. Here is an example of a yaml file used by Azure DevOps pipelines: trigger: - master pool: vmImage: 'ubuntu-latest' variables: solution: '**/*.sln' buildPlatform: 'Any CPU' buildConfiguration: 'Release' steps: - task: DockerCompose@0 displayName: Build, Test, E2E inputs: action: Run services dockerComposeFile: docker-compose.yml - script: dotnet restore SampleApp - script: dotnet build --configuration $( buildConfiguration ) SampleApp displayName: 'dotnet build $(buildConfiguration)' In this script the first step is docker-compose, which uses the same file we created the previous steps. The next steps, do the same using scripts, and are here for comparison. By the end of this step, your CI effectively runs the same build and test commands you run locally.","title":"Step by step with examples"},{"location":"developer-experience/fake-services-inner-loop/","text":"Fake Services Inner Dev Loop Introduction Consumers of remote services often find that their development cycle is not in sync with development of remote services, leaving developers of these consumers waiting for the remote services to \"catch up\". One approach to mitigate this issue and improve the inner dev loop is by decoupling and using Mock Services. Various Mock Service options are detailed here . This document will focus on providing an example using the Fake Services approach. API For our example API, we will work against a /User endpoint and the properties for User will be: id - int username - string firstName - string lastName - string email - string password - string phone - string userStatus - int Tooling For the Fake Service approach, we will be using Json-Server . Json-Server is a tool that provides the ability to fully fake REST APIs and run the server locally. It is designed to spin up REST APIs with CRUD functionality with minimal setup. Json-Server requires NodeJS and is installed via NPM. npm install -g json-server Setup In order to run Json-Server, it simply requires a source for data and will infer routes, etc. based on the data file. Note that additional customization can be performed for more advanced scenarios (e.g. custom routes). Details can be found here . For our example, we will use the following data file, db.json : { \"user\": [ { \"id\": 0, \"username\": \"user1\", \"firstName\": \"Kobe\", \"lastName\": \"Bryant\", \"email\": \"kobe@example.com\", \"password\": \"superSecure1\", \"phone\": \"(123) 123-1234\", \"userStatus\": 0 }, { \"id\": 1, \"username\": \"user2\", \"firstName\": \"Shaquille\", \"lastName\": \"O'Neal\", \"email\": \"shaq@example.com\", \"password\": \"superSecure2\", \"phone\": \"(123) 123-1235\", \"userStatus\": 0 } ] } Run Running Json-Server can be performed by simply running: json-server --watch src/db.json Once running, the User endpoint can be hit on the default localhost port: http:/localhost:3000/user Note that Json-Server can be configured to use other ports using the following syntax: json-server --watch db.json --port 3004 Endpoint The endpoint can be tested by running curl against it and we can narrow down which user object to get back with the following command: curl http://localhost:3000/user/1 which, as expected, returns: { \"id\": 1, \"username\": \"user2\", \"firstName\": \"Shaquille\", \"lastName\": \"O'Neal\", \"email\": \"shaq@example.com\", \"password\": \"superSecure2\", \"phone\": \"(123) 123-1235\", \"userStatus\": 0 }","title":"Fake Services Inner Dev Loop"},{"location":"developer-experience/fake-services-inner-loop/#fake-services-inner-dev-loop","text":"","title":"Fake Services Inner Dev Loop"},{"location":"developer-experience/fake-services-inner-loop/#introduction","text":"Consumers of remote services often find that their development cycle is not in sync with development of remote services, leaving developers of these consumers waiting for the remote services to \"catch up\". One approach to mitigate this issue and improve the inner dev loop is by decoupling and using Mock Services. Various Mock Service options are detailed here . This document will focus on providing an example using the Fake Services approach.","title":"Introduction"},{"location":"developer-experience/fake-services-inner-loop/#api","text":"For our example API, we will work against a /User endpoint and the properties for User will be: id - int username - string firstName - string lastName - string email - string password - string phone - string userStatus - int","title":"API"},{"location":"developer-experience/fake-services-inner-loop/#tooling","text":"For the Fake Service approach, we will be using Json-Server . Json-Server is a tool that provides the ability to fully fake REST APIs and run the server locally. It is designed to spin up REST APIs with CRUD functionality with minimal setup. Json-Server requires NodeJS and is installed via NPM. npm install -g json-server","title":"Tooling"},{"location":"developer-experience/fake-services-inner-loop/#setup","text":"In order to run Json-Server, it simply requires a source for data and will infer routes, etc. based on the data file. Note that additional customization can be performed for more advanced scenarios (e.g. custom routes). Details can be found here . For our example, we will use the following data file, db.json : { \"user\": [ { \"id\": 0, \"username\": \"user1\", \"firstName\": \"Kobe\", \"lastName\": \"Bryant\", \"email\": \"kobe@example.com\", \"password\": \"superSecure1\", \"phone\": \"(123) 123-1234\", \"userStatus\": 0 }, { \"id\": 1, \"username\": \"user2\", \"firstName\": \"Shaquille\", \"lastName\": \"O'Neal\", \"email\": \"shaq@example.com\", \"password\": \"superSecure2\", \"phone\": \"(123) 123-1235\", \"userStatus\": 0 } ] }","title":"Setup"},{"location":"developer-experience/fake-services-inner-loop/#run","text":"Running Json-Server can be performed by simply running: json-server --watch src/db.json Once running, the User endpoint can be hit on the default localhost port: http:/localhost:3000/user Note that Json-Server can be configured to use other ports using the following syntax: json-server --watch db.json --port 3004","title":"Run"},{"location":"developer-experience/fake-services-inner-loop/#endpoint","text":"The endpoint can be tested by running curl against it and we can narrow down which user object to get back with the following command: curl http://localhost:3000/user/1 which, as expected, returns: { \"id\": 1, \"username\": \"user2\", \"firstName\": \"Shaquille\", \"lastName\": \"O'Neal\", \"email\": \"shaq@example.com\", \"password\": \"superSecure2\", \"phone\": \"(123) 123-1235\", \"userStatus\": 0 }","title":"Endpoint"},{"location":"developer-experience/going-further/","text":"Dev Containers: Going further Dev Containers allow developers to share a common working environment, ensuring that the runtime and all dependencies versions are consistent for all developers. Dev containers also allow us to: Leverage existing tools to enhance the Dev Containers with more features, Provide custom tools (such as scripts) for other developers. Existing tools In the development phase, you will most probably need to use tools not installed by default in your Dev Container. For instance, if your project's target is to be deployed on Azure, you will need Azure-cli and maybe Terraform for resources and application deployment. You can find such Dev Containers in the VS Code dev container gallery repo . Some other tools may be: Linters for markdown files, Linters for bash scripts, Etc... Linting files that are not the source code can ensure a common format with common rules for each developer. These checks should be also run in a Continuous Integration Pipeline , but it is a good practice to run them prior opening a Pull Request . Limitation of custom tools If you decide to include Azure-cli in your Dev Container, developers will be able to run commands against their tenant. However, to make the developers' lives easier, we could go further by letting them prefill their connection information, such as the tenant ID and the subscription ID in a secure and persistent way (do not forget that your Dev Container, being a Docker container, might get deleted, or the image could be rebuilt, hence, all customization inside will be lost). One way to achieve this is to leverage environment variables, with untracked .env file part of the solution being injected in the Dev Container. Consider the following files structure: My Application # main repo directory \u2514\u2500\u2500\u2500.devcontainer | \u251c\u2500\u2500\u2500Dockerfile | \u251c\u2500\u2500\u2500devcontainer.json \u2514\u2500\u2500\u2500config | \u251c\u2500\u2500\u2500.env | \u251c\u2500\u2500\u2500.env-sample The file config/.env-sample is a tracked file where anyone can find environment variables to set (with no values, obviously): TENANT_ID = SUBSCRIPTION_ID = Then, each developer who clones the repository can create the file config/.env and fills it in with the appropriate values. In order now to inject the .env file into the container, you can update the file devcontainer.json with the following: { ... \"runArgs\" : [ \"--env-file\" , \"config/.env\" ], ... } As soon as the Dev Container is started, these environment variables are sent to the container. Another approach would be to use Docker Compose, a little bit more complex, and probably too much for just environment variables. Using Docker Compose can unlock other settings such as custom dns, ports forwarding or multiple containers. To achieve this, you need to add a file .devcontainer/docker-compose.yml with the following: version : '3' services : my-workspace : env_file : ../config/.env build : context : . dockerfile : Dockerfile command : sleep infinity To use the docker-compose.yml file instead of Dockerfile , we need to adjust devcontainer.json with: { \"name\" : \"My Application\" , \"dockerComposeFile\" : [ \"docker-compose.yml\" ], \"service\" : \"my-workspace\" ... } This approach can be applied for many other tools by preparing what would be required. The idea is to simplify developers' lives and new developers joining the project. Custom tools While working on a project, any developer might end up writing a script to automate a task. This script can be in bash , python or whatever scripting language they are comfortable with. Let's say you want to ensure that all markdown files written are validated against specific rules you have set up. As we have seen above, you can include the tool markdownlint in your Dev Container . Having the tool installed does not mean developer will know how to use it! Consider the following solution structure: My Application # main repo directory \u2514\u2500\u2500\u2500.devcontainer | \u251c\u2500\u2500\u2500Dockerfile | \u251c\u2500\u2500\u2500docker-compose.yml | \u251c\u2500\u2500\u2500devcontainer.json \u2514\u2500\u2500\u2500scripts | \u251c\u2500\u2500\u2500check-markdown.sh \u2514\u2500\u2500\u2500.markdownlint.json The file .devcontainer/Dockerfile installs markdownlint ... RUN apt-get update \\ && export DEBIAN_FRONTEND = noninteractive \\ && apt-get install -y nodejs npm # Add NodeJS tools RUN npm install -g markdownlint-cli ... The file .markdownlint.json contains the rules you want to validate in your markdown files (please refer to the markdownlint site for details). And finally, the script scripts/check-markdown.sh contains the following code to execute markdownlint : # Get the repository root repoRoot = \" $( cd \" $( dirname \" ${ BASH_SOURCE [0] } \" ) /..\" >/dev/null 2 > & 1 && pwd ) \" # Execute markdownlint for the entire solution markdownlint -c \" ${ repoRoot } \" /.markdownlint.json When the Dev Container is loaded, any developer can now run this script in their terminal: /> ./scripts/check-markdown.sh This is a small use case, there are unlimited other possibilities to capitalize on work done by developers to save time. Other considerations Platform architecture When installing tooling, you also need to ensure that you know what host computers developers are using. All Intel based computers, whether they are running Windows, Linux or MacOs will have the same behavior. However, the latest Mac architecture (Apple M1/Silicon) being ARM64, means that the behavior is not the same when building Dev Containers. For instance, if you want to install Azure-cli in your Dev Container, you won't be able to do it the same way you do it for Intel based machines. On Intel based computers you can install the deb package. However, this package is not available on ARM architecture. The only way to install Azure-cli on Linux ARM is via the Python installer pip . To achieve this you need to check the architecture of the host building the Dev Container, either in the Dockerfile, or by calling an external bash script to install remaining tools not having a universal version. Here is a snippet to call from the Dockerfile: # If Intel based, then use the deb file if [[ ` dpkg --print-architecture ` == \"amd64\" ]] ; then sudo curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash ; else # arm based, install pip (and gcc) then azure-cli sudo apt-get -y install gcc python3 -m pip install --upgrade pip python3 -m pip install azure-cli fi Reuse of credentials for GitHub If you develop inside a Dev Container, you will also want to share your GitHub credentials between your host and the Dev Container. Doing so, you would avoid copying your ssh keys back and forth (if you are using ssh to access your repositories). One approach would be to mount your local ~/.ssh folder into your Dev Container. You can either use the mounts option of the devcontainer.json , or use Docker Compose Using mounts : { ... \"mounts\" : [ \"source=${localEnv:HOME}/.ssh,target=/home/vscode/.ssh,type=bind\" ], ... } As you can see, ${localEnv:HOME} returns the host home folder, and it maps it to the container home folder. Using Docker Compose: version : '3' services : my-worspace : env_file : ../configs/.env build : context : . dockerfile : Dockerfile volumes : - \"~/.ssh:/home/alex/.ssh\" command : sleep infinity Please note that using Docker Compose requires to edit the devcontainer.json file as we have seen above. You can now access GitHub using the same credentials as your host machine, without worrying of persistence. Allow some customization As a final note, it is also interesting to leave developers some flexibility in their environment for customization. For instance, one might want to add aliases to their environment. However, changing the ~/.bashrc file in the Dev Container is not a good approach as the container might be destroyed. There are numerous ways to set persistence, here is one approach. Consider the following solution structure: My Application # main repo directory \u2514\u2500\u2500\u2500.devcontainer | \u251c\u2500\u2500\u2500Dockerfile | \u251c\u2500\u2500\u2500docker-compose.yml | \u251c\u2500\u2500\u2500devcontainer.json \u2514\u2500\u2500\u2500me | \u251c\u2500\u2500\u2500bashrc_extension The folder me is untracked in the repository, leaving developers the flexibility to add personal resources. One of these resources can be a .bashrc extension containing customization. For instance: # Sample alias alias gaa = \"git add --all\" We can now adapt our Dockerfile to load these changes when the Docker image is built (and of course, do nothing if there is no file): ... RUN echo \"[ -f PATH_TO_WORKSPACE/me/bashrc_extension ] && . PATH_TO_WORKSPACE/me/bashrc_extension\" >> ~/.bashrc ; ...","title":"Dev Containers: Going further"},{"location":"developer-experience/going-further/#dev-containers-going-further","text":"Dev Containers allow developers to share a common working environment, ensuring that the runtime and all dependencies versions are consistent for all developers. Dev containers also allow us to: Leverage existing tools to enhance the Dev Containers with more features, Provide custom tools (such as scripts) for other developers.","title":"Dev Containers: Going further"},{"location":"developer-experience/going-further/#existing-tools","text":"In the development phase, you will most probably need to use tools not installed by default in your Dev Container. For instance, if your project's target is to be deployed on Azure, you will need Azure-cli and maybe Terraform for resources and application deployment. You can find such Dev Containers in the VS Code dev container gallery repo . Some other tools may be: Linters for markdown files, Linters for bash scripts, Etc... Linting files that are not the source code can ensure a common format with common rules for each developer. These checks should be also run in a Continuous Integration Pipeline , but it is a good practice to run them prior opening a Pull Request .","title":"Existing tools"},{"location":"developer-experience/going-further/#limitation-of-custom-tools","text":"If you decide to include Azure-cli in your Dev Container, developers will be able to run commands against their tenant. However, to make the developers' lives easier, we could go further by letting them prefill their connection information, such as the tenant ID and the subscription ID in a secure and persistent way (do not forget that your Dev Container, being a Docker container, might get deleted, or the image could be rebuilt, hence, all customization inside will be lost). One way to achieve this is to leverage environment variables, with untracked .env file part of the solution being injected in the Dev Container. Consider the following files structure: My Application # main repo directory \u2514\u2500\u2500\u2500.devcontainer | \u251c\u2500\u2500\u2500Dockerfile | \u251c\u2500\u2500\u2500devcontainer.json \u2514\u2500\u2500\u2500config | \u251c\u2500\u2500\u2500.env | \u251c\u2500\u2500\u2500.env-sample The file config/.env-sample is a tracked file where anyone can find environment variables to set (with no values, obviously): TENANT_ID = SUBSCRIPTION_ID = Then, each developer who clones the repository can create the file config/.env and fills it in with the appropriate values. In order now to inject the .env file into the container, you can update the file devcontainer.json with the following: { ... \"runArgs\" : [ \"--env-file\" , \"config/.env\" ], ... } As soon as the Dev Container is started, these environment variables are sent to the container. Another approach would be to use Docker Compose, a little bit more complex, and probably too much for just environment variables. Using Docker Compose can unlock other settings such as custom dns, ports forwarding or multiple containers. To achieve this, you need to add a file .devcontainer/docker-compose.yml with the following: version : '3' services : my-workspace : env_file : ../config/.env build : context : . dockerfile : Dockerfile command : sleep infinity To use the docker-compose.yml file instead of Dockerfile , we need to adjust devcontainer.json with: { \"name\" : \"My Application\" , \"dockerComposeFile\" : [ \"docker-compose.yml\" ], \"service\" : \"my-workspace\" ... } This approach can be applied for many other tools by preparing what would be required. The idea is to simplify developers' lives and new developers joining the project.","title":"Limitation of custom tools"},{"location":"developer-experience/going-further/#custom-tools","text":"While working on a project, any developer might end up writing a script to automate a task. This script can be in bash , python or whatever scripting language they are comfortable with. Let's say you want to ensure that all markdown files written are validated against specific rules you have set up. As we have seen above, you can include the tool markdownlint in your Dev Container . Having the tool installed does not mean developer will know how to use it! Consider the following solution structure: My Application # main repo directory \u2514\u2500\u2500\u2500.devcontainer | \u251c\u2500\u2500\u2500Dockerfile | \u251c\u2500\u2500\u2500docker-compose.yml | \u251c\u2500\u2500\u2500devcontainer.json \u2514\u2500\u2500\u2500scripts | \u251c\u2500\u2500\u2500check-markdown.sh \u2514\u2500\u2500\u2500.markdownlint.json The file .devcontainer/Dockerfile installs markdownlint ... RUN apt-get update \\ && export DEBIAN_FRONTEND = noninteractive \\ && apt-get install -y nodejs npm # Add NodeJS tools RUN npm install -g markdownlint-cli ... The file .markdownlint.json contains the rules you want to validate in your markdown files (please refer to the markdownlint site for details). And finally, the script scripts/check-markdown.sh contains the following code to execute markdownlint : # Get the repository root repoRoot = \" $( cd \" $( dirname \" ${ BASH_SOURCE [0] } \" ) /..\" >/dev/null 2 > & 1 && pwd ) \" # Execute markdownlint for the entire solution markdownlint -c \" ${ repoRoot } \" /.markdownlint.json When the Dev Container is loaded, any developer can now run this script in their terminal: /> ./scripts/check-markdown.sh This is a small use case, there are unlimited other possibilities to capitalize on work done by developers to save time.","title":"Custom tools"},{"location":"developer-experience/going-further/#other-considerations","text":"","title":"Other considerations"},{"location":"developer-experience/going-further/#platform-architecture","text":"When installing tooling, you also need to ensure that you know what host computers developers are using. All Intel based computers, whether they are running Windows, Linux or MacOs will have the same behavior. However, the latest Mac architecture (Apple M1/Silicon) being ARM64, means that the behavior is not the same when building Dev Containers. For instance, if you want to install Azure-cli in your Dev Container, you won't be able to do it the same way you do it for Intel based machines. On Intel based computers you can install the deb package. However, this package is not available on ARM architecture. The only way to install Azure-cli on Linux ARM is via the Python installer pip . To achieve this you need to check the architecture of the host building the Dev Container, either in the Dockerfile, or by calling an external bash script to install remaining tools not having a universal version. Here is a snippet to call from the Dockerfile: # If Intel based, then use the deb file if [[ ` dpkg --print-architecture ` == \"amd64\" ]] ; then sudo curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash ; else # arm based, install pip (and gcc) then azure-cli sudo apt-get -y install gcc python3 -m pip install --upgrade pip python3 -m pip install azure-cli fi","title":"Platform architecture"},{"location":"developer-experience/going-further/#reuse-of-credentials-for-github","text":"If you develop inside a Dev Container, you will also want to share your GitHub credentials between your host and the Dev Container. Doing so, you would avoid copying your ssh keys back and forth (if you are using ssh to access your repositories). One approach would be to mount your local ~/.ssh folder into your Dev Container. You can either use the mounts option of the devcontainer.json , or use Docker Compose Using mounts : { ... \"mounts\" : [ \"source=${localEnv:HOME}/.ssh,target=/home/vscode/.ssh,type=bind\" ], ... } As you can see, ${localEnv:HOME} returns the host home folder, and it maps it to the container home folder. Using Docker Compose: version : '3' services : my-worspace : env_file : ../configs/.env build : context : . dockerfile : Dockerfile volumes : - \"~/.ssh:/home/alex/.ssh\" command : sleep infinity Please note that using Docker Compose requires to edit the devcontainer.json file as we have seen above. You can now access GitHub using the same credentials as your host machine, without worrying of persistence.","title":"Reuse of credentials for GitHub"},{"location":"developer-experience/going-further/#allow-some-customization","text":"As a final note, it is also interesting to leave developers some flexibility in their environment for customization. For instance, one might want to add aliases to their environment. However, changing the ~/.bashrc file in the Dev Container is not a good approach as the container might be destroyed. There are numerous ways to set persistence, here is one approach. Consider the following solution structure: My Application # main repo directory \u2514\u2500\u2500\u2500.devcontainer | \u251c\u2500\u2500\u2500Dockerfile | \u251c\u2500\u2500\u2500docker-compose.yml | \u251c\u2500\u2500\u2500devcontainer.json \u2514\u2500\u2500\u2500me | \u251c\u2500\u2500\u2500bashrc_extension The folder me is untracked in the repository, leaving developers the flexibility to add personal resources. One of these resources can be a .bashrc extension containing customization. For instance: # Sample alias alias gaa = \"git add --all\" We can now adapt our Dockerfile to load these changes when the Docker image is built (and of course, do nothing if there is no file): ... RUN echo \"[ -f PATH_TO_WORKSPACE/me/bashrc_extension ] && . PATH_TO_WORKSPACE/me/bashrc_extension\" >> ~/.bashrc ; ...","title":"Allow some customization"},{"location":"developer-experience/onboarding-guide-template/","text":"Onboarding Guide Template When developing an onboarding document for a team, it should contain details of engagement scope, team processes, codebase, coding standards, team agreements, software requirements and setup details. The onboarding guide can be used as an index to project specific content if it already exists elsewhere. Allowing this guide to be utilized as a foundation with the links will help keep the guide concise and effective. Overview and Goals List a few sentences explaining the high-level summary and the scope of the engagement. Consider adding any additional background and context as needed. Include the value proposition of the project, goals, what success looks like, and what the team is trying to achieve and why. Contacts List a few of the main contacts for the team and project overall such as the Dev Lead and Product Owner. Consider including the roles of these main contacts so that the team knows who to reach out to depending on the situation. Team Agreement and Code of Conduct Include the team's code of conduct or agreement that defines a set of expectation from each team member and how the team has agreed to operate. Working Agreement Template - working agreement Dev Environment Setup Consider adding steps to run the project end-to-end. This could be in form of a separate wiki page or document that can be linked here. Include any software that needs to be downloaded and specify if a specific version of the software is needed. Project Building Blocks This can include a more in depth description with different areas of the project to help increase the project understanding. It can include different sections on the various components of the project including deployment, e2e testing, repositories. Helpful Resources and Links This can include any additional links to documents related to the project It may include links to backlog items, work items, wiki pages or project history.","title":"Onboarding Guide Template"},{"location":"developer-experience/onboarding-guide-template/#onboarding-guide-template","text":"When developing an onboarding document for a team, it should contain details of engagement scope, team processes, codebase, coding standards, team agreements, software requirements and setup details. The onboarding guide can be used as an index to project specific content if it already exists elsewhere. Allowing this guide to be utilized as a foundation with the links will help keep the guide concise and effective.","title":"Onboarding Guide Template"},{"location":"developer-experience/onboarding-guide-template/#overview-and-goals","text":"List a few sentences explaining the high-level summary and the scope of the engagement. Consider adding any additional background and context as needed. Include the value proposition of the project, goals, what success looks like, and what the team is trying to achieve and why.","title":"Overview and Goals"},{"location":"developer-experience/onboarding-guide-template/#contacts","text":"List a few of the main contacts for the team and project overall such as the Dev Lead and Product Owner. Consider including the roles of these main contacts so that the team knows who to reach out to depending on the situation.","title":"Contacts"},{"location":"developer-experience/onboarding-guide-template/#team-agreement-and-code-of-conduct","text":"Include the team's code of conduct or agreement that defines a set of expectation from each team member and how the team has agreed to operate. Working Agreement Template - working agreement","title":"Team Agreement and Code of Conduct"},{"location":"developer-experience/onboarding-guide-template/#dev-environment-setup","text":"Consider adding steps to run the project end-to-end. This could be in form of a separate wiki page or document that can be linked here. Include any software that needs to be downloaded and specify if a specific version of the software is needed.","title":"Dev Environment Setup"},{"location":"developer-experience/onboarding-guide-template/#project-building-blocks","text":"This can include a more in depth description with different areas of the project to help increase the project understanding. It can include different sections on the various components of the project including deployment, e2e testing, repositories.","title":"Project Building Blocks"},{"location":"developer-experience/onboarding-guide-template/#helpful-resources-and-links","text":"This can include any additional links to documents related to the project It may include links to backlog items, work items, wiki pages or project history.","title":"Helpful Resources and Links"},{"location":"developer-experience/toggle-vnet-dev-environment/","text":"Toggle VNet on and off for production and development environment Problem Statement When deploying resources on Azure in a secure environment, resources are usually created behind a Private Network (VNet), without public access and with private endpoints to consume resources. This is the recommended approach for pre-production or production environments. Accessing protected resources from a local machine implies one of the following options: Use a VPN Use a jump box With SSH activated (less secure) With Bastion (recommended approach) However, a developer may want to deploy a test environment (in a non-production subscription) for their tests during development phase, without the complexity of networking. In addition, infrastructure code should not be duplicated: it has to be the same whether resources are deployed in a production like environment or in development environment. Option The idea is to offer, via a single boolean variable , the option to deploy resources behind a VNet or not using one infrastructure code base. Securing resources behind a VNet usually implies that public accesses are disabled and private endpoints are created. This is something to have in mind because, as a developer, public access must be activated in order to connect to this environment. The deployment pipeline will set these resources behind a VNet and will secure them by removing public accesses. Developers will be able to run the same deployment script, specifying that resources will not be behind a VNet nor have public accesses disabled. Let's consider the following use case: we want to deploy a VNet, a subnet, a storage account with no public access and a private endpoint for the table. The magic variable that will help toggling security will be called behind_vnet , of type boolean. Let's implement this use case using Terraform . The code below does not contain everything, the purpose is to show the pattern and not how to deploy these resources. For more information on Terraform, please refer to the official documentation . There is no if per se in Terraform to define whether a specific resource should be deployed or not based on a variable value. However, we can use the count meta-argument. The strength of this meta-argument is if its value is 0 , the block is skipped. Here is below the code snippets for this deployment: variables.tf variable \"behind_vnet\" { type = bool } main.tf resource \"azurerm_virtual_network\" \"vnet\" { count = var.behind_vnet ? 1 : 0 name = \"MyVnet\" address_space = [ x.x.x.x / 16 ] resource_group_name = \"MyResourceGroup\" location = \"WestEurope\" ... subnet { name = \"subnet_1\" address_prefix = \"x.x.x.x/24\" } } resource \"azurerm_storage_account\" \"storage_account\" { name = \"storage\" resource_group_name = \"MyResourceGroup\" location = \"WestEurope\" tags = var.tags ... public_network_access_enabled = var.behind_vnet ? false : true } resource \"azurerm_private_endpoint\" \"storage_account_table_private_endpoint\" { count = var.behind_vnet ? 1 : 0 name = \"pe-storage\" subnet_id = azurerm_virtual_network.vnet[0].subnet[0].id ... private_service_connection { name = \"psc-storage\" private_connection_resource_id = azurerm_storage_account.storage_account.id subresource_names = [ \"table\" ] ... } private_dns_zone_group { name = \"privateDnsZoneGroup\" ... } } If we run terraform apply -var behind_vnet = true then all the resources above will be deployed, and it is what we want on a pre-production or production environment. The instruction count = var.behind_vnet ? 1 : 0 will set count with the value 1 , therefore blocks will be executed. However, if we run terraform apply -var behind_vnet = false the azurerm_virtual_network and azurerm_private_endpoint resources will be skipped (because count will be 0 ). The resource azurerm_storage_account will be created, with minor differences in some properties: for instance, here, public_network_access_enabled will be set to true (and this is the goal for a developer to be able to access resources created). The same pattern can be applied over and over for the entire infrastructure code. Conclusion With this approach, the same infrastructure code base can be used to target a production like environment with secured resources behind a VNet with no public accesses and also a more permissive development environment. However, there are a couple of trade-offs with this approach: if a resource has the count argument, it needs to be treated as a list, and not a single item. In the example above, if there is a need to reference the resource azurerm_virtual_network later in the code, azurerm_virtual_network.vnet.id will not work. The following must be used azurerm_virtual_network.vnet[0].id # First (and only) item of the collection The meta-argument count cannot be used with for_each for a whole block. That means that the use of loops to deploy multiple endpoints for instance will not work. Each private endpoints will need to be deployed individually.","title":"Toggle VNet on and off for production and development environment"},{"location":"developer-experience/toggle-vnet-dev-environment/#toggle-vnet-on-and-off-for-production-and-development-environment","text":"","title":"Toggle VNet on and off for production and development environment"},{"location":"developer-experience/toggle-vnet-dev-environment/#problem-statement","text":"When deploying resources on Azure in a secure environment, resources are usually created behind a Private Network (VNet), without public access and with private endpoints to consume resources. This is the recommended approach for pre-production or production environments. Accessing protected resources from a local machine implies one of the following options: Use a VPN Use a jump box With SSH activated (less secure) With Bastion (recommended approach) However, a developer may want to deploy a test environment (in a non-production subscription) for their tests during development phase, without the complexity of networking. In addition, infrastructure code should not be duplicated: it has to be the same whether resources are deployed in a production like environment or in development environment.","title":"Problem Statement"},{"location":"developer-experience/toggle-vnet-dev-environment/#option","text":"The idea is to offer, via a single boolean variable , the option to deploy resources behind a VNet or not using one infrastructure code base. Securing resources behind a VNet usually implies that public accesses are disabled and private endpoints are created. This is something to have in mind because, as a developer, public access must be activated in order to connect to this environment. The deployment pipeline will set these resources behind a VNet and will secure them by removing public accesses. Developers will be able to run the same deployment script, specifying that resources will not be behind a VNet nor have public accesses disabled. Let's consider the following use case: we want to deploy a VNet, a subnet, a storage account with no public access and a private endpoint for the table. The magic variable that will help toggling security will be called behind_vnet , of type boolean. Let's implement this use case using Terraform . The code below does not contain everything, the purpose is to show the pattern and not how to deploy these resources. For more information on Terraform, please refer to the official documentation . There is no if per se in Terraform to define whether a specific resource should be deployed or not based on a variable value. However, we can use the count meta-argument. The strength of this meta-argument is if its value is 0 , the block is skipped. Here is below the code snippets for this deployment: variables.tf variable \"behind_vnet\" { type = bool } main.tf resource \"azurerm_virtual_network\" \"vnet\" { count = var.behind_vnet ? 1 : 0 name = \"MyVnet\" address_space = [ x.x.x.x / 16 ] resource_group_name = \"MyResourceGroup\" location = \"WestEurope\" ... subnet { name = \"subnet_1\" address_prefix = \"x.x.x.x/24\" } } resource \"azurerm_storage_account\" \"storage_account\" { name = \"storage\" resource_group_name = \"MyResourceGroup\" location = \"WestEurope\" tags = var.tags ... public_network_access_enabled = var.behind_vnet ? false : true } resource \"azurerm_private_endpoint\" \"storage_account_table_private_endpoint\" { count = var.behind_vnet ? 1 : 0 name = \"pe-storage\" subnet_id = azurerm_virtual_network.vnet[0].subnet[0].id ... private_service_connection { name = \"psc-storage\" private_connection_resource_id = azurerm_storage_account.storage_account.id subresource_names = [ \"table\" ] ... } private_dns_zone_group { name = \"privateDnsZoneGroup\" ... } } If we run terraform apply -var behind_vnet = true then all the resources above will be deployed, and it is what we want on a pre-production or production environment. The instruction count = var.behind_vnet ? 1 : 0 will set count with the value 1 , therefore blocks will be executed. However, if we run terraform apply -var behind_vnet = false the azurerm_virtual_network and azurerm_private_endpoint resources will be skipped (because count will be 0 ). The resource azurerm_storage_account will be created, with minor differences in some properties: for instance, here, public_network_access_enabled will be set to true (and this is the goal for a developer to be able to access resources created). The same pattern can be applied over and over for the entire infrastructure code.","title":"Option"},{"location":"developer-experience/toggle-vnet-dev-environment/#conclusion","text":"With this approach, the same infrastructure code base can be used to target a production like environment with secured resources behind a VNet with no public accesses and also a more permissive development environment. However, there are a couple of trade-offs with this approach: if a resource has the count argument, it needs to be treated as a list, and not a single item. In the example above, if there is a need to reference the resource azurerm_virtual_network later in the code, azurerm_virtual_network.vnet.id will not work. The following must be used azurerm_virtual_network.vnet[0].id # First (and only) item of the collection The meta-argument count cannot be used with for_each for a whole block. That means that the use of loops to deploy multiple endpoints for instance will not work. Each private endpoints will need to be deployed individually.","title":"Conclusion"},{"location":"documentation/","text":"Documentation Every software development project requires documentation. Agile Software Development values working software over comprehensive documentation . Still, projects should include the key information needed to understand the development and the use of the generated software. Documentation shouldn't be an afterthought. Different written documents and materials should be created during the whole life cycle of the project, as per the project needs. Table of Contents Goals Challenges What documentation should exist? Best practices Tools Recipes Resources Goals Facilitate onboarding of new team members. Improve communication and collaboration between teams (especially when distributed across time zones). Improve the transition of the project to another team. Challenges When working in an engineering project, we typically encounter one or more of these challenges related to documentation (including some examples): Non-existent . No onboarding documentation, so it takes a long time to set up the environment when you join the project. No document in the wiki explaining existing repositories, so you cannot tell which of the 10 available repositories you should clone. No main README, so you don't know where to start when you clone a repository. No \"how to contribute\" section, so you don't know which is the branch policy, where to add new documents, etc. No code guidelines, so everyone follows different naming conventions, etc. Hidden . Impossible to find useful documentation as it\u2019s scattered all over the place. E.g., no idea how to compile, run and test the code as the README is hidden in a folder within a folder within a folder. Useful processes (e.g., grooming process) explained outside the backlog management tool and not linked anywhere. Decisions taken in different channels other than the backlog management tool and not recorded anywhere else. Incomplete . No clear branch policy, so everyone names their branches differently. Missing settings in the \"how to run this\" document that are required to run the application. Inaccurate . Documents not updated along with the code, so they don't mention the right folders, settings, etc. Obsolete . Design documents that don't apply anymore, sitting next to valid documents. Which one shows the latest decisions? Out of order (subject / date) . Documents not organized per subject/workstream so not easy to find relevant information when you change to a new workstream. Design decision logs out of order and without a date that helps to determine which is the final decision on something. Duplicate . No settings file available in a centralized place as a single source of truth, so developers must keep sharing their own versions, and we end up with many files that might or might not work. Afterthought . Key documents created several weeks into the project: onboarding, how to run the app, etc. Documents created last minute just before the end of a project, forgetting that they also help the team while working on the project. What documentation should exist Project and Repositories Commit Messages Pull Requests Code Work Items REST APIs Engineering Feedback Best practices Establishing and managing documentation Creating good documentation Replacing documentation with automation Tools Wikis Languages markdown mermaid How to automate simple checks Integration with Teams/Slack Recipes How to sync a wiki between repositories Using DocFx and Companion Tools to generate a Documentation website Deploy the DocFx Documentation website to an Azure Website automatically How to create a static website for your documentation based on MkDocs and Material for MkDocs Resources Software Documentation Types and Best Practices","title":"Documentation"},{"location":"documentation/#documentation","text":"Every software development project requires documentation. Agile Software Development values working software over comprehensive documentation . Still, projects should include the key information needed to understand the development and the use of the generated software. Documentation shouldn't be an afterthought. Different written documents and materials should be created during the whole life cycle of the project, as per the project needs.","title":"Documentation"},{"location":"documentation/#table-of-contents","text":"Goals Challenges What documentation should exist? Best practices Tools Recipes Resources","title":"Table of Contents"},{"location":"documentation/#goals","text":"Facilitate onboarding of new team members. Improve communication and collaboration between teams (especially when distributed across time zones). Improve the transition of the project to another team.","title":"Goals"},{"location":"documentation/#challenges","text":"When working in an engineering project, we typically encounter one or more of these challenges related to documentation (including some examples): Non-existent . No onboarding documentation, so it takes a long time to set up the environment when you join the project. No document in the wiki explaining existing repositories, so you cannot tell which of the 10 available repositories you should clone. No main README, so you don't know where to start when you clone a repository. No \"how to contribute\" section, so you don't know which is the branch policy, where to add new documents, etc. No code guidelines, so everyone follows different naming conventions, etc. Hidden . Impossible to find useful documentation as it\u2019s scattered all over the place. E.g., no idea how to compile, run and test the code as the README is hidden in a folder within a folder within a folder. Useful processes (e.g., grooming process) explained outside the backlog management tool and not linked anywhere. Decisions taken in different channels other than the backlog management tool and not recorded anywhere else. Incomplete . No clear branch policy, so everyone names their branches differently. Missing settings in the \"how to run this\" document that are required to run the application. Inaccurate . Documents not updated along with the code, so they don't mention the right folders, settings, etc. Obsolete . Design documents that don't apply anymore, sitting next to valid documents. Which one shows the latest decisions? Out of order (subject / date) . Documents not organized per subject/workstream so not easy to find relevant information when you change to a new workstream. Design decision logs out of order and without a date that helps to determine which is the final decision on something. Duplicate . No settings file available in a centralized place as a single source of truth, so developers must keep sharing their own versions, and we end up with many files that might or might not work. Afterthought . Key documents created several weeks into the project: onboarding, how to run the app, etc. Documents created last minute just before the end of a project, forgetting that they also help the team while working on the project.","title":"Challenges"},{"location":"documentation/#what-documentation-should-exist","text":"Project and Repositories Commit Messages Pull Requests Code Work Items REST APIs Engineering Feedback","title":"What documentation should exist"},{"location":"documentation/#best-practices","text":"Establishing and managing documentation Creating good documentation Replacing documentation with automation","title":"Best practices"},{"location":"documentation/#tools","text":"Wikis Languages markdown mermaid How to automate simple checks Integration with Teams/Slack","title":"Tools"},{"location":"documentation/#recipes","text":"How to sync a wiki between repositories Using DocFx and Companion Tools to generate a Documentation website Deploy the DocFx Documentation website to an Azure Website automatically How to create a static website for your documentation based on MkDocs and Material for MkDocs","title":"Recipes"},{"location":"documentation/#resources","text":"Software Documentation Types and Best Practices","title":"Resources"},{"location":"documentation/best-practices/automation/","text":"Replacing Documentation with Automation You can document how to set up your dev machine with the right version of the framework required to run the code, which extensions are useful to develop the application with your editor, or how to configure your editor to launch and debug the application. If it is possible, a better solution is to provide the means to automate tool installs, application startup, etc., instead. Some examples are provided below: Dev containers in Visual Studio Code The Visual Studio Code Remote - Containers extension lets you use a Docker container as a full-featured development environment. It allows you to open any folder inside (or mounted into) a container and take advantage of Visual Studio Code's full feature set. Additional information: Developing inside a Container . Launch configurations and Tasks in Visual Studio Code Launch configurations allows you to configure and save debugging setup details. Tasks can be configured to run scripts and start processes so that many of these existing tools can be used from within VS Code without having to enter a command line or write new code.","title":"Replacing Documentation with Automation"},{"location":"documentation/best-practices/automation/#replacing-documentation-with-automation","text":"You can document how to set up your dev machine with the right version of the framework required to run the code, which extensions are useful to develop the application with your editor, or how to configure your editor to launch and debug the application. If it is possible, a better solution is to provide the means to automate tool installs, application startup, etc., instead. Some examples are provided below:","title":"Replacing Documentation with Automation"},{"location":"documentation/best-practices/automation/#dev-containers-in-visual-studio-code","text":"The Visual Studio Code Remote - Containers extension lets you use a Docker container as a full-featured development environment. It allows you to open any folder inside (or mounted into) a container and take advantage of Visual Studio Code's full feature set. Additional information: Developing inside a Container .","title":"Dev containers in Visual Studio Code"},{"location":"documentation/best-practices/automation/#launch-configurations-and-tasks-in-visual-studio-code","text":"Launch configurations allows you to configure and save debugging setup details. Tasks can be configured to run scripts and start processes so that many of these existing tools can be used from within VS Code without having to enter a command line or write new code.","title":"Launch configurations and Tasks in Visual Studio Code"},{"location":"documentation/best-practices/establish-and-manage/","text":"Establishing and Managing Documentation Documentation should be source-controlled. Pull Requests can be used to tell others about the changes, so they can be reviewed and discussed. E.g., Async Design Reviews . Tools: Wikis .","title":"Establishing and Managing Documentation"},{"location":"documentation/best-practices/establish-and-manage/#establishing-and-managing-documentation","text":"Documentation should be source-controlled. Pull Requests can be used to tell others about the changes, so they can be reviewed and discussed. E.g., Async Design Reviews . Tools: Wikis .","title":"Establishing and Managing Documentation"},{"location":"documentation/best-practices/good-documentation/","text":"Creating Good Documentation Review the Documentation Review Checklist for advice on how to write good documentation. Good documentation should follow good writing guidelines: Writing Style Guidelines .","title":"Creating Good Documentation"},{"location":"documentation/best-practices/good-documentation/#creating-good-documentation","text":"Review the Documentation Review Checklist for advice on how to write good documentation. Good documentation should follow good writing guidelines: Writing Style Guidelines .","title":"Creating Good Documentation"},{"location":"documentation/guidance/code/","text":"Code You might have heard more than once that you should write self-documenting code . This doesn't mean that you should never comment your code. There are two types of code comments, implementation comments and documentation comments. Implementation comments They are used for internal documentation, and are intended for anyone who may need to maintain the code in the future, including your future self. There can be single line and multi-line comments (e.g., C# Comments ). Comments are human-readable and not executed, thus ignored by the compiler. So you could potentially add as many as you want. Now, the use of these comments is often considered a code smell. If you need to clarify your code, that may mean the code is too complex. So you should work towards the removal of the clarification by making the code simpler, easier to read, and understand. Still, these comments can be useful to give overviews of the code, or provide additional context information that is not available in the code itself. Examples of useful comments: Single line comment in C# that explains why that piece of code is there (from a private method in System.Text.Json.JsonSerializer ): // For performance, avoid obtaining actual byte count unless memory usage is higher than the threshold. Span < byte > utf8 = json . Length <= ( ArrayPoolMaxSizeBeforeUsingNormalAlloc / JsonConstants . MaxExpansionFactorWhileTranscoding ) ? ... Multi-line comment in C# that provides additional context (from a private method in System.Text.Json.Utf8JsonReader ): // Transcoding from UTF-16 to UTF-8 will change the length by somewhere between 1x and 3x. // Un-escaping the token value will at most shrink its length by 6x. // There is no point incurring the transcoding/un-escaping/comparing cost if: // - The token value is smaller than charTextLength // - The token value needs to be transcoded AND unescaped and it is more than 6x larger than charTextLength // - For an ASCII UTF-16 characters, transcoding = 1x, escaping = 6x => 6x factor // - For non-ASCII UTF-16 characters within the BMP, transcoding = 2-3x, but they are represented as a single escaped hex value, \\uXXXX => 6x factor // - For non-ASCII UTF-16 characters outside of the BMP, transcoding = 4x, but the surrogate pair (2 characters) are represented by 16 bytes \\uXXXX\\uXXXX => 6x factor // - The token value needs to be transcoded, but NOT escaped and it is more than 3x larger than charTextLength // - For an ASCII UTF-16 characters, transcoding = 1x, // - For non-ASCII UTF-16 characters within the BMP, transcoding = 2-3x, // - For non-ASCII UTF-16 characters outside of the BMP, transcoding = 2x, (surrogate pairs - 2 characters transcode to 4 UTF-8 bytes) if ( sourceLength < charTextLength || sourceLength / ( _stringHasEscaping ? JsonConstants . MaxExpansionFactorWhileEscaping : JsonConstants . MaxExpansionFactorWhileTranscoding ) > charTextLength ) { Documentation comments Doc comments are a special kind of comment, added above the definition of any user-defined type or member, and are intended for anyone who may need to use those types or members in their own code. If, for example, you are building a library or framework, doc comments can be used to generate their documentation. This documentation should serve as API specification, and/or programming guide. Doc comments won't be included by the compiler in the final executable, as with single and multi-line comments. Example of a doc comment in C# (from Deserialize method in System.Text.Json.JsonSerializer ): /// <summary> /// Parse the text representing a single JSON value into a <typeparamref name=\"TValue\"/>. /// </summary> /// <returns>A <typeparamref name=\"TValue\"/> representation of the JSON value.</returns> /// <param name=\"json\">JSON text to parse.</param> /// <param name=\"options\">Options to control the behavior during parsing.</param> /// <exception cref=\"System.ArgumentNullException\"> /// <paramref name=\"json\"/> is <see langword=\"null\"/>. /// </exception> /// <exception cref=\"JsonException\"> /// The JSON is invalid. /// /// -or- /// /// <typeparamref name=\"TValue\" /> is not compatible with the JSON. /// /// -or- /// /// There is remaining data in the string beyond a single JSON value.</exception> /// <exception cref=\"NotSupportedException\"> /// There is no compatible <see cref=\"System.Text.Json.Serialization.JsonConverter\"/> /// for <typeparamref name=\"TValue\"/> or its serializable members. /// </exception> /// <remarks>Using a <see cref=\"string\"/> is not as efficient as using the /// UTF-8 methods since the implementation natively uses UTF-8. /// </remarks> [RequiresUnreferencedCode(SerializationUnreferencedCodeMessage)] public static TValue ? Deserialize < TValue > ( string json , JsonSerializerOptions ? options = null ) { In C# , doc comments can be processed by the compiler to generate XML documentation files. These files can be distributed alongside your libraries so that Visual Studio and other IDEs can use IntelliSense to show quick information about types or members. Additionally, these files can be run through tools like DocFx to generate API reference websites. More information: Recommended XML tags for C# documentation comments . In other languages, you may require external tools. For example, Java doc comments can be processed by Javadoc tool to generate HTML documentation files. More information: How to Write Doc Comments for the Javadoc Tool Javadoc Tool","title":"Code"},{"location":"documentation/guidance/code/#code","text":"You might have heard more than once that you should write self-documenting code . This doesn't mean that you should never comment your code. There are two types of code comments, implementation comments and documentation comments.","title":"Code"},{"location":"documentation/guidance/code/#implementation-comments","text":"They are used for internal documentation, and are intended for anyone who may need to maintain the code in the future, including your future self. There can be single line and multi-line comments (e.g., C# Comments ). Comments are human-readable and not executed, thus ignored by the compiler. So you could potentially add as many as you want. Now, the use of these comments is often considered a code smell. If you need to clarify your code, that may mean the code is too complex. So you should work towards the removal of the clarification by making the code simpler, easier to read, and understand. Still, these comments can be useful to give overviews of the code, or provide additional context information that is not available in the code itself. Examples of useful comments: Single line comment in C# that explains why that piece of code is there (from a private method in System.Text.Json.JsonSerializer ): // For performance, avoid obtaining actual byte count unless memory usage is higher than the threshold. Span < byte > utf8 = json . Length <= ( ArrayPoolMaxSizeBeforeUsingNormalAlloc / JsonConstants . MaxExpansionFactorWhileTranscoding ) ? ... Multi-line comment in C# that provides additional context (from a private method in System.Text.Json.Utf8JsonReader ): // Transcoding from UTF-16 to UTF-8 will change the length by somewhere between 1x and 3x. // Un-escaping the token value will at most shrink its length by 6x. // There is no point incurring the transcoding/un-escaping/comparing cost if: // - The token value is smaller than charTextLength // - The token value needs to be transcoded AND unescaped and it is more than 6x larger than charTextLength // - For an ASCII UTF-16 characters, transcoding = 1x, escaping = 6x => 6x factor // - For non-ASCII UTF-16 characters within the BMP, transcoding = 2-3x, but they are represented as a single escaped hex value, \\uXXXX => 6x factor // - For non-ASCII UTF-16 characters outside of the BMP, transcoding = 4x, but the surrogate pair (2 characters) are represented by 16 bytes \\uXXXX\\uXXXX => 6x factor // - The token value needs to be transcoded, but NOT escaped and it is more than 3x larger than charTextLength // - For an ASCII UTF-16 characters, transcoding = 1x, // - For non-ASCII UTF-16 characters within the BMP, transcoding = 2-3x, // - For non-ASCII UTF-16 characters outside of the BMP, transcoding = 2x, (surrogate pairs - 2 characters transcode to 4 UTF-8 bytes) if ( sourceLength < charTextLength || sourceLength / ( _stringHasEscaping ? JsonConstants . MaxExpansionFactorWhileEscaping : JsonConstants . MaxExpansionFactorWhileTranscoding ) > charTextLength ) {","title":"Implementation comments"},{"location":"documentation/guidance/code/#documentation-comments","text":"Doc comments are a special kind of comment, added above the definition of any user-defined type or member, and are intended for anyone who may need to use those types or members in their own code. If, for example, you are building a library or framework, doc comments can be used to generate their documentation. This documentation should serve as API specification, and/or programming guide. Doc comments won't be included by the compiler in the final executable, as with single and multi-line comments. Example of a doc comment in C# (from Deserialize method in System.Text.Json.JsonSerializer ): /// <summary> /// Parse the text representing a single JSON value into a <typeparamref name=\"TValue\"/>. /// </summary> /// <returns>A <typeparamref name=\"TValue\"/> representation of the JSON value.</returns> /// <param name=\"json\">JSON text to parse.</param> /// <param name=\"options\">Options to control the behavior during parsing.</param> /// <exception cref=\"System.ArgumentNullException\"> /// <paramref name=\"json\"/> is <see langword=\"null\"/>. /// </exception> /// <exception cref=\"JsonException\"> /// The JSON is invalid. /// /// -or- /// /// <typeparamref name=\"TValue\" /> is not compatible with the JSON. /// /// -or- /// /// There is remaining data in the string beyond a single JSON value.</exception> /// <exception cref=\"NotSupportedException\"> /// There is no compatible <see cref=\"System.Text.Json.Serialization.JsonConverter\"/> /// for <typeparamref name=\"TValue\"/> or its serializable members. /// </exception> /// <remarks>Using a <see cref=\"string\"/> is not as efficient as using the /// UTF-8 methods since the implementation natively uses UTF-8. /// </remarks> [RequiresUnreferencedCode(SerializationUnreferencedCodeMessage)] public static TValue ? Deserialize < TValue > ( string json , JsonSerializerOptions ? options = null ) { In C# , doc comments can be processed by the compiler to generate XML documentation files. These files can be distributed alongside your libraries so that Visual Studio and other IDEs can use IntelliSense to show quick information about types or members. Additionally, these files can be run through tools like DocFx to generate API reference websites. More information: Recommended XML tags for C# documentation comments . In other languages, you may require external tools. For example, Java doc comments can be processed by Javadoc tool to generate HTML documentation files. More information: How to Write Doc Comments for the Javadoc Tool Javadoc Tool","title":"Documentation comments"},{"location":"documentation/guidance/engineering-feedback/","text":"Engineering Feedback Good engineering feedback is: Actionable Specific Detailed Includes assets (script, data, code, etc.) to reproduce scenario and validate solution Includes details about the customer scenario / what the customer was trying to achieve Refer to Microsoft Engineering Feedback for more details, including guidance , FAQ and examples .","title":"Engineering Feedback"},{"location":"documentation/guidance/engineering-feedback/#engineering-feedback","text":"Good engineering feedback is: Actionable Specific Detailed Includes assets (script, data, code, etc.) to reproduce scenario and validate solution Includes details about the customer scenario / what the customer was trying to achieve Refer to Microsoft Engineering Feedback for more details, including guidance , FAQ and examples .","title":"Engineering Feedback"},{"location":"documentation/guidance/project-and-repositories/","text":"Projects and Repositories Every source code repository should include documentation that is specific to it (e.g., in a Wiki within the repository), while the project itself should include general documentation that is common to all its associated repositories (e.g., in a Wiki within the backlog management tool). Documentation specific to a repository Introduction Getting started Onboarding Setup: programming language, frameworks, platforms, tools, etc. Sandbox environment Working agreement Contributing guide Structure: folders, projects, etc. How to compile, test, build, deploy the solution/each project Different OS versions Command line + editors/IDEs Design Decision Logs Architecture Decision Record (ADRs) Trade Studies Some sections in the documentation of the repository might point to the project\u2019s documentation (e.g., Onboarding, Working Agreement, Contributing Guide). Common documentation to all repositories Introduction Project Stakeholders Definitions Requirements Onboarding Repository guide Production, Spikes Team agreements Team Manifesto Short summary of expectations around the technical way of working and supported mindset in the team. E.g., ownership, respect, collaboration, transparency. Working Agreement How we work together as a team and what our expectations and principles are. E.g., communication, work-life balance, scrum rhythm, backlog management, code management. Definition of Done List of tasks that must be completed to close a user story, a sprint, or a milestone. Definition of Ready How complete a user story should be in order to be selected as candidate for estimation in the sprint planning. Contributing Guide Repo structure Design documents Branching and branch name strategy Merge and commit history strategy Pull Requests Code Review Process Code Review Checklist Language Specific Checklists Project Design High Level / Game Plan Milestone / Epic Design Review Design Review Recipes Milestone / Epic Design Review Template Feature / Story Design Review Template Task Design Review Template Decision Log Template Architecture Decision Record (ADR) Template ( Example 1 , Example 2 ) Trade Study Template","title":"Projects and Repositories"},{"location":"documentation/guidance/project-and-repositories/#projects-and-repositories","text":"Every source code repository should include documentation that is specific to it (e.g., in a Wiki within the repository), while the project itself should include general documentation that is common to all its associated repositories (e.g., in a Wiki within the backlog management tool).","title":"Projects and Repositories"},{"location":"documentation/guidance/project-and-repositories/#documentation-specific-to-a-repository","text":"Introduction Getting started Onboarding Setup: programming language, frameworks, platforms, tools, etc. Sandbox environment Working agreement Contributing guide Structure: folders, projects, etc. How to compile, test, build, deploy the solution/each project Different OS versions Command line + editors/IDEs Design Decision Logs Architecture Decision Record (ADRs) Trade Studies Some sections in the documentation of the repository might point to the project\u2019s documentation (e.g., Onboarding, Working Agreement, Contributing Guide).","title":"Documentation specific to a repository"},{"location":"documentation/guidance/project-and-repositories/#common-documentation-to-all-repositories","text":"Introduction Project Stakeholders Definitions Requirements Onboarding Repository guide Production, Spikes Team agreements Team Manifesto Short summary of expectations around the technical way of working and supported mindset in the team. E.g., ownership, respect, collaboration, transparency. Working Agreement How we work together as a team and what our expectations and principles are. E.g., communication, work-life balance, scrum rhythm, backlog management, code management. Definition of Done List of tasks that must be completed to close a user story, a sprint, or a milestone. Definition of Ready How complete a user story should be in order to be selected as candidate for estimation in the sprint planning. Contributing Guide Repo structure Design documents Branching and branch name strategy Merge and commit history strategy Pull Requests Code Review Process Code Review Checklist Language Specific Checklists Project Design High Level / Game Plan Milestone / Epic Design Review Design Review Recipes Milestone / Epic Design Review Template Feature / Story Design Review Template Task Design Review Template Decision Log Template Architecture Decision Record (ADR) Template ( Example 1 , Example 2 ) Trade Study Template","title":"Common documentation to all repositories"},{"location":"documentation/guidance/pull-requests/","text":"Pull Requests When we create Pull Requests , we must ensure they are properly documented: Title and Description Pull Request Description Pull Request Template Linked worked items Comments As an author, address all comments As a reviewer, make comments clear","title":"Pull Requests"},{"location":"documentation/guidance/pull-requests/#pull-requests","text":"When we create Pull Requests , we must ensure they are properly documented: Title and Description Pull Request Description Pull Request Template Linked worked items Comments As an author, address all comments As a reviewer, make comments clear","title":"Pull Requests"},{"location":"documentation/guidance/rest-apis/","text":"REST APIs When creating REST APIs , you can leverage the OpenAPI-Specification (OAI) (originally known as the Swagger Specification) to describe them: The OpenAPI Specification (OAS) defines a standard, programming language-agnostic interface description for HTTP APIs, which allows both humans and computers to discover and understand the capabilities of a service without requiring access to source code, additional documentation, or inspection of network traffic. When properly defined via OpenAPI, a consumer can understand and interact with the remote service with a minimal amount of implementation logic. Use cases for machine-readable API definition documents include, but are not limited to: interactive documentation; code generation for documentation, clients, and servers; and automation of test cases. OpenAPI documents describe an APIs services and are represented in either YAML or JSON formats. These documents may either be produced and served statically or be generated dynamically from an application. There are implementations available for many languages like C#, including low-level tooling, editors, user interfaces, code generators, etc. Here you can find a list of known tooling for the different languages: OpenAPI-Specification/IMPLEMENTATIONS.md . Using Microsoft TypeSpec While the OpenAPI-Specification (OAI) is a popular method for defining and documenting RESTful APIs, there are other languages available that can simplify and expedite the documentation process. Microsoft TypeSpec is one such language that allows for the description of cloud service APIs and the generation of API description languages, client and service code, documentation, and other assets. Microsoft TypeSpec is a highly extensible language that offers a set of core primitives that can describe API shapes common among REST, OpenAPI, GraphQL, gRPC, and other protocols. This makes it a versatile option for developers who need to work with a range of different API styles and technologies. Microsoft TypeSpec is a widely adopted tool within Azure teams, particularly for generating OpenAPI Specifications in complex and interconnected APIs that span multiple teams. To ensure consistency across different parts of the API, teams commonly leverage shared libraries which contain reusable patterns. This makes easier to follow best practices rather than deviating from them. By promoting highly regular API designs that adhere to best practices by construction, TypeSpec can help improve the quality and consistency of APIs developed within an organization. References ASP.NET Core web API documentation with Swagger / OpenAPI . Microsoft TypeSpec . Design Patterns - REST API Guidance","title":"REST APIs"},{"location":"documentation/guidance/rest-apis/#rest-apis","text":"When creating REST APIs , you can leverage the OpenAPI-Specification (OAI) (originally known as the Swagger Specification) to describe them: The OpenAPI Specification (OAS) defines a standard, programming language-agnostic interface description for HTTP APIs, which allows both humans and computers to discover and understand the capabilities of a service without requiring access to source code, additional documentation, or inspection of network traffic. When properly defined via OpenAPI, a consumer can understand and interact with the remote service with a minimal amount of implementation logic. Use cases for machine-readable API definition documents include, but are not limited to: interactive documentation; code generation for documentation, clients, and servers; and automation of test cases. OpenAPI documents describe an APIs services and are represented in either YAML or JSON formats. These documents may either be produced and served statically or be generated dynamically from an application. There are implementations available for many languages like C#, including low-level tooling, editors, user interfaces, code generators, etc. Here you can find a list of known tooling for the different languages: OpenAPI-Specification/IMPLEMENTATIONS.md .","title":"REST APIs"},{"location":"documentation/guidance/rest-apis/#using-microsoft-typespec","text":"While the OpenAPI-Specification (OAI) is a popular method for defining and documenting RESTful APIs, there are other languages available that can simplify and expedite the documentation process. Microsoft TypeSpec is one such language that allows for the description of cloud service APIs and the generation of API description languages, client and service code, documentation, and other assets. Microsoft TypeSpec is a highly extensible language that offers a set of core primitives that can describe API shapes common among REST, OpenAPI, GraphQL, gRPC, and other protocols. This makes it a versatile option for developers who need to work with a range of different API styles and technologies. Microsoft TypeSpec is a widely adopted tool within Azure teams, particularly for generating OpenAPI Specifications in complex and interconnected APIs that span multiple teams. To ensure consistency across different parts of the API, teams commonly leverage shared libraries which contain reusable patterns. This makes easier to follow best practices rather than deviating from them. By promoting highly regular API designs that adhere to best practices by construction, TypeSpec can help improve the quality and consistency of APIs developed within an organization.","title":"Using Microsoft TypeSpec"},{"location":"documentation/guidance/rest-apis/#references","text":"ASP.NET Core web API documentation with Swagger / OpenAPI . Microsoft TypeSpec . Design Patterns - REST API Guidance","title":"References"},{"location":"documentation/guidance/work-items/","text":"Work Items While many teams can work with a flat list of items, sometimes it helps to group related items into a hierarchical structure. You can use portfolio backlogs to bring more order to your backlog. Agile process backlog work item hierarchy: Scrum process backlog work item hierarchy: Bugs can be set at the same level as User Stories / Product Backlog Items or Tasks. Epics and Features User stories / Product Backlog Items roll up into Features , which typically represent a shippable deliverable that addresses a customer need e.g., \"Add shopping cart\". And Features roll up into Epics , which represent a business initiative to be accomplished e.g., \"Increase customer engagement\". Take that into account when naming them. Each Feature or Epic should include as much detail as the team needs to: Understand the scope. Estimate the work required. Develop tests. Ensure the end product meets acceptance criteria. Details that should be added: Value Area : Business (directly deliver customer value) vs. Architectural (technical services to implement business features). Effort / Story Points / Size : Relative estimate of the amount of work required to complete the item. Business Value : Priority of an item compared to other items of the same type. Time Criticality : Higher values indicate an item is more time critical than items with lower values. Target Date by which the feature should be implemented. You may use work item tags to support queries and filtering. User Stories / Product Backlog Items Each User Story / Product Backlog Item should be sized so that they can be completed within a sprint. You should add the following details to the items: Title : Usually expressed as \"As a [persona], I want [to perform an action], so that [I can achieve an end result].\". Description : Provide enough detail to create shared understanding of scope and support estimation efforts. Focus on the user, what they want to accomplish, and why. Don't describe how to develop the product. Provide enough details so the team can write tasks and test cases to implement the item. Include Design Reviews. Acceptance Criteria : Define what \"Done\" means. Activity : Deployment, Design, Development, Documentation, Requirements, Testing. Effort / Story Points / Size : Relative estimate of the amount of work required to complete the item. Business Value : Priority of an item compared to other items of the same type. Original Estimate : The amount of estimated work required to complete a task. Remember to use the Discussion section of the items to keep track of related comments, and mention individuals, groups, work items or pull requests when required. Tasks Each Task should be sized so that they can be completed within a day. You should at least add the following details to the items: Title . Description : Provide enough detail to create shared understanding of scope. Any developer should be able to take the item and know what needs to be implemented. Include Design Reviews. Reference to the working branch in related code repository. Remember to use the Discussion section of the tasks to keep track of related comments. Bugs You should use bugs to capture both the initial issue and ongoing discoveries. You should at least add the following details to the bug items: Title . Description . Steps to Reproduce . System Info / Found in Build : Software and system configuration that is relevant to the bug and tests to apply. Acceptance Criteria : Criteria to meet so the bug can be closed. Integrated in Build : Name of the build that incorporates the code that fixes the bug. Priority : 1: Product should not ship without the successful resolution of the work item. The bug should be addressed as soon as possible. 2: Product should not ship without the successful resolution of the work item, but it does not need to be addressed immediately. 3: Resolution of the work item is optional based on resources, time, and risk. Severity : 1 - Critical: Must fix. No acceptable alternative methods. 2 - High: Consider fix. An acceptable alternative method exists. 3 - Medium: (Default). 4 - Low. Issues / Impediments Don't confuse with bugs. They represent unplanned activities that may block work from getting done. For example: feature ambiguity, personnel or resource issues, problems with environments, or other risks that impact scope, quality, or schedule. In general, you link these items to user stories or other work items. Actions from Retrospectives After a retrospective, every action that requires work should be tracked with its own Task or Issue / Impediment. These items might be unparented (without link to parent backlog item or user story). Related information Best practices for Agile project management - Azure Boards | Microsoft Docs . Define features and epics, organize backlog items - Azure Boards | Microsoft Docs . Create your product backlog - Azure Boards | Microsoft Docs . Add tasks to support sprint planning - Azure Boards | Microsoft Docs . Define, capture, triage, and manage bugs or code defects - Azure Boards | Microsoft Docs . Add and manage issues or impediments - Azure Boards | Microsoft Docs .","title":"Work Items"},{"location":"documentation/guidance/work-items/#work-items","text":"While many teams can work with a flat list of items, sometimes it helps to group related items into a hierarchical structure. You can use portfolio backlogs to bring more order to your backlog. Agile process backlog work item hierarchy: Scrum process backlog work item hierarchy: Bugs can be set at the same level as User Stories / Product Backlog Items or Tasks.","title":"Work Items"},{"location":"documentation/guidance/work-items/#epics-and-features","text":"User stories / Product Backlog Items roll up into Features , which typically represent a shippable deliverable that addresses a customer need e.g., \"Add shopping cart\". And Features roll up into Epics , which represent a business initiative to be accomplished e.g., \"Increase customer engagement\". Take that into account when naming them. Each Feature or Epic should include as much detail as the team needs to: Understand the scope. Estimate the work required. Develop tests. Ensure the end product meets acceptance criteria. Details that should be added: Value Area : Business (directly deliver customer value) vs. Architectural (technical services to implement business features). Effort / Story Points / Size : Relative estimate of the amount of work required to complete the item. Business Value : Priority of an item compared to other items of the same type. Time Criticality : Higher values indicate an item is more time critical than items with lower values. Target Date by which the feature should be implemented. You may use work item tags to support queries and filtering.","title":"Epics and Features"},{"location":"documentation/guidance/work-items/#user-stories-product-backlog-items","text":"Each User Story / Product Backlog Item should be sized so that they can be completed within a sprint. You should add the following details to the items: Title : Usually expressed as \"As a [persona], I want [to perform an action], so that [I can achieve an end result].\". Description : Provide enough detail to create shared understanding of scope and support estimation efforts. Focus on the user, what they want to accomplish, and why. Don't describe how to develop the product. Provide enough details so the team can write tasks and test cases to implement the item. Include Design Reviews. Acceptance Criteria : Define what \"Done\" means. Activity : Deployment, Design, Development, Documentation, Requirements, Testing. Effort / Story Points / Size : Relative estimate of the amount of work required to complete the item. Business Value : Priority of an item compared to other items of the same type. Original Estimate : The amount of estimated work required to complete a task. Remember to use the Discussion section of the items to keep track of related comments, and mention individuals, groups, work items or pull requests when required.","title":"User Stories / Product Backlog Items"},{"location":"documentation/guidance/work-items/#tasks","text":"Each Task should be sized so that they can be completed within a day. You should at least add the following details to the items: Title . Description : Provide enough detail to create shared understanding of scope. Any developer should be able to take the item and know what needs to be implemented. Include Design Reviews. Reference to the working branch in related code repository. Remember to use the Discussion section of the tasks to keep track of related comments.","title":"Tasks"},{"location":"documentation/guidance/work-items/#bugs","text":"You should use bugs to capture both the initial issue and ongoing discoveries. You should at least add the following details to the bug items: Title . Description . Steps to Reproduce . System Info / Found in Build : Software and system configuration that is relevant to the bug and tests to apply. Acceptance Criteria : Criteria to meet so the bug can be closed. Integrated in Build : Name of the build that incorporates the code that fixes the bug. Priority : 1: Product should not ship without the successful resolution of the work item. The bug should be addressed as soon as possible. 2: Product should not ship without the successful resolution of the work item, but it does not need to be addressed immediately. 3: Resolution of the work item is optional based on resources, time, and risk. Severity : 1 - Critical: Must fix. No acceptable alternative methods. 2 - High: Consider fix. An acceptable alternative method exists. 3 - Medium: (Default). 4 - Low.","title":"Bugs"},{"location":"documentation/guidance/work-items/#issues-impediments","text":"Don't confuse with bugs. They represent unplanned activities that may block work from getting done. For example: feature ambiguity, personnel or resource issues, problems with environments, or other risks that impact scope, quality, or schedule. In general, you link these items to user stories or other work items.","title":"Issues / Impediments"},{"location":"documentation/guidance/work-items/#actions-from-retrospectives","text":"After a retrospective, every action that requires work should be tracked with its own Task or Issue / Impediment. These items might be unparented (without link to parent backlog item or user story).","title":"Actions from Retrospectives"},{"location":"documentation/guidance/work-items/#related-information","text":"Best practices for Agile project management - Azure Boards | Microsoft Docs . Define features and epics, organize backlog items - Azure Boards | Microsoft Docs . Create your product backlog - Azure Boards | Microsoft Docs . Add tasks to support sprint planning - Azure Boards | Microsoft Docs . Define, capture, triage, and manage bugs or code defects - Azure Boards | Microsoft Docs . Add and manage issues or impediments - Azure Boards | Microsoft Docs .","title":"Related information"},{"location":"documentation/recipes/deploy-docfx-azure-website/","text":"Deploy the DocFx Documentation website to an Azure Website automatically In the article Using DocFx and Companion Tools to generate a Documentation website the process is described to generate content of a documentation website using DocFx. This document describes how to setup an Azure Website to host the content and automate the deployment to it using a pipeline in Azure DevOps. The QuickStart sample that is provided for a quick setup of DocFx generation also contains the files explained in this document. Especially the .pipelines and infrastructure folders. The following steps can be followed when using the Quick Start folder. In the infrastructure folder you can find the Terraform files to create the website in an Azure environment. Out of the box, the script will create a website where the documentation content can be deployed to. 1. Install Terraform You can use tools like Chocolatey to install Terraform: choco install terraform 2. Set the proper variables IMPORTANT: Make sure you modify the value of the app_name , rg_name and rg_location variables. The app_name value is appended by azurewebsites.net and must be unique. Otherwise the script will fail that it cannot create the website. In the Quick Start, authentication is disabled. If you want that enabled, make sure you have create an Application in the Azure AD and have the client ID . This client id must be set as the value of the client_id variable in variables.tf . In the main.tf make sure you uncomment the authentication settings in the app-service . For more information see Configure Azure AD authentication - Azure App Service . If you want to set a custom domain for your documentation website with an SSL certificate you have to do some extra steps. You have to create a Key Vault and store the certificate there. Next step is to uncomment and set the values in variables.tf . You also have to uncomment the necessary steps in main.tf . All is indicated by comment-boxes. For more information see Add a TLS/SSL certificate in Azure App Service . Some extra information on SSL certificate, custom domain and Azure App Service can be found in the following paragraphs. If you are familiar with that or don't need it, go ahead and continue with Step 3 . SSL Certificate To secure a website with a custom domain name and a certificate, you can find the steps to take in the article Add a TLS/SSL certificate in Azure App Service . That article also contains a description of ways to obtain a certificate and the requirements for a certificate. Usually you'll get a certificate from the customers IT department. If you want to start with a development certificate to test the process, you can create one yourself. You can do that in PowerShell with the script below. Replace: [YOUR DOMAIN] with the domain you would like to register, e.g. docs.somewhere.com [PASSWORD] with a password of the certificate. It's required for uploading a certificate in the Key Vault to have a password. You'll need this password in that step. [FILENAME] for the output file name of the certificate. You can even insert the path here where it should be store on your machine. You can store this script in a PowerShell script file (ps1 extension). $cert = New-SelfSignedCertificate -CertStoreLocation cert :\\ currentuser \\ my -Subject \"cn=[YOUR DOMAIN]\" -DnsName \"[YOUR DOMAIN]\" $pwd = ConvertTo-SecureString -String '[PASSWORD]' -Force -AsPlainText $path = 'cert:\\currentuser\\my\\' + $cert . thumbprint Export-PfxCertificate -cert $path -FilePath [FILENAME] . pfx -Password $pwd The certificate needs to be stored in the common Key Vault. Go to Settings > Certificates in the left menu of the Key Vault and click Generate/Import . Provide these details: Method of Certificate Creation: Import Certificate name: e.g. ssl-certificate Upload Certificate File: select the file on disc for this. Password: this is the [PASSWORD] we reference earlier. Custom domain registration To use a custom domain a few things need to be done. The process in the Azure portal is described in the article Tutorial: Map an existing custom DNS name to Azure App Service . An important part is described under the header Get a domain verification ID . This ID needs to be registered with the DNS description as a TXT record. Important to know is that this Custom Domain Verification ID is the same for all web resources in the same Azure subscription. See this StackOverflow issue . This means that this ID needs to be registered only once for one Azure Subscription. And this enables (re)creation of an App Service with the custom domain though script. Add Get-permissions for Microsoft Azure App Service The Azure App Service needs to access the Key Vault to get the certificate. This is needed for the first run, but also when the certificate is renewed in the Key Vault. For this purpose the Azure App Service accesses the Key Vault with the App Service resource provided identity. This identity can be found with the service principal name abfa0a7c-a6b6-4736-8310-5855508787cd or Microsoft Azure App Service and is of type Application . This ID is the same for all Azure subscriptions. It needs to have Get-permissions on secrets and certificates. For more information see this article Import a certificate from Key Vault . Add the custom domain and SSL certificate to the App Service Once we have the SSL certificate and there is a complete DNS registration as described, we can uncomment the code in the Terraform script from the Quick Start folder to attach this to the App Service. In this script you need to reference the certificate in the common Key Vault and use it in the custom hostname binding. The custom hostname is assigned in the script as well. The settings ssl_state needs to be SniEnabled if you're using an SSL certificate. Now the creation of the authenticated website with a custom domain is automated. 3. Deploy Azure resources from your local machine Open up a command prompt. For the commands to be executed, you need to have a connection to your Azure subscription. This can be done using Azure Cli . Type this command: az login This will use the web browser to login to your account. You can check the connected subscription with this command: az account show If you have to change to another subscription, use this command where you replace [id] with the id of the subscription to select: az account set --subscription [ id ] Once this is done run this command to initialize: terraform init Now you can run the command to plan what the script will do. You run this command every time changes are made to the terraform scripts: terraform plan Inspect the result shown. If that is what you expect, apply these changes with this command: terraform apply When asked for approval, type \"yes\" and ENTER. You can also add the -auto-approve flag to the apply command. The deployment using Terraform is not included in the pipeline from the Quick Start folder as described in the next step, as that asks for more configuration. But of course that can always be added. 4. Deploy the website from a pipeline The best way to create the resources and deploy to it, is to do this automatically in a pipeline. For this purpose the .pipelines/documentation.yml pipeline is provided. This pipeline is built for an Azure DevOps environment. Create a pipeline and reference this YAML file. IMPORTANT: the Quick Start folder contains a web.config that is needed for deployment to IIS or Azure App Service. This enables the use of the json file for search requests. If you don't have this in place, the search of text will never return anything and result in 404's under the hood. You have to create a Service Connection in your DevOps environment to connect to the Azure Subscription you want to deploy to. IMPORTANT: set the variables AzureConnectionName to the name of the Service Connection and the AzureAppServiceName to the name you determined in the infrastructure/variables.tf . In the Quick Start folder the pipeline uses master as trigger, which means that any push being done to master triggers the pipeline. You will probably change this to another branch.","title":"Deploy the DocFx Documentation website to an Azure Website automatically"},{"location":"documentation/recipes/deploy-docfx-azure-website/#deploy-the-docfx-documentation-website-to-an-azure-website-automatically","text":"In the article Using DocFx and Companion Tools to generate a Documentation website the process is described to generate content of a documentation website using DocFx. This document describes how to setup an Azure Website to host the content and automate the deployment to it using a pipeline in Azure DevOps. The QuickStart sample that is provided for a quick setup of DocFx generation also contains the files explained in this document. Especially the .pipelines and infrastructure folders. The following steps can be followed when using the Quick Start folder. In the infrastructure folder you can find the Terraform files to create the website in an Azure environment. Out of the box, the script will create a website where the documentation content can be deployed to.","title":"Deploy the DocFx Documentation website to an Azure Website automatically"},{"location":"documentation/recipes/deploy-docfx-azure-website/#1-install-terraform","text":"You can use tools like Chocolatey to install Terraform: choco install terraform","title":"1. Install Terraform"},{"location":"documentation/recipes/deploy-docfx-azure-website/#2-set-the-proper-variables","text":"IMPORTANT: Make sure you modify the value of the app_name , rg_name and rg_location variables. The app_name value is appended by azurewebsites.net and must be unique. Otherwise the script will fail that it cannot create the website. In the Quick Start, authentication is disabled. If you want that enabled, make sure you have create an Application in the Azure AD and have the client ID . This client id must be set as the value of the client_id variable in variables.tf . In the main.tf make sure you uncomment the authentication settings in the app-service . For more information see Configure Azure AD authentication - Azure App Service . If you want to set a custom domain for your documentation website with an SSL certificate you have to do some extra steps. You have to create a Key Vault and store the certificate there. Next step is to uncomment and set the values in variables.tf . You also have to uncomment the necessary steps in main.tf . All is indicated by comment-boxes. For more information see Add a TLS/SSL certificate in Azure App Service . Some extra information on SSL certificate, custom domain and Azure App Service can be found in the following paragraphs. If you are familiar with that or don't need it, go ahead and continue with Step 3 .","title":"2. Set the proper variables"},{"location":"documentation/recipes/deploy-docfx-azure-website/#ssl-certificate","text":"To secure a website with a custom domain name and a certificate, you can find the steps to take in the article Add a TLS/SSL certificate in Azure App Service . That article also contains a description of ways to obtain a certificate and the requirements for a certificate. Usually you'll get a certificate from the customers IT department. If you want to start with a development certificate to test the process, you can create one yourself. You can do that in PowerShell with the script below. Replace: [YOUR DOMAIN] with the domain you would like to register, e.g. docs.somewhere.com [PASSWORD] with a password of the certificate. It's required for uploading a certificate in the Key Vault to have a password. You'll need this password in that step. [FILENAME] for the output file name of the certificate. You can even insert the path here where it should be store on your machine. You can store this script in a PowerShell script file (ps1 extension). $cert = New-SelfSignedCertificate -CertStoreLocation cert :\\ currentuser \\ my -Subject \"cn=[YOUR DOMAIN]\" -DnsName \"[YOUR DOMAIN]\" $pwd = ConvertTo-SecureString -String '[PASSWORD]' -Force -AsPlainText $path = 'cert:\\currentuser\\my\\' + $cert . thumbprint Export-PfxCertificate -cert $path -FilePath [FILENAME] . pfx -Password $pwd The certificate needs to be stored in the common Key Vault. Go to Settings > Certificates in the left menu of the Key Vault and click Generate/Import . Provide these details: Method of Certificate Creation: Import Certificate name: e.g. ssl-certificate Upload Certificate File: select the file on disc for this. Password: this is the [PASSWORD] we reference earlier.","title":"SSL Certificate"},{"location":"documentation/recipes/deploy-docfx-azure-website/#custom-domain-registration","text":"To use a custom domain a few things need to be done. The process in the Azure portal is described in the article Tutorial: Map an existing custom DNS name to Azure App Service . An important part is described under the header Get a domain verification ID . This ID needs to be registered with the DNS description as a TXT record. Important to know is that this Custom Domain Verification ID is the same for all web resources in the same Azure subscription. See this StackOverflow issue . This means that this ID needs to be registered only once for one Azure Subscription. And this enables (re)creation of an App Service with the custom domain though script.","title":"Custom domain registration"},{"location":"documentation/recipes/deploy-docfx-azure-website/#add-get-permissions-for-microsoft-azure-app-service","text":"The Azure App Service needs to access the Key Vault to get the certificate. This is needed for the first run, but also when the certificate is renewed in the Key Vault. For this purpose the Azure App Service accesses the Key Vault with the App Service resource provided identity. This identity can be found with the service principal name abfa0a7c-a6b6-4736-8310-5855508787cd or Microsoft Azure App Service and is of type Application . This ID is the same for all Azure subscriptions. It needs to have Get-permissions on secrets and certificates. For more information see this article Import a certificate from Key Vault .","title":"Add Get-permissions for Microsoft Azure App Service"},{"location":"documentation/recipes/deploy-docfx-azure-website/#add-the-custom-domain-and-ssl-certificate-to-the-app-service","text":"Once we have the SSL certificate and there is a complete DNS registration as described, we can uncomment the code in the Terraform script from the Quick Start folder to attach this to the App Service. In this script you need to reference the certificate in the common Key Vault and use it in the custom hostname binding. The custom hostname is assigned in the script as well. The settings ssl_state needs to be SniEnabled if you're using an SSL certificate. Now the creation of the authenticated website with a custom domain is automated.","title":"Add the custom domain and SSL certificate to the App Service"},{"location":"documentation/recipes/deploy-docfx-azure-website/#3-deploy-azure-resources-from-your-local-machine","text":"Open up a command prompt. For the commands to be executed, you need to have a connection to your Azure subscription. This can be done using Azure Cli . Type this command: az login This will use the web browser to login to your account. You can check the connected subscription with this command: az account show If you have to change to another subscription, use this command where you replace [id] with the id of the subscription to select: az account set --subscription [ id ] Once this is done run this command to initialize: terraform init Now you can run the command to plan what the script will do. You run this command every time changes are made to the terraform scripts: terraform plan Inspect the result shown. If that is what you expect, apply these changes with this command: terraform apply When asked for approval, type \"yes\" and ENTER. You can also add the -auto-approve flag to the apply command. The deployment using Terraform is not included in the pipeline from the Quick Start folder as described in the next step, as that asks for more configuration. But of course that can always be added.","title":"3. Deploy Azure resources from your local machine"},{"location":"documentation/recipes/deploy-docfx-azure-website/#4-deploy-the-website-from-a-pipeline","text":"The best way to create the resources and deploy to it, is to do this automatically in a pipeline. For this purpose the .pipelines/documentation.yml pipeline is provided. This pipeline is built for an Azure DevOps environment. Create a pipeline and reference this YAML file. IMPORTANT: the Quick Start folder contains a web.config that is needed for deployment to IIS or Azure App Service. This enables the use of the json file for search requests. If you don't have this in place, the search of text will never return anything and result in 404's under the hood. You have to create a Service Connection in your DevOps environment to connect to the Azure Subscription you want to deploy to. IMPORTANT: set the variables AzureConnectionName to the name of the Service Connection and the AzureAppServiceName to the name you determined in the infrastructure/variables.tf . In the Quick Start folder the pipeline uses master as trigger, which means that any push being done to master triggers the pipeline. You will probably change this to another branch.","title":"4. Deploy the website from a pipeline"},{"location":"documentation/recipes/static-website-with-mkdocs/","text":"How to create a static website for your documentation based on mkdocs and mkdocs-material MkDocs is a tool built to create static websites from raw markdown files. Other alternatives include Sphinx , and Jekyll . We used MkDocs to create ISE Code-With Engineering Playbook static website from the contents in the GitHub repository . Then we deployed it to GitHub Pages . We found MkDocs to be a good choice since: It's easy to set up and looks great even with the vanilla version. It works well with markdown, which is what we already have in the Playbook. It uses a Python stack which is friendly to many contributors of this Playbook. For comparison, Sphinx mainly generates docs from restructured-text (rst) format, and Jekyll is written in Ruby. To setup an MkDocs website, the main assets needed are: An mkdocs.yaml file, similar to the one we have in the Playbook . This is the configuration file that defines the appearance of the website, the navigation, the plugins used and more. A folder named docs (the default value for the directory) that contains the documentation source files. A GitHub Action for automatically generating the website (e.g. on every commit to main), similar to this one from the Playbook . A list of plugins used during the build phase of the website. We specified ours here . And these are the plugins we've used: - Material for MkDocs : Material design appearance and user experience. - pymdown-extensions : Improves the appearance of markdown based content. - mdx_truly_sane_lists : For defining the indent level for lists without having to refactor the entire documentation we already had in the Playbook. Setting up locally is very easy. See Getting Started with MkDocs for details. For publishing the website, there's a good integration with GitHub for storing the website as a GitHub Page . Additional links MkDocs Plugins The best MkDocs plugins and customizations","title":"How to create a static website for your documentation based on mkdocs and mkdocs-material"},{"location":"documentation/recipes/static-website-with-mkdocs/#how-to-create-a-static-website-for-your-documentation-based-on-mkdocs-and-mkdocs-material","text":"MkDocs is a tool built to create static websites from raw markdown files. Other alternatives include Sphinx , and Jekyll . We used MkDocs to create ISE Code-With Engineering Playbook static website from the contents in the GitHub repository . Then we deployed it to GitHub Pages . We found MkDocs to be a good choice since: It's easy to set up and looks great even with the vanilla version. It works well with markdown, which is what we already have in the Playbook. It uses a Python stack which is friendly to many contributors of this Playbook. For comparison, Sphinx mainly generates docs from restructured-text (rst) format, and Jekyll is written in Ruby. To setup an MkDocs website, the main assets needed are: An mkdocs.yaml file, similar to the one we have in the Playbook . This is the configuration file that defines the appearance of the website, the navigation, the plugins used and more. A folder named docs (the default value for the directory) that contains the documentation source files. A GitHub Action for automatically generating the website (e.g. on every commit to main), similar to this one from the Playbook . A list of plugins used during the build phase of the website. We specified ours here . And these are the plugins we've used: - Material for MkDocs : Material design appearance and user experience. - pymdown-extensions : Improves the appearance of markdown based content. - mdx_truly_sane_lists : For defining the indent level for lists without having to refactor the entire documentation we already had in the Playbook. Setting up locally is very easy. See Getting Started with MkDocs for details. For publishing the website, there's a good integration with GitHub for storing the website as a GitHub Page .","title":"How to create a static website for your documentation based on mkdocs and mkdocs-material"},{"location":"documentation/recipes/static-website-with-mkdocs/#additional-links","text":"MkDocs Plugins The best MkDocs plugins and customizations","title":"Additional links"},{"location":"documentation/recipes/sync-wiki-between-repos/","text":"How to Sync a Wiki between Repositories This is a quick guide to mirroring a Project Wiki to another repository. # Clone the wiki git clone < source wiki repo url> # Add mirror repository as a remote cd < source wiki repo working folder> git remote add mirror <mirror repo that must already exist> Now each time you wish to sync run the following to get latest from the source wiki repo: # Get everything git pull -v Warning : Check that the output of the pull shows \"From source repo URL\". If this shows the mirror repo url then you've forgotten to reset the tracking. Run git branch -u origin/wikiMaster then continue. Then run this to push it to the mirror repo and reset the branch to track the source repo again: # Push all branches up to mirror remote git push -u mirror # Reset local to track source remote git branch -u origin/wikiMaster Your output should look like this when run: PS C :\\ Git \\ MyProject . wiki > git pull -v POST git-upload-pack ( 909 bytes ) remote : Azure Repos remote : Found 5 objects to send . ( 0 ms ) Unpacking objects : 100 % ( 5 / 5 ), done . From https ://..... wikiMaster -> origin / wikiMaster Updating 7412b94 .. a0f543b Fast-forward .../ dffffds . md | 4 ++++ 1 file changed , 4 insertions (+) PS C :\\ Git \\ MyProject . wiki > git push -u mirror Enumerating objects : 9 , done . Counting objects : 100 % ( 9 / 9 ), done . Delta compression using up to 8 threads Compressing objects : 100 % ( 5 / 5 ), done . Writing objects : 100 % ( 5 / 5 ), 2 . 08 KiB | 2 . 08 MiB / s , done . Total 5 ( delta 4 ), reused 0 ( delta 0 ) remote : Analyzing objects ... ( 5 / 5 ) ( 6 ms ) remote : Storing packfile ... done ( 48 ms ) remote : Storing index ... done ( 59 ms ) To https ://...... 7412b94 .. a0f543b wikiMaster -> wikiMaster Branch 'wikiMaster' set up to track remote branch 'wikiMaster' from 'mirror' . PS C :\\ Git \\ MyProject . wiki > git branch -u origin / wikiMaster Branch 'wikiMaster' set up to track remote branch 'wikiMaster' from 'origin' .","title":"How to Sync a Wiki between Repositories"},{"location":"documentation/recipes/sync-wiki-between-repos/#how-to-sync-a-wiki-between-repositories","text":"This is a quick guide to mirroring a Project Wiki to another repository. # Clone the wiki git clone < source wiki repo url> # Add mirror repository as a remote cd < source wiki repo working folder> git remote add mirror <mirror repo that must already exist> Now each time you wish to sync run the following to get latest from the source wiki repo: # Get everything git pull -v Warning : Check that the output of the pull shows \"From source repo URL\". If this shows the mirror repo url then you've forgotten to reset the tracking. Run git branch -u origin/wikiMaster then continue. Then run this to push it to the mirror repo and reset the branch to track the source repo again: # Push all branches up to mirror remote git push -u mirror # Reset local to track source remote git branch -u origin/wikiMaster Your output should look like this when run: PS C :\\ Git \\ MyProject . wiki > git pull -v POST git-upload-pack ( 909 bytes ) remote : Azure Repos remote : Found 5 objects to send . ( 0 ms ) Unpacking objects : 100 % ( 5 / 5 ), done . From https ://..... wikiMaster -> origin / wikiMaster Updating 7412b94 .. a0f543b Fast-forward .../ dffffds . md | 4 ++++ 1 file changed , 4 insertions (+) PS C :\\ Git \\ MyProject . wiki > git push -u mirror Enumerating objects : 9 , done . Counting objects : 100 % ( 9 / 9 ), done . Delta compression using up to 8 threads Compressing objects : 100 % ( 5 / 5 ), done . Writing objects : 100 % ( 5 / 5 ), 2 . 08 KiB | 2 . 08 MiB / s , done . Total 5 ( delta 4 ), reused 0 ( delta 0 ) remote : Analyzing objects ... ( 5 / 5 ) ( 6 ms ) remote : Storing packfile ... done ( 48 ms ) remote : Storing index ... done ( 59 ms ) To https ://...... 7412b94 .. a0f543b wikiMaster -> wikiMaster Branch 'wikiMaster' set up to track remote branch 'wikiMaster' from 'mirror' . PS C :\\ Git \\ MyProject . wiki > git branch -u origin / wikiMaster Branch 'wikiMaster' set up to track remote branch 'wikiMaster' from 'origin' .","title":"How to Sync a Wiki between Repositories"},{"location":"documentation/recipes/using-docfx-and-tools/","text":"Using DocFx and Companion Tools to generate a Documentation website If you want an easy way to have a website with all your documentation coming from Markdown files and comments coming from code, you can use DocFx . The website generated by DocFx also includes fast search capabilities. There are some gaps in the DocFx solution, but we've provided companion tools that help you fill those gaps. Also see the blog post Providing quality documentation in your project with DocFx and Companion Tools for more explanation about the solution. Prerequisites This document is followed best by cloning the sample from https://github.com/mtirionMSFT/DocFxQuickStart first. Copy the contents of the QuickStart folder to the root of your own repository to get started in your own environment. Quick Start TLDR; If you want a really quick start using Azure DevOps and Azure App Service without reading the what and how, follow these steps: Azure DevOps: If you don't have it yet, create a project in Azure DevOps and create a Service Connection to your Azure environment . Clone the repository. QuickStart folder: Copy the contents of the QuickStart folder in there repository that can be found on https://github.com/mtirionMSFT/DocFxQuickStart to the root of the repository. Azure: Create a resource group in your Azure environment where the documentation website resources should be created. Create Azure resources: Fill in the default values in infrastructure/variables.tf and run the commands from Step 3 - Deploy Azure resources from your local machine to create the Azure Resources. Pipeline: Fill in the variables in .pipelines/documentation.yml , commit the changes and push the contents of the repository to your branch (possibly through a PR). Now you can create a pipeline in your Azure DevOps project that uses the .pipelines/documentation.yml and run it. Documents and projects folder structure The easiest is to work with a mono repository where documentation and code live together. If that's not the case in your situation but you still want to combine multiple repositories into one documentation website, you'll have to clone all repositories first to be able to combine the information. In this recipe we'll assume a monorepo is used. In the steps below we'll consider the generation of the documentation website from this content structure: \u251c\u2500\u2500 .pipelines // Azure DevOps pipeline for automatic generation and deployment \u2502 \u251c\u2500\u2500 docs // all documents \u2502 \u251c\u2500\u2500 .attachments // all images and other attachments used by documents \u2502 \u251c\u2500\u2500 infrastructure // Terraform scripts for creation of the Azure website \u2502 \u251c\u2500\u2500 src // all projects \u2502 \u251c\u2500\u2500 build // build settings \u2502 \u251c\u2500\u2500 dotnet // .NET build settings \u2502 \u251c\u2500\u2500 Directory.Build.props // project settings for all .NET projects in sub folders \u2502 \u251c\u2500\u2500 [Project folders] \u2502 \u251c\u2500\u2500 x-cross \u2502 \u251c\u2500\u2500 toc.yml // Cross reference definition (optional) \u2502 \u251c\u2500\u2500 .markdownlint.json // Markdownlinter settings \u251c\u2500\u2500 docfx.json // DocFx configuration \u251c\u2500\u2500 index.md // Website landing page \u251c\u2500\u2500 toc.yml // Definition of the website header content links \u251c\u2500\u2500 web.config // web.config to enable search in deployed website We'll be using the DocLinkChecker tool to validate all links in documentation and for orphaned attachments. That's the reason we have all attachments in the .attachments folder. In the generated website from the QuickStart folder you'll see that the hierarchies of documentation and references is combined in the left table of contents. This is achieved by the definition and use of x-cross\\toc.yml . If you don't want the hierarchies combined, just remove the folder and file from your environment and (re)generate the website. A .markdownlint.json is included with the contents below. The MD013 setting is set to false to prevent checking for maximum line length. You can modify this file to your likings to include or exclude certain tests. { \"MD013\" : false } The contents of the .pipelines and infrastructure folders are explained in the recipe Deploy the DocFx Documentation website to an Azure Website automatically . Reference documentation from source code DocFx can generate reference documentation from code, where C# and Typescript are supported best at the moment. In the QuickStart folder we only used C# projects. For DocFx to generate quality reference documentation, quality triple slash-comments are required. See Triple-slash (///) Code Comments Support . To enforce this, it's a good idea to enforce the use of StyleCop . There are a few steps that will give you an easy start with this. First, you can use the Directory.Build.props file in the /src folder in combination with the files in the build/dotnet folder. By having this, you enforce StyleCop in all Visual Studio project files in it's sub folders with a configuration of which rules should be used or ignored. You can tailor this to your needs of course. For more information, see Customize your build and Use rule sets to group code analysis rules . To make sure developers are forced to add the triple-slash comments by throwing compiler errors and to have the proper settings for the generation of documentation XML-files, add the TreatWarningsAsErrors and GenerateDocumentationFile settings to every .csproj file. You can add that in the first PropertyGroup settings like this: <Project Sdk= \"Microsoft.NET.Sdk\" > <PropertyGroup> ... <GenerateDocumentationFile> true </GenerateDocumentationFile> <TreatWarningsAsErrors> true </TreatWarningsAsErrors> </PropertyGroup> ... </Project> Now you are all set to generate documentation from your C# code. For more information about languages supported by DocFx and how to configure it, see Introduction to Multiple Languages Support . NOTE: You can also add a PropertyGroup definition with the two settings in Directory.Build.props to have that settings in all projects. But in that case it will also be inherited in your Test projects. 1. Install DocFx and markdownlint-cli Go to the DocFx website to the Download section and download the latest version of DocFx. Go to the github page of markdownlint-cli to find download and install options. You can also use tools like Chocolatey to install: choco install docfx choco install markdownlint-cli 2. Configure DocFx Configuration for DocFx is done in a docfx.json file. Store this file in the root of your repository. NOTE: You can store the docfx.json somewhere else in the hierarchy, but then you need to provide the path of the file as an argument to the docfx command so it can be located. Below is a good configuration to start with, where documentation is in the /docs folder and the sources are in the /src folder: { \"metadata\" : [ { \"src\" : [ { \"files\" : [ \"src/**.csproj\" ], \"exclude\" : [ \"_site/**\" , \"**/bin/**\" , \"**/obj/**\" , \"**/[Tt]ests/**\" ] } ], \"dest\" : \"reference\" , \"disableGitFeatures\" : false } ], \"build\" : { \"content\" : [ { \"files\" : [ \"reference/**\" ] }, { \"files\" : [ \"**.md\" , \"**/toc.yml\" ], \"exclude\" : [ \"_site/**\" , \"**/bin/**\" , \"**/obj/**\" , \"**/[Tt]ests/**\" ] } ], \"resource\" : [ { \"files\" : [ \"docs/.attachments/**\" ] }, { \"files\" : [ \"web.config\" ] } ], \"template\" : [ \"templates/cse\" ], \"globalMetadata\" : { \"_appTitle\" : \"CSE Documentation\" , \"_enableSearch\" : true }, \"markdownEngineName\" : \"markdig\" , \"dest\" : \"_site\" , \"xrefService\" : [ \"https://xref.learn.microsoft.com/query?uid={uid}\" ] } } 3. Setup some basic documents We suggest starting with a basic documentation structure in the /docs folder. In the provided QuickStart folder we have a basic setup: \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 .attachments // All images and other attachments used by documents \u2502 \u2502 \u251c\u2500\u2500 architecture-decisions \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 decision-log.md // Sample index into all ADRs \u2502 \u2514\u2500\u2500 README.md // Landing page architecture decisions \u2502 \u2502 \u251c\u2500\u2500 getting-started \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 README.md // This recipe document. Replace the content with something meaningful to the project \u2502 \u2502 \u251c\u2500\u2500 guidelines \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 docs-guidelines.md // General documentation guidelines \u2502 \u2514\u2500\u2500 README.md // Landing page guidelines \u2502 \u2502 \u251c\u2500\u2500 templates // all templates like ADR template and such \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 README.md // Landing page templates \u2502 \u2502 \u251c\u2500\u2500 working-agreements \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 README.md // Landing page working agreements \u2502 \u2502 \u251c\u2500\u2500 .order // Providing a fixed order of files and directories \u2502 \u251c\u2500\u2500 index.md // Landing page documentation You can use templates like working agreements and such from the ISE Playbook . To have a proper landing page of your documentation website, you can use a markdown file called INDEX.MD in the root of your repository. Contents can be something like this: # ISE Documentation This is the landing page of the ISE Documentation website. This is the page to introduce everything on the website. You can add specific links that are important to provide direct access. > Try not to duplicate the links on the top of the page, unless it really makes sense. To get started with the setup of this website, read the getting started document with the title [ Using DocFx and Companion Tools ]( using-docfx-and-tools.md ). 4. Compile the companion tools and run them NOTE: To explain each step, we'll be going through the various steps in the next few paragraphs. In the provided sample, a batch-file called GenerateDocWebsite.cmd is included. This script will take all the necessary steps to compile the tools, execute the checks, generate the table of contents and execute docfx to generate the website. To check for proper markdown formatting the markdownlint-cli tool is used. The command takes it's configuration from the .markdownlint.json file in the root of the project. To check all markdown files, simply execute this command: markdownlint **/*.md In the QuickStart folder you should have copied in the two companion tools TocDocFxCreation and DocLinkChecker as described in the introduction of this article. You can compile the tools from Visual Studio, but you can also run dotnet build in both tool folders. The DocLinkChecker companion tool is used to validate what's in the docs folder. It validates links between documents and attachments in the docs folder and checks if there aren't orphaned attachments. An example of executing this tool, where the check of attachments is included: DocLinkChecker.exe -d ./docs -a The TocDocFxCreation tool is needed to generate a table of contents for your documentation, so users can navigate between folders and documents. If you have compiled the tool, use this command to generate a table of content file toc.yml . To generate a table of contents with the use of the .order files for determining the sequence of articles and to automatically generate index.md documents if no default document is available in a folder, this command can be used: TocDocFxCreation.exe -d ./docs -sri 5. Run DocFx to generate the website Run the docfx command to generate the website, by default in the _site folder. TIP: If you want to check the website in your local environment, provide the --serve option to either the docfx command or the GenerateDocWebsite script. A small webserver is launched that hosts your website, which is accessible on localhost. Style of the website If you started with the QuickStart folder, the website is generated using a custom theme using material design and the Microsoft logo. You can change this to your likings. For more information see How-to: Create A Custom Template | DocFX website (dotnet.github.io) . Deploy to an Azure Website After you completed the steps, you should have a default website generated in the _site folder. But of course, you want this to be accessible for everyone. So, the next step is to create for instance an Azure Website and have a process to automatically generate and deploy the contents to that website. That process is described in the recipe Deploy the DocFx Documentation website to an Azure Website automatically . References DocFX - static documentation generator Deploy the DocFx Documentation website to an Azure Website automatically Providing quality documentation in your project with DocFx and Companion Tools Monorepo For Beginners","title":"Using DocFx and Companion Tools to generate a Documentation website"},{"location":"documentation/recipes/using-docfx-and-tools/#using-docfx-and-companion-tools-to-generate-a-documentation-website","text":"If you want an easy way to have a website with all your documentation coming from Markdown files and comments coming from code, you can use DocFx . The website generated by DocFx also includes fast search capabilities. There are some gaps in the DocFx solution, but we've provided companion tools that help you fill those gaps. Also see the blog post Providing quality documentation in your project with DocFx and Companion Tools for more explanation about the solution.","title":"Using DocFx and Companion Tools to generate a Documentation website"},{"location":"documentation/recipes/using-docfx-and-tools/#prerequisites","text":"This document is followed best by cloning the sample from https://github.com/mtirionMSFT/DocFxQuickStart first. Copy the contents of the QuickStart folder to the root of your own repository to get started in your own environment.","title":"Prerequisites"},{"location":"documentation/recipes/using-docfx-and-tools/#quick-start","text":"TLDR; If you want a really quick start using Azure DevOps and Azure App Service without reading the what and how, follow these steps: Azure DevOps: If you don't have it yet, create a project in Azure DevOps and create a Service Connection to your Azure environment . Clone the repository. QuickStart folder: Copy the contents of the QuickStart folder in there repository that can be found on https://github.com/mtirionMSFT/DocFxQuickStart to the root of the repository. Azure: Create a resource group in your Azure environment where the documentation website resources should be created. Create Azure resources: Fill in the default values in infrastructure/variables.tf and run the commands from Step 3 - Deploy Azure resources from your local machine to create the Azure Resources. Pipeline: Fill in the variables in .pipelines/documentation.yml , commit the changes and push the contents of the repository to your branch (possibly through a PR). Now you can create a pipeline in your Azure DevOps project that uses the .pipelines/documentation.yml and run it.","title":"Quick Start"},{"location":"documentation/recipes/using-docfx-and-tools/#documents-and-projects-folder-structure","text":"The easiest is to work with a mono repository where documentation and code live together. If that's not the case in your situation but you still want to combine multiple repositories into one documentation website, you'll have to clone all repositories first to be able to combine the information. In this recipe we'll assume a monorepo is used. In the steps below we'll consider the generation of the documentation website from this content structure: \u251c\u2500\u2500 .pipelines // Azure DevOps pipeline for automatic generation and deployment \u2502 \u251c\u2500\u2500 docs // all documents \u2502 \u251c\u2500\u2500 .attachments // all images and other attachments used by documents \u2502 \u251c\u2500\u2500 infrastructure // Terraform scripts for creation of the Azure website \u2502 \u251c\u2500\u2500 src // all projects \u2502 \u251c\u2500\u2500 build // build settings \u2502 \u251c\u2500\u2500 dotnet // .NET build settings \u2502 \u251c\u2500\u2500 Directory.Build.props // project settings for all .NET projects in sub folders \u2502 \u251c\u2500\u2500 [Project folders] \u2502 \u251c\u2500\u2500 x-cross \u2502 \u251c\u2500\u2500 toc.yml // Cross reference definition (optional) \u2502 \u251c\u2500\u2500 .markdownlint.json // Markdownlinter settings \u251c\u2500\u2500 docfx.json // DocFx configuration \u251c\u2500\u2500 index.md // Website landing page \u251c\u2500\u2500 toc.yml // Definition of the website header content links \u251c\u2500\u2500 web.config // web.config to enable search in deployed website We'll be using the DocLinkChecker tool to validate all links in documentation and for orphaned attachments. That's the reason we have all attachments in the .attachments folder. In the generated website from the QuickStart folder you'll see that the hierarchies of documentation and references is combined in the left table of contents. This is achieved by the definition and use of x-cross\\toc.yml . If you don't want the hierarchies combined, just remove the folder and file from your environment and (re)generate the website. A .markdownlint.json is included with the contents below. The MD013 setting is set to false to prevent checking for maximum line length. You can modify this file to your likings to include or exclude certain tests. { \"MD013\" : false } The contents of the .pipelines and infrastructure folders are explained in the recipe Deploy the DocFx Documentation website to an Azure Website automatically .","title":"Documents and projects folder structure"},{"location":"documentation/recipes/using-docfx-and-tools/#reference-documentation-from-source-code","text":"DocFx can generate reference documentation from code, where C# and Typescript are supported best at the moment. In the QuickStart folder we only used C# projects. For DocFx to generate quality reference documentation, quality triple slash-comments are required. See Triple-slash (///) Code Comments Support . To enforce this, it's a good idea to enforce the use of StyleCop . There are a few steps that will give you an easy start with this. First, you can use the Directory.Build.props file in the /src folder in combination with the files in the build/dotnet folder. By having this, you enforce StyleCop in all Visual Studio project files in it's sub folders with a configuration of which rules should be used or ignored. You can tailor this to your needs of course. For more information, see Customize your build and Use rule sets to group code analysis rules . To make sure developers are forced to add the triple-slash comments by throwing compiler errors and to have the proper settings for the generation of documentation XML-files, add the TreatWarningsAsErrors and GenerateDocumentationFile settings to every .csproj file. You can add that in the first PropertyGroup settings like this: <Project Sdk= \"Microsoft.NET.Sdk\" > <PropertyGroup> ... <GenerateDocumentationFile> true </GenerateDocumentationFile> <TreatWarningsAsErrors> true </TreatWarningsAsErrors> </PropertyGroup> ... </Project> Now you are all set to generate documentation from your C# code. For more information about languages supported by DocFx and how to configure it, see Introduction to Multiple Languages Support . NOTE: You can also add a PropertyGroup definition with the two settings in Directory.Build.props to have that settings in all projects. But in that case it will also be inherited in your Test projects.","title":"Reference documentation from source code"},{"location":"documentation/recipes/using-docfx-and-tools/#1-install-docfx-and-markdownlint-cli","text":"Go to the DocFx website to the Download section and download the latest version of DocFx. Go to the github page of markdownlint-cli to find download and install options. You can also use tools like Chocolatey to install: choco install docfx choco install markdownlint-cli","title":"1. Install DocFx and markdownlint-cli"},{"location":"documentation/recipes/using-docfx-and-tools/#2-configure-docfx","text":"Configuration for DocFx is done in a docfx.json file. Store this file in the root of your repository. NOTE: You can store the docfx.json somewhere else in the hierarchy, but then you need to provide the path of the file as an argument to the docfx command so it can be located. Below is a good configuration to start with, where documentation is in the /docs folder and the sources are in the /src folder: { \"metadata\" : [ { \"src\" : [ { \"files\" : [ \"src/**.csproj\" ], \"exclude\" : [ \"_site/**\" , \"**/bin/**\" , \"**/obj/**\" , \"**/[Tt]ests/**\" ] } ], \"dest\" : \"reference\" , \"disableGitFeatures\" : false } ], \"build\" : { \"content\" : [ { \"files\" : [ \"reference/**\" ] }, { \"files\" : [ \"**.md\" , \"**/toc.yml\" ], \"exclude\" : [ \"_site/**\" , \"**/bin/**\" , \"**/obj/**\" , \"**/[Tt]ests/**\" ] } ], \"resource\" : [ { \"files\" : [ \"docs/.attachments/**\" ] }, { \"files\" : [ \"web.config\" ] } ], \"template\" : [ \"templates/cse\" ], \"globalMetadata\" : { \"_appTitle\" : \"CSE Documentation\" , \"_enableSearch\" : true }, \"markdownEngineName\" : \"markdig\" , \"dest\" : \"_site\" , \"xrefService\" : [ \"https://xref.learn.microsoft.com/query?uid={uid}\" ] } }","title":"2. Configure DocFx"},{"location":"documentation/recipes/using-docfx-and-tools/#3-setup-some-basic-documents","text":"We suggest starting with a basic documentation structure in the /docs folder. In the provided QuickStart folder we have a basic setup: \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 .attachments // All images and other attachments used by documents \u2502 \u2502 \u251c\u2500\u2500 architecture-decisions \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 decision-log.md // Sample index into all ADRs \u2502 \u2514\u2500\u2500 README.md // Landing page architecture decisions \u2502 \u2502 \u251c\u2500\u2500 getting-started \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 README.md // This recipe document. Replace the content with something meaningful to the project \u2502 \u2502 \u251c\u2500\u2500 guidelines \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 docs-guidelines.md // General documentation guidelines \u2502 \u2514\u2500\u2500 README.md // Landing page guidelines \u2502 \u2502 \u251c\u2500\u2500 templates // all templates like ADR template and such \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 README.md // Landing page templates \u2502 \u2502 \u251c\u2500\u2500 working-agreements \u2502 \u2514\u2500\u2500 .order \u2502 \u2514\u2500\u2500 README.md // Landing page working agreements \u2502 \u2502 \u251c\u2500\u2500 .order // Providing a fixed order of files and directories \u2502 \u251c\u2500\u2500 index.md // Landing page documentation You can use templates like working agreements and such from the ISE Playbook . To have a proper landing page of your documentation website, you can use a markdown file called INDEX.MD in the root of your repository. Contents can be something like this: # ISE Documentation This is the landing page of the ISE Documentation website. This is the page to introduce everything on the website. You can add specific links that are important to provide direct access. > Try not to duplicate the links on the top of the page, unless it really makes sense. To get started with the setup of this website, read the getting started document with the title [ Using DocFx and Companion Tools ]( using-docfx-and-tools.md ).","title":"3. Setup some basic documents"},{"location":"documentation/recipes/using-docfx-and-tools/#4-compile-the-companion-tools-and-run-them","text":"NOTE: To explain each step, we'll be going through the various steps in the next few paragraphs. In the provided sample, a batch-file called GenerateDocWebsite.cmd is included. This script will take all the necessary steps to compile the tools, execute the checks, generate the table of contents and execute docfx to generate the website. To check for proper markdown formatting the markdownlint-cli tool is used. The command takes it's configuration from the .markdownlint.json file in the root of the project. To check all markdown files, simply execute this command: markdownlint **/*.md In the QuickStart folder you should have copied in the two companion tools TocDocFxCreation and DocLinkChecker as described in the introduction of this article. You can compile the tools from Visual Studio, but you can also run dotnet build in both tool folders. The DocLinkChecker companion tool is used to validate what's in the docs folder. It validates links between documents and attachments in the docs folder and checks if there aren't orphaned attachments. An example of executing this tool, where the check of attachments is included: DocLinkChecker.exe -d ./docs -a The TocDocFxCreation tool is needed to generate a table of contents for your documentation, so users can navigate between folders and documents. If you have compiled the tool, use this command to generate a table of content file toc.yml . To generate a table of contents with the use of the .order files for determining the sequence of articles and to automatically generate index.md documents if no default document is available in a folder, this command can be used: TocDocFxCreation.exe -d ./docs -sri","title":"4. Compile the companion tools and run them"},{"location":"documentation/recipes/using-docfx-and-tools/#5-run-docfx-to-generate-the-website","text":"Run the docfx command to generate the website, by default in the _site folder. TIP: If you want to check the website in your local environment, provide the --serve option to either the docfx command or the GenerateDocWebsite script. A small webserver is launched that hosts your website, which is accessible on localhost.","title":"5. Run DocFx to generate the website"},{"location":"documentation/recipes/using-docfx-and-tools/#style-of-the-website","text":"If you started with the QuickStart folder, the website is generated using a custom theme using material design and the Microsoft logo. You can change this to your likings. For more information see How-to: Create A Custom Template | DocFX website (dotnet.github.io) .","title":"Style of the website"},{"location":"documentation/recipes/using-docfx-and-tools/#deploy-to-an-azure-website","text":"After you completed the steps, you should have a default website generated in the _site folder. But of course, you want this to be accessible for everyone. So, the next step is to create for instance an Azure Website and have a process to automatically generate and deploy the contents to that website. That process is described in the recipe Deploy the DocFx Documentation website to an Azure Website automatically .","title":"Deploy to an Azure Website"},{"location":"documentation/recipes/using-docfx-and-tools/#references","text":"DocFX - static documentation generator Deploy the DocFx Documentation website to an Azure Website automatically Providing quality documentation in your project with DocFx and Companion Tools Monorepo For Beginners","title":"References"},{"location":"documentation/tools/automation/","text":"How to Automate Simple Checks If you want to automate some checks on your Markdown documents, there are several tools that you could leverage. For example: Code Analysis / Linting markdownlint to verify Markdown syntax and enforce rules that make the text more readable. markdown-link-check to extract links from markdown texts and check whether each link is alive (200 OK) or dead. proselint to check for jargon, spelling errors, redundancy, corporate speak and other language related issues. write-good to check English prose. Docker image for node-markdown-spellcheck , a lightweight docker image to spellcheck markdown files. static code analysis VS Code Extensions Write Good Linter to get grammar and language advice while editing a document. markdownlint to examine Markdown documents and get warnings for rule violations while editing. Automation pre-commit to use Git hook scripts to identify simple issues before submitting our code or documentation for review. Check Build validation to automate linting for PRs. Check CI Pipeline for better documentation for a sample pipeline with markdownlint , markdown-link-check and write-good . Sample output: On linting rules The team needs to be clear what linting rules are required and shouldn't be overridden with tooling or comments. The team should have consensus on when to override tooling rules.","title":"How to Automate Simple Checks"},{"location":"documentation/tools/automation/#how-to-automate-simple-checks","text":"If you want to automate some checks on your Markdown documents, there are several tools that you could leverage. For example: Code Analysis / Linting markdownlint to verify Markdown syntax and enforce rules that make the text more readable. markdown-link-check to extract links from markdown texts and check whether each link is alive (200 OK) or dead. proselint to check for jargon, spelling errors, redundancy, corporate speak and other language related issues. write-good to check English prose. Docker image for node-markdown-spellcheck , a lightweight docker image to spellcheck markdown files. static code analysis VS Code Extensions Write Good Linter to get grammar and language advice while editing a document. markdownlint to examine Markdown documents and get warnings for rule violations while editing. Automation pre-commit to use Git hook scripts to identify simple issues before submitting our code or documentation for review. Check Build validation to automate linting for PRs. Check CI Pipeline for better documentation for a sample pipeline with markdownlint , markdown-link-check and write-good . Sample output:","title":"How to Automate Simple Checks"},{"location":"documentation/tools/automation/#on-linting-rules","text":"The team needs to be clear what linting rules are required and shouldn't be overridden with tooling or comments. The team should have consensus on when to override tooling rules.","title":"On linting rules"},{"location":"documentation/tools/integrations/","text":"Integration with Teams/Slack Monitor your Azure repositories and receive notifications in your channel whenever code is pushed/checked in and whenever a pull request (PR) is created, updated, or a merge is attempted. Azure Repos with Microsoft Teams Azure Repos with Slack","title":"Integration with Teams/Slack"},{"location":"documentation/tools/integrations/#integration-with-teamsslack","text":"Monitor your Azure repositories and receive notifications in your channel whenever code is pushed/checked in and whenever a pull request (PR) is created, updated, or a merge is attempted. Azure Repos with Microsoft Teams Azure Repos with Slack","title":"Integration with Teams/Slack"},{"location":"documentation/tools/languages/","text":"Languages Markdown Markdown is one of the most popular markup languages to add rich formatting, tables and images to your documentation using plain text documents. Markdown files (.md) can be source-controlled along with your code. More information: Getting Started Cheat Sheet Basic Syntax Extended Syntax Wiki Markdown Syntax Tools: Markdown and Visual Studio Code How to automate simple checks Mermaid Mermaid lets you create diagrams using text definitions that can later be rendered with a diagramming and charting tool. Mermaid files (.mmd) can be source-controlled along with your code. It's also recommended to include image files (.png) with the rendered diagrams under source control. Your markdown files should link the image files, so they can be read without the need of a Mermaid rendering tool (e.g., during Pull Request review). Example Mermaid diagram This is an example of a Mermaid flowchart diagram written as code. graph LR A[Diagram Idea] -->|Write mermaid code| B(mermaid.mmd file) B -->|Add to source control| C{Code repo} B -->|Export as .png| G(.png file of diagram) G -->|Add to source control| C This is an example of how it can be rendered as an image. More information: About Mermaid Diagram syntax Tools: Mermaid Live Editor Markdown Preview Mermaid Support for Visual Studio Code","title":"Languages"},{"location":"documentation/tools/languages/#languages","text":"","title":"Languages"},{"location":"documentation/tools/languages/#markdown","text":"Markdown is one of the most popular markup languages to add rich formatting, tables and images to your documentation using plain text documents. Markdown files (.md) can be source-controlled along with your code. More information: Getting Started Cheat Sheet Basic Syntax Extended Syntax Wiki Markdown Syntax Tools: Markdown and Visual Studio Code How to automate simple checks","title":"Markdown"},{"location":"documentation/tools/languages/#mermaid","text":"Mermaid lets you create diagrams using text definitions that can later be rendered with a diagramming and charting tool. Mermaid files (.mmd) can be source-controlled along with your code. It's also recommended to include image files (.png) with the rendered diagrams under source control. Your markdown files should link the image files, so they can be read without the need of a Mermaid rendering tool (e.g., during Pull Request review).","title":"Mermaid"},{"location":"documentation/tools/languages/#example-mermaid-diagram","text":"This is an example of a Mermaid flowchart diagram written as code. graph LR A[Diagram Idea] -->|Write mermaid code| B(mermaid.mmd file) B -->|Add to source control| C{Code repo} B -->|Export as .png| G(.png file of diagram) G -->|Add to source control| C This is an example of how it can be rendered as an image. More information: About Mermaid Diagram syntax Tools: Mermaid Live Editor Markdown Preview Mermaid Support for Visual Studio Code","title":"Example Mermaid diagram"},{"location":"documentation/tools/wikis/","text":"Wikis Use a team project wiki to share information with other team members. When you provision a wiki from scratch, a new Git repository stores your Markdown files, images, attachments, and sequence of pages. This wiki supports collaborative editing of its content and structure. In Azure DevOps, you have the following options for maintaining wiki content : Provision a wiki for your team project. This option supports only one wiki for the team project. Publish Markdown files defined in a Git repository to a wiki. With this option, you can maintain several versioned wikis to support your content needs. More information: About Wikis, READMEs, and Markdown . Provisioned wikis vs. published code as a wiki . Create a Wiki for your project . Manage wikis . Wikis vs. digital notebooks (e.g., OneNote) When you work on a project, you may decide to document relevant details or record important decisions about the project in a digital notebook. Tools like OneNote allows you to easily organize, navigate and search your notes. You can provide type, highlighting, or ink annotations to your notes. These notes can easily be shared and created together with others. Still, Wikis greatly facilitate the process of establishing and managing documentation by allowing us to source control the documentation.","title":"Wikis"},{"location":"documentation/tools/wikis/#wikis","text":"Use a team project wiki to share information with other team members. When you provision a wiki from scratch, a new Git repository stores your Markdown files, images, attachments, and sequence of pages. This wiki supports collaborative editing of its content and structure. In Azure DevOps, you have the following options for maintaining wiki content : Provision a wiki for your team project. This option supports only one wiki for the team project. Publish Markdown files defined in a Git repository to a wiki. With this option, you can maintain several versioned wikis to support your content needs. More information: About Wikis, READMEs, and Markdown . Provisioned wikis vs. published code as a wiki . Create a Wiki for your project . Manage wikis .","title":"Wikis"},{"location":"documentation/tools/wikis/#wikis-vs-digital-notebooks-eg-onenote","text":"When you work on a project, you may decide to document relevant details or record important decisions about the project in a digital notebook. Tools like OneNote allows you to easily organize, navigate and search your notes. You can provide type, highlighting, or ink annotations to your notes. These notes can easily be shared and created together with others. Still, Wikis greatly facilitate the process of establishing and managing documentation by allowing us to source control the documentation.","title":"Wikis vs. digital notebooks (e.g., OneNote)"},{"location":"engineering-feedback/","text":"Microsoft Engineering Feedback Why is it important to submit Microsoft Engineering Feedback Engineering Feedback captures the \"voice of the customer\" and is an important mechanism to provide actionable insights and help Microsoft product groups continuously improve the platform and cloud services to enable all customers to be as productive as possible. Please note that Engineering Feedback is an asynchronous (i.e. not real-time) method to capture and aggregate friction points across multiple customers and code-with engagements. Therefore, if you need to report a service outage, or an immediately-blocking bug, you should file an official Azure support ticket and, if possible, reference the ticket id in the feedback that you submit later. Even if the feedback has already been raised directly with a product group or on through online channels like GitHub or Stack Overflow, it is still important to raise it via Microsoft Engineering feedback, so it can be consolidated with other customer projects that have the same feedback to help with prioritization. When to submit Engineering Feedback Capturing and providing high-quality actionable Engineering Feedback is an integral ongoing part of all code-with engagements. It is recommended to submit feedback on an ongoing basis instead of batching it up for submission at the end of the engagement. You should jot down the details of the feedback close to the time when you encounter the specific blockers, challenges, and friction since that is when it is freshest in your mind. The project team can then decide how to prioritize and when to submit the feedback into the official CSE Feedback system (accessible to ISE team members) during each sprint. What is good and high-quality Engineering Feedback Good engineering feedback provides enough information for those who are not part of the code-with engagement to understand the customer pain, the associated product issues, the impact and priority of these issues, and any potential workarounds that exist to minimize that impact. High-Quality Engineering Feedback is Goal Oriented - states what the customer is trying to accomplish Specific - details the scenario, observation, or challenge faced by the customer Actionable - includes the necessary clarifying information to enable a decision Examples of Good Engineering Feedback For example, here is an evolution of transforming a fictitious feedback with the above high-quality engineering feedback guidance in mind: Stage Feedback Evolution Initial feedback Azure Functions Service Bus Trigger is slow for in-order scenarios Making it Goal Oriented Customer requests batch receiving for Azure Functions Service Bus trigger with sessions enabled to better support higher throughput messaging. They want to use Azure Functions to process as many messages per second as possible with minimum latency and in a given order. Adding Specifics Customer scenario was to receive a total of 250 messages/second from 50 producers with requirement for ordering per producer & minimum latency, using a Service Bus topic with sessions enabled for ordering. Batch receiving is not supported in Azure Functions Service Bus Trigger. Making it Actionable Customer scenario was to receive a total of 250 messages/second from 50 producers with requirement for ordering per producer & minimum latency, using a Service Bus topic with sessions enabled for ordering. According to Microsoft documentation , batch receiving is recommended for better performance but this is not currently supported in the Azure Functions Service Bus Trigger. The impact and workaround was choosing containers over Functions. The desired outcome is for Azure Functions to support Service Bus sessions with batch and non-batch processing for all Azure Functions GA languages. For real-world examples please follow Feedback Examples . How to submit Engineering Feedback Please follow the Engineering Feedback Guidance to ensure that you provide feedback that can be triaged and processed most efficiently. Please review the Frequently Asked Questions page for additional information on the engineering feedback process.","title":"Microsoft Engineering Feedback"},{"location":"engineering-feedback/#microsoft-engineering-feedback","text":"","title":"Microsoft Engineering Feedback"},{"location":"engineering-feedback/#why-is-it-important-to-submit-microsoft-engineering-feedback","text":"Engineering Feedback captures the \"voice of the customer\" and is an important mechanism to provide actionable insights and help Microsoft product groups continuously improve the platform and cloud services to enable all customers to be as productive as possible. Please note that Engineering Feedback is an asynchronous (i.e. not real-time) method to capture and aggregate friction points across multiple customers and code-with engagements. Therefore, if you need to report a service outage, or an immediately-blocking bug, you should file an official Azure support ticket and, if possible, reference the ticket id in the feedback that you submit later. Even if the feedback has already been raised directly with a product group or on through online channels like GitHub or Stack Overflow, it is still important to raise it via Microsoft Engineering feedback, so it can be consolidated with other customer projects that have the same feedback to help with prioritization.","title":"Why is it important to submit Microsoft Engineering Feedback"},{"location":"engineering-feedback/#when-to-submit-engineering-feedback","text":"Capturing and providing high-quality actionable Engineering Feedback is an integral ongoing part of all code-with engagements. It is recommended to submit feedback on an ongoing basis instead of batching it up for submission at the end of the engagement. You should jot down the details of the feedback close to the time when you encounter the specific blockers, challenges, and friction since that is when it is freshest in your mind. The project team can then decide how to prioritize and when to submit the feedback into the official CSE Feedback system (accessible to ISE team members) during each sprint.","title":"When to submit Engineering Feedback"},{"location":"engineering-feedback/#what-is-good-and-high-quality-engineering-feedback","text":"Good engineering feedback provides enough information for those who are not part of the code-with engagement to understand the customer pain, the associated product issues, the impact and priority of these issues, and any potential workarounds that exist to minimize that impact.","title":"What is good and high-quality Engineering Feedback"},{"location":"engineering-feedback/#high-quality-engineering-feedback-is","text":"Goal Oriented - states what the customer is trying to accomplish Specific - details the scenario, observation, or challenge faced by the customer Actionable - includes the necessary clarifying information to enable a decision","title":"High-Quality Engineering Feedback is"},{"location":"engineering-feedback/#examples-of-good-engineering-feedback","text":"For example, here is an evolution of transforming a fictitious feedback with the above high-quality engineering feedback guidance in mind: Stage Feedback Evolution Initial feedback Azure Functions Service Bus Trigger is slow for in-order scenarios Making it Goal Oriented Customer requests batch receiving for Azure Functions Service Bus trigger with sessions enabled to better support higher throughput messaging. They want to use Azure Functions to process as many messages per second as possible with minimum latency and in a given order. Adding Specifics Customer scenario was to receive a total of 250 messages/second from 50 producers with requirement for ordering per producer & minimum latency, using a Service Bus topic with sessions enabled for ordering. Batch receiving is not supported in Azure Functions Service Bus Trigger. Making it Actionable Customer scenario was to receive a total of 250 messages/second from 50 producers with requirement for ordering per producer & minimum latency, using a Service Bus topic with sessions enabled for ordering. According to Microsoft documentation , batch receiving is recommended for better performance but this is not currently supported in the Azure Functions Service Bus Trigger. The impact and workaround was choosing containers over Functions. The desired outcome is for Azure Functions to support Service Bus sessions with batch and non-batch processing for all Azure Functions GA languages. For real-world examples please follow Feedback Examples .","title":"Examples of Good Engineering Feedback"},{"location":"engineering-feedback/#how-to-submit-engineering-feedback","text":"Please follow the Engineering Feedback Guidance to ensure that you provide feedback that can be triaged and processed most efficiently. Please review the Frequently Asked Questions page for additional information on the engineering feedback process.","title":"How to submit Engineering Feedback"},{"location":"engineering-feedback/feedback-examples/","text":"Engineering Feedback Examples The following are real-world examples of Engineering Feedback that have led to product improvements and unblocked customers. Windows Server Container support for Azure Kubernetes Service The Azure Kubernetes Service should have first class Windows container support so solutions that require Windows workloads can be deployed on a wildly popular container orchestration platform. The need was to be able to deploy Windows Server containers on AKS the managed Azure Kubernetes Service. According to this FAQ (and in parallel confirmation) it is not available yet. We tried to deploy anyway as a test, and it did not work \u2013 the deployment would be pending without success. More than a dozen large partners/customers are blocked in deploying Windows workloads to AKS due to a lack of support for Windows Server containers. They need this feature so solutions requiring Windows workloads can be deployed to this popular container orchestration platform. We are seeing an emergence of companies beginning to try Windows containers as an option to move their Windows workloads to the cloud.\u202f Gartner is claiming that 80% of enterprise apps run on Windows. Containers have become the de facto deployment mechanism in the industry, and deployment consistency and speed are a few of the important factors companies are looking for. Enabling Windows applications and ensuring that developers have a good experience when moving their workloads to Azure via Windows containers is key to keeping existing Windows customers within the Azure ecosystem and driving Azure adoption for new workloads. We are also seeing increased interest, particularly among enterprise customers, in using a single orchestrator control plane for managing both Linux and Windows workloads. This feedback was created as a high priority feedback and followed up internally until addressed. Here is the announcement . Support Batch Receiving with Sessions in Azure Functions Service Bus Trigger Customer scenario was to receive a total of 250 messages per second from 50 producers with requirement for ordering & minimum latency, using a Service Bus topic with sessions enabled for ordering. According to Microsoft documentation , batch receiving is recommended for better performance but this is not currently supported in Azure Functions Service Bus Trigger. The impact (and work around) was choosing containers over Functions. The Acceptance Criteria is for Azure Functions to support Service Bus sessions with batch and non-batch processing for all Azure Functions GA languages. This feedback was created as a feedback with the Azure Functions product group and also followed up internally until addressed. Stream Analytics - No support for zero-downtime scale-down In order to update the Streaming Unit number in Stream Analytics you need to stop the service and wait for minutes for it to restart. This unacceptable by customers who need near real-time analysis\u200b. In order to have a job re-started, up to 2 minutes are needed and this is not acceptable for a real-time streaming solution. It would also be optimal if scale-up and scale-down could be done automatically, by setting threshold values that when reached increase or decrease automatically the amount of RU available. This feedback is for customers' request for zero down-time scale-down capability in stream analytics. Problem Statement: In order to update the \"Streaming Unit\" number, partners must stop the service and wait until it restarts. The partner needs to be able to update the number without stopping the service. Desired Experience: Partners should be able to update the Streaming Unit number without stopping the associated service. This feedback was created as a high priority feedback and followed up until addressed in December 2019. Python Support for Azure Functions Several customers already use Python as part of their workflow, and would like to be able to use Python for Azure Functions. This is specially true since many of them are already have scripts running on other clouds and services. In addition, Python support has been in Preview for a very long time, and it's missing a lot of functionality. This feature request is one of the most asked, and a huge upside potential to pull through Machine Learning (ML) based workloads. This feedback was created as a feedback with the Azure Functions product group and also followed up internally until addressed. Here is the announcement .","title":"Engineering Feedback Examples"},{"location":"engineering-feedback/feedback-examples/#engineering-feedback-examples","text":"The following are real-world examples of Engineering Feedback that have led to product improvements and unblocked customers.","title":"Engineering Feedback Examples"},{"location":"engineering-feedback/feedback-examples/#windows-server-container-support-for-azure-kubernetes-service","text":"The Azure Kubernetes Service should have first class Windows container support so solutions that require Windows workloads can be deployed on a wildly popular container orchestration platform. The need was to be able to deploy Windows Server containers on AKS the managed Azure Kubernetes Service. According to this FAQ (and in parallel confirmation) it is not available yet. We tried to deploy anyway as a test, and it did not work \u2013 the deployment would be pending without success. More than a dozen large partners/customers are blocked in deploying Windows workloads to AKS due to a lack of support for Windows Server containers. They need this feature so solutions requiring Windows workloads can be deployed to this popular container orchestration platform. We are seeing an emergence of companies beginning to try Windows containers as an option to move their Windows workloads to the cloud.\u202f Gartner is claiming that 80% of enterprise apps run on Windows. Containers have become the de facto deployment mechanism in the industry, and deployment consistency and speed are a few of the important factors companies are looking for. Enabling Windows applications and ensuring that developers have a good experience when moving their workloads to Azure via Windows containers is key to keeping existing Windows customers within the Azure ecosystem and driving Azure adoption for new workloads. We are also seeing increased interest, particularly among enterprise customers, in using a single orchestrator control plane for managing both Linux and Windows workloads. This feedback was created as a high priority feedback and followed up internally until addressed. Here is the announcement .","title":"Windows Server Container support for Azure Kubernetes Service"},{"location":"engineering-feedback/feedback-examples/#support-batch-receiving-with-sessions-in-azure-functions-service-bus-trigger","text":"Customer scenario was to receive a total of 250 messages per second from 50 producers with requirement for ordering & minimum latency, using a Service Bus topic with sessions enabled for ordering. According to Microsoft documentation , batch receiving is recommended for better performance but this is not currently supported in Azure Functions Service Bus Trigger. The impact (and work around) was choosing containers over Functions. The Acceptance Criteria is for Azure Functions to support Service Bus sessions with batch and non-batch processing for all Azure Functions GA languages. This feedback was created as a feedback with the Azure Functions product group and also followed up internally until addressed.","title":"Support Batch Receiving with Sessions in Azure Functions Service Bus Trigger"},{"location":"engineering-feedback/feedback-examples/#stream-analytics-no-support-for-zero-downtime-scale-down","text":"In order to update the Streaming Unit number in Stream Analytics you need to stop the service and wait for minutes for it to restart. This unacceptable by customers who need near real-time analysis\u200b. In order to have a job re-started, up to 2 minutes are needed and this is not acceptable for a real-time streaming solution. It would also be optimal if scale-up and scale-down could be done automatically, by setting threshold values that when reached increase or decrease automatically the amount of RU available. This feedback is for customers' request for zero down-time scale-down capability in stream analytics. Problem Statement: In order to update the \"Streaming Unit\" number, partners must stop the service and wait until it restarts. The partner needs to be able to update the number without stopping the service. Desired Experience: Partners should be able to update the Streaming Unit number without stopping the associated service. This feedback was created as a high priority feedback and followed up until addressed in December 2019.","title":"Stream Analytics - No support for zero-downtime scale-down"},{"location":"engineering-feedback/feedback-examples/#python-support-for-azure-functions","text":"Several customers already use Python as part of their workflow, and would like to be able to use Python for Azure Functions. This is specially true since many of them are already have scripts running on other clouds and services. In addition, Python support has been in Preview for a very long time, and it's missing a lot of functionality. This feature request is one of the most asked, and a huge upside potential to pull through Machine Learning (ML) based workloads. This feedback was created as a feedback with the Azure Functions product group and also followed up internally until addressed. Here is the announcement .","title":"Python Support for Azure Functions"},{"location":"engineering-feedback/feedback-faq/","text":"Engineering Feedback Frequently Asked Questions (F.A.Q.) The questions below are common questions related to the feedback process. The answers are intended to help both Microsoft employees and customers. When should I submit feedback versus creating an issue on GitHub, UserVoice, or sending an email directly to a Microsoft employee? It is appropriate to do both. As a customer or Microsoft employee, you are empowered to create an issue or submit feedback via the medium appropriate for service. In addition to an issue on GitHub, feedback on UserVoice, or a personal email, Microsoft employees in CSE should submit feedback via CSE Feedback. In doing so, please reference the GitHub issue, UserVoice feedback, or email by including a link to the item or attaching the email. Submitting to ISE Feedback allows the ISE Feedback team to coalesce feedback across a wide range of sources, and thus create a unified case to submit to the appropriate Azure engineering team(s). How can a customer track the status of a specific feedback item? At this time, customers are not able to directly track the status of feedback submitted via ISE Feedback. The ISE Feedback process is internal to Microsoft, and as such, available only to Microsoft employees. Customers may request an update from their ISE engineering partner or Microsoft account representative(s). Customers can also submit their feedback directly via GitHub or UserVoice (as appropriate for the specific service), and inform their ISE engineering partner. The ISE engineer should submit the feedback via the ISE Feedback process, and in doing so reference the previously created issue. Customers can follow the GitHub or UserVoice item to be alerted on updates. How can a Microsoft employee track the status of a specific feedback item? The easiest way for a Microsoft employee within ISE to track a specific feedback item is to follow the feedback (a work item) in Azure DevOps. As a Microsoft employee within ISE, if I submit a feedback and move to another dev crew engagement, how would my customer get an update on that feedback? If the feedback is also submitted via GitHub or UserVoice, the customer may elect to follow that item for publicly available updates. The customer may also contact their Microsoft account representative to request an update. As a Microsoft employee within ISE, what should I expect/do after submitting feedback via ISE Feedback? After submitting the feedback, it is recommended to follow the feedback (a work item) in Azure DevOps. If you have configured Azure DevOps notifications to send an email on work item updates, you will receive an email when the feedback is updated. If more information about the feedback is needed, a member of the ISE Feedback team will contact you to gather more information. How/when are feedback aggregated? Members of the CSE Feedback team will make a best effort to triage and review new CSE Feedback items within two weeks of the original submission date. If there is similarity across multiple feedback items, a member of the ISE Feedback team may decide to create a new feedback item which is an aggregate of similar items. This is done to aid in the creation of a unified feedback item to present to the appropriate Microsoft engineering team. On a monthly basis, the ISE Feedback team will review all feedback and generate a report consisting of the highest priority feedback. The report is presented to appropriate ISE and Microsoft leadership teams.","title":"Engineering Feedback Frequently Asked Questions (F.A.Q.)"},{"location":"engineering-feedback/feedback-faq/#engineering-feedback-frequently-asked-questions-faq","text":"The questions below are common questions related to the feedback process. The answers are intended to help both Microsoft employees and customers.","title":"Engineering Feedback Frequently Asked Questions (F.A.Q.)"},{"location":"engineering-feedback/feedback-faq/#when-should-i-submit-feedback-versus-creating-an-issue-on-github-uservoice-or-sending-an-email-directly-to-a-microsoft-employee","text":"It is appropriate to do both. As a customer or Microsoft employee, you are empowered to create an issue or submit feedback via the medium appropriate for service. In addition to an issue on GitHub, feedback on UserVoice, or a personal email, Microsoft employees in CSE should submit feedback via CSE Feedback. In doing so, please reference the GitHub issue, UserVoice feedback, or email by including a link to the item or attaching the email. Submitting to ISE Feedback allows the ISE Feedback team to coalesce feedback across a wide range of sources, and thus create a unified case to submit to the appropriate Azure engineering team(s).","title":"When should I submit feedback versus creating an issue on GitHub, UserVoice, or sending an email directly to a Microsoft employee?"},{"location":"engineering-feedback/feedback-faq/#how-can-a-customer-track-the-status-of-a-specific-feedback-item","text":"At this time, customers are not able to directly track the status of feedback submitted via ISE Feedback. The ISE Feedback process is internal to Microsoft, and as such, available only to Microsoft employees. Customers may request an update from their ISE engineering partner or Microsoft account representative(s). Customers can also submit their feedback directly via GitHub or UserVoice (as appropriate for the specific service), and inform their ISE engineering partner. The ISE engineer should submit the feedback via the ISE Feedback process, and in doing so reference the previously created issue. Customers can follow the GitHub or UserVoice item to be alerted on updates.","title":"How can a customer track the status of a specific feedback item?"},{"location":"engineering-feedback/feedback-faq/#how-can-a-microsoft-employee-track-the-status-of-a-specific-feedback-item","text":"The easiest way for a Microsoft employee within ISE to track a specific feedback item is to follow the feedback (a work item) in Azure DevOps.","title":"How can a Microsoft employee track the status of a specific feedback item?"},{"location":"engineering-feedback/feedback-faq/#as-a-microsoft-employee-within-ise-if-i-submit-a-feedback-and-move-to-another-dev-crew-engagement-how-would-my-customer-get-an-update-on-that-feedback","text":"If the feedback is also submitted via GitHub or UserVoice, the customer may elect to follow that item for publicly available updates. The customer may also contact their Microsoft account representative to request an update.","title":"As a Microsoft employee within ISE, if I submit a feedback and move to another dev crew engagement, how would my customer get an update on that feedback?"},{"location":"engineering-feedback/feedback-faq/#as-a-microsoft-employee-within-ise-what-should-i-expectdo-after-submitting-feedback-via-ise-feedback","text":"After submitting the feedback, it is recommended to follow the feedback (a work item) in Azure DevOps. If you have configured Azure DevOps notifications to send an email on work item updates, you will receive an email when the feedback is updated. If more information about the feedback is needed, a member of the ISE Feedback team will contact you to gather more information.","title":"As a Microsoft employee within ISE, what should I expect/do after submitting feedback via ISE Feedback?"},{"location":"engineering-feedback/feedback-faq/#howwhen-are-feedback-aggregated","text":"Members of the CSE Feedback team will make a best effort to triage and review new CSE Feedback items within two weeks of the original submission date. If there is similarity across multiple feedback items, a member of the ISE Feedback team may decide to create a new feedback item which is an aggregate of similar items. This is done to aid in the creation of a unified feedback item to present to the appropriate Microsoft engineering team. On a monthly basis, the ISE Feedback team will review all feedback and generate a report consisting of the highest priority feedback. The report is presented to appropriate ISE and Microsoft leadership teams.","title":"How/when are feedback aggregated?"},{"location":"engineering-feedback/feedback-guidance/","text":"Engineering Feedback Guidance The following guidance provides a minimum set of details that will result in actionable engineering feedback. Ensure that you provide as much detail for each of the following sections as relevant and possible. Title Provide a meaningful and descriptive title. There is no need to include the Azure service in the title as this will be included as part of the Categorization section. Good examples: Supported X versions not documented Require all-in-one Y story Summary Summarize the feedback in a short paragraph. Categorization Azure Service Which Azure service does this feedback item refer to? If there are multiple Azure services involved, pick the primary service and include the details of the others in the Notes section. Type Select one of the following to describe what type of feedback is being provided: Business Blocker (e.g. No SLA on X, Service Y not GA, Service A not in Region B) Technical Blocker (e.g. Accelerated networking not available on Service X) Documentation (e.g. Instructions for configuring scenario X missing) Feature Request (e.g. Enable simple integration to X on Service Y) Stage Select one of the following to describe the lifecycle stage of the engagement that has generated this feedback: Production Staging Testing Development Impact Describe the impact to the customer and engagement that this feedback implies. Time frame Provide a time frame that this feedback item needs to be resolved within (if relevant). Priority Please provide the customer perspective priority of the feedback. Feedback is prioritized at one of the following four levels: P0 - Impact is critical and large : Needs to be addressed immediately; impact is critical and large in scope (i.e. major service outage; makes service or functions unusable/unavailable to a high portion of addressable space; no known workaround). P1 - Impact is high and significant : Needs to be addressed quickly; impacts a large percentage of addressable space and impedes progress. A partial workaround exists or is overly painful. P2 - Impact is moderate and varies in scope : Needs to be addressed in a reasonable time frame (i.e. issues that are impeding adoption and usage with no reasonable workarounds). For example, feedback may be related to feature-level issue to solve for friction. P3 - Impact is low : Issue can be address when able or eventually (i.e. relevant to core addressable space but issue does not impede progress or has reasonable workaround). For example, feedback may be related to feature ideas or opportunities. Reproduction Steps The reproduction steps are important since they help confirm and replay the issue, and are essential in demonstrating success once there is a resolution. Pre-requisites Provide a clear set of all conditions and pre-requisites required before following the set of reproduction steps. These could include: Platform (e.g. AKS 1.16.4 cluster with Azure CNI, Ubuntu 19.04 VM) Services (e.g. Azure Key Vault, Azure Monitor) Networking (e.g. VNET with subnet) Steps Provide a clear set of repeatable steps that will allow for this feedback to be reproduced. This can take the form of: Scripts (e.g. bash, PowerShell, terraform, arm template) Command line instructions (e.g. az, helm, terraform) Screen shots (e.g. azure portal screens) Notes Include items like architecture diagrams, screenshots, logs, traces etc which can help with understanding your notes and the feedback item. Also include details about the scenario customer/partner verbatim as much as possible in the main content. What didn't work Describe what didn't work or what feature gap you identified. What was your expectation or the desired outcome Describe what you expected to happen. What was the outcome that was expected? Describe the steps you took Provide a clear description of the steps taken and the outcome/description at each point.","title":"Engineering Feedback Guidance"},{"location":"engineering-feedback/feedback-guidance/#engineering-feedback-guidance","text":"The following guidance provides a minimum set of details that will result in actionable engineering feedback. Ensure that you provide as much detail for each of the following sections as relevant and possible.","title":"Engineering Feedback Guidance"},{"location":"engineering-feedback/feedback-guidance/#title","text":"Provide a meaningful and descriptive title. There is no need to include the Azure service in the title as this will be included as part of the Categorization section. Good examples: Supported X versions not documented Require all-in-one Y story","title":"Title"},{"location":"engineering-feedback/feedback-guidance/#summary","text":"Summarize the feedback in a short paragraph.","title":"Summary"},{"location":"engineering-feedback/feedback-guidance/#categorization","text":"","title":"Categorization"},{"location":"engineering-feedback/feedback-guidance/#azure-service","text":"Which Azure service does this feedback item refer to? If there are multiple Azure services involved, pick the primary service and include the details of the others in the Notes section.","title":"Azure Service"},{"location":"engineering-feedback/feedback-guidance/#type","text":"Select one of the following to describe what type of feedback is being provided: Business Blocker (e.g. No SLA on X, Service Y not GA, Service A not in Region B) Technical Blocker (e.g. Accelerated networking not available on Service X) Documentation (e.g. Instructions for configuring scenario X missing) Feature Request (e.g. Enable simple integration to X on Service Y)","title":"Type"},{"location":"engineering-feedback/feedback-guidance/#stage","text":"Select one of the following to describe the lifecycle stage of the engagement that has generated this feedback: Production Staging Testing Development","title":"Stage"},{"location":"engineering-feedback/feedback-guidance/#impact","text":"Describe the impact to the customer and engagement that this feedback implies.","title":"Impact"},{"location":"engineering-feedback/feedback-guidance/#time-frame","text":"Provide a time frame that this feedback item needs to be resolved within (if relevant).","title":"Time frame"},{"location":"engineering-feedback/feedback-guidance/#priority","text":"Please provide the customer perspective priority of the feedback. Feedback is prioritized at one of the following four levels: P0 - Impact is critical and large : Needs to be addressed immediately; impact is critical and large in scope (i.e. major service outage; makes service or functions unusable/unavailable to a high portion of addressable space; no known workaround). P1 - Impact is high and significant : Needs to be addressed quickly; impacts a large percentage of addressable space and impedes progress. A partial workaround exists or is overly painful. P2 - Impact is moderate and varies in scope : Needs to be addressed in a reasonable time frame (i.e. issues that are impeding adoption and usage with no reasonable workarounds). For example, feedback may be related to feature-level issue to solve for friction. P3 - Impact is low : Issue can be address when able or eventually (i.e. relevant to core addressable space but issue does not impede progress or has reasonable workaround). For example, feedback may be related to feature ideas or opportunities.","title":"Priority"},{"location":"engineering-feedback/feedback-guidance/#reproduction-steps","text":"The reproduction steps are important since they help confirm and replay the issue, and are essential in demonstrating success once there is a resolution.","title":"Reproduction Steps"},{"location":"engineering-feedback/feedback-guidance/#pre-requisites","text":"Provide a clear set of all conditions and pre-requisites required before following the set of reproduction steps. These could include: Platform (e.g. AKS 1.16.4 cluster with Azure CNI, Ubuntu 19.04 VM) Services (e.g. Azure Key Vault, Azure Monitor) Networking (e.g. VNET with subnet)","title":"Pre-requisites"},{"location":"engineering-feedback/feedback-guidance/#steps","text":"Provide a clear set of repeatable steps that will allow for this feedback to be reproduced. This can take the form of: Scripts (e.g. bash, PowerShell, terraform, arm template) Command line instructions (e.g. az, helm, terraform) Screen shots (e.g. azure portal screens)","title":"Steps"},{"location":"engineering-feedback/feedback-guidance/#notes","text":"Include items like architecture diagrams, screenshots, logs, traces etc which can help with understanding your notes and the feedback item. Also include details about the scenario customer/partner verbatim as much as possible in the main content.","title":"Notes"},{"location":"engineering-feedback/feedback-guidance/#what-didnt-work","text":"Describe what didn't work or what feature gap you identified.","title":"What didn't work"},{"location":"engineering-feedback/feedback-guidance/#what-was-your-expectation-or-the-desired-outcome","text":"Describe what you expected to happen. What was the outcome that was expected?","title":"What was your expectation or the desired outcome"},{"location":"engineering-feedback/feedback-guidance/#describe-the-steps-you-took","text":"Provide a clear description of the steps taken and the outcome/description at each point.","title":"Describe the steps you took"},{"location":"machine-learning/","text":"Machine Learning Fundamentals at ISE This guideline documents the Machine Learning (ML) practices in ISE. ISE works with customers on developing ML models and putting them in production, with an emphasis on engineering and research best practices throughout the project's life cycle. Goals Provide a set of ML practices to follow in an ML project. Provide clarity on ML process and how it fits within a software engineering project. Provide best practices for the different stages of an ML project. How to use these fundamentals If you are starting a new ML project, consider reading through the general guidance documents . For specific aspects of an ML project, refer to the guidelines for different project phases . ML Project phases The diagram below shows different phases in an ideal ML project. Due to practical constraints and requirements, it might not always be possible to have a project structured in such a manner, however best practices should be followed for each individual phase. Envisioning : Initial problem understanding, customer goals and objectives. Feasibility Study : Assess whether the problem in question is feasible to solve satisfactorily using ML with the available data. Model Milestone : There is a basic model that is achieving the minimum required performance, both in terms of ML performance and system performance. Using the knowledge gathered to this milestone, define the scope, objectives, high-level architecture, definition of done and plan for the entire project. Model(s) experimentation : Tools and best practices for conducting successful model experimentation. Model(s) Operationalization : Model readiness for production checklist. General guidance ML Process Guidance ML Fundamentals checklist Data Exploration Agile ML development Testing Data Science and ML Ops code Profiling Machine Learning and ML Ops code Responsible AI Program Management for ML projects References Model Operationalization","title":"Machine Learning Fundamentals at ISE"},{"location":"machine-learning/#machine-learning-fundamentals-at-ise","text":"This guideline documents the Machine Learning (ML) practices in ISE. ISE works with customers on developing ML models and putting them in production, with an emphasis on engineering and research best practices throughout the project's life cycle.","title":"Machine Learning Fundamentals at ISE"},{"location":"machine-learning/#goals","text":"Provide a set of ML practices to follow in an ML project. Provide clarity on ML process and how it fits within a software engineering project. Provide best practices for the different stages of an ML project.","title":"Goals"},{"location":"machine-learning/#how-to-use-these-fundamentals","text":"If you are starting a new ML project, consider reading through the general guidance documents . For specific aspects of an ML project, refer to the guidelines for different project phases .","title":"How to use these fundamentals"},{"location":"machine-learning/#ml-project-phases","text":"The diagram below shows different phases in an ideal ML project. Due to practical constraints and requirements, it might not always be possible to have a project structured in such a manner, however best practices should be followed for each individual phase. Envisioning : Initial problem understanding, customer goals and objectives. Feasibility Study : Assess whether the problem in question is feasible to solve satisfactorily using ML with the available data. Model Milestone : There is a basic model that is achieving the minimum required performance, both in terms of ML performance and system performance. Using the knowledge gathered to this milestone, define the scope, objectives, high-level architecture, definition of done and plan for the entire project. Model(s) experimentation : Tools and best practices for conducting successful model experimentation. Model(s) Operationalization : Model readiness for production checklist.","title":"ML Project phases"},{"location":"machine-learning/#general-guidance","text":"ML Process Guidance ML Fundamentals checklist Data Exploration Agile ML development Testing Data Science and ML Ops code Profiling Machine Learning and ML Ops code Responsible AI Program Management for ML projects","title":"General guidance"},{"location":"machine-learning/#references","text":"Model Operationalization","title":"References"},{"location":"machine-learning/ml-data-exploration/","text":"Data Exploration After envisioning , and typically as part of the ML feasibility study , the next step is to confirm resource access and then dive deep into the available data through data exploration workshops. Purpose of the Data Exploration Workshop The purpose of the data exploration workshop is as follows: Ensure the team can access the data and compute resources that are necessary for the ML feasibility study Ensure that the data provided is of quality and is relevant to the ML solution Make sure that the project team has a good understanding of the data Make sure that the SMEs (Subject Matter Experts) needed are present for Data Exploration Workshop List people needed for the data exploration workshop Accessing Resources Prior to diving into data exploration workshops, it is important to confirm that you have access to the necessary resources (including data). Below is an example list of questions to consider before starting a data exploration workshop. What are the requirements for an account to be set up in order for the team to access data and compute resources? Are there security requirements around accessing resources (Subscriptions, Azure Resources, project management, etc.) such as VPN, 2FA, jump boxes, etc.? Data access: * Is it on-prem or on Azure already? * If it is on-prem, can we move the needed data to Azure under the appropriate subscription? Who has permission to move the data? * Is the data access approved from a legal/compliance perspective? Computation: * Is a VPN needed for the project team to access these computation nodes (Virtual Machines, Databricks clusters, etc) from their work PCs/Macs? * Any restrictions on accessing the source data system from these computation nodes? * If we want to create some compute resources, who has permissions to do so? Source code repository: * Do you have any preference on source code repository location? Backlog management and work planning: * Do you have any preference on backlog management and work planning, such as Azure DevOps, Jira or anything else? * If an existing system, are special accounts / system setups required to access? Programming Language: * Is Python/PySpark a preferred language? * Is there any internal approval processes for the Python/PySpark libraries we want to use for this engagement? Data Exploration Workshop Key objectives of the exploration workshops include the following: Understand and document the features, location, and availability of the data. What order of magnitude is the current data (e.g., GB, TB)? Is this all relevant? How does the organization decide when to collect additional data or purchase external data? Are there any examples of this? Understand the quality of the data. Is there already a data validation strategy in place? What data has been used so far to analyze recent data-driven projects? What has been found to be most useful? What was not useful? How was this judged? What additional internal data may provide insights useful for data-driven decision-making for proposed projects? What external data could be useful? What are the possible constraints or challenges in accessing or incorporating this data? How was the data collected? Are there any obvious biases due to how the data was collected? What changes to data collection, coding, integration, etc has occurred in the last 2 years that may impact the interpretation or availability of the collected data","title":"Data Exploration"},{"location":"machine-learning/ml-data-exploration/#data-exploration","text":"After envisioning , and typically as part of the ML feasibility study , the next step is to confirm resource access and then dive deep into the available data through data exploration workshops.","title":"Data Exploration"},{"location":"machine-learning/ml-data-exploration/#purpose-of-the-data-exploration-workshop","text":"The purpose of the data exploration workshop is as follows: Ensure the team can access the data and compute resources that are necessary for the ML feasibility study Ensure that the data provided is of quality and is relevant to the ML solution Make sure that the project team has a good understanding of the data Make sure that the SMEs (Subject Matter Experts) needed are present for Data Exploration Workshop List people needed for the data exploration workshop","title":"Purpose of the Data Exploration Workshop"},{"location":"machine-learning/ml-data-exploration/#accessing-resources","text":"Prior to diving into data exploration workshops, it is important to confirm that you have access to the necessary resources (including data). Below is an example list of questions to consider before starting a data exploration workshop. What are the requirements for an account to be set up in order for the team to access data and compute resources? Are there security requirements around accessing resources (Subscriptions, Azure Resources, project management, etc.) such as VPN, 2FA, jump boxes, etc.? Data access: * Is it on-prem or on Azure already? * If it is on-prem, can we move the needed data to Azure under the appropriate subscription? Who has permission to move the data? * Is the data access approved from a legal/compliance perspective? Computation: * Is a VPN needed for the project team to access these computation nodes (Virtual Machines, Databricks clusters, etc) from their work PCs/Macs? * Any restrictions on accessing the source data system from these computation nodes? * If we want to create some compute resources, who has permissions to do so? Source code repository: * Do you have any preference on source code repository location? Backlog management and work planning: * Do you have any preference on backlog management and work planning, such as Azure DevOps, Jira or anything else? * If an existing system, are special accounts / system setups required to access? Programming Language: * Is Python/PySpark a preferred language? * Is there any internal approval processes for the Python/PySpark libraries we want to use for this engagement?","title":"Accessing Resources"},{"location":"machine-learning/ml-data-exploration/#data-exploration-workshop","text":"Key objectives of the exploration workshops include the following: Understand and document the features, location, and availability of the data. What order of magnitude is the current data (e.g., GB, TB)? Is this all relevant? How does the organization decide when to collect additional data or purchase external data? Are there any examples of this? Understand the quality of the data. Is there already a data validation strategy in place? What data has been used so far to analyze recent data-driven projects? What has been found to be most useful? What was not useful? How was this judged? What additional internal data may provide insights useful for data-driven decision-making for proposed projects? What external data could be useful? What are the possible constraints or challenges in accessing or incorporating this data? How was the data collected? Are there any obvious biases due to how the data was collected? What changes to data collection, coding, integration, etc has occurred in the last 2 years that may impact the interpretation or availability of the collected data","title":"Data Exploration Workshop"},{"location":"machine-learning/ml-envisioning-summary-template/","text":"Generic Envisioning Summary Purpose of this template This is an example of an envisioning summary completed after envisioning sessions have concluded. It summarizes the materials reviewed, application scenarios discussed and decided, and the next steps in the process. Summary of Envisioning Introduction This document is to summarize what we have discussed in these envisioning sessions, and what we have decided to work on in this machine learning (ML) engagement. With this document, we hope that everyone can be on the same page regarding the scope of this ML engagement, and will ensure a successful start for the project. Materials Shared with the team List materials shared with you here. The list below contains some examples. You will want to be more specific. Business vision statement Sample Data Current problem statement Also discuss: How the current solution is built and implemented Details about the current state of the systems and processes. Applications Scenarios that Can Help [People] Achieve [Task] The following application scenarios were discussed: Scenario 1: Scenario 2: Add more scenarios as needed For each scenario, provide an appropriately descriptive name and then follow up with more details. For each scenario, discuss: What problem statement was discussed How we propose to solve the problem (there may be several proposals) Who would use the solution What would it look like to use our solution? An example of how it would bring value to the end user. Selected Scenario for this ML Engagement Which scenario was selected? Why was this scenario prioritised over the others? Will other scenarios be considered in the future? When will we revisit them / what conditions need to be met to pursue them? More Details of the Scope for Selected Scenario What is in scope? What data is available? Which performance metric to use? Bar of performance metrics What are deliverables? What\u2019s Next? Legal documents to be signed State documents and timeline Responsible AI Review Plan when to conduct a responsible AI process. What are the prerequisites to start this process? Data Exploration Workshop A data exploration workshop is planned for DATE RANGE . This data exploration workshops will be X - Y days, not including the time to gain access resources. The purpose of the data exploration workshop is as follows: Ensure the team can access the data and compute resources that are necessary for the ML feasibility study Ensure that the data provided is of quality and is relevant to the ML solution Make sure that the project team has a good understanding of the data Make sure that the SMEs (Subject Matter Experts) needed are present for Data Exploration Workshop List people needed for the data exploration workshop ML Feasibility Study till [date] Objectives State what we expect to be the objective in the feasibility study Timeline Give a possible timeline for the feasibility study Personnel needed What sorts of people/roles are needed for the feasibility study? What\u2019s After ML Feasibility Study Detail here Summary of Timeline Below is a high-level summary of the upcoming timeline: Discuss dates for the data exploration workshop, and feasibility study along with any to-do items such as starting responsible AI process, identifying engineering resources. We suggest using a concise bulleted list or a table to easily convey the information.","title":"Generic Envisioning Summary"},{"location":"machine-learning/ml-envisioning-summary-template/#generic-envisioning-summary","text":"","title":"Generic Envisioning Summary"},{"location":"machine-learning/ml-envisioning-summary-template/#purpose-of-this-template","text":"This is an example of an envisioning summary completed after envisioning sessions have concluded. It summarizes the materials reviewed, application scenarios discussed and decided, and the next steps in the process.","title":"Purpose of this template"},{"location":"machine-learning/ml-envisioning-summary-template/#summary-of-envisioning","text":"","title":"Summary of Envisioning"},{"location":"machine-learning/ml-envisioning-summary-template/#introduction","text":"This document is to summarize what we have discussed in these envisioning sessions, and what we have decided to work on in this machine learning (ML) engagement. With this document, we hope that everyone can be on the same page regarding the scope of this ML engagement, and will ensure a successful start for the project.","title":"Introduction"},{"location":"machine-learning/ml-envisioning-summary-template/#materials-shared-with-the-team","text":"List materials shared with you here. The list below contains some examples. You will want to be more specific. Business vision statement Sample Data Current problem statement Also discuss: How the current solution is built and implemented Details about the current state of the systems and processes.","title":"Materials Shared with the team"},{"location":"machine-learning/ml-envisioning-summary-template/#applications-scenarios-that-can-help-people-achieve-task","text":"The following application scenarios were discussed: Scenario 1: Scenario 2: Add more scenarios as needed For each scenario, provide an appropriately descriptive name and then follow up with more details. For each scenario, discuss: What problem statement was discussed How we propose to solve the problem (there may be several proposals) Who would use the solution What would it look like to use our solution? An example of how it would bring value to the end user.","title":"Applications Scenarios that Can Help [People] Achieve [Task]"},{"location":"machine-learning/ml-envisioning-summary-template/#selected-scenario-for-this-ml-engagement","text":"Which scenario was selected? Why was this scenario prioritised over the others? Will other scenarios be considered in the future? When will we revisit them / what conditions need to be met to pursue them?","title":"Selected Scenario for this ML Engagement"},{"location":"machine-learning/ml-envisioning-summary-template/#more-details-of-the-scope-for-selected-scenario","text":"What is in scope? What data is available? Which performance metric to use? Bar of performance metrics What are deliverables?","title":"More Details of the Scope for Selected Scenario"},{"location":"machine-learning/ml-envisioning-summary-template/#whats-next","text":"","title":"What\u2019s Next?"},{"location":"machine-learning/ml-envisioning-summary-template/#legal-documents-to-be-signed","text":"State documents and timeline","title":"Legal documents to be signed"},{"location":"machine-learning/ml-envisioning-summary-template/#responsible-ai-review","text":"Plan when to conduct a responsible AI process. What are the prerequisites to start this process?","title":"Responsible AI Review"},{"location":"machine-learning/ml-envisioning-summary-template/#data-exploration-workshop","text":"A data exploration workshop is planned for DATE RANGE . This data exploration workshops will be X - Y days, not including the time to gain access resources. The purpose of the data exploration workshop is as follows: Ensure the team can access the data and compute resources that are necessary for the ML feasibility study Ensure that the data provided is of quality and is relevant to the ML solution Make sure that the project team has a good understanding of the data Make sure that the SMEs (Subject Matter Experts) needed are present for Data Exploration Workshop List people needed for the data exploration workshop","title":"Data Exploration Workshop"},{"location":"machine-learning/ml-envisioning-summary-template/#ml-feasibility-study-till-date","text":"","title":"ML Feasibility Study till [date]"},{"location":"machine-learning/ml-envisioning-summary-template/#objectives","text":"State what we expect to be the objective in the feasibility study","title":"Objectives"},{"location":"machine-learning/ml-envisioning-summary-template/#timeline","text":"Give a possible timeline for the feasibility study","title":"Timeline"},{"location":"machine-learning/ml-envisioning-summary-template/#personnel-needed","text":"What sorts of people/roles are needed for the feasibility study?","title":"Personnel needed"},{"location":"machine-learning/ml-envisioning-summary-template/#whats-after-ml-feasibility-study","text":"Detail here","title":"What\u2019s After ML Feasibility Study"},{"location":"machine-learning/ml-envisioning-summary-template/#summary-of-timeline","text":"Below is a high-level summary of the upcoming timeline: Discuss dates for the data exploration workshop, and feasibility study along with any to-do items such as starting responsible AI process, identifying engineering resources. We suggest using a concise bulleted list or a table to easily convey the information.","title":"Summary of Timeline"},{"location":"machine-learning/ml-experimentation/","text":"Model Experimentation Overview Machine learning model experimentation involves uncertainty around the expected model results and future operationalization. To handle this uncertainty as much as possible, we propose a semi-structured process, balancing between engineering/research best practices and rapid model/data exploration. Model experimentation goals Performance : Find the best performing solution Operationalization : Keep an eye towards production, making sure that operationalization is feasible Code quality Maintain code and artifacts quality Reproducibility : Keep research active by allowing experiment tracking and reproducibility Collaboration : Foster the collaboration and joint work of multiple people on the team Model experimentation challenges Trial and error process : Difficult to plan and estimate durations and capacity. Quick and dirty : We want to fail fast and get a sense of what\u2019s working efficiently. Collaboration : How do we form a team-wide trial and error process and effective brainstorming. Code quality : How do we maintain the quality of non-production code during research. Operationalization : Switching between approaches might have a significant impact on operationalization (e.g. GPU/CPU, batch/online, parallel/sequential, runtime environments). Creating an experimentation framework which facilitates rapid experimentation , collaboration , experiment and model reproducibility , evaluation and defined APIs , and lets each team member focus on the model development and improvement, while trusting the framework to do the rest. The following tools and guidelines are aimed at achieving experimentation goals as well as addressing the aforementioned challenges. Tools and guidelines for successful model experimentation Virtual environments Source control and folder/package structure Experiment tracking Datasets and models abstractions Model evaluation Virtual environments In languages like Python and R, it is always advised to employ virtual environments. Virtual environments facilitate reproducibility, collaboration and productization. Virtual environments allow us to be consistent across our local dev envs as well as with compute resources. These environments' configuration files can be used to build the code from source in an consistent way. For more details on why we need virtual environments visit this blog post . Which virtual environment framework should I choose All virtual environments frameworks create isolation, some also propose dependency management and additional features. Decision on which framework to use depends on the complexity of the development environment (dependencies and other required resources) and on the ease of use of the framework. Types of virtual environments In ISE, we often choose from either venv , Conda or Poetry , depending on the project requirements and complexity. venv is included in Python, is the easiest to use, but lacks more advanced features like dependency management. Conda is a popular package, dependency and environment management framework. It supports multiple stacks (Python, R) and multiple versions of the same environment (e.g. multiple Python versions). Conda maintains its own package repository, therefore some packages might not be downloaded and managed directly through Conda . Poetry is a Python dependency management system which manages dependencies in a standard way using pyproject.toml files and lock files. Similar to Conda , Poetry 's dependency resolution process is sometimes slow (see FAQ ), but in cases where dependency issues are common or tricky, it provides a robust way to create reproducible and stable environments. Expected outcomes for virtual environments setup Documentation describing how to create the selected virtual environment and how to install dependencies. Environment configuration files if applicable (e.g. requirements.txt for venv , environment.yml for Conda or pyrpoject.toml for Poetry ). Virtual environments benefits Productization Collaboration Reproducibility Source control and folder or package structure Applied ML projects often contain source code, notebooks, devops scripts, documentation, scientific resources, datasets and more. We recommend coming up with an agreed folder structure to keep resources tidy. Consider deciding upon a generic folder structure for projects (e.g. which contains the folders data , src , docs and notebooks ), or adopt popular structures like the CookieCutter Data Science folder structure. Source control should be applied to allow collaboration, versioning, code reviews, traceability and backup. In data science projects, source control should be used for code, and the storing and versioning of other artifacts (e.g. data, scientific literature) should be decided upon depending on the scenario. Folder structure and source control expected outcomes Defined folder structure for all users to use, pushed to the repo. .gitignore file determining which folders should be synced with git and which should be kept locally. For example, this one . Determine how notebooks are stored and versioned (e.g. strip output from Jupyter notebooks ) Source control and folder structure benefits Collaboration Reproducibility Code quality Experiment tracking Experiment tracking tools allow data scientists and researchers to keep track of previous experiments for better understanding of the experimentation process and for the reproducibility of experiments or models. Types of experiment tracking frameworks Experiment tracking frameworks differ by the set of features they provide for collecting experiment metadata, and comparing and analyzing experiments. In ISE, we mainly use MLFlow on Databricks or Azure ML Experimentation . Note that some experiment tracking frameworks require a deployment, while others are SaaS. Experiment tracking outcomes Decide on an experiment tracking framework Ensure it is accessible to all users Document set-up on local environments Define datasets and evaluation in a way which will allow the comparison of all experiments. Consistency across datasets and evaluation is paramount for experiment comparison . Ensure full reproducibility by assuring that all required details are tracked (i.e. dataset names and versions, parameters, code, environment) Experiment tracking benefits Model performance Reproducibility Collaboration Code quality Datasets and models abstractions By creating abstractions to building blocks (e.g., datasets, models, evaluators), we allow the easy introduction of new logic into the experimentation pipeline while keeping the agreed upon experimentation flow intact. These abstractions can be created using different mechanisms. For example, we can use Object-Oriented Programming (OOP) solutions like abstract classes: An example from scikit-learn describing the creation of new estimators compatible with the API . An example from PyTorch on extending the abstract Dataset class . Abstraction outcomes Different building blocks have defined APIs allowing them to be replaced or extended. Replacing building blocks does not break the original experimentation flow. Mock building blocks are used for unit tests APIs/mocks are shared with the engineering teams for integration with other modules. Abstraction benefits Collaboration Code quality Reproducibility Operationalization Model performance Model evaluation When deciding on the evaluation of the ML model/process, consider the following checklist: Evaluation logic is approved by all stakeholders. Relationship between evaluation logic and business KPIs is analyzed and decided. Evaluation flow is applicable for all present and future models (i.e. does not assume some prediction structure or method-specific process). Evaluation code is unit-tested and reviewed by all team members. Evaluation flow facilitates further results and error analysis. Evaluation development process outcomes Evaluation strategy is agreed upon all stakeholders Research and discussion on various evaluation methods and metrics is documented. The code holding the logic and data structures for evaluation is reviewed and tested. Documentation on how to apply evaluation is reviewed. Performance metrics are automatically tracked into the experiment tracker. Evaluation development process benefits Model performance Code quality Collaboration Reproducibility","title":"Model Experimentation"},{"location":"machine-learning/ml-experimentation/#model-experimentation","text":"","title":"Model Experimentation"},{"location":"machine-learning/ml-experimentation/#overview","text":"Machine learning model experimentation involves uncertainty around the expected model results and future operationalization. To handle this uncertainty as much as possible, we propose a semi-structured process, balancing between engineering/research best practices and rapid model/data exploration.","title":"Overview"},{"location":"machine-learning/ml-experimentation/#model-experimentation-goals","text":"Performance : Find the best performing solution Operationalization : Keep an eye towards production, making sure that operationalization is feasible Code quality Maintain code and artifacts quality Reproducibility : Keep research active by allowing experiment tracking and reproducibility Collaboration : Foster the collaboration and joint work of multiple people on the team","title":"Model experimentation goals"},{"location":"machine-learning/ml-experimentation/#model-experimentation-challenges","text":"Trial and error process : Difficult to plan and estimate durations and capacity. Quick and dirty : We want to fail fast and get a sense of what\u2019s working efficiently. Collaboration : How do we form a team-wide trial and error process and effective brainstorming. Code quality : How do we maintain the quality of non-production code during research. Operationalization : Switching between approaches might have a significant impact on operationalization (e.g. GPU/CPU, batch/online, parallel/sequential, runtime environments). Creating an experimentation framework which facilitates rapid experimentation , collaboration , experiment and model reproducibility , evaluation and defined APIs , and lets each team member focus on the model development and improvement, while trusting the framework to do the rest. The following tools and guidelines are aimed at achieving experimentation goals as well as addressing the aforementioned challenges.","title":"Model experimentation challenges"},{"location":"machine-learning/ml-experimentation/#tools-and-guidelines-for-successful-model-experimentation","text":"Virtual environments Source control and folder/package structure Experiment tracking Datasets and models abstractions Model evaluation","title":"Tools and guidelines for successful model experimentation"},{"location":"machine-learning/ml-experimentation/#virtual-environments","text":"In languages like Python and R, it is always advised to employ virtual environments. Virtual environments facilitate reproducibility, collaboration and productization. Virtual environments allow us to be consistent across our local dev envs as well as with compute resources. These environments' configuration files can be used to build the code from source in an consistent way. For more details on why we need virtual environments visit this blog post .","title":"Virtual environments"},{"location":"machine-learning/ml-experimentation/#which-virtual-environment-framework-should-i-choose","text":"All virtual environments frameworks create isolation, some also propose dependency management and additional features. Decision on which framework to use depends on the complexity of the development environment (dependencies and other required resources) and on the ease of use of the framework.","title":"Which virtual environment framework should I choose"},{"location":"machine-learning/ml-experimentation/#types-of-virtual-environments","text":"In ISE, we often choose from either venv , Conda or Poetry , depending on the project requirements and complexity. venv is included in Python, is the easiest to use, but lacks more advanced features like dependency management. Conda is a popular package, dependency and environment management framework. It supports multiple stacks (Python, R) and multiple versions of the same environment (e.g. multiple Python versions). Conda maintains its own package repository, therefore some packages might not be downloaded and managed directly through Conda . Poetry is a Python dependency management system which manages dependencies in a standard way using pyproject.toml files and lock files. Similar to Conda , Poetry 's dependency resolution process is sometimes slow (see FAQ ), but in cases where dependency issues are common or tricky, it provides a robust way to create reproducible and stable environments.","title":"Types of virtual environments"},{"location":"machine-learning/ml-experimentation/#expected-outcomes-for-virtual-environments-setup","text":"Documentation describing how to create the selected virtual environment and how to install dependencies. Environment configuration files if applicable (e.g. requirements.txt for venv , environment.yml for Conda or pyrpoject.toml for Poetry ).","title":"Expected outcomes for virtual environments setup"},{"location":"machine-learning/ml-experimentation/#virtual-environments-benefits","text":"Productization Collaboration Reproducibility","title":"Virtual environments benefits"},{"location":"machine-learning/ml-experimentation/#source-control-and-folder-or-package-structure","text":"Applied ML projects often contain source code, notebooks, devops scripts, documentation, scientific resources, datasets and more. We recommend coming up with an agreed folder structure to keep resources tidy. Consider deciding upon a generic folder structure for projects (e.g. which contains the folders data , src , docs and notebooks ), or adopt popular structures like the CookieCutter Data Science folder structure. Source control should be applied to allow collaboration, versioning, code reviews, traceability and backup. In data science projects, source control should be used for code, and the storing and versioning of other artifacts (e.g. data, scientific literature) should be decided upon depending on the scenario.","title":"Source control and folder or package structure"},{"location":"machine-learning/ml-experimentation/#folder-structure-and-source-control-expected-outcomes","text":"Defined folder structure for all users to use, pushed to the repo. .gitignore file determining which folders should be synced with git and which should be kept locally. For example, this one . Determine how notebooks are stored and versioned (e.g. strip output from Jupyter notebooks )","title":"Folder structure and source control expected outcomes"},{"location":"machine-learning/ml-experimentation/#source-control-and-folder-structure-benefits","text":"Collaboration Reproducibility Code quality","title":"Source control and folder structure benefits"},{"location":"machine-learning/ml-experimentation/#experiment-tracking","text":"Experiment tracking tools allow data scientists and researchers to keep track of previous experiments for better understanding of the experimentation process and for the reproducibility of experiments or models.","title":"Experiment tracking"},{"location":"machine-learning/ml-experimentation/#types-of-experiment-tracking-frameworks","text":"Experiment tracking frameworks differ by the set of features they provide for collecting experiment metadata, and comparing and analyzing experiments. In ISE, we mainly use MLFlow on Databricks or Azure ML Experimentation . Note that some experiment tracking frameworks require a deployment, while others are SaaS.","title":"Types of experiment tracking frameworks"},{"location":"machine-learning/ml-experimentation/#experiment-tracking-outcomes","text":"Decide on an experiment tracking framework Ensure it is accessible to all users Document set-up on local environments Define datasets and evaluation in a way which will allow the comparison of all experiments. Consistency across datasets and evaluation is paramount for experiment comparison . Ensure full reproducibility by assuring that all required details are tracked (i.e. dataset names and versions, parameters, code, environment)","title":"Experiment tracking outcomes"},{"location":"machine-learning/ml-experimentation/#experiment-tracking-benefits","text":"Model performance Reproducibility Collaboration Code quality","title":"Experiment tracking benefits"},{"location":"machine-learning/ml-experimentation/#datasets-and-models-abstractions","text":"By creating abstractions to building blocks (e.g., datasets, models, evaluators), we allow the easy introduction of new logic into the experimentation pipeline while keeping the agreed upon experimentation flow intact. These abstractions can be created using different mechanisms. For example, we can use Object-Oriented Programming (OOP) solutions like abstract classes: An example from scikit-learn describing the creation of new estimators compatible with the API . An example from PyTorch on extending the abstract Dataset class .","title":"Datasets and models abstractions"},{"location":"machine-learning/ml-experimentation/#abstraction-outcomes","text":"Different building blocks have defined APIs allowing them to be replaced or extended. Replacing building blocks does not break the original experimentation flow. Mock building blocks are used for unit tests APIs/mocks are shared with the engineering teams for integration with other modules.","title":"Abstraction outcomes"},{"location":"machine-learning/ml-experimentation/#abstraction-benefits","text":"Collaboration Code quality Reproducibility Operationalization Model performance","title":"Abstraction benefits"},{"location":"machine-learning/ml-experimentation/#model-evaluation","text":"When deciding on the evaluation of the ML model/process, consider the following checklist: Evaluation logic is approved by all stakeholders. Relationship between evaluation logic and business KPIs is analyzed and decided. Evaluation flow is applicable for all present and future models (i.e. does not assume some prediction structure or method-specific process). Evaluation code is unit-tested and reviewed by all team members. Evaluation flow facilitates further results and error analysis.","title":"Model evaluation"},{"location":"machine-learning/ml-experimentation/#evaluation-development-process-outcomes","text":"Evaluation strategy is agreed upon all stakeholders Research and discussion on various evaluation methods and metrics is documented. The code holding the logic and data structures for evaluation is reviewed and tested. Documentation on how to apply evaluation is reviewed. Performance metrics are automatically tracked into the experiment tracker.","title":"Evaluation development process outcomes"},{"location":"machine-learning/ml-experimentation/#evaluation-development-process-benefits","text":"Model performance Code quality Collaboration Reproducibility","title":"Evaluation development process benefits"},{"location":"machine-learning/ml-feasibility-study/","text":"Feasibility Studies The main goal of feasibility studies is to assess whether it is feasible to solve the problem satisfactorily using ML with the available data. We want to avoid investing too much in the solution before we have: Sufficient evidence that a solution would be the best technical solution given the business case Sufficient evidence that a solution is compatible with the problem context Sufficient evidence that a solution is possible Some vetted direction on what a solution should look like This effort ensures quality solutions backed by the appropriate, thorough amount of consideration and evidence. When are feasibility studies useful? Every engagement can benefit from a feasibility study early in the project. Architectural discussions can still occur in parallel as the team works towards gaining a solid understanding and definition of what will be built. Feasibility studies can last between 4-16 weeks, depending on specific problem details, volume of data, state of the data etc. Starting with a 4-week milestone might be useful, during which it can be determined how much more time, if any, is required for completion. Who collaborates on feasibility studies? Collaboration from individuals with diverse skill sets is desired at this stage, including data scientists, data engineers, software engineers, PMs, human experience researchers, and domain experts. It embraces the use of engineering fundamentals, with some flexibility. For example, not all experimentation requires full test coverage and code review. Experimentation is typically not part of a CI/CD pipeline. Artifacts may live in the main branch as a folder excluded from the CI/CD pipeline, or as a separate experimental branch, depending on customer/team preferences. What do feasibility studies entail? Problem definition and desired outcome Ensure that the problem is complex enough that coding rules or manual scaling is unrealistic Clear definition of the problem from business and technical perspectives Deep contextual understanding Confirm that the following questions can be answered based on what was learned during the Discovery Phase of the project. For items that can not be satisfactorily answered, undertake additional investigation to answer. Understanding the people who are using and/or affected by the solution Understanding the contextual forces at play around the problem, including goals, culture, and historical context To accomplish this a researcher will: Collaborate with customers and colleagues to explore the landscape of people who relate to and may be affected by the problem space being explored (Users, stakeholders, subject matter experts, etc) Formulate the research question(s) to be addressed Select and design research to best serve the research question(s) Identify and select representative research participants across the problem space with whom to conduct the research Construct a research plan and necessary preparation documents for the selected research method(s) Conduct research activity with the participants via the selected method(s) Synthesize, analyze, and interpret research findings Where relevant, build frameworks, artifacts and processes that help explore the findings and implications of the research across the team Share what was uncovered and understood, and the implications thereof across the engagement team and relevant stakeholders. If the above research was conducted during the Discovery phase, it should be reviewed, and any substantial knowledge gaps should be identified and filled by following the above process. Data access Verify that the full team has access to the data Set up a dedicated and/or restricted environment if required Perform any required de-identification or redaction of sensitive information Understand data access requirements (retention, role-based access, etc.) Data discovery Hold a data exploration workshop and deep dive with domain experts Understand data availability and confirm the team's access Understand the data dictionary, if available Understand the quality of the data. Is there already a data validation strategy in place? Ensure required data is present in reasonable volumes For supervised problems (most common), assess the availability of labels or data that can be used to effectively approximate labels If applicable, ensure all data can be joined as required and understand how Ideally obtain or create an entity relationship diagram (ERD) Potentially uncover new useful data sources Architecture discovery Clear picture of existing architecture Infrastructure spikes Concept ideation and iteration Develop value proposition(s) for users and stakeholders based on the contextual understanding developed through the discovery process (e.g. key elements of value, benefits) As relevant, make use of Co-creation with team Co-creation with users and stakeholders As relevant, create vignettes, narratives or other materials to communicate the concept Identify the next set of hypotheses or unknowns to be tested (see concept testing) Revisit and iterate on the concept throughout discovery as understanding of the problem space evolves Exploratory data analysis (EDA) Data deep dive Understand feature and label value distributions Understand correlations among features and between features and labels Understand data specific problem constraints like missing values, categorical cardinality, potential for data leakage etc. Identify any gaps in data that couldn't be identified in the data discovery phase Pave the way of further understanding of what techniques are applicable Establish a mutual understanding of what data is in or out of scope for feasibility, ensuring that the data in scope is significant for the business Data pre-processing Happens during EDA and hypothesis testing Feature engineering Sampling Scaling and/or discretization Noise handling Hypothesis testing Design several potential solutions using theoretically applicable algorithms and techniques, starting with the simplest reasonable baseline Train model(s) Evaluate performance and determine if satisfactory Tweak experimental solution designs based on outcomes Iterate Thoroughly document each step and outcome, plus any resulting hypotheses for easy following of the decision-making process Concept testing Where relevant, to test the value proposition, concepts or aspects of the experience Plan user, stakeholder and expert research Develop and design necessary research materials Synthesize and evaluate feedback to incorporate into concept development Continue to iterate and test different elements of the concept as necessary, including testing to best serve RAI goals and guidelines Ensure that the proposed solution and framing are compatible with and acceptable to affected people Ensure that the proposed solution and framing is compatible with existing business goals and context Risk assessment Identification and assessment of risks and constraints Responsible AI Consideration of responsible AI principles Understanding of users and stakeholders\u2019 contexts, needs and concerns to inform development of RAI Testing AI concept and experience elements with users and stakeholders Discussion and feedback from diverse perspectives around any responsible AI concerns Output of a feasibility study Possible outcomes The main outcome is a feasibility study report, with a recommendation on next steps: - If there is not enough evidence to support the hypothesis that this problem can be solved using ML, as aligned with the pre-determined performance measures and business impact: * We detail the gaps and challenges that prevented us from reaching a positive outcome * We may scope down the project, if applicable * We may look at re-scoping the problem taking into account the findings of the feasibility study * We assess the possibility to collect more data or improve data quality If there is enough evidence to support the hypothesis that this problem can be solved using ML Provide recommendations and technical assets for moving to the operationalization phase","title":"Feasibility Studies"},{"location":"machine-learning/ml-feasibility-study/#feasibility-studies","text":"The main goal of feasibility studies is to assess whether it is feasible to solve the problem satisfactorily using ML with the available data. We want to avoid investing too much in the solution before we have: Sufficient evidence that a solution would be the best technical solution given the business case Sufficient evidence that a solution is compatible with the problem context Sufficient evidence that a solution is possible Some vetted direction on what a solution should look like This effort ensures quality solutions backed by the appropriate, thorough amount of consideration and evidence.","title":"Feasibility Studies"},{"location":"machine-learning/ml-feasibility-study/#when-are-feasibility-studies-useful","text":"Every engagement can benefit from a feasibility study early in the project. Architectural discussions can still occur in parallel as the team works towards gaining a solid understanding and definition of what will be built. Feasibility studies can last between 4-16 weeks, depending on specific problem details, volume of data, state of the data etc. Starting with a 4-week milestone might be useful, during which it can be determined how much more time, if any, is required for completion.","title":"When are feasibility studies useful?"},{"location":"machine-learning/ml-feasibility-study/#who-collaborates-on-feasibility-studies","text":"Collaboration from individuals with diverse skill sets is desired at this stage, including data scientists, data engineers, software engineers, PMs, human experience researchers, and domain experts. It embraces the use of engineering fundamentals, with some flexibility. For example, not all experimentation requires full test coverage and code review. Experimentation is typically not part of a CI/CD pipeline. Artifacts may live in the main branch as a folder excluded from the CI/CD pipeline, or as a separate experimental branch, depending on customer/team preferences.","title":"Who collaborates on feasibility studies?"},{"location":"machine-learning/ml-feasibility-study/#what-do-feasibility-studies-entail","text":"","title":"What do feasibility studies entail?"},{"location":"machine-learning/ml-feasibility-study/#problem-definition-and-desired-outcome","text":"Ensure that the problem is complex enough that coding rules or manual scaling is unrealistic Clear definition of the problem from business and technical perspectives","title":"Problem definition and desired outcome"},{"location":"machine-learning/ml-feasibility-study/#deep-contextual-understanding","text":"Confirm that the following questions can be answered based on what was learned during the Discovery Phase of the project. For items that can not be satisfactorily answered, undertake additional investigation to answer. Understanding the people who are using and/or affected by the solution Understanding the contextual forces at play around the problem, including goals, culture, and historical context To accomplish this a researcher will: Collaborate with customers and colleagues to explore the landscape of people who relate to and may be affected by the problem space being explored (Users, stakeholders, subject matter experts, etc) Formulate the research question(s) to be addressed Select and design research to best serve the research question(s) Identify and select representative research participants across the problem space with whom to conduct the research Construct a research plan and necessary preparation documents for the selected research method(s) Conduct research activity with the participants via the selected method(s) Synthesize, analyze, and interpret research findings Where relevant, build frameworks, artifacts and processes that help explore the findings and implications of the research across the team Share what was uncovered and understood, and the implications thereof across the engagement team and relevant stakeholders. If the above research was conducted during the Discovery phase, it should be reviewed, and any substantial knowledge gaps should be identified and filled by following the above process.","title":"Deep contextual understanding"},{"location":"machine-learning/ml-feasibility-study/#data-access","text":"Verify that the full team has access to the data Set up a dedicated and/or restricted environment if required Perform any required de-identification or redaction of sensitive information Understand data access requirements (retention, role-based access, etc.)","title":"Data access"},{"location":"machine-learning/ml-feasibility-study/#data-discovery","text":"Hold a data exploration workshop and deep dive with domain experts Understand data availability and confirm the team's access Understand the data dictionary, if available Understand the quality of the data. Is there already a data validation strategy in place? Ensure required data is present in reasonable volumes For supervised problems (most common), assess the availability of labels or data that can be used to effectively approximate labels If applicable, ensure all data can be joined as required and understand how Ideally obtain or create an entity relationship diagram (ERD) Potentially uncover new useful data sources","title":"Data discovery"},{"location":"machine-learning/ml-feasibility-study/#architecture-discovery","text":"Clear picture of existing architecture Infrastructure spikes","title":"Architecture discovery"},{"location":"machine-learning/ml-feasibility-study/#concept-ideation-and-iteration","text":"Develop value proposition(s) for users and stakeholders based on the contextual understanding developed through the discovery process (e.g. key elements of value, benefits) As relevant, make use of Co-creation with team Co-creation with users and stakeholders As relevant, create vignettes, narratives or other materials to communicate the concept Identify the next set of hypotheses or unknowns to be tested (see concept testing) Revisit and iterate on the concept throughout discovery as understanding of the problem space evolves","title":"Concept ideation and iteration"},{"location":"machine-learning/ml-feasibility-study/#exploratory-data-analysis-eda","text":"Data deep dive Understand feature and label value distributions Understand correlations among features and between features and labels Understand data specific problem constraints like missing values, categorical cardinality, potential for data leakage etc. Identify any gaps in data that couldn't be identified in the data discovery phase Pave the way of further understanding of what techniques are applicable Establish a mutual understanding of what data is in or out of scope for feasibility, ensuring that the data in scope is significant for the business","title":"Exploratory data analysis (EDA)"},{"location":"machine-learning/ml-feasibility-study/#data-pre-processing","text":"Happens during EDA and hypothesis testing Feature engineering Sampling Scaling and/or discretization Noise handling","title":"Data pre-processing"},{"location":"machine-learning/ml-feasibility-study/#hypothesis-testing","text":"Design several potential solutions using theoretically applicable algorithms and techniques, starting with the simplest reasonable baseline Train model(s) Evaluate performance and determine if satisfactory Tweak experimental solution designs based on outcomes Iterate Thoroughly document each step and outcome, plus any resulting hypotheses for easy following of the decision-making process","title":"Hypothesis testing"},{"location":"machine-learning/ml-feasibility-study/#concept-testing","text":"Where relevant, to test the value proposition, concepts or aspects of the experience Plan user, stakeholder and expert research Develop and design necessary research materials Synthesize and evaluate feedback to incorporate into concept development Continue to iterate and test different elements of the concept as necessary, including testing to best serve RAI goals and guidelines Ensure that the proposed solution and framing are compatible with and acceptable to affected people Ensure that the proposed solution and framing is compatible with existing business goals and context","title":"Concept testing"},{"location":"machine-learning/ml-feasibility-study/#risk-assessment","text":"Identification and assessment of risks and constraints","title":"Risk assessment"},{"location":"machine-learning/ml-feasibility-study/#responsible-ai","text":"Consideration of responsible AI principles Understanding of users and stakeholders\u2019 contexts, needs and concerns to inform development of RAI Testing AI concept and experience elements with users and stakeholders Discussion and feedback from diverse perspectives around any responsible AI concerns","title":"Responsible AI"},{"location":"machine-learning/ml-feasibility-study/#output-of-a-feasibility-study","text":"","title":"Output of a feasibility study"},{"location":"machine-learning/ml-feasibility-study/#possible-outcomes","text":"The main outcome is a feasibility study report, with a recommendation on next steps: - If there is not enough evidence to support the hypothesis that this problem can be solved using ML, as aligned with the pre-determined performance measures and business impact: * We detail the gaps and challenges that prevented us from reaching a positive outcome * We may scope down the project, if applicable * We may look at re-scoping the problem taking into account the findings of the feasibility study * We assess the possibility to collect more data or improve data quality If there is enough evidence to support the hypothesis that this problem can be solved using ML Provide recommendations and technical assets for moving to the operationalization phase","title":"Possible outcomes"},{"location":"machine-learning/ml-fundamentals-checklist/","text":"ML Fundamentals Checklist This checklist helps ensure that our ML projects meet our ML Fundamentals. The items below are not sequential, but rather organized by different parts of an ML project. Data Quality and Governance There is access to data. Labels exist for dataset of interest. Data quality evaluation. Able to track data lineage. Understanding of where the data is coming from and any policies related to data access. Gather Security and Compliance requirements. Feasibility Study A feasibility study was performed to assess if the data supports the proposed tasks. Rigorous Exploratory data analysis was performed (including analysis of data distribution). Hypotheses were tested producing sufficient evidence to either support or reject that an ML approach is feasible to solve the problem. ROI estimation and risk analysis was performed for the project. ML outputs/assets can be integrated within the production system. Recommendations on how to proceed have been documented. Evaluation and Metrics Clear definition of how performance will be measured. The evaluation metrics are somewhat connected to the success criteria. The metrics can be calculated with the datasets available. Evaluation flow can be applied to all versions of the model. Evaluation code is unit-tested and reviewed by all team members. Evaluation flow facilitates further results and error analysis. Model Baseline Well-defined baseline model exists and its performance is calculated. ( More details on well defined baselines ) The performance of other ML models can be compared with the model baseline. Experimentation setup Well-defined train/test dataset with labels. Reproducible and logged experiments in an environment accessible by all data scientists to quickly iterate. Defined experiments/hypothesis to test. Results of experiments are documented. Model hyper parameters are tuned systematically. Same performance evaluation metrics and consistent datasets are used when comparing candidate models. Production Model readiness checklist reviewed. Model reviews were performed (covering model debugging, reviews of training and evaluation approaches, model performance). Data pipeline for inferencing, including an end-to-end tests. SLAs requirements for models are gathered and documented. Monitoring of data feeds and model output. Ensure consistent schema is used across the system with expected input/output defined for each component of the pipelines (data processing as well as models). Responsible AI reviewed.","title":"ML Fundamentals Checklist"},{"location":"machine-learning/ml-fundamentals-checklist/#ml-fundamentals-checklist","text":"This checklist helps ensure that our ML projects meet our ML Fundamentals. The items below are not sequential, but rather organized by different parts of an ML project.","title":"ML Fundamentals Checklist"},{"location":"machine-learning/ml-fundamentals-checklist/#data-quality-and-governance","text":"There is access to data. Labels exist for dataset of interest. Data quality evaluation. Able to track data lineage. Understanding of where the data is coming from and any policies related to data access. Gather Security and Compliance requirements.","title":"Data Quality and Governance"},{"location":"machine-learning/ml-fundamentals-checklist/#feasibility-study","text":"A feasibility study was performed to assess if the data supports the proposed tasks. Rigorous Exploratory data analysis was performed (including analysis of data distribution). Hypotheses were tested producing sufficient evidence to either support or reject that an ML approach is feasible to solve the problem. ROI estimation and risk analysis was performed for the project. ML outputs/assets can be integrated within the production system. Recommendations on how to proceed have been documented.","title":"Feasibility Study"},{"location":"machine-learning/ml-fundamentals-checklist/#evaluation-and-metrics","text":"Clear definition of how performance will be measured. The evaluation metrics are somewhat connected to the success criteria. The metrics can be calculated with the datasets available. Evaluation flow can be applied to all versions of the model. Evaluation code is unit-tested and reviewed by all team members. Evaluation flow facilitates further results and error analysis.","title":"Evaluation and Metrics"},{"location":"machine-learning/ml-fundamentals-checklist/#model-baseline","text":"Well-defined baseline model exists and its performance is calculated. ( More details on well defined baselines ) The performance of other ML models can be compared with the model baseline.","title":"Model Baseline"},{"location":"machine-learning/ml-fundamentals-checklist/#experimentation-setup","text":"Well-defined train/test dataset with labels. Reproducible and logged experiments in an environment accessible by all data scientists to quickly iterate. Defined experiments/hypothesis to test. Results of experiments are documented. Model hyper parameters are tuned systematically. Same performance evaluation metrics and consistent datasets are used when comparing candidate models.","title":"Experimentation setup"},{"location":"machine-learning/ml-fundamentals-checklist/#production","text":"Model readiness checklist reviewed. Model reviews were performed (covering model debugging, reviews of training and evaluation approaches, model performance). Data pipeline for inferencing, including an end-to-end tests. SLAs requirements for models are gathered and documented. Monitoring of data feeds and model output. Ensure consistent schema is used across the system with expected input/output defined for each component of the pipelines (data processing as well as models). Responsible AI reviewed.","title":"Production"},{"location":"machine-learning/ml-model-checklist/","text":"ML model production checklist The purpose of this checklist is to make sure that: The team assessed if the model is ready for production before moving to the scoring process The team has prepared a production plan for the model The checklist provides guidelines for creating this production plan. It should be used by teams/organizations that already built/trained an ML model and are now considering putting it into production. Checklist Before putting an individual ML model into production, the following aspects should be considered: Is there a well defined baseline? Is the model performing better than the baseline? Are machine learning performance metrics defined for both training and scoring? Is the model benchmarked? Can ground truth be obtained or inferred in production? Has the data distribution of training, testing and validation sets been analyzed? Have goals and hard limits for performance, speed of prediction and costs been established so they can be considered if trade-offs need to be made? How will the model be integrated into other systems, and what impact will it have? How will incoming data quality be monitored? How will drift in data characteristics be monitored? How will performance be monitored? Have any ethical concerns been taken into account? Please note that there might be scenarios where it is not possible to check all the items on this checklist. However, it is advised to go through all items and make informed decisions based on your specific use case. Will your model performance be different in production than during training phase Once deployed into production, the model might be performing much worse than expected. This poor performance could be a result of: The data to be scored in production is significantly different from the train and test datasets The feature engineering steps are different or inconsistent in production compared to the training process The performance measure is not consistent (for example your test set covers several months of data where the performance metric for production has been calculated for one month of data) Is there a well-defined baseline? Is the model performing better than the baseline? A good way to think of a model baseline is the simplest model one can come up with: either a simple threshold, a random guess or a very basic linear model. This baseline is the reference point your model needs to outperform. A well-defined baseline is different for each problem type and there is no one size fits all approach. As an example, let's consider some common types of machine learning problems: Classification : Predicting between a positive and a negative class. Either the class with the most observations or a simple logistic regression model can be the baseline. Regression : Predicting the house prices in a city. The average house price for the last year or last month, a simple linear regression model, or the previous median house price in a neighborhood could be the baseline. Image classification : Building an image classifier to distinguish between cats and no cats in an image. If your classes are unbalanced: 70% cats and 30% no cats and if you always predict cats, your naive classifier has 70% accuracy and this can be your baseline. If your classes are balanced: 52% cats and 48% no cats, then a simple convolutional architecture can be the baseline (1 conv layer + 1 max pooling + 1 dense). Additionally, human accuracy at labelling can also be the baseline in an image classification scenario. Some questions to ask when comparing to a baseline: How does your model compare to a random guess? How does your model performance compare to applying a simple threshold? How does your model compare with always predicting the most common value? Note : In some cases, human parity might be too ambitious as a baseline, but this should be decided on a case by case basis. Human accuracy is one of the available options, but not the only one. Resources: \"How To Get Baseline Results And Why They Matter\" article \"Always start with a stupid model, no exceptions.\" article Are machine learning performance metrics defined for both training and scoring? The methodology of translating the training metrics to scoring metrics should be well-defined and understood. Depending on the data type and model, the model metrics calculation might differ in production and in training. For example, the training procedure calculated metrics for a long period of time (a year, a decade) with different seasonal characteristics while the scoring procedure will calculate the metrics per a restricted time interval (for example a week, a month, a quarter). Well-defined ML performance metrics are essential in production so that a decrease or increase in model performance can be accurately detected. Things to consider: In forecasting, if you change the period of assessing the performance, from one month to a year for example, then you might get a different result. For example, if your model is predicting sales of a product per day and the RMSE (Root Mean Squared Error) is very low for the first month the model is in production. As the model is live for longer, the RMSE is increasing, becoming 10x the RMSE for the first year compared to the first month. In a classification scenario, the overall accuracy is good, but the model is performing poorly for some subgroups. For example, a classifier has an accuracy of 80% overall, but only 55% for the 20-30 age group. If this is a significant age group for the production data, then your accuracy might suffer greatly when in production. In scene classification scenario, the model is trying to identify a specific scene in a video, and the model has been trained and tested (80-20 split) on 50000 segments where half are segments containing the scene and half of the segments do not contain the scene. The accuracy on the training set is 85% and 84% on the test set. However, when an entire video is scored, scores are obtained on all segments, and we expect few segments to contain the scene. The accuracy for an entire video is not comparable with the training/test set procedure in this case, hence different metrics should be considered. If sampling techniques (over-sampling, under-sampling) are used to train model when classes are imbalanced, ensure the metrics used during training are comparable with the ones used in scoring. If the number of samples used for training and testing is small, the performance metrics might change significantly as new data is scored. Is the model benchmarked? The trained model to be put into production is well benchmarked if machine learning performance metrics (such as accuracy, recall, RMSE or whatever is appropriate) are measured on the train and test set. Furthermore, the train and test set split should be well documented and reproducible. Can ground truth be obtained or inferred in production? Without a reliable ground truth, the machine learning metrics cannot be calculated. It is important to identify if the ground truth can be obtained as the model is scoring new data by either manual or automatic means. If the ground truth cannot be obtained systematically, other proxies and methodology should be investigated in order to obtain some measure of model performance. One option is to use humans to manually label samples. One important aspect of human labelling is to take into account the human accuracy. If there are two different individuals labelling an image, the labels will likely be different for some samples. It is important to understand how the labels were obtained to assess the reliability of the ground truth (that is why we talk about human accuracy). For clarity, let's consider the following examples (by no means an exhaustive list): Forecasting : Forecasting scenarios are an example of machine learning problems where the ground truth could be obtained in most cases even though a delay might occur. For example, for a model predicting the sales of ice cream in a local shop, the ground truth will be obtained as the sales are happening, but it might appear in the system at a later time than as the model prediction. Recommender systems : For recommender system, obtaining the ground truth is a complex problem in most cases as there is no way of identifying the ideal recommendation. For a retail website for example, click/not click, buy/not buy or other user interaction with recommendation can be used as ground truth proxies. Object detection in images : For an object detection model, as new images are scored, there are no new labels being generated automatically. One option to obtain the ground truth for the new images is to use people to manually label the images. Human labelling is costly, time-consuming and not 100% accurate, so in most cases, only a subset of images can be labelled. These samples can be chosen at random or by using active learning techniques of selecting the most informative unlabeled samples. Has the data distribution of training, testing and validation sets been analyzed? The data distribution of your training, test and validation (if applicable) dataset (including labels) should be analyzed to ensure they all come from the same distribution. If this is not the case, some options to consider are: re-shuffling, re-sampling, modifying the data, more samples need to be gathered or features removed from the dataset. Significant differences in the data distributions of the different datasets can greatly impact the performance of the model. Some potential questions to ask: How much does the training and test data represent the end result? Is the distribution of each individual feature consistent across all your datasets? (i.e. same representation of age groups, gender, race etc.) Is there any data lineage information? Where did the data come from? How was the data collected? Can collection and labelling be automated? Resources: \"Splitting into train, dev and test\" tutorial Have goals and hard limits for performance, speed of prediction and costs been established, so they can be considered if trade-offs need to be made? Some machine learning models achieve high ML performance, but they are costly and time-consuming to run. In those cases, a less performant and cheaper model could be preferred. Hence, it is important to calculate the model performance metrics (accuracy, precision, recall, RMSE etc), but also to gather data on how expensive it will be to run the model and how long it will take to run. Once this data is gathered, an informed decision should be made on what model to productionize. System metrics to consider: CPU/GPU/memory usage Cost per prediction Time taken to make a prediction How will the model be integrated into other systems, and what impact will it have? Machine Learning models do not exist in isolation, but rather they are part of a much larger system. These systems could be old, proprietary systems or new systems being developed as a results of the creation a new machine learning model. In both of those cases, it is important to understand where the actual model is going to fit in, what output is expected from the model and how that output is going to be used by the larger system. Additionally, it is essential to decide if the model will be used for batch and/or real-time inference as production paths might differ. Possible questions to assess model impact: Is there a human in the loop? How is feedback collected through the system? (for example how do we know if a prediction is wrong) Is there a fallback mechanism when things go wrong? Is the system transparent that there is a model making a prediction and what data is used to make this prediction? What is the cost of a wrong prediction? How will incoming data quality be monitored? As data systems become increasingly complex in the mainstream, it is especially vital to employ data quality monitoring, alerting and rectification protocols. Following data validation best practices can prevent insidious issues from creeping into machine learning models that, at best, reduce the usefulness of the model, and at worst, introduce harm. Data validation, reduces the risk of data downtime (increasing headroom) and technical debt and supports long-term success of machine learning models and other applications that rely on the data. Data validation best practices include: Employing automated data quality testing processes at each stage of the data pipeline Re-routing data that fails quality tests to a separate data store for diagnosis and resolution Employing end-to-end data observability on data freshness, distribution, volume, schema and lineage Note that data validation is distinct from data drift detection. Data validation detects errors in the data (ex. a datum is outside of the expected range), while data drift detection uncovers legitimate changes in the data that are truly representative of the phenomenon being modeled (ex. user preferences change). Data validation issues should trigger re-routing and rectification, while data drift should trigger adaptation or retraining of a model. Resources: \"Data Quality Fundamentals\" by Moses et al. How will drift in data characteristics be monitored? Data drift detection uncovers legitimate changes in incoming data that are truly representative of the phenomenon being modeled,and are not erroneous (ex. user preferences change). It is imperative to understand if the new data in production will be significantly different from the data in the training phase. It is also important to check that the data distribution information can be obtained for any of the new data coming in. Drift monitoring can inform when changes are occurring and what their characteristics are (ex. abrupt vs gradual) and guide effective adaptation or retraining strategies to maintain performance. Possible questions to ask: What are some examples of drift, or deviation from the norm, that have been experience in the past or that might be expected? Is there a drift detection strategy in place? Does it align with expected types of changes? Are there warnings when anomalies in input data are occurring? Is there an adaptation strategy in place? Does it align with expected types of changes? Resources: \"Learning Under Concept Drift: A Review\" by Lu at al. Understanding dataset shift How will performance be monitored? It is important to define how the model will be monitored when it is in production and how that data is going to be used to make decisions. For example, when will a model need retraining as the performance has degraded and how to identify what are the underlying causes of this degradation could be part of this monitoring methodology. Ideally, model monitoring should be done automatically. However, if this is not possible, then there should be a manual periodical check of the model performance. Model monitoring should lead to: Ability to identify changes in model performance Warnings when anomalies in model output are occurring Retraining decisions and adaptation strategy Have any ethical concerns been taken into account? Every ML project goes through the Responsible AI process to ensure that it upholds Microsoft's 6 Responsible AI principles .","title":"ML model production checklist"},{"location":"machine-learning/ml-model-checklist/#ml-model-production-checklist","text":"The purpose of this checklist is to make sure that: The team assessed if the model is ready for production before moving to the scoring process The team has prepared a production plan for the model The checklist provides guidelines for creating this production plan. It should be used by teams/organizations that already built/trained an ML model and are now considering putting it into production.","title":"ML model production checklist"},{"location":"machine-learning/ml-model-checklist/#checklist","text":"Before putting an individual ML model into production, the following aspects should be considered: Is there a well defined baseline? Is the model performing better than the baseline? Are machine learning performance metrics defined for both training and scoring? Is the model benchmarked? Can ground truth be obtained or inferred in production? Has the data distribution of training, testing and validation sets been analyzed? Have goals and hard limits for performance, speed of prediction and costs been established so they can be considered if trade-offs need to be made? How will the model be integrated into other systems, and what impact will it have? How will incoming data quality be monitored? How will drift in data characteristics be monitored? How will performance be monitored? Have any ethical concerns been taken into account? Please note that there might be scenarios where it is not possible to check all the items on this checklist. However, it is advised to go through all items and make informed decisions based on your specific use case.","title":"Checklist"},{"location":"machine-learning/ml-model-checklist/#will-your-model-performance-be-different-in-production-than-during-training-phase","text":"Once deployed into production, the model might be performing much worse than expected. This poor performance could be a result of: The data to be scored in production is significantly different from the train and test datasets The feature engineering steps are different or inconsistent in production compared to the training process The performance measure is not consistent (for example your test set covers several months of data where the performance metric for production has been calculated for one month of data)","title":"Will your model performance be different in production than during training phase"},{"location":"machine-learning/ml-model-checklist/#is-there-a-well-defined-baseline-is-the-model-performing-better-than-the-baseline","text":"A good way to think of a model baseline is the simplest model one can come up with: either a simple threshold, a random guess or a very basic linear model. This baseline is the reference point your model needs to outperform. A well-defined baseline is different for each problem type and there is no one size fits all approach. As an example, let's consider some common types of machine learning problems: Classification : Predicting between a positive and a negative class. Either the class with the most observations or a simple logistic regression model can be the baseline. Regression : Predicting the house prices in a city. The average house price for the last year or last month, a simple linear regression model, or the previous median house price in a neighborhood could be the baseline. Image classification : Building an image classifier to distinguish between cats and no cats in an image. If your classes are unbalanced: 70% cats and 30% no cats and if you always predict cats, your naive classifier has 70% accuracy and this can be your baseline. If your classes are balanced: 52% cats and 48% no cats, then a simple convolutional architecture can be the baseline (1 conv layer + 1 max pooling + 1 dense). Additionally, human accuracy at labelling can also be the baseline in an image classification scenario. Some questions to ask when comparing to a baseline: How does your model compare to a random guess? How does your model performance compare to applying a simple threshold? How does your model compare with always predicting the most common value? Note : In some cases, human parity might be too ambitious as a baseline, but this should be decided on a case by case basis. Human accuracy is one of the available options, but not the only one. Resources: \"How To Get Baseline Results And Why They Matter\" article \"Always start with a stupid model, no exceptions.\" article","title":"Is there a well-defined baseline? Is the model performing better than the baseline?"},{"location":"machine-learning/ml-model-checklist/#are-machine-learning-performance-metrics-defined-for-both-training-and-scoring","text":"The methodology of translating the training metrics to scoring metrics should be well-defined and understood. Depending on the data type and model, the model metrics calculation might differ in production and in training. For example, the training procedure calculated metrics for a long period of time (a year, a decade) with different seasonal characteristics while the scoring procedure will calculate the metrics per a restricted time interval (for example a week, a month, a quarter). Well-defined ML performance metrics are essential in production so that a decrease or increase in model performance can be accurately detected. Things to consider: In forecasting, if you change the period of assessing the performance, from one month to a year for example, then you might get a different result. For example, if your model is predicting sales of a product per day and the RMSE (Root Mean Squared Error) is very low for the first month the model is in production. As the model is live for longer, the RMSE is increasing, becoming 10x the RMSE for the first year compared to the first month. In a classification scenario, the overall accuracy is good, but the model is performing poorly for some subgroups. For example, a classifier has an accuracy of 80% overall, but only 55% for the 20-30 age group. If this is a significant age group for the production data, then your accuracy might suffer greatly when in production. In scene classification scenario, the model is trying to identify a specific scene in a video, and the model has been trained and tested (80-20 split) on 50000 segments where half are segments containing the scene and half of the segments do not contain the scene. The accuracy on the training set is 85% and 84% on the test set. However, when an entire video is scored, scores are obtained on all segments, and we expect few segments to contain the scene. The accuracy for an entire video is not comparable with the training/test set procedure in this case, hence different metrics should be considered. If sampling techniques (over-sampling, under-sampling) are used to train model when classes are imbalanced, ensure the metrics used during training are comparable with the ones used in scoring. If the number of samples used for training and testing is small, the performance metrics might change significantly as new data is scored.","title":"Are machine learning performance metrics defined for both training and scoring?"},{"location":"machine-learning/ml-model-checklist/#is-the-model-benchmarked","text":"The trained model to be put into production is well benchmarked if machine learning performance metrics (such as accuracy, recall, RMSE or whatever is appropriate) are measured on the train and test set. Furthermore, the train and test set split should be well documented and reproducible.","title":"Is the model benchmarked?"},{"location":"machine-learning/ml-model-checklist/#can-ground-truth-be-obtained-or-inferred-in-production","text":"Without a reliable ground truth, the machine learning metrics cannot be calculated. It is important to identify if the ground truth can be obtained as the model is scoring new data by either manual or automatic means. If the ground truth cannot be obtained systematically, other proxies and methodology should be investigated in order to obtain some measure of model performance. One option is to use humans to manually label samples. One important aspect of human labelling is to take into account the human accuracy. If there are two different individuals labelling an image, the labels will likely be different for some samples. It is important to understand how the labels were obtained to assess the reliability of the ground truth (that is why we talk about human accuracy). For clarity, let's consider the following examples (by no means an exhaustive list): Forecasting : Forecasting scenarios are an example of machine learning problems where the ground truth could be obtained in most cases even though a delay might occur. For example, for a model predicting the sales of ice cream in a local shop, the ground truth will be obtained as the sales are happening, but it might appear in the system at a later time than as the model prediction. Recommender systems : For recommender system, obtaining the ground truth is a complex problem in most cases as there is no way of identifying the ideal recommendation. For a retail website for example, click/not click, buy/not buy or other user interaction with recommendation can be used as ground truth proxies. Object detection in images : For an object detection model, as new images are scored, there are no new labels being generated automatically. One option to obtain the ground truth for the new images is to use people to manually label the images. Human labelling is costly, time-consuming and not 100% accurate, so in most cases, only a subset of images can be labelled. These samples can be chosen at random or by using active learning techniques of selecting the most informative unlabeled samples.","title":"Can ground truth be obtained or inferred in production?"},{"location":"machine-learning/ml-model-checklist/#has-the-data-distribution-of-training-testing-and-validation-sets-been-analyzed","text":"The data distribution of your training, test and validation (if applicable) dataset (including labels) should be analyzed to ensure they all come from the same distribution. If this is not the case, some options to consider are: re-shuffling, re-sampling, modifying the data, more samples need to be gathered or features removed from the dataset. Significant differences in the data distributions of the different datasets can greatly impact the performance of the model. Some potential questions to ask: How much does the training and test data represent the end result? Is the distribution of each individual feature consistent across all your datasets? (i.e. same representation of age groups, gender, race etc.) Is there any data lineage information? Where did the data come from? How was the data collected? Can collection and labelling be automated? Resources: \"Splitting into train, dev and test\" tutorial","title":"Has the data distribution of training, testing and validation sets been analyzed?"},{"location":"machine-learning/ml-model-checklist/#have-goals-and-hard-limits-for-performance-speed-of-prediction-and-costs-been-established-so-they-can-be-considered-if-trade-offs-need-to-be-made","text":"Some machine learning models achieve high ML performance, but they are costly and time-consuming to run. In those cases, a less performant and cheaper model could be preferred. Hence, it is important to calculate the model performance metrics (accuracy, precision, recall, RMSE etc), but also to gather data on how expensive it will be to run the model and how long it will take to run. Once this data is gathered, an informed decision should be made on what model to productionize. System metrics to consider: CPU/GPU/memory usage Cost per prediction Time taken to make a prediction","title":"Have goals and hard limits for performance, speed of prediction and costs been established, so they can be considered if trade-offs need to be made?"},{"location":"machine-learning/ml-model-checklist/#how-will-the-model-be-integrated-into-other-systems-and-what-impact-will-it-have","text":"Machine Learning models do not exist in isolation, but rather they are part of a much larger system. These systems could be old, proprietary systems or new systems being developed as a results of the creation a new machine learning model. In both of those cases, it is important to understand where the actual model is going to fit in, what output is expected from the model and how that output is going to be used by the larger system. Additionally, it is essential to decide if the model will be used for batch and/or real-time inference as production paths might differ. Possible questions to assess model impact: Is there a human in the loop? How is feedback collected through the system? (for example how do we know if a prediction is wrong) Is there a fallback mechanism when things go wrong? Is the system transparent that there is a model making a prediction and what data is used to make this prediction? What is the cost of a wrong prediction?","title":"How will the model be integrated into other systems, and what impact will it have?"},{"location":"machine-learning/ml-model-checklist/#how-will-incoming-data-quality-be-monitored","text":"As data systems become increasingly complex in the mainstream, it is especially vital to employ data quality monitoring, alerting and rectification protocols. Following data validation best practices can prevent insidious issues from creeping into machine learning models that, at best, reduce the usefulness of the model, and at worst, introduce harm. Data validation, reduces the risk of data downtime (increasing headroom) and technical debt and supports long-term success of machine learning models and other applications that rely on the data. Data validation best practices include: Employing automated data quality testing processes at each stage of the data pipeline Re-routing data that fails quality tests to a separate data store for diagnosis and resolution Employing end-to-end data observability on data freshness, distribution, volume, schema and lineage Note that data validation is distinct from data drift detection. Data validation detects errors in the data (ex. a datum is outside of the expected range), while data drift detection uncovers legitimate changes in the data that are truly representative of the phenomenon being modeled (ex. user preferences change). Data validation issues should trigger re-routing and rectification, while data drift should trigger adaptation or retraining of a model. Resources: \"Data Quality Fundamentals\" by Moses et al.","title":"How will incoming data quality be monitored?"},{"location":"machine-learning/ml-model-checklist/#how-will-drift-in-data-characteristics-be-monitored","text":"Data drift detection uncovers legitimate changes in incoming data that are truly representative of the phenomenon being modeled,and are not erroneous (ex. user preferences change). It is imperative to understand if the new data in production will be significantly different from the data in the training phase. It is also important to check that the data distribution information can be obtained for any of the new data coming in. Drift monitoring can inform when changes are occurring and what their characteristics are (ex. abrupt vs gradual) and guide effective adaptation or retraining strategies to maintain performance. Possible questions to ask: What are some examples of drift, or deviation from the norm, that have been experience in the past or that might be expected? Is there a drift detection strategy in place? Does it align with expected types of changes? Are there warnings when anomalies in input data are occurring? Is there an adaptation strategy in place? Does it align with expected types of changes? Resources: \"Learning Under Concept Drift: A Review\" by Lu at al. Understanding dataset shift","title":"How will drift in data characteristics be monitored?"},{"location":"machine-learning/ml-model-checklist/#how-will-performance-be-monitored","text":"It is important to define how the model will be monitored when it is in production and how that data is going to be used to make decisions. For example, when will a model need retraining as the performance has degraded and how to identify what are the underlying causes of this degradation could be part of this monitoring methodology. Ideally, model monitoring should be done automatically. However, if this is not possible, then there should be a manual periodical check of the model performance. Model monitoring should lead to: Ability to identify changes in model performance Warnings when anomalies in model output are occurring Retraining decisions and adaptation strategy","title":"How will performance be monitored?"},{"location":"machine-learning/ml-model-checklist/#have-any-ethical-concerns-been-taken-into-account","text":"Every ML project goes through the Responsible AI process to ensure that it upholds Microsoft's 6 Responsible AI principles .","title":"Have any ethical concerns been taken into account?"},{"location":"machine-learning/ml-problem-formulation-envisioning/","text":"Envisioning and Problem Formulation Before beginning a data science investigation, we need to define a problem statement which the data science team can explore; this problem statement can have a significant influence on whether the project is likely to be successful. Envisioning goals The main goals of the envisioning process are: Establish a clear understanding of the problem domain and the underlying business objective Define how a potential solution would be used and how its performance should be measured Determine what data is available to solve the problem Understand the capabilities and working practices of the data science team Ensure all parties have the same understanding of the scope and next steps (e.g., onboarding, data exploration workshop) The envisioning process usually entails a series of 'envisioning' sessions where the data science team work alongside subject-matter experts to formulate the problem in such a way that there is a shared understanding a shared understanding of the problem domain, a clear goal, and a predefined approach to evaluating a potential solution. Understanding the problem domain Generally, before defining a project scope for a data science investigation, we must first understand the problem domain: What is the problem? Why does the problem need to be solved? Does this problem require a machine learning solution? How would a potential solution be used? However, establishing this understanding can prove difficult, especially for those unfamiliar with the problem domain. To ease this process, we can approach problems in a structured way by taking the following steps: Identify a measurable problem and define this in business terms. The objective should be clear, and we should have a good understanding of the factors that we can control - that can be used as inputs - and how they affect the objective. Be as specific as possible. Decide how the performance of a solution should be measured and identify whether this is possible within the restrictions of this problem. Make sure it aligns with the business objective and that you have identified the data required to evaluate the solution. Note that the data required to evaluate a solution may differ from the data needed to create a solution. Thinking about the solution as a black box, detail the function that a solution to this problem should perform to fulfil the objective and verify that the relevant data is available to solve the problem. One way of approaching this is by thinking about how a subject-matter expert could solve the problem manually, and the data that would be required; if a human subject-matter expert is unable to solve the problem given the available data, this is indicative that additional information is required and/or more data needs to be collected. Based on the available data, define specific hypothesis statements - which can be proved or disproved - to guide the exploration of the data science team. Where possible, each hypothesis statement should have a clearly defined success criteria (e.g., with an accuracy of over 60% ), however, this is not always possible - especially for projects where no solution to the problem currently exists. In these cases, the measure of success could be based on a subject-matter expert verifying that the results meet their expectations. Document all the above information, to ensure alignment between stakeholders and establish a clear understanding of the problem to be solved. Try to ensure that as much relevant domain knowledge is captured as possible, and that the features present in available data - and the way that the data was collected - are clearly explained, such that they can be understood by a non-subject matter expert. Once an understanding of the problem domain has been established, it may be necessary to break down the overall problem into smaller, meaningful chunks of work to maintain team focus and ensure a realistic project scope within the given time frame. Listening to the end user These problems are complex and require understanding from a variety of perspectives. It is not uncommon for the stakeholders to not be the end user of the solution framework. In these cases, listening to the actual end users is critical to the success of the project. The following questions can help guide discussion in understanding the stakeholders' perspectives: Who is the end user? What is the current practice related to the business problem? What's the performance of the current solution? What are their pain points? What is their toughest problem? What is the state of the data used to build the solution? How does the end user or SME envision the solution? Envisioning Guidance During envisioning sessions, the following may prove useful for guiding the discussion. Many of these points are taken directly, or adapted from, [1] and [2] . Problem Framing Define the objective in business terms. How will the solution be used? What are the current solutions/workarounds (if any)? What work has been done in this area so far? Does this solution need to fit into an existing system? How should performance be measured? Is the performance measure aligned with the business objective? What would be the minimum performance needed to reach the business objective? Are there any known constraints around non-functional requirements that would have to be taken into account? (e.g., computation times) Frame this problem (supervised/unsupervised, online/offline, etc.) Is human expertise available? How would you solve the problem manually? Are there any restrictions on the type of approaches which can be used? (e.g., does the solution need to be completely explainable?) List the assumptions you or others have made so far. Verify these assumptions if possible. Define some initial hypothesis statements to be explored. Highlight and discuss any responsible AI concerns if appropriate. Workflow What data science skills exist in the organization? How many data scientists/engineers would be available to work on this project? In what capacity would these resources be available (full-time, part-time, etc.)? What does the team's current workflow practices look like? Do they work on the cloud/on-prem? In notebooks/IDE? Is version control used? How are data, experiments and models currently tracked? Does the team employ an Agile methodology? How is work tracked? Are there any ML solutions currently running in production? Who is responsible for maintaining these solutions? Who would be responsible for maintaining a solution produced during this project? Are there any restrictions on tooling that must/cannot be used? Example - a recommendation engine problem To illustrate how the above process can be applied to a tangible problem domain, as an example, consider that we are looking at implementing a recommendation engine for a clothing retailer. This example was, in part, inspired by [3] . Often, the objective may be simply presented, in a form such as \"to improve sales\". However, whilst this is ultimately the main goal, we would benefit from being more specific here. Suppose that we were to deploy a solution in November and then observed a December sales surge; how would we be able to distinguish how much of this was as a result of the new recommendation engine, as opposed to the fact that December is a peak buying season? A better objective, in this case, would be \"to drive additional sales by presenting the customer with items that they would not otherwise have purchased without the recommendation \". Here, the inputs that we can control are the choice of items that are presented to each customer, and the order in which they are displayed; considering factors such as how frequently these should change, seasonality, etc. The data required to evaluate a potential solution in this case would be which recommendations resulted in new sales, and an estimation of a customer's likeliness to purchase a specific item without a recommendation. Note that, whilst this data could also be used to build a recommendation engine, it is unlikely that this data will be available before a recommendation system has been implemented, so it is likely that we will have to use an alternate data source to build the model. We can get an initial idea of how to approach a solution to this problem by considering how it would be solved by a subject-matter expert. Thinking of how a personal stylist may provide a recommendation, they are likely to recommend items based on one or more of the following: generally popular items items similar to those liked/purchased by the customer items that were liked/purchased by similar customers items which are complementary to those owned by the customer Whilst this list is by no means exhaustive, it provides a good indication of the data that is likely to be useful to us: item sales data customer purchase histories customer demographics item descriptions and tags previous outfits, or sets, which have been curated by the stylist We would then be able to use this data to explore: a method of measuring similarity between items a method of measuring similarity between customers a method of measuring how complementary items are relative to one another which can be used to create and rank recommendations. Depending on the project scope, and available data, one or more of these areas could be selected to create hypotheses to be explored by the data science team. Some examples of such hypothesis statements could be: From the descriptions of each item, we can determine a measure of similarity between different items to a degree of accuracy which is specified by a stylist. Based on the behavior of customers with similar purchasing histories, we are able to predict certain items that a customer is likely to purchase; with a certainty which is greater than random choice. Using sets of items which have previously been sold together, we can formulate rules around the features which determine whether items are complementary or not which can be verified by a stylist. Next Steps To ensure clarity and alignment, it is useful to summarize the envisioning stage findings focusing on proposed detailed scenarios, assumptions and agreed decisions as well next steps. We suggest confirming that you have access to all necessary resources (including data) as a next step before proceeding with data exploration workshops. Below are the links to the exit document template and to some questions which may be helpful in confirming resource access. Summary of Scope Exit Document Template List of Resource Access Questions List of Data Exploration Workshop Questions References Many of the ideas presented here - and much more - were inspired by, and can be found in the following resources; all of which are highly recommended. Aur\u00e9lien G\u00e9ron's Machine learning project checklist Fast.ai's Data project checklist Designing great data products. Jeremy Howard, Margit Zwemer and Mike Loukides","title":"Envisioning and Problem Formulation"},{"location":"machine-learning/ml-problem-formulation-envisioning/#envisioning-and-problem-formulation","text":"Before beginning a data science investigation, we need to define a problem statement which the data science team can explore; this problem statement can have a significant influence on whether the project is likely to be successful.","title":"Envisioning and Problem Formulation"},{"location":"machine-learning/ml-problem-formulation-envisioning/#envisioning-goals","text":"The main goals of the envisioning process are: Establish a clear understanding of the problem domain and the underlying business objective Define how a potential solution would be used and how its performance should be measured Determine what data is available to solve the problem Understand the capabilities and working practices of the data science team Ensure all parties have the same understanding of the scope and next steps (e.g., onboarding, data exploration workshop) The envisioning process usually entails a series of 'envisioning' sessions where the data science team work alongside subject-matter experts to formulate the problem in such a way that there is a shared understanding a shared understanding of the problem domain, a clear goal, and a predefined approach to evaluating a potential solution.","title":"Envisioning goals"},{"location":"machine-learning/ml-problem-formulation-envisioning/#understanding-the-problem-domain","text":"Generally, before defining a project scope for a data science investigation, we must first understand the problem domain: What is the problem? Why does the problem need to be solved? Does this problem require a machine learning solution? How would a potential solution be used? However, establishing this understanding can prove difficult, especially for those unfamiliar with the problem domain. To ease this process, we can approach problems in a structured way by taking the following steps: Identify a measurable problem and define this in business terms. The objective should be clear, and we should have a good understanding of the factors that we can control - that can be used as inputs - and how they affect the objective. Be as specific as possible. Decide how the performance of a solution should be measured and identify whether this is possible within the restrictions of this problem. Make sure it aligns with the business objective and that you have identified the data required to evaluate the solution. Note that the data required to evaluate a solution may differ from the data needed to create a solution. Thinking about the solution as a black box, detail the function that a solution to this problem should perform to fulfil the objective and verify that the relevant data is available to solve the problem. One way of approaching this is by thinking about how a subject-matter expert could solve the problem manually, and the data that would be required; if a human subject-matter expert is unable to solve the problem given the available data, this is indicative that additional information is required and/or more data needs to be collected. Based on the available data, define specific hypothesis statements - which can be proved or disproved - to guide the exploration of the data science team. Where possible, each hypothesis statement should have a clearly defined success criteria (e.g., with an accuracy of over 60% ), however, this is not always possible - especially for projects where no solution to the problem currently exists. In these cases, the measure of success could be based on a subject-matter expert verifying that the results meet their expectations. Document all the above information, to ensure alignment between stakeholders and establish a clear understanding of the problem to be solved. Try to ensure that as much relevant domain knowledge is captured as possible, and that the features present in available data - and the way that the data was collected - are clearly explained, such that they can be understood by a non-subject matter expert. Once an understanding of the problem domain has been established, it may be necessary to break down the overall problem into smaller, meaningful chunks of work to maintain team focus and ensure a realistic project scope within the given time frame.","title":"Understanding the problem domain"},{"location":"machine-learning/ml-problem-formulation-envisioning/#listening-to-the-end-user","text":"These problems are complex and require understanding from a variety of perspectives. It is not uncommon for the stakeholders to not be the end user of the solution framework. In these cases, listening to the actual end users is critical to the success of the project. The following questions can help guide discussion in understanding the stakeholders' perspectives: Who is the end user? What is the current practice related to the business problem? What's the performance of the current solution? What are their pain points? What is their toughest problem? What is the state of the data used to build the solution? How does the end user or SME envision the solution?","title":"Listening to the end user"},{"location":"machine-learning/ml-problem-formulation-envisioning/#envisioning-guidance","text":"During envisioning sessions, the following may prove useful for guiding the discussion. Many of these points are taken directly, or adapted from, [1] and [2] .","title":"Envisioning Guidance"},{"location":"machine-learning/ml-problem-formulation-envisioning/#problem-framing","text":"Define the objective in business terms. How will the solution be used? What are the current solutions/workarounds (if any)? What work has been done in this area so far? Does this solution need to fit into an existing system? How should performance be measured? Is the performance measure aligned with the business objective? What would be the minimum performance needed to reach the business objective? Are there any known constraints around non-functional requirements that would have to be taken into account? (e.g., computation times) Frame this problem (supervised/unsupervised, online/offline, etc.) Is human expertise available? How would you solve the problem manually? Are there any restrictions on the type of approaches which can be used? (e.g., does the solution need to be completely explainable?) List the assumptions you or others have made so far. Verify these assumptions if possible. Define some initial hypothesis statements to be explored. Highlight and discuss any responsible AI concerns if appropriate.","title":"Problem Framing"},{"location":"machine-learning/ml-problem-formulation-envisioning/#workflow","text":"What data science skills exist in the organization? How many data scientists/engineers would be available to work on this project? In what capacity would these resources be available (full-time, part-time, etc.)? What does the team's current workflow practices look like? Do they work on the cloud/on-prem? In notebooks/IDE? Is version control used? How are data, experiments and models currently tracked? Does the team employ an Agile methodology? How is work tracked? Are there any ML solutions currently running in production? Who is responsible for maintaining these solutions? Who would be responsible for maintaining a solution produced during this project? Are there any restrictions on tooling that must/cannot be used?","title":"Workflow"},{"location":"machine-learning/ml-problem-formulation-envisioning/#example-a-recommendation-engine-problem","text":"To illustrate how the above process can be applied to a tangible problem domain, as an example, consider that we are looking at implementing a recommendation engine for a clothing retailer. This example was, in part, inspired by [3] . Often, the objective may be simply presented, in a form such as \"to improve sales\". However, whilst this is ultimately the main goal, we would benefit from being more specific here. Suppose that we were to deploy a solution in November and then observed a December sales surge; how would we be able to distinguish how much of this was as a result of the new recommendation engine, as opposed to the fact that December is a peak buying season? A better objective, in this case, would be \"to drive additional sales by presenting the customer with items that they would not otherwise have purchased without the recommendation \". Here, the inputs that we can control are the choice of items that are presented to each customer, and the order in which they are displayed; considering factors such as how frequently these should change, seasonality, etc. The data required to evaluate a potential solution in this case would be which recommendations resulted in new sales, and an estimation of a customer's likeliness to purchase a specific item without a recommendation. Note that, whilst this data could also be used to build a recommendation engine, it is unlikely that this data will be available before a recommendation system has been implemented, so it is likely that we will have to use an alternate data source to build the model. We can get an initial idea of how to approach a solution to this problem by considering how it would be solved by a subject-matter expert. Thinking of how a personal stylist may provide a recommendation, they are likely to recommend items based on one or more of the following: generally popular items items similar to those liked/purchased by the customer items that were liked/purchased by similar customers items which are complementary to those owned by the customer Whilst this list is by no means exhaustive, it provides a good indication of the data that is likely to be useful to us: item sales data customer purchase histories customer demographics item descriptions and tags previous outfits, or sets, which have been curated by the stylist We would then be able to use this data to explore: a method of measuring similarity between items a method of measuring similarity between customers a method of measuring how complementary items are relative to one another which can be used to create and rank recommendations. Depending on the project scope, and available data, one or more of these areas could be selected to create hypotheses to be explored by the data science team. Some examples of such hypothesis statements could be: From the descriptions of each item, we can determine a measure of similarity between different items to a degree of accuracy which is specified by a stylist. Based on the behavior of customers with similar purchasing histories, we are able to predict certain items that a customer is likely to purchase; with a certainty which is greater than random choice. Using sets of items which have previously been sold together, we can formulate rules around the features which determine whether items are complementary or not which can be verified by a stylist.","title":"Example - a recommendation engine problem"},{"location":"machine-learning/ml-problem-formulation-envisioning/#next-steps","text":"To ensure clarity and alignment, it is useful to summarize the envisioning stage findings focusing on proposed detailed scenarios, assumptions and agreed decisions as well next steps. We suggest confirming that you have access to all necessary resources (including data) as a next step before proceeding with data exploration workshops. Below are the links to the exit document template and to some questions which may be helpful in confirming resource access. Summary of Scope Exit Document Template List of Resource Access Questions List of Data Exploration Workshop Questions","title":"Next Steps"},{"location":"machine-learning/ml-problem-formulation-envisioning/#references","text":"Many of the ideas presented here - and much more - were inspired by, and can be found in the following resources; all of which are highly recommended. Aur\u00e9lien G\u00e9ron's Machine learning project checklist Fast.ai's Data project checklist Designing great data products. Jeremy Howard, Margit Zwemer and Mike Loukides","title":"References"},{"location":"machine-learning/ml-profiling/","text":"Profiling Machine Learning and MLOps Code Data Science projects, especially the ones that involve Deep Learning techniques, usually are resource intensive. One model training iteration might be multiple hours long. Although large data volumes processing genuinely takes time, minor bugs and suboptimal implementation of some functional pieces might cause extra resources consumption. Profiling can be used to identify performance bottlenecks and see which functions are the costliest in the application code. Based on the outputs of the profiler, one can focus on largest and easiest-to-resolve inefficiencies and therefore achieve better code performance. Although profiling follows the same principles of any other software project, the purpose of this document is to provide profiling samples for the most common scenarios in MLOps/Data Science projects. Below are some common scenarios in MLOps/Data Science projects, along with suggestions on how to profile them. Generic Python profiling PyTorch model training profiling Azure Machine Learning pipeline profiling Generic Python profiling Usually an MLOps/Data Science solution contains plain Python code serving different purposes (e.g. data processing) along with specialized model training code. Although many Machine Learning frameworks provide their own profiler, sometimes it is also useful to profile the whole solution. There are two types of profilers: deterministic (all events are tracked, e.g. cProfile ) and statistical (sampling with regular intervals, e.g., py-spy ). The sample below shows an example of a deterministic profiler. There are many options of generic deterministic Python code profiling. One of the default options for profiling used to be a built-in cProfile profiler. Using cProfile one can easily profile either a Python script or just a chunk of code. This profiling tool produces a file that can be either visualized using open source tools or analyzed using stats.Stats class. The latter option requires setting up filtering and sorting parameters for better analysis experience. Below you can find an example of using cProfile to profile a chunk of code. import cProfile # Start profiling profiler = cProfile . Profile () profiler . enable () # -- YOUR CODE GOES HERE --- # Stop profiling profiler . disable () # Write profiler results to an html file profiler . dump_stats ( \"profiler_results.prof\" ) You can also run cProfile outside of the Python script using the following command: python -m cProfile [ -o output_file ] [ -s sort_order ] ( -m module | myscript.py ) Note: one epoch of model training is usually enough for profiling. There's no need to run more epochs and produce additional cost. Refer to The Python Profilers for further details. PyTorch model training profiling PyTorch 1.8 includes an updated PyTorch profiler that is supplied together with the PyTorch distribution and doesn't require any additional installation. Using PyTorch profiler one can record CPU side operations as well as CUDA kernel launches on GPU side. The profiler can visualize analysis results using TensorBoard plugin as well as provide suggestions on bottlenecks and potential code improvements. with torch . profiler . profile ( # Limit number of training steps included in profiling schedule = torch . profiler . schedule ( wait = 1 , warmup = 1 , active = 3 , repeat = 2 ), # Automatically saves profiling results to disk on_trace_ready = torch . profiler . tensorboard_trace_handler , with_stack = True ) as profiler : for step , data in enumerate ( trainloader , 0 ): # -- TRAINING STEP CODE GOES HERE --- profiler . step () The tensorboard_trace_handler can be used to generate result files for TensorBoard. Those can be visualized by installing TensorBoard. plugin and running TensorBoard on your log directory. pip install torch_tb_profiler tensorboard --logdir = <LOG_DIR_PATH> # Navigate to `http://localhost:6006/#pytorch_profiler` Note: make sure to provide the right parameters to the torch.profiler.schedule . Usually you would need several steps of training to be profiled rather than the whole epoch. More information on PyTorch profiler : PyTorch Profiler Recipe Introducing PyTorch Profiler - the new and improved performance tool Azure Machine Learning pipeline profiling In our projects we often use Azure Machine Learning pipelines to train Machine Learning models. Most of the profilers can also be used in conjunction with Azure Machine Learning. For a profiler to be used with Azure Machine Learning, it should meet the following criteria: Turning the profiler on/off can be achieved by passing a parameter to the script ran by Azure Machine Learning The profiler produces a file as an output In general, a recipe for using profilers with Azure Machine Learning is the following: (Optional) If you're using profiling with an Azure Machine Learning pipeline, you might want to add --profile Boolean flag as a pipeline parameter Use one of the profilers described above or any other profiler that can produce a file as an output Inside of your Python script, create step output folder, e.g.: output_dir = \"./outputs/profiler_results\" os . makedirs ( output_dir , exist_ok = True ) Run your training pipeline Once the pipeline is completed, navigate to Azure ML portal and open details of the step that contains training code. The results can be found in the Outputs+logs tab, under outputs/profiler_results folder. You might want to download the results and visualize it locally. Note: it's not recommended to run profilers simultaneously. Profiles also consume resources, therefore a simultaneous run might significantly affect the results.","title":"Profiling Machine Learning and MLOps Code"},{"location":"machine-learning/ml-profiling/#profiling-machine-learning-and-mlops-code","text":"Data Science projects, especially the ones that involve Deep Learning techniques, usually are resource intensive. One model training iteration might be multiple hours long. Although large data volumes processing genuinely takes time, minor bugs and suboptimal implementation of some functional pieces might cause extra resources consumption. Profiling can be used to identify performance bottlenecks and see which functions are the costliest in the application code. Based on the outputs of the profiler, one can focus on largest and easiest-to-resolve inefficiencies and therefore achieve better code performance. Although profiling follows the same principles of any other software project, the purpose of this document is to provide profiling samples for the most common scenarios in MLOps/Data Science projects. Below are some common scenarios in MLOps/Data Science projects, along with suggestions on how to profile them. Generic Python profiling PyTorch model training profiling Azure Machine Learning pipeline profiling","title":"Profiling Machine Learning and MLOps Code"},{"location":"machine-learning/ml-profiling/#generic-python-profiling","text":"Usually an MLOps/Data Science solution contains plain Python code serving different purposes (e.g. data processing) along with specialized model training code. Although many Machine Learning frameworks provide their own profiler, sometimes it is also useful to profile the whole solution. There are two types of profilers: deterministic (all events are tracked, e.g. cProfile ) and statistical (sampling with regular intervals, e.g., py-spy ). The sample below shows an example of a deterministic profiler. There are many options of generic deterministic Python code profiling. One of the default options for profiling used to be a built-in cProfile profiler. Using cProfile one can easily profile either a Python script or just a chunk of code. This profiling tool produces a file that can be either visualized using open source tools or analyzed using stats.Stats class. The latter option requires setting up filtering and sorting parameters for better analysis experience. Below you can find an example of using cProfile to profile a chunk of code. import cProfile # Start profiling profiler = cProfile . Profile () profiler . enable () # -- YOUR CODE GOES HERE --- # Stop profiling profiler . disable () # Write profiler results to an html file profiler . dump_stats ( \"profiler_results.prof\" ) You can also run cProfile outside of the Python script using the following command: python -m cProfile [ -o output_file ] [ -s sort_order ] ( -m module | myscript.py ) Note: one epoch of model training is usually enough for profiling. There's no need to run more epochs and produce additional cost. Refer to The Python Profilers for further details.","title":"Generic Python profiling"},{"location":"machine-learning/ml-profiling/#pytorch-model-training-profiling","text":"PyTorch 1.8 includes an updated PyTorch profiler that is supplied together with the PyTorch distribution and doesn't require any additional installation. Using PyTorch profiler one can record CPU side operations as well as CUDA kernel launches on GPU side. The profiler can visualize analysis results using TensorBoard plugin as well as provide suggestions on bottlenecks and potential code improvements. with torch . profiler . profile ( # Limit number of training steps included in profiling schedule = torch . profiler . schedule ( wait = 1 , warmup = 1 , active = 3 , repeat = 2 ), # Automatically saves profiling results to disk on_trace_ready = torch . profiler . tensorboard_trace_handler , with_stack = True ) as profiler : for step , data in enumerate ( trainloader , 0 ): # -- TRAINING STEP CODE GOES HERE --- profiler . step () The tensorboard_trace_handler can be used to generate result files for TensorBoard. Those can be visualized by installing TensorBoard. plugin and running TensorBoard on your log directory. pip install torch_tb_profiler tensorboard --logdir = <LOG_DIR_PATH> # Navigate to `http://localhost:6006/#pytorch_profiler` Note: make sure to provide the right parameters to the torch.profiler.schedule . Usually you would need several steps of training to be profiled rather than the whole epoch. More information on PyTorch profiler : PyTorch Profiler Recipe Introducing PyTorch Profiler - the new and improved performance tool","title":"PyTorch model training profiling"},{"location":"machine-learning/ml-profiling/#azure-machine-learning-pipeline-profiling","text":"In our projects we often use Azure Machine Learning pipelines to train Machine Learning models. Most of the profilers can also be used in conjunction with Azure Machine Learning. For a profiler to be used with Azure Machine Learning, it should meet the following criteria: Turning the profiler on/off can be achieved by passing a parameter to the script ran by Azure Machine Learning The profiler produces a file as an output In general, a recipe for using profilers with Azure Machine Learning is the following: (Optional) If you're using profiling with an Azure Machine Learning pipeline, you might want to add --profile Boolean flag as a pipeline parameter Use one of the profilers described above or any other profiler that can produce a file as an output Inside of your Python script, create step output folder, e.g.: output_dir = \"./outputs/profiler_results\" os . makedirs ( output_dir , exist_ok = True ) Run your training pipeline Once the pipeline is completed, navigate to Azure ML portal and open details of the step that contains training code. The results can be found in the Outputs+logs tab, under outputs/profiler_results folder. You might want to download the results and visualize it locally. Note: it's not recommended to run profilers simultaneously. Profiles also consume resources, therefore a simultaneous run might significantly affect the results.","title":"Azure Machine Learning pipeline profiling"},{"location":"machine-learning/ml-project-management/","text":"Agile Development Considerations for ML Projects Overview When running ML projects, we follow the Agile methodology for software development with some adaptations, as we acknowledge that research and experimentation are sometimes difficult to plan and estimate. Goals Run and manage ML projects effectively Create effective collaboration between the ML team and the other teams working on the project To learn more about how ISE runs the Agile process for software development teams, refer to this doc . Within this framework, the team follows these Agile ceremonies: Backlog management Retrospectives Scrum of Scrums (where applicable) Sprint planning Stand-ups Working agreement Notes on Agile process during exploration and experimentation While acknowledging the fact that ML user stories and research spikes are less predictable than software development ones, we strive to have a deliverable for every user story in every sprint. User stories and spikes are usually estimated using T-shirt sizes or similar, and not in actual days/hours. See more here on story estimation. ML design sessions should be included in each sprint. Examples of ML deliverables for each sprint Working code (e.g. models, pipelines, exploratory code) Documentation of new hypotheses, and the acceptance or rejection of previous hypotheses as part of a Hypothesis Driven Analysis (HDA). For more information see Hypothesis Driven Development on Barry Oreilly's website Exploratory Data Analysis (EDA) results and learnings documented Notes on collaboration between ML team and software development team The ML and Software Development teams work together on the project. The team uses one backlog and attend the same Agile ceremonies. In cases where the project has many participants, we will divide into working groups, but still have the entire team join the Agile ceremonies. If possible, feasibility study and initial model experimentation takes place before the operationalization work kicks off. The ML team and dev team both share the accountability for the MLOps solution. The ML model interface (API) is determined as early as possible, to allow the developers to consider its integration into the production pipeline. MLOps artifacts are developed with a continuous collaboration and review of the ML team, to ensure the appropriate approaches for experimentation and productization are used. Retrospectives and sprint planning are performed on the entire team level, and not the specific work groups level.","title":"Agile Development Considerations for ML Projects"},{"location":"machine-learning/ml-project-management/#agile-development-considerations-for-ml-projects","text":"","title":"Agile Development Considerations for ML Projects"},{"location":"machine-learning/ml-project-management/#overview","text":"When running ML projects, we follow the Agile methodology for software development with some adaptations, as we acknowledge that research and experimentation are sometimes difficult to plan and estimate.","title":"Overview"},{"location":"machine-learning/ml-project-management/#goals","text":"Run and manage ML projects effectively Create effective collaboration between the ML team and the other teams working on the project To learn more about how ISE runs the Agile process for software development teams, refer to this doc . Within this framework, the team follows these Agile ceremonies: Backlog management Retrospectives Scrum of Scrums (where applicable) Sprint planning Stand-ups Working agreement","title":"Goals"},{"location":"machine-learning/ml-project-management/#notes-on-agile-process-during-exploration-and-experimentation","text":"While acknowledging the fact that ML user stories and research spikes are less predictable than software development ones, we strive to have a deliverable for every user story in every sprint. User stories and spikes are usually estimated using T-shirt sizes or similar, and not in actual days/hours. See more here on story estimation. ML design sessions should be included in each sprint.","title":"Notes on Agile process during exploration and experimentation"},{"location":"machine-learning/ml-project-management/#examples-of-ml-deliverables-for-each-sprint","text":"Working code (e.g. models, pipelines, exploratory code) Documentation of new hypotheses, and the acceptance or rejection of previous hypotheses as part of a Hypothesis Driven Analysis (HDA). For more information see Hypothesis Driven Development on Barry Oreilly's website Exploratory Data Analysis (EDA) results and learnings documented","title":"Examples of ML deliverables for each sprint"},{"location":"machine-learning/ml-project-management/#notes-on-collaboration-between-ml-team-and-software-development-team","text":"The ML and Software Development teams work together on the project. The team uses one backlog and attend the same Agile ceremonies. In cases where the project has many participants, we will divide into working groups, but still have the entire team join the Agile ceremonies. If possible, feasibility study and initial model experimentation takes place before the operationalization work kicks off. The ML team and dev team both share the accountability for the MLOps solution. The ML model interface (API) is determined as early as possible, to allow the developers to consider its integration into the production pipeline. MLOps artifacts are developed with a continuous collaboration and review of the ML team, to ensure the appropriate approaches for experimentation and productization are used. Retrospectives and sprint planning are performed on the entire team level, and not the specific work groups level.","title":"Notes on collaboration between ML team and software development team"},{"location":"machine-learning/ml-proposed-process/","text":"Proposed ML Process Introduction The objective of this document is to provide guidance to produce machine learning (ML) applications that are based on code, data and models that can be reproduced and reliably released to production environments. When developing ML applications, we consider the following approaches: Best practices in ML engineering: The ML application development should use engineering fundamentals to ensure high quality software deliverables. The ML application should be reliability released into production, leveraging automation as much as possible. The ML application can be deployed into production at any time. This makes the decision about when to release it a business decision rather than a technical one. Best practices in ML research: All artifacts, specifically data, code and ML models, should be versioned and managed using standard tools and workflows, in order to facilitate continuous research and development. While the model outputs can be non-deterministic and hard to reproduce, the process of releasing ML software into production should be reproducible. Responsible AI aspects are carefully analyzed and addressed. Cross-functional team: A cross-functional team consisting of different skill sets in data science, data engineering, development, operations, and industry domain specialists is required. ML process The proposed ML development process consists of: Data and problem understanding Responsible AI assessment Feasibility study Baseline model experimentation Model evaluation and experimentation Model operationalization * Unit and Integration testing * Deployment * Monitoring and Observability Version control During all stages of the process, it is suggested that artifacts should be version-controlled. Typically, the process is iterative and versioned artifacts can assist in traceability and reviewing. See more here . Understanding the problem Define the business problem for the ML project: Agree on the success criteria with the customer. Identify potential data sources and determine the availability of these sources. Define performance evaluation metrics on ground truth data Conduct a Responsible AI assessment to ensure development and deployment of the ML solution in a responsible manner. Conduct a feasibility study to assess whether the business problem is feasible to solve satisfactorily using ML with the available data. The objective of the feasibility study is to mitigate potential over-investment by ensuring sufficient evidence that ML is possible and would be the best solution. The study also provides initial indications of what the ML solution should look like. This ensures quality solutions supported by thorough consideration and evidence. Refer to feasibility study . Exploratory data analysis is performed and discussed with the team Typical output : Data exploration source code (Jupyter notebooks/scripts) and slides/docs Initial ML model code (Jupyter notebook or scripts) Initial solution architecture with initial data engineering requirements Data dictionary (if not yet available) List of assumptions Baseline Model Experimentation Data preparation: creating data source connectors, determining storage services to be used and potential versioning of raw datasets. Feature engineering: create new features from raw source data to increase the predictive power of the learning algorithm. The features should capture additional information that is not apparent in the original feature set. Split data into training, validation and test sets: creating training, validation, and test datasets with ground truth to develop ML models. This would entail joining or merging various feature engineered datasets. The training dataset is used to train the model to find the patterns between its features and labels (ground truth). The validation dataset is used to assess the model architecture, and the test data is used to confirm the prediction quality of the model. Initial code to create access data sources, transform raw data into features and model training as well as scoring. During this phase, experiment code (Jupyter notebooks or scripts) and accompanying utility code should be version-controlled using tools such as ADO (Azure DevOps). Typical output : Rough Jupyter notebooks or scripts in Python or R, initial results from baseline model. For more information on experimentation, refer to the experimentation section. Model Evaluation Compare the effectiveness of different algorithms on the given problem. Typical output : Evaluation flow is fully set up . Reproducible experiments for the different approaches experimented with. Model Operationalization Taking \"experimental\" code and preparing it, so it can be deployed. This includes data pre-processing, featurization code, training model code (if required to be trained using CI/CD) and model inference code. Typical output : Production-grade code (Preferably in the form of a package) for: Data preprocessing / post processing Serving a model Training a model CI/CD scripts. Reproducibility steps for the model in production. See more here . Unit and Integration Testing Ensuring that production code behaves in the way we expect it to, and that its results match those we saw during the Model Evaluation and Experimentation phases. Refer to ML testing post for further details. Typical output : Test suite with unit and end-to-end tests is created and completes successfully. Deployment Responsible AI considerations such as bias and fairness analysis. Additionally, explainability/interpretability of the model should also be considered. It is recommended for a human-in-the-loop to verify the model and manually approve deployment to production. Getting the model into production where it can start adding value by serving predictions. Typical artifacts are APIs for accessing the model and integrating the model to the solution architecture. Additionally, certain scenarios may require training the model periodically in production. Reproducibility steps of the production model are available. Typical output : model readiness checklist is completed. Monitoring and Observability This is the final phase, where we ensure our model is doing what we expect it to in production. Read more about ML observability . Read more about Azure ML's offerings around ML models production monitoring . It is recommended to consider incorporating data drift monitoring process in the production solution. This will assist in detecting potential changes in new datasets presented for inference that may significantly impact model performance. For more info on detecting data drift with Azure ML see the Microsoft docs article on how to monitor datasets . Typical output : Logging and monitoring scripts and tools set up, permissions for users to access monitoring tools.","title":"Proposed ML Process"},{"location":"machine-learning/ml-proposed-process/#proposed-ml-process","text":"","title":"Proposed ML Process"},{"location":"machine-learning/ml-proposed-process/#introduction","text":"The objective of this document is to provide guidance to produce machine learning (ML) applications that are based on code, data and models that can be reproduced and reliably released to production environments. When developing ML applications, we consider the following approaches: Best practices in ML engineering: The ML application development should use engineering fundamentals to ensure high quality software deliverables. The ML application should be reliability released into production, leveraging automation as much as possible. The ML application can be deployed into production at any time. This makes the decision about when to release it a business decision rather than a technical one. Best practices in ML research: All artifacts, specifically data, code and ML models, should be versioned and managed using standard tools and workflows, in order to facilitate continuous research and development. While the model outputs can be non-deterministic and hard to reproduce, the process of releasing ML software into production should be reproducible. Responsible AI aspects are carefully analyzed and addressed. Cross-functional team: A cross-functional team consisting of different skill sets in data science, data engineering, development, operations, and industry domain specialists is required.","title":"Introduction"},{"location":"machine-learning/ml-proposed-process/#ml-process","text":"The proposed ML development process consists of: Data and problem understanding Responsible AI assessment Feasibility study Baseline model experimentation Model evaluation and experimentation Model operationalization * Unit and Integration testing * Deployment * Monitoring and Observability","title":"ML process"},{"location":"machine-learning/ml-proposed-process/#version-control","text":"During all stages of the process, it is suggested that artifacts should be version-controlled. Typically, the process is iterative and versioned artifacts can assist in traceability and reviewing. See more here .","title":"Version control"},{"location":"machine-learning/ml-proposed-process/#understanding-the-problem","text":"Define the business problem for the ML project: Agree on the success criteria with the customer. Identify potential data sources and determine the availability of these sources. Define performance evaluation metrics on ground truth data Conduct a Responsible AI assessment to ensure development and deployment of the ML solution in a responsible manner. Conduct a feasibility study to assess whether the business problem is feasible to solve satisfactorily using ML with the available data. The objective of the feasibility study is to mitigate potential over-investment by ensuring sufficient evidence that ML is possible and would be the best solution. The study also provides initial indications of what the ML solution should look like. This ensures quality solutions supported by thorough consideration and evidence. Refer to feasibility study . Exploratory data analysis is performed and discussed with the team Typical output : Data exploration source code (Jupyter notebooks/scripts) and slides/docs Initial ML model code (Jupyter notebook or scripts) Initial solution architecture with initial data engineering requirements Data dictionary (if not yet available) List of assumptions","title":"Understanding the problem"},{"location":"machine-learning/ml-proposed-process/#baseline-model-experimentation","text":"Data preparation: creating data source connectors, determining storage services to be used and potential versioning of raw datasets. Feature engineering: create new features from raw source data to increase the predictive power of the learning algorithm. The features should capture additional information that is not apparent in the original feature set. Split data into training, validation and test sets: creating training, validation, and test datasets with ground truth to develop ML models. This would entail joining or merging various feature engineered datasets. The training dataset is used to train the model to find the patterns between its features and labels (ground truth). The validation dataset is used to assess the model architecture, and the test data is used to confirm the prediction quality of the model. Initial code to create access data sources, transform raw data into features and model training as well as scoring. During this phase, experiment code (Jupyter notebooks or scripts) and accompanying utility code should be version-controlled using tools such as ADO (Azure DevOps). Typical output : Rough Jupyter notebooks or scripts in Python or R, initial results from baseline model. For more information on experimentation, refer to the experimentation section.","title":"Baseline Model Experimentation"},{"location":"machine-learning/ml-proposed-process/#model-evaluation","text":"Compare the effectiveness of different algorithms on the given problem. Typical output : Evaluation flow is fully set up . Reproducible experiments for the different approaches experimented with.","title":"Model Evaluation"},{"location":"machine-learning/ml-proposed-process/#model-operationalization","text":"Taking \"experimental\" code and preparing it, so it can be deployed. This includes data pre-processing, featurization code, training model code (if required to be trained using CI/CD) and model inference code. Typical output : Production-grade code (Preferably in the form of a package) for: Data preprocessing / post processing Serving a model Training a model CI/CD scripts. Reproducibility steps for the model in production. See more here .","title":"Model Operationalization"},{"location":"machine-learning/ml-proposed-process/#unit-and-integration-testing","text":"Ensuring that production code behaves in the way we expect it to, and that its results match those we saw during the Model Evaluation and Experimentation phases. Refer to ML testing post for further details. Typical output : Test suite with unit and end-to-end tests is created and completes successfully.","title":"Unit and Integration Testing"},{"location":"machine-learning/ml-proposed-process/#deployment","text":"Responsible AI considerations such as bias and fairness analysis. Additionally, explainability/interpretability of the model should also be considered. It is recommended for a human-in-the-loop to verify the model and manually approve deployment to production. Getting the model into production where it can start adding value by serving predictions. Typical artifacts are APIs for accessing the model and integrating the model to the solution architecture. Additionally, certain scenarios may require training the model periodically in production. Reproducibility steps of the production model are available. Typical output : model readiness checklist is completed.","title":"Deployment"},{"location":"machine-learning/ml-proposed-process/#monitoring-and-observability","text":"This is the final phase, where we ensure our model is doing what we expect it to in production. Read more about ML observability . Read more about Azure ML's offerings around ML models production monitoring . It is recommended to consider incorporating data drift monitoring process in the production solution. This will assist in detecting potential changes in new datasets presented for inference that may significantly impact model performance. For more info on detecting data drift with Azure ML see the Microsoft docs article on how to monitor datasets . Typical output : Logging and monitoring scripts and tools set up, permissions for users to access monitoring tools.","title":"Monitoring and Observability"},{"location":"machine-learning/ml-testing/","text":"Testing Data Science and MLOps Code The purpose of this document is to provide samples of tests for the most common operations in MLOps/Data Science projects. Testing the code used for MLOps or data science projects follows the same principles of any other software project. Some scenarios might seem different or more difficult to test. The best way to approach this is to always have a test design session, where the focus is on the input/outputs, exceptions and testing the behavior of data transformations. Designing the tests first makes it easier to test as it forces a more modular style, where each function has one purpose, and extracting common functionality functions and modules. Below are some common operations in MLOps or Data Science projects, along with suggestions on how to test them. Saving and loading data Transforming data Model load or predict Data validation Model testing Saving and loading data Reading and writing to csv, reading images or loading audio files are common scenarios encountered in MLOps projects. Example: Verify that a load function calls read_csv if the file exists utils.py def load_data ( filename : str ) -> pd . DataFrame : if os . path . isfile ( filename ): df = pd . read_csv ( filename , index_col = 'ID' ) return df return None There's no need to test the read_csv function, or the isfile functions, we can leave testing them to the pandas and os developers. The only thing we need to test here is the logic in this function, i.e. that load_data loads the file if the file exists with the right index column, and doesn't load the file if it doesn't exist, and that it returns the expected results. One way to do this would be to provide a sample file and call the function, and verify that the output is None or a DataFrame . This requires separate files to be present, or not present, for the tests to run. This can cause the same test to run on one machine and then fail on a build server which is not a desired behavior. A much better way is to mock calls to isfile , and read_csv . Instead of calling the real function, we will return a predefined return value, or call a stub that doesn't have any side effects. This way no files are needed in the repository to execute the test, and the test will always work the same, independent of what machine it runs on. Note: Below we mock the specific os and pd functions referenced in the utils file, any others are left unaffected and would run as normal. test_utils.py import utils from mock import patch @patch ( 'utils.os.path.isfile' ) @patch ( 'utils.pd.read_csv' ) def test_load_data_calls_read_csv_if_exists ( mock_isfile , mock_read_csv ): # arrange # always return true for isfile utils . os . path . isfile . return_value = True filename = 'file.csv' # act _ = utils . load_data ( filename ) # assert # check that read_csv is called with the correct parameters utils . pd . read_csv . assert_called_once_with ( filename , index_col = 'ID' ) Similarly, we can verify that it's called 0 or multiple times. In the example below where we verify that it's not called if the file doesn't exist @patch ( 'utils.os.path.isfile' ) @patch ( 'utils.pd.read_csv' ) def test_load_data_does_not_call_read_csv_if_not_exists ( mock_isfile , mock_read_csv ): # arrange # file doesn't exist utils . os . path . isfile . return_value = False filename = 'file.csv' # act _ = utils . load_data ( filename ) # assert # check that read_csv is not called assert utils . pd . read_csv . call_count == 0 Example: Using the same sample data for multiple tests If more than one test will use the same sample data, fixtures are a good way to reuse this sample data. The sample data can be the contents of a json file, or a csv, or a DataFrame, or even an image. Note: The sample data is still hard coded if possible, and does not need to be large. Only add as much sample data as required for the tests to make the tests readable. Use the fixture to return the sample data, and add this as a parameter to the tests where you want to use the sample data. import pytest @pytest . fixture def house_features_json (): return { 'area' : 25 , 'price' : 2500 , 'rooms' : np . nan } def test_clean_features_cleans_nan_values ( house_features_json ): cleaned_features = clean_features ( house_features_json ) assert cleaned_features [ 'rooms' ] == 0 def test_extract_features_extracts_price_per_area ( house_features_json ): extracted_features = extract_features ( house_features_json ) assert extracted_features [ 'price_per_area' ] == 100 Transforming data For cleaning and transforming data, test fixed input and output, but try to limit each test to one verification. For example, create one test to verify the output shape of the data. def test_resize_image_generates_the_correct_size (): # Arrange original_image = np . ones (( 10 , 5 , 2 , 3 )) # act resized_image = utils . resize_image ( original_image , 100 , 100 ) # assert resized_image . shape [: 2 ] = ( 100 , 100 ) and one to verify that any padding is made appropriately def test_resize_image_pads_correctly (): # Arrange original_image = np . ones (( 10 , 5 , 2 , 3 )) # Act resized_image = utils . resize_image ( original_image , 100 , 100 ) # Assert assert resized_image [ 0 ][ 0 ][ 0 ][ 0 ] == 0 assert resized_image [ 0 ][ 0 ][ 2 ][ 0 ] == 1 To test different inputs and expected outputs automatically, use parametrize @pytest . mark . parametrize ( 'orig_height, orig_width, expected_height, expected_width' , [ # smaller than target ( 10 , 10 , 20 , 20 ), # larger than target ( 20 , 20 , 10 , 10 ), # wider than target ( 10 , 20 , 10 , 10 ) ]) def test_resize_image_generates_the_correct_size ( orig_height , orig_width , expected_height , expected_width ): # Arrange original_image = np . ones (( orig_height , orig_width , 2 , 3 )) # act resized_image = utils . resize_image ( original_image , expected_height , expected_width ) # assert resized_image . shape [: 2 ] = ( expected_height , expected_width ) Model load or predict When unit testing we should mock model load and model predictions similarly to mocking file access. There may be cases when you want to load your model to do smoke tests, or integration tests. Since these will often take a bit longer to run it's important to be able to separate them from unit tests so that the developers on the team can still run unit tests as part of their test driven development. One way to do this is using marks @pytest . mark . longrunning def test_integration_between_two_systems (): # this might take a while Run all tests that are not marked longrunning pytest -v -m \"not longrunning\" Basic Unit Tests for ML Models ML unit tests are not intended to check the accuracy or performance of a model. Unit tests for an ML model is for code quality checks - for example: Does the model accept the correct inputs and produce the correctly shaped outputs? Do the weights of the model update when running fit ? To do this, the ML model tests do not strictly follow best practices of standard Unit tests - not all outside calls are mocked. These tests are much closer to a narrow integration test . However, the benefits of having simple tests for the ML model help to stop a poorly configured model from spending hours in training, while still producing poor results. Examples of how to implement these tests (for Deep Learning models) include: Build a model and compare the shape of input layers to that of an example source of data. Then, compare the output layer shape to the expected output. Initialize the model and record the weights of each layer. Then, run a single epoch of training on a dummy data set, and compare the weights of the \"trained model\" - only check if the values have changed. Train the model on a dummy dataset for a single epoch, and then validate with dummy data - only validate that the prediction is formatted correctly, this model will not be accurate. Data Validation An important part of the unit testing is to include test cases for data validation. For example, no data supplied, images that are not in the expected format, data containing null values or outliers to make sure that the data processing pipeline is robust. Model Testing Apart from unit testing code, we can also test, debug and validate our models in different ways during the training process Some options to consider at this stage: Adversarial and Boundary tests to increase robustness Verifying accuracy for under-represented classes","title":"Testing Data Science and MLOps Code"},{"location":"machine-learning/ml-testing/#testing-data-science-and-mlops-code","text":"The purpose of this document is to provide samples of tests for the most common operations in MLOps/Data Science projects. Testing the code used for MLOps or data science projects follows the same principles of any other software project. Some scenarios might seem different or more difficult to test. The best way to approach this is to always have a test design session, where the focus is on the input/outputs, exceptions and testing the behavior of data transformations. Designing the tests first makes it easier to test as it forces a more modular style, where each function has one purpose, and extracting common functionality functions and modules. Below are some common operations in MLOps or Data Science projects, along with suggestions on how to test them. Saving and loading data Transforming data Model load or predict Data validation Model testing","title":"Testing Data Science and MLOps Code"},{"location":"machine-learning/ml-testing/#saving-and-loading-data","text":"Reading and writing to csv, reading images or loading audio files are common scenarios encountered in MLOps projects.","title":"Saving and loading data"},{"location":"machine-learning/ml-testing/#example-verify-that-a-load-function-calls-read_csv-if-the-file-exists","text":"utils.py def load_data ( filename : str ) -> pd . DataFrame : if os . path . isfile ( filename ): df = pd . read_csv ( filename , index_col = 'ID' ) return df return None There's no need to test the read_csv function, or the isfile functions, we can leave testing them to the pandas and os developers. The only thing we need to test here is the logic in this function, i.e. that load_data loads the file if the file exists with the right index column, and doesn't load the file if it doesn't exist, and that it returns the expected results. One way to do this would be to provide a sample file and call the function, and verify that the output is None or a DataFrame . This requires separate files to be present, or not present, for the tests to run. This can cause the same test to run on one machine and then fail on a build server which is not a desired behavior. A much better way is to mock calls to isfile , and read_csv . Instead of calling the real function, we will return a predefined return value, or call a stub that doesn't have any side effects. This way no files are needed in the repository to execute the test, and the test will always work the same, independent of what machine it runs on. Note: Below we mock the specific os and pd functions referenced in the utils file, any others are left unaffected and would run as normal. test_utils.py import utils from mock import patch @patch ( 'utils.os.path.isfile' ) @patch ( 'utils.pd.read_csv' ) def test_load_data_calls_read_csv_if_exists ( mock_isfile , mock_read_csv ): # arrange # always return true for isfile utils . os . path . isfile . return_value = True filename = 'file.csv' # act _ = utils . load_data ( filename ) # assert # check that read_csv is called with the correct parameters utils . pd . read_csv . assert_called_once_with ( filename , index_col = 'ID' ) Similarly, we can verify that it's called 0 or multiple times. In the example below where we verify that it's not called if the file doesn't exist @patch ( 'utils.os.path.isfile' ) @patch ( 'utils.pd.read_csv' ) def test_load_data_does_not_call_read_csv_if_not_exists ( mock_isfile , mock_read_csv ): # arrange # file doesn't exist utils . os . path . isfile . return_value = False filename = 'file.csv' # act _ = utils . load_data ( filename ) # assert # check that read_csv is not called assert utils . pd . read_csv . call_count == 0","title":"Example: Verify that a load function calls read_csv if the file exists"},{"location":"machine-learning/ml-testing/#example-using-the-same-sample-data-for-multiple-tests","text":"If more than one test will use the same sample data, fixtures are a good way to reuse this sample data. The sample data can be the contents of a json file, or a csv, or a DataFrame, or even an image. Note: The sample data is still hard coded if possible, and does not need to be large. Only add as much sample data as required for the tests to make the tests readable. Use the fixture to return the sample data, and add this as a parameter to the tests where you want to use the sample data. import pytest @pytest . fixture def house_features_json (): return { 'area' : 25 , 'price' : 2500 , 'rooms' : np . nan } def test_clean_features_cleans_nan_values ( house_features_json ): cleaned_features = clean_features ( house_features_json ) assert cleaned_features [ 'rooms' ] == 0 def test_extract_features_extracts_price_per_area ( house_features_json ): extracted_features = extract_features ( house_features_json ) assert extracted_features [ 'price_per_area' ] == 100","title":"Example: Using the same sample data for multiple tests"},{"location":"machine-learning/ml-testing/#transforming-data","text":"For cleaning and transforming data, test fixed input and output, but try to limit each test to one verification. For example, create one test to verify the output shape of the data. def test_resize_image_generates_the_correct_size (): # Arrange original_image = np . ones (( 10 , 5 , 2 , 3 )) # act resized_image = utils . resize_image ( original_image , 100 , 100 ) # assert resized_image . shape [: 2 ] = ( 100 , 100 ) and one to verify that any padding is made appropriately def test_resize_image_pads_correctly (): # Arrange original_image = np . ones (( 10 , 5 , 2 , 3 )) # Act resized_image = utils . resize_image ( original_image , 100 , 100 ) # Assert assert resized_image [ 0 ][ 0 ][ 0 ][ 0 ] == 0 assert resized_image [ 0 ][ 0 ][ 2 ][ 0 ] == 1 To test different inputs and expected outputs automatically, use parametrize @pytest . mark . parametrize ( 'orig_height, orig_width, expected_height, expected_width' , [ # smaller than target ( 10 , 10 , 20 , 20 ), # larger than target ( 20 , 20 , 10 , 10 ), # wider than target ( 10 , 20 , 10 , 10 ) ]) def test_resize_image_generates_the_correct_size ( orig_height , orig_width , expected_height , expected_width ): # Arrange original_image = np . ones (( orig_height , orig_width , 2 , 3 )) # act resized_image = utils . resize_image ( original_image , expected_height , expected_width ) # assert resized_image . shape [: 2 ] = ( expected_height , expected_width )","title":"Transforming data"},{"location":"machine-learning/ml-testing/#model-load-or-predict","text":"When unit testing we should mock model load and model predictions similarly to mocking file access. There may be cases when you want to load your model to do smoke tests, or integration tests. Since these will often take a bit longer to run it's important to be able to separate them from unit tests so that the developers on the team can still run unit tests as part of their test driven development. One way to do this is using marks @pytest . mark . longrunning def test_integration_between_two_systems (): # this might take a while Run all tests that are not marked longrunning pytest -v -m \"not longrunning\"","title":"Model load or predict"},{"location":"machine-learning/ml-testing/#basic-unit-tests-for-ml-models","text":"ML unit tests are not intended to check the accuracy or performance of a model. Unit tests for an ML model is for code quality checks - for example: Does the model accept the correct inputs and produce the correctly shaped outputs? Do the weights of the model update when running fit ? To do this, the ML model tests do not strictly follow best practices of standard Unit tests - not all outside calls are mocked. These tests are much closer to a narrow integration test . However, the benefits of having simple tests for the ML model help to stop a poorly configured model from spending hours in training, while still producing poor results. Examples of how to implement these tests (for Deep Learning models) include: Build a model and compare the shape of input layers to that of an example source of data. Then, compare the output layer shape to the expected output. Initialize the model and record the weights of each layer. Then, run a single epoch of training on a dummy data set, and compare the weights of the \"trained model\" - only check if the values have changed. Train the model on a dummy dataset for a single epoch, and then validate with dummy data - only validate that the prediction is formatted correctly, this model will not be accurate.","title":"Basic Unit Tests for ML Models"},{"location":"machine-learning/ml-testing/#data-validation","text":"An important part of the unit testing is to include test cases for data validation. For example, no data supplied, images that are not in the expected format, data containing null values or outliers to make sure that the data processing pipeline is robust.","title":"Data Validation"},{"location":"machine-learning/ml-testing/#model-testing","text":"Apart from unit testing code, we can also test, debug and validate our models in different ways during the training process Some options to consider at this stage: Adversarial and Boundary tests to increase robustness Verifying accuracy for under-represented classes","title":"Model Testing"},{"location":"machine-learning/ml-tpm-guidance/","text":"TPM considerations for Machine Learning projects In this document, we explore some of the Program Management considerations for Machine Learning (ML) projects and suggest recommendations for Technical Program Managers (TPM) to effectively work with Data and Applied Machine Learning engineering teams. Determine the need for Machine Learning in the project In Artificial Intelligence (AI) projects, the ML component is generally a part of an overall business problem and NOT the problem itself. Determine the overall business problem first and then evaluate if ML can help address a part of the problem space. Few considerations for identifying the right fit for the project: Engage experts in human experience and employ techniques such as Design Thinking and Problem Formulation to understand the customer needs and human behavior first. Identify the right stakeholders from both business and technical leadership and invite them to these workshops. The outcome should be end-user scenarios and personas to determine the real needs of the users. Focus on System Design principles to identify the architectural components, entities, interfaces, constraints. Ask the right questions early and explore design alternatives with the engineering team. Think hard about the costs of ML and whether we are solving a repetitive problem at scale. Many a times, customer problems can be solved with data analytics, dashboards, or rule-based algorithms as the first phase of the project. Set Expectations for high ambiguity in ML components ML projects can be plagued with a phenomenon we can call as the \" Death by Unknowns \". Unlike software engineering projects, ML focused projects can result in quick success early (aka sudden decrease in error rate), but this may flatten eventually. Few things to consider: Set clear expectations : Identify the performance metrics and discuss on a \"good enough\" prediction rate that will bring value to the business. An 80% \"good enough\" rate may save business costs and increase productivity but if going from 80 to 95% would require unimaginable cost and effort. Is it worth it? Can it be a progressive road map? Create a smaller team and undertake a feasibility analysis through techniques like EDA (Exploratory Data Analysis). A feasibility study is much cheaper to evaluate data quality, customer constraints and model feasibility. It allows a TPM to better understand customer use cases and current environment and can act as a fail-fast mechanism. Note that feasibility should be shorter (in weeks) else it misses the point of saving costs. As in any project, there will be new needs (additional data sources, technical constraints, hiring data labelers, business users time etc.). Incorporate Agile techniques to fail fast and minimize cost and schedule surprises. Notebooks != ML Production Notebooks are a great way to kick start Data Analytics and Applied Machine Learning efforts, however for a production releases, additional constraints should be considered: Understand the end-end flow of data management , how data will be made available (ingestion flows), what's the frequency, storage, retention of data. Plan user stories and design spikes around these flows to ensure a robust ML pipeline is developed. Engineering team should follow the same rigor in building ML projects as in any software engineering project. We at ISE (Industry Solutions Engineering) have built a good set of resources from our learnings in our ISE Engineering Playbook . Think about the how the model will be deployed, for example, are there technical constraints due to an edge device, or network constraints that will prevent updating the model. Understanding of the environment is critical, refer to the Model Production Checklist as a reference to determine model deployment choices. ML Focussed projects are not a \"one-shot\" release solution, they need to be nurtured, evolved, and improved over time. Plan for a continuous improvement lifecycle, the initial phases can be model feasibility and validation to get the good enough prediction rate, the later phases can be then be scaling and improving the models through feedback loops and fresh data sets. Garbage Data In -> Garbage Model Out Data quality is a major factor in affecting model performance and production roll-out, consider the following: Conduct a data exploration workshop and generate a report on data quality that includes missing values, duplicates, unlabeled data, expired or not valid data, incomplete data (e.g., only having male representation in a people dataset). Identify data source reliability to ensure data is coming from a production source. (e.g., are the images from a production or industrial camera or taken from an iPhone/Android phone.) Identify data acquisition constraints : Determine how the data is being obtained and the constraints around it. Some example may include legal, contractual, Privacy, regulation, ethics constraints. These can significantly slow down production roll out if not captured in the early phases of the project. Determine data volumes : Identify if we have enough data for sampling the required business use case and how will the data be improved over time. The thumb rule here is that data should be enough for generalization to avoid overfitting. Plan for Unique Roles in AI projects An ML Project has multiple stages, and each stage may require additional roles. For example, Design Research & Designers for Human Experience, Data Engineer for Data Collection, Feature Engineering, a Data Labeler for labeling structured data, engineers for MLOps and model deployment and the list can go on. As a TPM, factor in having these resources available at the right time to avoid any schedule risks. Feature Engineering and Hyperparameter tuning Feature Engineering enables the transformation of data so that it becomes usable for an algorithm. Creating the right features is an art and may require experimentation as well as domain expertise. Allocate time for domain experts to help with improving and identifying the best features. For example, for a natural language processing engine for text extraction of financial documents, we may involve financial researchers and run a relevance judgment exercise and provide a feedback loop to evaluate model performance. Responsible AI considerations Bias in machine learning could be the number one issue of a model not performing to its intended needs. Plan to incorporate Responsible AI principles from Day 1 to ensure fairness, security, privacy and transparency of the models. For example, for a person recognition algorithm, if the data source is only feeding a specific skin type, then production scenarios may not provide good results. PM Fundamentals Core to a TPM role are the fundamentals that include bringing clarity to the team, design thinking, driving the team to the right technical decisions, managing risk, managing stakeholders, backlog management, project management. These are a TPM superpowers . A TPM can complement the machine learning team by ensuring the problem and customer needs are understood, a wholistic system design is evaluated, the stakeholder expectations and driving customer objectives. Here are some references that may help: The T in a TPM The TPM Don't M*ck up framework The mind of a TPM ML Learning Journey for a TPM","title":"TPM considerations for Machine Learning projects"},{"location":"machine-learning/ml-tpm-guidance/#tpm-considerations-for-machine-learning-projects","text":"In this document, we explore some of the Program Management considerations for Machine Learning (ML) projects and suggest recommendations for Technical Program Managers (TPM) to effectively work with Data and Applied Machine Learning engineering teams.","title":"TPM considerations for Machine Learning projects"},{"location":"machine-learning/ml-tpm-guidance/#determine-the-need-for-machine-learning-in-the-project","text":"In Artificial Intelligence (AI) projects, the ML component is generally a part of an overall business problem and NOT the problem itself. Determine the overall business problem first and then evaluate if ML can help address a part of the problem space. Few considerations for identifying the right fit for the project: Engage experts in human experience and employ techniques such as Design Thinking and Problem Formulation to understand the customer needs and human behavior first. Identify the right stakeholders from both business and technical leadership and invite them to these workshops. The outcome should be end-user scenarios and personas to determine the real needs of the users. Focus on System Design principles to identify the architectural components, entities, interfaces, constraints. Ask the right questions early and explore design alternatives with the engineering team. Think hard about the costs of ML and whether we are solving a repetitive problem at scale. Many a times, customer problems can be solved with data analytics, dashboards, or rule-based algorithms as the first phase of the project.","title":"Determine the need for Machine Learning in the project"},{"location":"machine-learning/ml-tpm-guidance/#set-expectations-for-high-ambiguity-in-ml-components","text":"ML projects can be plagued with a phenomenon we can call as the \" Death by Unknowns \". Unlike software engineering projects, ML focused projects can result in quick success early (aka sudden decrease in error rate), but this may flatten eventually. Few things to consider: Set clear expectations : Identify the performance metrics and discuss on a \"good enough\" prediction rate that will bring value to the business. An 80% \"good enough\" rate may save business costs and increase productivity but if going from 80 to 95% would require unimaginable cost and effort. Is it worth it? Can it be a progressive road map? Create a smaller team and undertake a feasibility analysis through techniques like EDA (Exploratory Data Analysis). A feasibility study is much cheaper to evaluate data quality, customer constraints and model feasibility. It allows a TPM to better understand customer use cases and current environment and can act as a fail-fast mechanism. Note that feasibility should be shorter (in weeks) else it misses the point of saving costs. As in any project, there will be new needs (additional data sources, technical constraints, hiring data labelers, business users time etc.). Incorporate Agile techniques to fail fast and minimize cost and schedule surprises.","title":"Set Expectations for high ambiguity in ML components"},{"location":"machine-learning/ml-tpm-guidance/#notebooks-ml-production","text":"Notebooks are a great way to kick start Data Analytics and Applied Machine Learning efforts, however for a production releases, additional constraints should be considered: Understand the end-end flow of data management , how data will be made available (ingestion flows), what's the frequency, storage, retention of data. Plan user stories and design spikes around these flows to ensure a robust ML pipeline is developed. Engineering team should follow the same rigor in building ML projects as in any software engineering project. We at ISE (Industry Solutions Engineering) have built a good set of resources from our learnings in our ISE Engineering Playbook . Think about the how the model will be deployed, for example, are there technical constraints due to an edge device, or network constraints that will prevent updating the model. Understanding of the environment is critical, refer to the Model Production Checklist as a reference to determine model deployment choices. ML Focussed projects are not a \"one-shot\" release solution, they need to be nurtured, evolved, and improved over time. Plan for a continuous improvement lifecycle, the initial phases can be model feasibility and validation to get the good enough prediction rate, the later phases can be then be scaling and improving the models through feedback loops and fresh data sets.","title":"Notebooks != ML Production"},{"location":"machine-learning/ml-tpm-guidance/#garbage-data-in-garbage-model-out","text":"Data quality is a major factor in affecting model performance and production roll-out, consider the following: Conduct a data exploration workshop and generate a report on data quality that includes missing values, duplicates, unlabeled data, expired or not valid data, incomplete data (e.g., only having male representation in a people dataset). Identify data source reliability to ensure data is coming from a production source. (e.g., are the images from a production or industrial camera or taken from an iPhone/Android phone.) Identify data acquisition constraints : Determine how the data is being obtained and the constraints around it. Some example may include legal, contractual, Privacy, regulation, ethics constraints. These can significantly slow down production roll out if not captured in the early phases of the project. Determine data volumes : Identify if we have enough data for sampling the required business use case and how will the data be improved over time. The thumb rule here is that data should be enough for generalization to avoid overfitting.","title":"Garbage Data In -> Garbage Model Out"},{"location":"machine-learning/ml-tpm-guidance/#plan-for-unique-roles-in-ai-projects","text":"An ML Project has multiple stages, and each stage may require additional roles. For example, Design Research & Designers for Human Experience, Data Engineer for Data Collection, Feature Engineering, a Data Labeler for labeling structured data, engineers for MLOps and model deployment and the list can go on. As a TPM, factor in having these resources available at the right time to avoid any schedule risks.","title":"Plan for Unique Roles in AI projects"},{"location":"machine-learning/ml-tpm-guidance/#feature-engineering-and-hyperparameter-tuning","text":"Feature Engineering enables the transformation of data so that it becomes usable for an algorithm. Creating the right features is an art and may require experimentation as well as domain expertise. Allocate time for domain experts to help with improving and identifying the best features. For example, for a natural language processing engine for text extraction of financial documents, we may involve financial researchers and run a relevance judgment exercise and provide a feedback loop to evaluate model performance.","title":"Feature Engineering and Hyperparameter tuning"},{"location":"machine-learning/ml-tpm-guidance/#responsible-ai-considerations","text":"Bias in machine learning could be the number one issue of a model not performing to its intended needs. Plan to incorporate Responsible AI principles from Day 1 to ensure fairness, security, privacy and transparency of the models. For example, for a person recognition algorithm, if the data source is only feeding a specific skin type, then production scenarios may not provide good results.","title":"Responsible AI considerations"},{"location":"machine-learning/ml-tpm-guidance/#pm-fundamentals","text":"Core to a TPM role are the fundamentals that include bringing clarity to the team, design thinking, driving the team to the right technical decisions, managing risk, managing stakeholders, backlog management, project management. These are a TPM superpowers . A TPM can complement the machine learning team by ensuring the problem and customer needs are understood, a wholistic system design is evaluated, the stakeholder expectations and driving customer objectives. Here are some references that may help: The T in a TPM The TPM Don't M*ck up framework The mind of a TPM ML Learning Journey for a TPM","title":"PM Fundamentals"},{"location":"machine-learning/responsible-ai/","text":"Responsible AI in ISE Microsoft's Responsible AI principles Every ML project in ISE goes through a Responsible AI (RAI) assessment to ensure that it upholds Microsoft's 6 Responsible AI principles : Fairness Reliability & Safety Privacy & Security Inclusiveness Transparency Accountability Every project goes through the RAI process, whether we are building a new ML model from scratch, or putting an existing model in production. ISE's Responsible AI process The process begins as soon as we start a prospective project. We start to complete a Responsible AI review document, and an impact assessment, which provides a structured way to explore topics such as: Can the problem be addressed with a non-technical (e.g. social) solution? Can the problem be solved without AI? Would simpler technology suffice? Will the team have access to domain experts (e.g. doctors, refugees) in the field where the AI is applicable? Who are the stakeholders in this project? Who does the AI impact? Are there any vulnerable groups affected? What are the possible benefits and harms to each stakeholder? How can the technology be misused, and what can go wrong? Has the team analyzed the input data properly to make sure that the training data is suitable for machine learning? Is the training data an accurate representation of data that will be used as input in production? Is there a good representation of all users? Is there a fall-back mechanism (a human in the loop, or a way to revert decisions based on the model)? Does data used by the model for training or scoring contain PII? What measures have been taken to remove sensitive data? Does the model impact consequential decisions, like blocking people from getting jobs, loans, health care etc. or in the cases where it may, have appropriate ethical considerations been discussed? Have measures for re-training been considered? How can we address any concerns that arise, and how can we mitigate risk? At this point we research available tools and resources , such as InterpretML or Fairlearn , that we may use on the project. We may change the project scope or re-define the ML problem definition if necessary. The Responsible AI review documents remain living documents that we re-visit and update throughout project development, through the feasibility study , as the model is developed and prepared for production, and new information unfolds. The documents can be used and expanded once the model is deployed, and monitored in production.","title":"Responsible AI in ISE"},{"location":"machine-learning/responsible-ai/#responsible-ai-in-ise","text":"","title":"Responsible AI in ISE"},{"location":"machine-learning/responsible-ai/#microsofts-responsible-ai-principles","text":"Every ML project in ISE goes through a Responsible AI (RAI) assessment to ensure that it upholds Microsoft's 6 Responsible AI principles : Fairness Reliability & Safety Privacy & Security Inclusiveness Transparency Accountability Every project goes through the RAI process, whether we are building a new ML model from scratch, or putting an existing model in production.","title":"Microsoft's Responsible AI principles"},{"location":"machine-learning/responsible-ai/#ises-responsible-ai-process","text":"The process begins as soon as we start a prospective project. We start to complete a Responsible AI review document, and an impact assessment, which provides a structured way to explore topics such as: Can the problem be addressed with a non-technical (e.g. social) solution? Can the problem be solved without AI? Would simpler technology suffice? Will the team have access to domain experts (e.g. doctors, refugees) in the field where the AI is applicable? Who are the stakeholders in this project? Who does the AI impact? Are there any vulnerable groups affected? What are the possible benefits and harms to each stakeholder? How can the technology be misused, and what can go wrong? Has the team analyzed the input data properly to make sure that the training data is suitable for machine learning? Is the training data an accurate representation of data that will be used as input in production? Is there a good representation of all users? Is there a fall-back mechanism (a human in the loop, or a way to revert decisions based on the model)? Does data used by the model for training or scoring contain PII? What measures have been taken to remove sensitive data? Does the model impact consequential decisions, like blocking people from getting jobs, loans, health care etc. or in the cases where it may, have appropriate ethical considerations been discussed? Have measures for re-training been considered? How can we address any concerns that arise, and how can we mitigate risk? At this point we research available tools and resources , such as InterpretML or Fairlearn , that we may use on the project. We may change the project scope or re-define the ML problem definition if necessary. The Responsible AI review documents remain living documents that we re-visit and update throughout project development, through the feasibility study , as the model is developed and prepared for production, and new information unfolds. The documents can be used and expanded once the model is deployed, and monitored in production.","title":"ISE's Responsible AI process"},{"location":"observability/","text":"Observability Building observable systems enables development teams at ISE to measure how well the application is behaving. Observability serves the following goals: Provide holistic view of the application health . Help measure business performance for the customer. Measure operational performance of the system. Identify and diagnose failures to get to the problem fast. Pillars of Observability Logs Metrics Tracing Logs vs Metrics vs Traces Insights Dashboards and Reporting Tools, Patterns and Recommended Practices Tooling and Patterns Observability As Code Recommended Practices Diagnostics tools OpenTelemetry Facets of Observability Observability for Microservices Observability in Machine Learning Observability of CI/CD Pipelines Observability in Azure Databricks Recipes Useful links Non-Functional Requirements Guidance","title":"Observability"},{"location":"observability/#observability","text":"Building observable systems enables development teams at ISE to measure how well the application is behaving. Observability serves the following goals: Provide holistic view of the application health . Help measure business performance for the customer. Measure operational performance of the system. Identify and diagnose failures to get to the problem fast.","title":"Observability"},{"location":"observability/#pillars-of-observability","text":"Logs Metrics Tracing Logs vs Metrics vs Traces","title":"Pillars of Observability"},{"location":"observability/#insights","text":"Dashboards and Reporting","title":"Insights"},{"location":"observability/#tools-patterns-and-recommended-practices","text":"Tooling and Patterns Observability As Code Recommended Practices Diagnostics tools OpenTelemetry","title":"Tools, Patterns and Recommended Practices"},{"location":"observability/#facets-of-observability","text":"Observability for Microservices Observability in Machine Learning Observability of CI/CD Pipelines Observability in Azure Databricks Recipes","title":"Facets of Observability"},{"location":"observability/#useful-links","text":"Non-Functional Requirements Guidance","title":"Useful links"},{"location":"observability/alerting/","text":"Guidance for Alerting One of the goals of building highly observable systems is to provide valuable insight into the behavior of the application. Observable systems allow problems to be identified and surfaced through alerts before end users are impacted. Best Practices The foremost thing to do before creating alerts is to implement observability. Without monitoring systems in place, it becomes next to impossible to know what activities need to be monitored and when to alert the teams. Identify what the application's minimum viable service quality needs to be. It is not what you intend to deliver, but is acceptable for the customer. These Service Level Objectives (SLOs) are a metric for measurement of the application's performance. SLOs are defined with respect to the end users. The alerts must watch for visible impact to the user. For example, alerting on request rate, latency and errors. Use automated, scriptable tools to mimic end-to-end important code paths relatable to activities in the application. Create alert polices on user impacting events or metric rate of change. Alert fatigue is real. Engineers are recommended to pay attention to their monitoring system so that accurate alerts and thresholds can be defined. Establish a primary channel for alerts that needs immediate attention and tag the right team/person(s) based on the nature of the incident. Not every single alert needs to be sent to the primary on-call channel. Establish a secondary channel for items that need to be looked into and does not affect the users, yet. For example, storage that nearing capacity threshold. These items will be what the engineering services will look to regularly to monitor the health of the system. Ensure to set up proper alerting for failures in dependent services like Redis cache, Service Bus etc. For example, if Redis cache is throwing 10 exceptions in last 60 secs, proper alerts are recommended to be created so that these failures are surfaced and action be taken. It is important to learn from each incident and continually improve the process. After every incident has been triaged, conduct a post mortem of the scenario . Scenarios and situations that were not initially considered will occur, and the post-mortem workflow is a great way to highlight that to improve the monitoring/alerting of the system. Configuring an alert to detect that incident scenario is a good idea to see if the event occurs again.","title":"Guidance for Alerting"},{"location":"observability/alerting/#guidance-for-alerting","text":"One of the goals of building highly observable systems is to provide valuable insight into the behavior of the application. Observable systems allow problems to be identified and surfaced through alerts before end users are impacted.","title":"Guidance for Alerting"},{"location":"observability/alerting/#best-practices","text":"The foremost thing to do before creating alerts is to implement observability. Without monitoring systems in place, it becomes next to impossible to know what activities need to be monitored and when to alert the teams. Identify what the application's minimum viable service quality needs to be. It is not what you intend to deliver, but is acceptable for the customer. These Service Level Objectives (SLOs) are a metric for measurement of the application's performance. SLOs are defined with respect to the end users. The alerts must watch for visible impact to the user. For example, alerting on request rate, latency and errors. Use automated, scriptable tools to mimic end-to-end important code paths relatable to activities in the application. Create alert polices on user impacting events or metric rate of change. Alert fatigue is real. Engineers are recommended to pay attention to their monitoring system so that accurate alerts and thresholds can be defined. Establish a primary channel for alerts that needs immediate attention and tag the right team/person(s) based on the nature of the incident. Not every single alert needs to be sent to the primary on-call channel. Establish a secondary channel for items that need to be looked into and does not affect the users, yet. For example, storage that nearing capacity threshold. These items will be what the engineering services will look to regularly to monitor the health of the system. Ensure to set up proper alerting for failures in dependent services like Redis cache, Service Bus etc. For example, if Redis cache is throwing 10 exceptions in last 60 secs, proper alerts are recommended to be created so that these failures are surfaced and action be taken. It is important to learn from each incident and continually improve the process. After every incident has been triaged, conduct a post mortem of the scenario . Scenarios and situations that were not initially considered will occur, and the post-mortem workflow is a great way to highlight that to improve the monitoring/alerting of the system. Configuring an alert to detect that incident scenario is a good idea to see if the event occurs again.","title":"Best Practices"},{"location":"observability/best-practices/","text":"Recommended Practices Correlation Id : Include unique identifier at the start of the interaction to tie down aggregated data from various system components and provide a holistic view. Read more guidelines about using correlation id . Ensure health of the services are monitored and provide insights into system's performance and behavior. Ensure dependent services are monitored properly. Errors and exceptions in dependent services like Redis cache, Service bus, etc. should be logged and alerted. Also, metrics related to dependent services should be captured and logged. - Additionally, failures in dependent services should be propagated up each level of the stack by the health check. Faults, crashes, and failures are logged as discrete events. This helps engineers identify problem area(s) during failures. Ensure logging configuration (eg: setting logging to \"verbose\") can be controlled without code changes. Ensure that metrics around latency and duration are collected and can be aggregated. Start small and add where there is customer impact. Avoiding metric fatigue is very crucial to collecting actionable data. It is important that every data that is collected contains relevant and rich context. Personally Identifiable Information or any other customer sensitive information should never be logged. Special attention should be paid to any local privacy data regulations and collected data must adhere to those. (ex: GDPR) Health checks : Appropriate health checks should added to determine if service is healthy and ready to serve traffic. On a kubernetes platform different types of probes e.g. Liveness, Readiness, Startup etc. can be used to determine health and readiness of the deployed service. Read more here to understand what to watch out for while designing and building an observable system.","title":"Recommended Practices"},{"location":"observability/best-practices/#recommended-practices","text":"Correlation Id : Include unique identifier at the start of the interaction to tie down aggregated data from various system components and provide a holistic view. Read more guidelines about using correlation id . Ensure health of the services are monitored and provide insights into system's performance and behavior. Ensure dependent services are monitored properly. Errors and exceptions in dependent services like Redis cache, Service bus, etc. should be logged and alerted. Also, metrics related to dependent services should be captured and logged. - Additionally, failures in dependent services should be propagated up each level of the stack by the health check. Faults, crashes, and failures are logged as discrete events. This helps engineers identify problem area(s) during failures. Ensure logging configuration (eg: setting logging to \"verbose\") can be controlled without code changes. Ensure that metrics around latency and duration are collected and can be aggregated. Start small and add where there is customer impact. Avoiding metric fatigue is very crucial to collecting actionable data. It is important that every data that is collected contains relevant and rich context. Personally Identifiable Information or any other customer sensitive information should never be logged. Special attention should be paid to any local privacy data regulations and collected data must adhere to those. (ex: GDPR) Health checks : Appropriate health checks should added to determine if service is healthy and ready to serve traffic. On a kubernetes platform different types of probes e.g. Liveness, Readiness, Startup etc. can be used to determine health and readiness of the deployed service. Read more here to understand what to watch out for while designing and building an observable system.","title":"Recommended Practices"},{"location":"observability/correlation-id/","text":"Correlation IDs The Need In a distributed system architecture (microservice architecture), it is highly difficult to understand a single end to end customer transaction flow through the various components. Here are some the general challenges - It becomes challenging to understand the end-to-end behavior of a client request entering the application. Aggregation: Consolidating logs from multiple components and making sense out of these logs is difficult, if not impossible. Cyclic dependencies on services, course of events and asynchronous requests are not easily deciphered. While troubleshooting a request, the diagnostic context of the logs are very important to get to the root of the problem. Solution A Correlation ID is a unique identifier that is added to the very first interaction (incoming request) to identify the context and is passed to all components that are involved in the transaction flow. Correlation ID becomes the glue that binds the transaction together and helps to draw an overall picture of events. Note: Before implementing your own Correlation ID, investigate if your telemetry tool of choice provides an auto-generated Correlation ID and that it serves the purposes of your application. For instance, Application Insights offers dependency auto-collection for some application frameworks Recommended Practices Assign each external request a Correlation ID that binds the message to a transaction. The Correlation ID for a transaction must be assigned as early as you can. Propagate Correlation ID to all downstream components/services. All components/services of the transaction use this Correlation ID in their logs. For an HTTP Request, Correlation ID is typically passed in the header. Add it to an outgoing response where possible. Based on the use case, there can be additional correlation IDs that may be needed. For instance, tracking logs based on both Session ID and User ID may be required. While adding multiple correlation ID, remember to propagate them through the components. Consider using OpenTelemetry as it implements open-source cross-platform context propagation for end-to-end distributed transactions over heterogeneous components out-of-the-box. It takes care of automatically creating and managing the \"Correlation-id\", called TraceId. Use Cases Log Correlation Log correlation is the ability to track disparate events through different parts of the application. Having a Correlation ID provides more context making it easy to build rules for reporting and analysis. Secondary reporting/observer systems Using Correlation ID helps secondary systems to correlate data without application context. Some examples - generating metrics based on tracing data, integrating runtime/system diagnostics etc. For example, feeding AppInsights data and correlating it to infrastructure issues. Troubleshooting Errors For troubleshooting an errors, Correlation ID is a great starting point to trace the workflow of a transaction.","title":"Correlation IDs"},{"location":"observability/correlation-id/#correlation-ids","text":"","title":"Correlation IDs"},{"location":"observability/correlation-id/#the-need","text":"In a distributed system architecture (microservice architecture), it is highly difficult to understand a single end to end customer transaction flow through the various components. Here are some the general challenges - It becomes challenging to understand the end-to-end behavior of a client request entering the application. Aggregation: Consolidating logs from multiple components and making sense out of these logs is difficult, if not impossible. Cyclic dependencies on services, course of events and asynchronous requests are not easily deciphered. While troubleshooting a request, the diagnostic context of the logs are very important to get to the root of the problem.","title":"The Need"},{"location":"observability/correlation-id/#solution","text":"A Correlation ID is a unique identifier that is added to the very first interaction (incoming request) to identify the context and is passed to all components that are involved in the transaction flow. Correlation ID becomes the glue that binds the transaction together and helps to draw an overall picture of events. Note: Before implementing your own Correlation ID, investigate if your telemetry tool of choice provides an auto-generated Correlation ID and that it serves the purposes of your application. For instance, Application Insights offers dependency auto-collection for some application frameworks","title":"Solution"},{"location":"observability/correlation-id/#recommended-practices","text":"Assign each external request a Correlation ID that binds the message to a transaction. The Correlation ID for a transaction must be assigned as early as you can. Propagate Correlation ID to all downstream components/services. All components/services of the transaction use this Correlation ID in their logs. For an HTTP Request, Correlation ID is typically passed in the header. Add it to an outgoing response where possible. Based on the use case, there can be additional correlation IDs that may be needed. For instance, tracking logs based on both Session ID and User ID may be required. While adding multiple correlation ID, remember to propagate them through the components. Consider using OpenTelemetry as it implements open-source cross-platform context propagation for end-to-end distributed transactions over heterogeneous components out-of-the-box. It takes care of automatically creating and managing the \"Correlation-id\", called TraceId.","title":"Recommended Practices"},{"location":"observability/correlation-id/#use-cases","text":"","title":"Use Cases"},{"location":"observability/correlation-id/#log-correlation","text":"Log correlation is the ability to track disparate events through different parts of the application. Having a Correlation ID provides more context making it easy to build rules for reporting and analysis.","title":"Log Correlation"},{"location":"observability/correlation-id/#secondary-reportingobserver-systems","text":"Using Correlation ID helps secondary systems to correlate data without application context. Some examples - generating metrics based on tracing data, integrating runtime/system diagnostics etc. For example, feeding AppInsights data and correlating it to infrastructure issues.","title":"Secondary reporting/observer systems"},{"location":"observability/correlation-id/#troubleshooting-errors","text":"For troubleshooting an errors, Correlation ID is a great starting point to trace the workflow of a transaction.","title":"Troubleshooting Errors"},{"location":"observability/diagnostic-tools/","text":"Diagnostic tools Besides Logging , Tracing and Metrics , there are additional tools to help diagnose issues when applications do not behave as expected. In some scenarios, analyzing the memory consumption and drilling down into why a specific process takes longer than expected may require additional measures. In these cases, platform or programming language specific diagnostic tools come into play and are useful to debug a memory leak, profile the CPU usage, or the cause of delays in multi-threading. Profilers and Memory Analyzers There are two types of diagnostics tools you may want to use: profilers and memory analyzers. Profiling Profiling is a technique where you take small snapshots of all the threads in a running application to see the stack trace of each thread for a specified duration. This tool can help you identify where you are spending CPU time during the execution of your application. There are two main techniques to achieve this: CPU-Sampling and Instrumentation. CPU-Sampling is a non-invasive method which takes snapshots of all the stacks at a set interval. It is the most common technique for profiling and doesn't require any modification to your code. Instrumentation is the other technique where you insert a small piece of code at the beginning and end of each function which is going to signal back to the profiler about the time spent in the function, the function name, parameters and others. This way you modify the code of your running application. There are two effects to this: your code may run a little bit more slowly, but on the other hand you have a more accurate view of every function and class that has been executed so far in your application. When to use Sampling vs Instrumentation? Not all programming languages support instrumentation. Instrumentation is mostly supported for compiled languages like .NET and Java, and some languages interpreted at runtime like Python and Javascript. Keep in mind that enabling instrumentation can require to modify your build pipeline, i.e. by adding special parameters to the command line argument. You should normally start with Sampling because it doesn't require to modify your binaries, it doesn't affect your process performance, and can be quicker to start with. Once you have your profiling data, there are multiple ways to visualize this information depending of the format you saved it. As an example for .NET (dotnet-trace), there are three available formats to save these traces: Chromium, NetTrace and SpeedScope. Select the output format depending on the tool you are going to use. SpeedScope is an online web application you can use to visualize and analyze traces, and you only need a modern browser. Be careful with online tools, as dumps/traces might contain confidential information that you don't want to share outside of your organization. Memory analyzers Memory analyzers and memory dumps are another set of diagnostic tools you can use to identify issues in your process. Normally these types of tools take the whole memory the process is using at a point in time and saves it in a file which can be analyzed. When using these types of tools, you want to stress your process as much as possible to amplify whatever deficiency you may have in terms of memory management. The memory dump should then be taken when the process is in this stressed state. In some scenarios we recommend to take more than one memory dump during the reproduction of a problem. For example, if you suspect a memory leak and you are running a test for 30 min, it is useful to take at least 3 dumps at different intervals (i.e. 10, 20 & 30 min) to compare them with each other. There are multiple ways to take a memory dump depending the operating system you are using. Also, each operating system has it own debugger which is able to load this memory dump, and explore the state of the process at the time the memory dump was taken. The most common debuggers are: Windows - WinDbg and WinDgbNext (included in the Windows SDK), Visual Studio can also load a memory dump for a .NET Framework and .NET Core process Linux - GDB is the GNU Debugger Mac OS - LLDB Debugger There are a range of developer platform specific diagnostic tools which can be used: .NET Core diagnostic tools , GitHub repository Java diagnostic tools - version specific Python debugging and profiling - version specific Node.js Diagnostics working group Environment for profiling To create an application profile as close to production as possible, the environment in which the application is intended to run in production has to be considered and it might be necessary to perform a snapshot of the application state under load . Diagnostics in containers For monolithic applications, diagnostics tools can be installed and run on the VM hosting them. Most scalable applications are developed as microservices and have complex interactions which require to install the tools in the containers running the process or to leverage a sidecar container (see sidecar pattern ). Some platforms expose endpoints to interact with the application and return a dump. Useful links: .NET Core diagnostics in containers Experimental tool dotnet-monitor , What's new , GItHub repository Spring Boot actuator endpoints","title":"Diagnostic tools"},{"location":"observability/diagnostic-tools/#diagnostic-tools","text":"Besides Logging , Tracing and Metrics , there are additional tools to help diagnose issues when applications do not behave as expected. In some scenarios, analyzing the memory consumption and drilling down into why a specific process takes longer than expected may require additional measures. In these cases, platform or programming language specific diagnostic tools come into play and are useful to debug a memory leak, profile the CPU usage, or the cause of delays in multi-threading.","title":"Diagnostic tools"},{"location":"observability/diagnostic-tools/#profilers-and-memory-analyzers","text":"There are two types of diagnostics tools you may want to use: profilers and memory analyzers.","title":"Profilers and Memory Analyzers"},{"location":"observability/diagnostic-tools/#profiling","text":"Profiling is a technique where you take small snapshots of all the threads in a running application to see the stack trace of each thread for a specified duration. This tool can help you identify where you are spending CPU time during the execution of your application. There are two main techniques to achieve this: CPU-Sampling and Instrumentation. CPU-Sampling is a non-invasive method which takes snapshots of all the stacks at a set interval. It is the most common technique for profiling and doesn't require any modification to your code. Instrumentation is the other technique where you insert a small piece of code at the beginning and end of each function which is going to signal back to the profiler about the time spent in the function, the function name, parameters and others. This way you modify the code of your running application. There are two effects to this: your code may run a little bit more slowly, but on the other hand you have a more accurate view of every function and class that has been executed so far in your application.","title":"Profiling"},{"location":"observability/diagnostic-tools/#when-to-use-sampling-vs-instrumentation","text":"Not all programming languages support instrumentation. Instrumentation is mostly supported for compiled languages like .NET and Java, and some languages interpreted at runtime like Python and Javascript. Keep in mind that enabling instrumentation can require to modify your build pipeline, i.e. by adding special parameters to the command line argument. You should normally start with Sampling because it doesn't require to modify your binaries, it doesn't affect your process performance, and can be quicker to start with. Once you have your profiling data, there are multiple ways to visualize this information depending of the format you saved it. As an example for .NET (dotnet-trace), there are three available formats to save these traces: Chromium, NetTrace and SpeedScope. Select the output format depending on the tool you are going to use. SpeedScope is an online web application you can use to visualize and analyze traces, and you only need a modern browser. Be careful with online tools, as dumps/traces might contain confidential information that you don't want to share outside of your organization.","title":"When to use Sampling vs Instrumentation?"},{"location":"observability/diagnostic-tools/#memory-analyzers","text":"Memory analyzers and memory dumps are another set of diagnostic tools you can use to identify issues in your process. Normally these types of tools take the whole memory the process is using at a point in time and saves it in a file which can be analyzed. When using these types of tools, you want to stress your process as much as possible to amplify whatever deficiency you may have in terms of memory management. The memory dump should then be taken when the process is in this stressed state. In some scenarios we recommend to take more than one memory dump during the reproduction of a problem. For example, if you suspect a memory leak and you are running a test for 30 min, it is useful to take at least 3 dumps at different intervals (i.e. 10, 20 & 30 min) to compare them with each other. There are multiple ways to take a memory dump depending the operating system you are using. Also, each operating system has it own debugger which is able to load this memory dump, and explore the state of the process at the time the memory dump was taken. The most common debuggers are: Windows - WinDbg and WinDgbNext (included in the Windows SDK), Visual Studio can also load a memory dump for a .NET Framework and .NET Core process Linux - GDB is the GNU Debugger Mac OS - LLDB Debugger There are a range of developer platform specific diagnostic tools which can be used: .NET Core diagnostic tools , GitHub repository Java diagnostic tools - version specific Python debugging and profiling - version specific Node.js Diagnostics working group","title":"Memory analyzers"},{"location":"observability/diagnostic-tools/#environment-for-profiling","text":"To create an application profile as close to production as possible, the environment in which the application is intended to run in production has to be considered and it might be necessary to perform a snapshot of the application state under load .","title":"Environment for profiling"},{"location":"observability/diagnostic-tools/#diagnostics-in-containers","text":"For monolithic applications, diagnostics tools can be installed and run on the VM hosting them. Most scalable applications are developed as microservices and have complex interactions which require to install the tools in the containers running the process or to leverage a sidecar container (see sidecar pattern ). Some platforms expose endpoints to interact with the application and return a dump. Useful links: .NET Core diagnostics in containers Experimental tool dotnet-monitor , What's new , GItHub repository Spring Boot actuator endpoints","title":"Diagnostics in containers"},{"location":"observability/log-vs-metric-vs-trace/","text":"Logs vs Metrics vs Traces Overview Metrics The purpose of metrics is to inform observers about the health & operations regarding a component or system. A metric represents a point in time measure of a particular source, and data-wise tends to be very small. The compact size allows for efficient collection even at scale in large systems. Metrics also lend themselves very well to pre-aggregation within the component before collection, reducing computation cost for processing & storing large numbers of metric time series in a central system. Due to how efficiently metrics are processed & stored, it lends itself very well for use in automated alerting, as metrics are an excellent source for the health data for all components in the system. Logs Log data inform observers about the discrete events that occurred within a component or a set of components. Just about every software component log information about its activities over time. This rich data tends to be much larger than metric data and can cause processing issues, especially if components are logging too verbosely. Therefore, using log data to understand the health of an extensive system tends to be avoided and depends on metrics for that data. Once metric telemetry highlights potential problem sources, filtered log data for those sources can be used to understand what occurred. Traces Where logging provides an overview to a discrete, event-triggered log, tracing encompasses a much wider, continuous view of an application. The goal of tracing is to following a program\u2019s flow and data progression. In many instances, tracing represents a single user\u2019s journey through an entire app stack. Its purpose isn\u2019t reactive, but instead focused on optimization. By tracing through a stack, developers can identify bottlenecks and focus on improving performance. A distributed trace is defined as a collection of spans. A span is the smallest unit in a trace and represents a piece of the workflow in a distributed landscape. It can be an HTTP request, call to a database, or execution of a message from a queue. When a problem does occur, tracing allows you to see how you got there: Which function. The function\u2019s duration. Parameters passed. How deep into the function the user could get. Usage Guidance When to use metric or log data to track a particular piece of telemetry can be summarized with the following points: Use metrics to track the occurrence of an event, counting of items, the time taken to perform an action or to report the current value of a resource (CPU, memory, etc.) Use logs to track detailed information about an event also monitored by a metric, particularly errors, warnings or other exceptional situations. A trace provides visibility into how a request is processed across multiple services in a microservices environment. Every trace needs to have a unique identifier associated with it.","title":"Logs vs Metrics vs Traces"},{"location":"observability/log-vs-metric-vs-trace/#logs-vs-metrics-vs-traces","text":"","title":"Logs vs Metrics vs Traces"},{"location":"observability/log-vs-metric-vs-trace/#overview","text":"","title":"Overview"},{"location":"observability/log-vs-metric-vs-trace/#metrics","text":"The purpose of metrics is to inform observers about the health & operations regarding a component or system. A metric represents a point in time measure of a particular source, and data-wise tends to be very small. The compact size allows for efficient collection even at scale in large systems. Metrics also lend themselves very well to pre-aggregation within the component before collection, reducing computation cost for processing & storing large numbers of metric time series in a central system. Due to how efficiently metrics are processed & stored, it lends itself very well for use in automated alerting, as metrics are an excellent source for the health data for all components in the system.","title":"Metrics"},{"location":"observability/log-vs-metric-vs-trace/#logs","text":"Log data inform observers about the discrete events that occurred within a component or a set of components. Just about every software component log information about its activities over time. This rich data tends to be much larger than metric data and can cause processing issues, especially if components are logging too verbosely. Therefore, using log data to understand the health of an extensive system tends to be avoided and depends on metrics for that data. Once metric telemetry highlights potential problem sources, filtered log data for those sources can be used to understand what occurred.","title":"Logs"},{"location":"observability/log-vs-metric-vs-trace/#traces","text":"Where logging provides an overview to a discrete, event-triggered log, tracing encompasses a much wider, continuous view of an application. The goal of tracing is to following a program\u2019s flow and data progression. In many instances, tracing represents a single user\u2019s journey through an entire app stack. Its purpose isn\u2019t reactive, but instead focused on optimization. By tracing through a stack, developers can identify bottlenecks and focus on improving performance. A distributed trace is defined as a collection of spans. A span is the smallest unit in a trace and represents a piece of the workflow in a distributed landscape. It can be an HTTP request, call to a database, or execution of a message from a queue. When a problem does occur, tracing allows you to see how you got there: Which function. The function\u2019s duration. Parameters passed. How deep into the function the user could get.","title":"Traces"},{"location":"observability/log-vs-metric-vs-trace/#usage-guidance","text":"When to use metric or log data to track a particular piece of telemetry can be summarized with the following points: Use metrics to track the occurrence of an event, counting of items, the time taken to perform an action or to report the current value of a resource (CPU, memory, etc.) Use logs to track detailed information about an event also monitored by a metric, particularly errors, warnings or other exceptional situations. A trace provides visibility into how a request is processed across multiple services in a microservices environment. Every trace needs to have a unique identifier associated with it.","title":"Usage Guidance"},{"location":"observability/logs-privacy/","text":"Guidance for Privacy Overview To ensure the privacy of your system users, as well as comply with several regulations like GDPR, some types of data shouldn\u2019t exist in logs. This includes customer's sensitive, Personal Identifiable Information (PII), and any other data that wasn't legally sanctioned. Recommended Practices Separate components and minimize the parts of the system that log sensitive data. Keep sensitive data out of URLs, since request URLs are typically logged by proxies and web servers. Avoid using PII data for system debugging as much as possible. For example, use ids instead of usernames. Use Structured Logging and include a deny-list for sensitive properties. Put an extra effort on spotting logging statements with sensitive data during code review, as it is common for reviewers to skip reading logging statements. This can be added as an additional checkbox if you're using Pull Request Templates. Include mechanisms to detect sensitive data in logs, on your organizational pipelines for QA or Automated Testing. Tools and Implementation Methods Use these tools and methods for sensitive data de-identification in logs. Application Insights Application Insights offers telemetry interception in some of the SDKs, that can be done by implementing the ITelemetryProcessor interface. ITelemetryProcessor processes the telemetry information before it is sent to Application Insights, and can be useful in many situations, such as filtering and modifications. Below is an example of intercepting 'trace' typed telemetry: using Microsoft.ApplicationInsights.DataContracts ; namespace Example { using Microsoft.ApplicationInsights.Channel ; using Microsoft.ApplicationInsights.Extensibility ; internal class RedactTelemetryInitializer : ITelemetryInitializer { public void Initialize ( ITelemetry telemetry ) { var requestTelemetry = telemetry as TraceTelemetry ; if ( requestTelemetry == null ) return ; # redact emails from the message parameter requestTelemetry . Message = Regex . Replace ( requestTelemetry . Message , @\"[^@\\s]+@[^@\\s]+\\.[^@\\s]+\" , \"[email removed]\" ); } } } Elastic Stack Elastic Stack (formerly \"ELK stack\") allows logs interception by Logstash's filter-plugins . Using some of the existing plugins, like 'mutate', 'alter' and 'prune' might be sufficient for most cases of deidentifying and redacting PIIs. For a more robust and customized use-case, a 'ruby' plugin can be used, executing arbitrary Ruby code. Filter plugins also exists in some Logstash alternatives, like Fluentd and Fluent Bit . Presidio Presidio offers data protection and anonymization API. It provides fast identification and anonymization modules for private entities in text. Presidio allows using predefined or custom PII recognizers, leveraging Named Entity Recognition, regular expressions, rule based logic and checksum with relevant context in multiple languages. It can be used alongside the log interception methods mentioned above to help and ensure sensitive data is properly managed and governed. Presidio is containerized for REST HTTP API and also can be installed as a python package, to be called from python code. Instead of handling the anonymization in the application code, both APIs can be used using external calls. Elastic Stack, for example, can handle PII redaction using the 'ruby' filter plugin to call Presidio in REST HTTP API, or by calling a python script consuming Presidio as a package: logstash.conf input { ... } filter { ruby { code => 'require \"open3\" message = event.get(\"message\") # Call a python script triggering Presidio analyzer and anonymizer, and printing the result. cmd = \"python /path/to/presidio/anonymization/script.py \\\" #{ message } \\\" \" # Fetch the script' s stdout stdin , stdout , stderr = Open3 . popen3 ( cmd ) # Override message with the anonymized text. event . set ( \"message\" , stdout . read ) filter_matched ( event ) ' } } output { ... }","title":"Guidance for Privacy"},{"location":"observability/logs-privacy/#guidance-for-privacy","text":"","title":"Guidance for Privacy"},{"location":"observability/logs-privacy/#overview","text":"To ensure the privacy of your system users, as well as comply with several regulations like GDPR, some types of data shouldn\u2019t exist in logs. This includes customer's sensitive, Personal Identifiable Information (PII), and any other data that wasn't legally sanctioned.","title":"Overview"},{"location":"observability/logs-privacy/#recommended-practices","text":"Separate components and minimize the parts of the system that log sensitive data. Keep sensitive data out of URLs, since request URLs are typically logged by proxies and web servers. Avoid using PII data for system debugging as much as possible. For example, use ids instead of usernames. Use Structured Logging and include a deny-list for sensitive properties. Put an extra effort on spotting logging statements with sensitive data during code review, as it is common for reviewers to skip reading logging statements. This can be added as an additional checkbox if you're using Pull Request Templates. Include mechanisms to detect sensitive data in logs, on your organizational pipelines for QA or Automated Testing.","title":"Recommended Practices"},{"location":"observability/logs-privacy/#tools-and-implementation-methods","text":"Use these tools and methods for sensitive data de-identification in logs.","title":"Tools and Implementation Methods"},{"location":"observability/logs-privacy/#application-insights","text":"Application Insights offers telemetry interception in some of the SDKs, that can be done by implementing the ITelemetryProcessor interface. ITelemetryProcessor processes the telemetry information before it is sent to Application Insights, and can be useful in many situations, such as filtering and modifications. Below is an example of intercepting 'trace' typed telemetry: using Microsoft.ApplicationInsights.DataContracts ; namespace Example { using Microsoft.ApplicationInsights.Channel ; using Microsoft.ApplicationInsights.Extensibility ; internal class RedactTelemetryInitializer : ITelemetryInitializer { public void Initialize ( ITelemetry telemetry ) { var requestTelemetry = telemetry as TraceTelemetry ; if ( requestTelemetry == null ) return ; # redact emails from the message parameter requestTelemetry . Message = Regex . Replace ( requestTelemetry . Message , @\"[^@\\s]+@[^@\\s]+\\.[^@\\s]+\" , \"[email removed]\" ); } } }","title":"Application Insights"},{"location":"observability/logs-privacy/#elastic-stack","text":"Elastic Stack (formerly \"ELK stack\") allows logs interception by Logstash's filter-plugins . Using some of the existing plugins, like 'mutate', 'alter' and 'prune' might be sufficient for most cases of deidentifying and redacting PIIs. For a more robust and customized use-case, a 'ruby' plugin can be used, executing arbitrary Ruby code. Filter plugins also exists in some Logstash alternatives, like Fluentd and Fluent Bit .","title":"Elastic Stack"},{"location":"observability/logs-privacy/#presidio","text":"Presidio offers data protection and anonymization API. It provides fast identification and anonymization modules for private entities in text. Presidio allows using predefined or custom PII recognizers, leveraging Named Entity Recognition, regular expressions, rule based logic and checksum with relevant context in multiple languages. It can be used alongside the log interception methods mentioned above to help and ensure sensitive data is properly managed and governed. Presidio is containerized for REST HTTP API and also can be installed as a python package, to be called from python code. Instead of handling the anonymization in the application code, both APIs can be used using external calls. Elastic Stack, for example, can handle PII redaction using the 'ruby' filter plugin to call Presidio in REST HTTP API, or by calling a python script consuming Presidio as a package: logstash.conf input { ... } filter { ruby { code => 'require \"open3\" message = event.get(\"message\") # Call a python script triggering Presidio analyzer and anonymizer, and printing the result. cmd = \"python /path/to/presidio/anonymization/script.py \\\" #{ message } \\\" \" # Fetch the script' s stdout stdin , stdout , stderr = Open3 . popen3 ( cmd ) # Override message with the anonymized text. event . set ( \"message\" , stdout . read ) filter_matched ( event ) ' } } output { ... }","title":"Presidio"},{"location":"observability/microservices/","text":"Observability in Microservices Microservices is a very popular software architecture, where the application is arranged as a collection of loosely coupled services. Some of those services can be written in different languages by different teams. Motivations We need to consider special cases when creating a microservice architecture from the perspective of observability. We want to capture the interactions when making requests between those microservices and correlate them. Imagine we have a microservice that accesses a database to retrieve some data as part of a request. This microservice is going to be called by someone else as part of an incoming http request or an internal process being executed. What happens if a problem occurs during the retrieval of the data (or the update of the data)? How can we associate, or correlate, that this particular call failed in the destination microservice? This is a common issue. When calling other microservices, depending on the technology stack we use, we can accidentally hide errors and exceptions that might happen on the other side. If we are using a simple REST interface, the other microservice can return a 500 HTTP status code and we don't have any idea what happen inside that microservice. More important, we don't have any way to associate our Correlation Id to whatever happens inside that microservice. Therefore, is so important to have a plan in place to be able to extend your traceability and monitoring efforts, especially when using a microservice architecture. How to extend your tracing information between microservices The W3C consortium is working on a Trace Context definition that can be applied when using HTTP as the protocol in a microservice architecture. But let's explain how we can implement this functionality in our software. The main idea behind this is to propagate the correlation information between HTTP request so other pieces of software can read this information and correctly correlate telemetry across microservices. The way to propagate this information is to use HTTP Headers for the Correlation Id, parent Correlation Id, etc. When you are in the scope of a HTTP Request, your tracing system should already have created four properties that you can use to send across your microservices. RequestId:0HLQV2BC3VP2T:00000001, SpanId:da13aa3c6fd9c146, TraceId:f11a03e3f078414fa7c0a0ce568c8b5c, ParentId:5076c17d0a604244 This is an example of the four properties you can find which identify the current request. RequestId is the unique id that represent the current HTTP Request. SpanId is the default automatically generated span. You can have more than one Span that scope different functionality inside your software. TraceId represent the id for current log trace. ParentId is the parent span id, that in some case can be the same or something different. Example Now we are going to explore an example with 3 microservices that calls to each other in a row. This image is the summary of what is needed in each microservice to propagate the trace-id from A to C. The root caller is A and that is why it doesn't have a parent-id, only have a new trace-id. Next, A calls B using HTTP. To propagate the correlation information as part of the request, we are using two new headers based on the W3C Correlation specification, trace-id and parent-id. In this example because A is the root caller, A only sends its own trace-id to microservice B. When microservice B receives the incoming HTTP request, it checks the contents of these two headers. It reads the content of the trace-id header and sets its own parent-id to this trace-id (as shown in the green rectangle inside's B). In addition, it creates a new trace-id to signal that is a new scope for the telemetry. During the execution of microservice B, it also calls microservice C and repeats the pattern. As part of the request it includes the two headers and propagates trace-id and parent-id as well. Finally, microservice C, reads the value for the incoming trace-id and sets as his own parent-id, but also creates a new trace-id that will use to send telemetry about his own operations. Summary A number of Application Monitoring (APM) technology products already supports most of this Correlation Propagation. The most popular is OpenZipkin/B3-Propagation . W3C already proposed a recommendation for the W3C Trace Context , where you can see what SDK and frameworks already support this functionality. It's important to correctly implement the propagation specially when there are different teams that used different technology stacks in the same project. Consider using OpenTelemetry as it implements open-source cross-platform context propagation for end-to-end distributed transactions over heterogeneous components out-of-the-box. It takes care of automatically creating and managing the Trace Context object among a full stack of microservices implemented across different technical stacks.","title":"Observability in Microservices"},{"location":"observability/microservices/#observability-in-microservices","text":"Microservices is a very popular software architecture, where the application is arranged as a collection of loosely coupled services. Some of those services can be written in different languages by different teams.","title":"Observability in Microservices"},{"location":"observability/microservices/#motivations","text":"We need to consider special cases when creating a microservice architecture from the perspective of observability. We want to capture the interactions when making requests between those microservices and correlate them. Imagine we have a microservice that accesses a database to retrieve some data as part of a request. This microservice is going to be called by someone else as part of an incoming http request or an internal process being executed. What happens if a problem occurs during the retrieval of the data (or the update of the data)? How can we associate, or correlate, that this particular call failed in the destination microservice? This is a common issue. When calling other microservices, depending on the technology stack we use, we can accidentally hide errors and exceptions that might happen on the other side. If we are using a simple REST interface, the other microservice can return a 500 HTTP status code and we don't have any idea what happen inside that microservice. More important, we don't have any way to associate our Correlation Id to whatever happens inside that microservice. Therefore, is so important to have a plan in place to be able to extend your traceability and monitoring efforts, especially when using a microservice architecture.","title":"Motivations"},{"location":"observability/microservices/#how-to-extend-your-tracing-information-between-microservices","text":"The W3C consortium is working on a Trace Context definition that can be applied when using HTTP as the protocol in a microservice architecture. But let's explain how we can implement this functionality in our software. The main idea behind this is to propagate the correlation information between HTTP request so other pieces of software can read this information and correctly correlate telemetry across microservices. The way to propagate this information is to use HTTP Headers for the Correlation Id, parent Correlation Id, etc. When you are in the scope of a HTTP Request, your tracing system should already have created four properties that you can use to send across your microservices. RequestId:0HLQV2BC3VP2T:00000001, SpanId:da13aa3c6fd9c146, TraceId:f11a03e3f078414fa7c0a0ce568c8b5c, ParentId:5076c17d0a604244 This is an example of the four properties you can find which identify the current request. RequestId is the unique id that represent the current HTTP Request. SpanId is the default automatically generated span. You can have more than one Span that scope different functionality inside your software. TraceId represent the id for current log trace. ParentId is the parent span id, that in some case can be the same or something different.","title":"How to extend your tracing information between microservices"},{"location":"observability/microservices/#example","text":"Now we are going to explore an example with 3 microservices that calls to each other in a row. This image is the summary of what is needed in each microservice to propagate the trace-id from A to C. The root caller is A and that is why it doesn't have a parent-id, only have a new trace-id. Next, A calls B using HTTP. To propagate the correlation information as part of the request, we are using two new headers based on the W3C Correlation specification, trace-id and parent-id. In this example because A is the root caller, A only sends its own trace-id to microservice B. When microservice B receives the incoming HTTP request, it checks the contents of these two headers. It reads the content of the trace-id header and sets its own parent-id to this trace-id (as shown in the green rectangle inside's B). In addition, it creates a new trace-id to signal that is a new scope for the telemetry. During the execution of microservice B, it also calls microservice C and repeats the pattern. As part of the request it includes the two headers and propagates trace-id and parent-id as well. Finally, microservice C, reads the value for the incoming trace-id and sets as his own parent-id, but also creates a new trace-id that will use to send telemetry about his own operations.","title":"Example"},{"location":"observability/microservices/#summary","text":"A number of Application Monitoring (APM) technology products already supports most of this Correlation Propagation. The most popular is OpenZipkin/B3-Propagation . W3C already proposed a recommendation for the W3C Trace Context , where you can see what SDK and frameworks already support this functionality. It's important to correctly implement the propagation specially when there are different teams that used different technology stacks in the same project. Consider using OpenTelemetry as it implements open-source cross-platform context propagation for end-to-end distributed transactions over heterogeneous components out-of-the-box. It takes care of automatically creating and managing the Trace Context object among a full stack of microservices implemented across different technical stacks.","title":"Summary"},{"location":"observability/ml-observability/","text":"Observability in Machine Learning Development process of software system with machine learning component is more complex than traditional software. We need to monitor changes and variations in three dimensions: the code, the model and the data. We can distinguish two stages of such system lifespan: experimentation and production that require different approaches to observability as discussed below: Model experimentation and tuning Experimentation is a process of finding suitable machine learning model and its parameters via training and evaluating such models with one or more datasets. When developing and tuning machine learning models, the data scientists are interested in observing and comparing selected performance metrics for various model parameters. They also need a reliable way to reproduce a training process, such that a given dataset and given parameters produces the same models. There are many model metric evaluation solutions available, both open source (like MLFlow) and proprietary (like Azure Machine Learning Service), and of which some serve different purposes. To capture model metrics, there are a.o. the following options available: Azure Machine Learning Service SDK Azure Machine Learning service provides an SDK for Python, R and C# to capture your evaluation metrics to an Azure Machine Learning service (AML) Experiment. Experiments are viewed in the AML dashboard. Reproducibility is achieved by storing code or notebook snapshot together with viewed metric. You can create versioned Datasets within Azure Machine Learning service. MLFlow (for Databricks) MLFlow is open source framework, and can be hosted on Azure Databricks as its remote tracking server (it currently is the only solution that offers first-party integration with Databricks). You can use the MLFlow SDK tracking component to capture your evaluation metrics or any parameter you would like and track it at experimentation board in Azure Databricks. Source code and dataset version are also saved with log snapshot to provide reproducibility. TensorBoard TensorBoard is a popular tool amongst data scientist to visualize specific metrics of Deep Learning runs, especially of TensorFlow runs. TensorBoard is not an MLOps tool like AML/MLFlow, and therefore does not offer extensive logging capabilities. It is meant to be transient; and can therefore be used as an addition to an end-to-end MLOps tool like AML, but not as a complete MLOps tool. Application Insights Application Insights can be used as an alternative sink to capture model metrics, and can therefore offer more extensive options as metrics can be transferred to e.g. a PowerBI dashboard. It also enables log querying. However, this solution means that a custom application needs to be written to send logs to AppInsights (using for example the OpenCensus Python SDK), which would mean extra effort of creating/maintaining custom code. An extensive comparison of the four tools can be found as follows: Azure ML MLFlow TensorBoard Application Insights Metrics support Values, images, matrices, logs Values, images, matrices and plots as files Metrics relevant to DL research phase Values, images, matrices, logs Customizabile Basic Basic Very basic High Metrics accessible AML portal, AML SDK MLFlow UI, Tracking service API Tensorboard UI, history object Application Insights Logs accessible Rolling logs written to .txt files in blob storage, accessible via blob or AML portal. Not query-able Rolling logs are not stored Rolling logs are not stored Application Insights in Azure Portal. Query-able with KQL Ease of use and set up Very straightforward, only one portal More moving parts due to remote tracking server A bit over process overhead. Also depending on ML framework More moving parts as a custom app needs to be maintained Shareability Across people with access to AML workspace Across people with access to remote tracking server Across people with access to same directory Across people with access to AppInsights Model in production The trained model can be deployed to production as container. Azure Machine Learning service provides SDK to deploy model as Azure Container Instance and publishes REST endpoint. You can monitor it using microservice observability methods( for more details -refer to Recipes section). MLFLow is an alternative way to deploy ML model as a service. Training and re-training To automatically retrain the model you can use AML Pipelines or Azure Databricks. When re-training with AML Pipelines you can monitor information of each run, including the output, logs, and various metrics in the Azure portal experiment dashboard, or manually extract it using the AML SDK Model performance over time: data drift We re-train machine learning models to improve their performance and make models better aligned with data changing over time. However, in some cases model performance may degrade. This may happen in case data change dramatically and do not exhibit the patterns we observed during model development anymore. This effect is called data drift. Azure Machine Learning Service has preview feature to observe and report data drift. This article describes it in detail. Data versioning It is recommended practice to add version to all datasets. You can create a versioned Azure ML Dataset for this purpose, or manually version it if using other systems.","title":"Observability in Machine Learning"},{"location":"observability/ml-observability/#observability-in-machine-learning","text":"Development process of software system with machine learning component is more complex than traditional software. We need to monitor changes and variations in three dimensions: the code, the model and the data. We can distinguish two stages of such system lifespan: experimentation and production that require different approaches to observability as discussed below:","title":"Observability in Machine Learning"},{"location":"observability/ml-observability/#model-experimentation-and-tuning","text":"Experimentation is a process of finding suitable machine learning model and its parameters via training and evaluating such models with one or more datasets. When developing and tuning machine learning models, the data scientists are interested in observing and comparing selected performance metrics for various model parameters. They also need a reliable way to reproduce a training process, such that a given dataset and given parameters produces the same models. There are many model metric evaluation solutions available, both open source (like MLFlow) and proprietary (like Azure Machine Learning Service), and of which some serve different purposes. To capture model metrics, there are a.o. the following options available: Azure Machine Learning Service SDK Azure Machine Learning service provides an SDK for Python, R and C# to capture your evaluation metrics to an Azure Machine Learning service (AML) Experiment. Experiments are viewed in the AML dashboard. Reproducibility is achieved by storing code or notebook snapshot together with viewed metric. You can create versioned Datasets within Azure Machine Learning service. MLFlow (for Databricks) MLFlow is open source framework, and can be hosted on Azure Databricks as its remote tracking server (it currently is the only solution that offers first-party integration with Databricks). You can use the MLFlow SDK tracking component to capture your evaluation metrics or any parameter you would like and track it at experimentation board in Azure Databricks. Source code and dataset version are also saved with log snapshot to provide reproducibility. TensorBoard TensorBoard is a popular tool amongst data scientist to visualize specific metrics of Deep Learning runs, especially of TensorFlow runs. TensorBoard is not an MLOps tool like AML/MLFlow, and therefore does not offer extensive logging capabilities. It is meant to be transient; and can therefore be used as an addition to an end-to-end MLOps tool like AML, but not as a complete MLOps tool. Application Insights Application Insights can be used as an alternative sink to capture model metrics, and can therefore offer more extensive options as metrics can be transferred to e.g. a PowerBI dashboard. It also enables log querying. However, this solution means that a custom application needs to be written to send logs to AppInsights (using for example the OpenCensus Python SDK), which would mean extra effort of creating/maintaining custom code. An extensive comparison of the four tools can be found as follows: Azure ML MLFlow TensorBoard Application Insights Metrics support Values, images, matrices, logs Values, images, matrices and plots as files Metrics relevant to DL research phase Values, images, matrices, logs Customizabile Basic Basic Very basic High Metrics accessible AML portal, AML SDK MLFlow UI, Tracking service API Tensorboard UI, history object Application Insights Logs accessible Rolling logs written to .txt files in blob storage, accessible via blob or AML portal. Not query-able Rolling logs are not stored Rolling logs are not stored Application Insights in Azure Portal. Query-able with KQL Ease of use and set up Very straightforward, only one portal More moving parts due to remote tracking server A bit over process overhead. Also depending on ML framework More moving parts as a custom app needs to be maintained Shareability Across people with access to AML workspace Across people with access to remote tracking server Across people with access to same directory Across people with access to AppInsights","title":"Model experimentation and tuning"},{"location":"observability/ml-observability/#model-in-production","text":"The trained model can be deployed to production as container. Azure Machine Learning service provides SDK to deploy model as Azure Container Instance and publishes REST endpoint. You can monitor it using microservice observability methods( for more details -refer to Recipes section). MLFLow is an alternative way to deploy ML model as a service.","title":"Model in production"},{"location":"observability/ml-observability/#training-and-re-training","text":"To automatically retrain the model you can use AML Pipelines or Azure Databricks. When re-training with AML Pipelines you can monitor information of each run, including the output, logs, and various metrics in the Azure portal experiment dashboard, or manually extract it using the AML SDK","title":"Training and re-training"},{"location":"observability/ml-observability/#model-performance-over-time-data-drift","text":"We re-train machine learning models to improve their performance and make models better aligned with data changing over time. However, in some cases model performance may degrade. This may happen in case data change dramatically and do not exhibit the patterns we observed during model development anymore. This effect is called data drift. Azure Machine Learning Service has preview feature to observe and report data drift. This article describes it in detail.","title":"Model performance over time: data drift"},{"location":"observability/ml-observability/#data-versioning","text":"It is recommended practice to add version to all datasets. You can create a versioned Azure ML Dataset for this purpose, or manually version it if using other systems.","title":"Data versioning"},{"location":"observability/observability-as-code/","text":"Observability as Code As much as possible, configuration and management of observability assets such as cloud resource provisioning, monitoring alerts and dashboards must be managed as code. Observability as Code is achieved using any one of Terraform / Ansible / ARM Templates Examples of Observability as Code Dashboards as Code - Monitoring Dashboards can be created as JSON or XML templates. This template is source control maintained and any changes to the dashboards can be reviewed. Automation can be built for enabling the dashboard. More about how to do this in Azure . Grafana dashboard can also be configured as code which eventually can be source-controlled to be used in automation and pipelines. Alerts as Code - Alerts can be created within Azure by using Terraform or ARM templates. Such alerts can be source-controlled and be deployed as part of pipelines (Azure DevOps pipelines, Jenkins, GitHub Actions etc.). Few references of how to do this are: Terraform Monitor Metric Alert . Alerts can also be created based on log analytics query and can be defined as code using Terraform Monitor Scheduled Query Rules Alert . Automating Log Analytics Queries - There are several use cases where automation of log analytics queries may be needed. Example, Automatic Report Generation, Running custom queries programmatically for analysis, debugging etc. For these use cases to work, log queries should be source-controlled and automation can be built using log analytics REST or azure cli . Why It makes configuration repeatable and automatable. It also avoids manual configuration of monitoring alerts and dashboards from scratch across environments. Configured dashboards help troubleshoot errors during integration and deployment (CI/CD) We can audit changes and roll them back if there are any issues. Identify actionable insights from the generated metrics data across all environments, not just production. Configuration and management of observability assets like alert threshold, duration, configuration values using IAC help us in avoiding configuration mistakes, errors or overlooks during deployment. When practicing observability as code, the changes can be reviewed by the team similar to other code contributions.","title":"Observability as Code"},{"location":"observability/observability-as-code/#observability-as-code","text":"As much as possible, configuration and management of observability assets such as cloud resource provisioning, monitoring alerts and dashboards must be managed as code. Observability as Code is achieved using any one of Terraform / Ansible / ARM Templates","title":"Observability as Code"},{"location":"observability/observability-as-code/#examples-of-observability-as-code","text":"Dashboards as Code - Monitoring Dashboards can be created as JSON or XML templates. This template is source control maintained and any changes to the dashboards can be reviewed. Automation can be built for enabling the dashboard. More about how to do this in Azure . Grafana dashboard can also be configured as code which eventually can be source-controlled to be used in automation and pipelines. Alerts as Code - Alerts can be created within Azure by using Terraform or ARM templates. Such alerts can be source-controlled and be deployed as part of pipelines (Azure DevOps pipelines, Jenkins, GitHub Actions etc.). Few references of how to do this are: Terraform Monitor Metric Alert . Alerts can also be created based on log analytics query and can be defined as code using Terraform Monitor Scheduled Query Rules Alert . Automating Log Analytics Queries - There are several use cases where automation of log analytics queries may be needed. Example, Automatic Report Generation, Running custom queries programmatically for analysis, debugging etc. For these use cases to work, log queries should be source-controlled and automation can be built using log analytics REST or azure cli .","title":"Examples of Observability as Code"},{"location":"observability/observability-as-code/#why","text":"It makes configuration repeatable and automatable. It also avoids manual configuration of monitoring alerts and dashboards from scratch across environments. Configured dashboards help troubleshoot errors during integration and deployment (CI/CD) We can audit changes and roll them back if there are any issues. Identify actionable insights from the generated metrics data across all environments, not just production. Configuration and management of observability assets like alert threshold, duration, configuration values using IAC help us in avoiding configuration mistakes, errors or overlooks during deployment. When practicing observability as code, the changes can be reviewed by the team similar to other code contributions.","title":"Why"},{"location":"observability/observability-databricks/","text":"Observability for Azure Databricks Overview Azure Databricks is an Apache Spark\u2013based analytics service that makes it easy to rapidly develop and deploy big data analytics. Monitoring and troubleshooting performance issues is critical when operating production Azure Databricks workloads. It is important to log adequate information from Azure Databricks so that it is helpful to monitor and troubleshoot performance issues. Spark is designed to run on a cluster - a cluster is a set of Virtual Machines (VMs). Spark can horizontally scale with bigger workloads needed more VMs. Azure Databricks can scale in and out as needed. Approaches to Observability Azure Diagnostic Logs Azure Diagnostic Logging is provided out-of-the-box by Azure Databricks, providing visibility into actions performed against DBFS, Clusters, Accounts, Jobs, Notebooks, SSH, Workspace, Secrets, SQL Permissions, and Instance Pools. These logs are enabled using Azure Portal or CLI and can be configured to be delivered to one of these Azure resources. Log Analytics Workspace Blob Storage Event Hub Cluster Event Logs Cluster Event logs provide a quick overview into important Cluster lifecycle events. The log are structured - Timestamp, Event Type and Details. Unfortunately, there is no native way to export logs to Log Analytics. Logs will have to be delivered to Log Analytics either using REST API or polled in the dbfs using Azure Functions. VM Performance Metrics (OMS) Log Analytics Agent provides insights into the performance counters from the Cluster VMs and helps to understand the Cluster Utilization patters. Leveraging Linux OMX Agent to onboard VMs into Log Analytics, helps provide insights into the VM metrics, performance, inventory and syslog metrics. It is important to note that Linux OMS Agent is not specific to Azure Databricks. Application Logging Of all the logs collected, this is perhaps the most important one. Spark Monitoring library collects metrics about the driver, executors, JVM, HDFS, cache shuffling, DAGs, and much more. This library provides helpful insights to fine-tune Spark jobs. It allows monitoring and tracing each layer within Spark workloads, including performance and resource usage on the host and JVM, as well as Spark metrics and application-level logging. The library also includes ready-made Grafana dashboards that is a great starting point for building Azure Databricks dashboard. Logs via REST API Azure Databricks also provides REST API support. If there's any specific log data that is required, this data can be collected using the REST API calls. NSG Flow Logs Network security group (NSG) flow logs is a feature of Azure Network Watcher that allows you to log information about IP traffic flowing through an NSG. Flow data is sent to Azure Storage accounts from where you can access it as well as export it to any visualization tool, SIEM, or IDS of your choice. This log information is not specific to NSG Flow logs. This data can be used to identify unknown or undesired traffic and monitor traffic levels and/or bandwidth consumption. This is possible only with VNET-injected workspaces. Platform Logs Platform logs can be used to review provisioning/de-provisioning operations. This can be used to review activity in Databricks managed resource group. It helps discover operations performed at subscription level (like provisioning of VM, Disk etc.) These logs can be enabled via Azure Monitor > Activity Logs and shipped to Log Analytics. Ganglia metrics Ganglia metrics is a Cluster Utilization UI and is available on the Azure Databricks. It is great for viewing live metrics of interactive clusters. Ganglia metrics is available by default and takes snapshot of usage every 15 minutes. Historical metrics are stored as .png files, making it impossible to analyze data.","title":"Observability for Azure Databricks"},{"location":"observability/observability-databricks/#observability-for-azure-databricks","text":"","title":"Observability for Azure Databricks"},{"location":"observability/observability-databricks/#overview","text":"Azure Databricks is an Apache Spark\u2013based analytics service that makes it easy to rapidly develop and deploy big data analytics. Monitoring and troubleshooting performance issues is critical when operating production Azure Databricks workloads. It is important to log adequate information from Azure Databricks so that it is helpful to monitor and troubleshoot performance issues. Spark is designed to run on a cluster - a cluster is a set of Virtual Machines (VMs). Spark can horizontally scale with bigger workloads needed more VMs. Azure Databricks can scale in and out as needed.","title":"Overview"},{"location":"observability/observability-databricks/#approaches-to-observability","text":"","title":"Approaches to Observability"},{"location":"observability/observability-databricks/#azure-diagnostic-logs","text":"Azure Diagnostic Logging is provided out-of-the-box by Azure Databricks, providing visibility into actions performed against DBFS, Clusters, Accounts, Jobs, Notebooks, SSH, Workspace, Secrets, SQL Permissions, and Instance Pools. These logs are enabled using Azure Portal or CLI and can be configured to be delivered to one of these Azure resources. Log Analytics Workspace Blob Storage Event Hub","title":"Azure Diagnostic Logs"},{"location":"observability/observability-databricks/#cluster-event-logs","text":"Cluster Event logs provide a quick overview into important Cluster lifecycle events. The log are structured - Timestamp, Event Type and Details. Unfortunately, there is no native way to export logs to Log Analytics. Logs will have to be delivered to Log Analytics either using REST API or polled in the dbfs using Azure Functions.","title":"Cluster Event Logs"},{"location":"observability/observability-databricks/#vm-performance-metrics-oms","text":"Log Analytics Agent provides insights into the performance counters from the Cluster VMs and helps to understand the Cluster Utilization patters. Leveraging Linux OMX Agent to onboard VMs into Log Analytics, helps provide insights into the VM metrics, performance, inventory and syslog metrics. It is important to note that Linux OMS Agent is not specific to Azure Databricks.","title":"VM Performance Metrics (OMS)"},{"location":"observability/observability-databricks/#application-logging","text":"Of all the logs collected, this is perhaps the most important one. Spark Monitoring library collects metrics about the driver, executors, JVM, HDFS, cache shuffling, DAGs, and much more. This library provides helpful insights to fine-tune Spark jobs. It allows monitoring and tracing each layer within Spark workloads, including performance and resource usage on the host and JVM, as well as Spark metrics and application-level logging. The library also includes ready-made Grafana dashboards that is a great starting point for building Azure Databricks dashboard.","title":"Application Logging"},{"location":"observability/observability-databricks/#logs-via-rest-api","text":"Azure Databricks also provides REST API support. If there's any specific log data that is required, this data can be collected using the REST API calls.","title":"Logs via REST API"},{"location":"observability/observability-databricks/#nsg-flow-logs","text":"Network security group (NSG) flow logs is a feature of Azure Network Watcher that allows you to log information about IP traffic flowing through an NSG. Flow data is sent to Azure Storage accounts from where you can access it as well as export it to any visualization tool, SIEM, or IDS of your choice. This log information is not specific to NSG Flow logs. This data can be used to identify unknown or undesired traffic and monitor traffic levels and/or bandwidth consumption. This is possible only with VNET-injected workspaces.","title":"NSG Flow Logs"},{"location":"observability/observability-databricks/#platform-logs","text":"Platform logs can be used to review provisioning/de-provisioning operations. This can be used to review activity in Databricks managed resource group. It helps discover operations performed at subscription level (like provisioning of VM, Disk etc.) These logs can be enabled via Azure Monitor > Activity Logs and shipped to Log Analytics.","title":"Platform Logs"},{"location":"observability/observability-databricks/#ganglia-metrics","text":"Ganglia metrics is a Cluster Utilization UI and is available on the Azure Databricks. It is great for viewing live metrics of interactive clusters. Ganglia metrics is available by default and takes snapshot of usage every 15 minutes. Historical metrics are stored as .png files, making it impossible to analyze data.","title":"Ganglia metrics"},{"location":"observability/observability-pipelines/","text":"Observability of CI/CD Pipelines With increasing complexity to delivery pipelines, it is very important to consider Observability in the context of build and release of applications. Benefits Having proper instrumentation during build time helps gain insights into the various stages of the build and release process. Helps developers understand where the pipeline performance bottlenecks are, based on the data collected. This helps in having data-driven conversations around identifying latency between jobs, performance issues, artifact upload/download times providing valuable insights into agents availability and capacity. Helps to identify trends in failures, thus allowing developers to quickly do root cause analysis. Helps to provide an organization-wide view of pipeline health to easily identify trends. Points to Consider It is important to identify the Key Performance Indicators (KPIs) for evaluating a successful CI/CD pipeline. Where needed, additional tracing can be added to better record KPI metrics. For example, adding pipeline build tags to identify a 'Release Candidate' vs. 'Non-Release Candidate' helps in evaluating the end-to-end release process timeline. Depending on the tooling used (Azure DevOps, Jenkins etc.,), basic reporting on the pipelines is available out-of-the-box. It is important to evaluate these reports against the KPIs to understand if a custom reporting solution for their pipelines is needed. If required, custom dashboards can be built using third-party tools like Grafana or Power BI Dashboards.","title":"Observability of CI/CD Pipelines"},{"location":"observability/observability-pipelines/#observability-of-cicd-pipelines","text":"With increasing complexity to delivery pipelines, it is very important to consider Observability in the context of build and release of applications.","title":"Observability of CI/CD Pipelines"},{"location":"observability/observability-pipelines/#benefits","text":"Having proper instrumentation during build time helps gain insights into the various stages of the build and release process. Helps developers understand where the pipeline performance bottlenecks are, based on the data collected. This helps in having data-driven conversations around identifying latency between jobs, performance issues, artifact upload/download times providing valuable insights into agents availability and capacity. Helps to identify trends in failures, thus allowing developers to quickly do root cause analysis. Helps to provide an organization-wide view of pipeline health to easily identify trends.","title":"Benefits"},{"location":"observability/observability-pipelines/#points-to-consider","text":"It is important to identify the Key Performance Indicators (KPIs) for evaluating a successful CI/CD pipeline. Where needed, additional tracing can be added to better record KPI metrics. For example, adding pipeline build tags to identify a 'Release Candidate' vs. 'Non-Release Candidate' helps in evaluating the end-to-end release process timeline. Depending on the tooling used (Azure DevOps, Jenkins etc.,), basic reporting on the pipelines is available out-of-the-box. It is important to evaluate these reports against the KPIs to understand if a custom reporting solution for their pipelines is needed. If required, custom dashboards can be built using third-party tools like Grafana or Power BI Dashboards.","title":"Points to Consider"},{"location":"observability/pitfalls/","text":"Things to Watch for when Building Observable Systems Observability as an afterthought One of the design goals when building a system should be to enable monitoring of the system. This helps planning and thinking application availability, logging and metrics at the time of design and development. Observability also acts as a great debugging tool providing developers a bird's eye view of the system. By leaving instrumentation and logging of metrics towards the end, the development teams lose valuable insights during development. Metric Fatigue It is recommended to collect and measure what you need and not what you can . Don't attempt to monitor everything. If the data is not actionable, it is useless and becomes noise. On the contrary, it is sometimes very difficult to forecast every possible scenario that could go wrong. There must be a balance between collecting what is needed vs. logging every single activity in the system. A general rule of thumb is to follow these principles rules that catch incidents must be simple, relevant and reliable any data that is collected but not aggregated or alerted on must be reviewed if it is still required. Context All data logged must contain rich context, which is useful for getting an overall view of the system and easy to trace back errors/failures during troubleshooting. While logging data, care must also be taken to avoid data silos. Personally Identifiable Information As a general rule, do not log any customer sensitive and Personal Identifiable Information (PII). Ensure any pertinent privacy regulations are followed regarding PII (Ex: GDPR etc.) Read more here on how to keep sensitive data out of logs.","title":"Things to Watch for when Building Observable Systems"},{"location":"observability/pitfalls/#things-to-watch-for-when-building-observable-systems","text":"","title":"Things to Watch for when Building Observable Systems"},{"location":"observability/pitfalls/#observability-as-an-afterthought","text":"One of the design goals when building a system should be to enable monitoring of the system. This helps planning and thinking application availability, logging and metrics at the time of design and development. Observability also acts as a great debugging tool providing developers a bird's eye view of the system. By leaving instrumentation and logging of metrics towards the end, the development teams lose valuable insights during development.","title":"Observability as an afterthought"},{"location":"observability/pitfalls/#metric-fatigue","text":"It is recommended to collect and measure what you need and not what you can . Don't attempt to monitor everything. If the data is not actionable, it is useless and becomes noise. On the contrary, it is sometimes very difficult to forecast every possible scenario that could go wrong. There must be a balance between collecting what is needed vs. logging every single activity in the system. A general rule of thumb is to follow these principles rules that catch incidents must be simple, relevant and reliable any data that is collected but not aggregated or alerted on must be reviewed if it is still required.","title":"Metric Fatigue"},{"location":"observability/pitfalls/#context","text":"All data logged must contain rich context, which is useful for getting an overall view of the system and easy to trace back errors/failures during troubleshooting. While logging data, care must also be taken to avoid data silos.","title":"Context"},{"location":"observability/pitfalls/#personally-identifiable-information","text":"As a general rule, do not log any customer sensitive and Personal Identifiable Information (PII). Ensure any pertinent privacy regulations are followed regarding PII (Ex: GDPR etc.) Read more here on how to keep sensitive data out of logs.","title":"Personally Identifiable Information"},{"location":"observability/profiling/","text":"Profiling Overview Profiling is a form of runtime analysis that measures various components of the runtime such as, memory allocation, garbage collection, threads and locks, call stacks, or frequency and duration of specific functions. It can be used to see which functions are the most costly in your binary, allowing you to focus your effort on removing the largest inefficiencies as quickly as possible. It can help you find deadlocks, memory leaks, or inefficient memory allocation, and help inform decisions around resource allocation (ie: CPU or RAM). How to Profile your Applications Profiling is somewhat language dependent, so start off by searching for \"profile $language\" (some common tools are listed below). Additionally, Linux Perf is a good fallback, since a lot of languages have bindings in C/C++. Profiling does incur some cost, as it requires inspecting the call stack, and sometimes pausing the application all together (ie: to trigger a full GC in Java). It is recommended to continuously profile your services, say for 10s every 10 minutes. Consider the cost when deciding on tuning these parameters. Different tools visualize profiles differently. Common CPU profiles might use a directed graph or a flame graph. Unfortunately, each profiler tool typically uses its own format for storing profiles, and comes with its own visualization. Specific tools (Java, Go, Python, Ruby, eBPF) Pyroscope continuous profiling out of the box. (Java and Go) Flame - profiling containers in Kubernetes (Java, Python, Go) Datadog Continuous profiler (Go) profefe , which builds pprof to provide continuous profiling (Java) Eclipse Memory Analyzer","title":"Profiling"},{"location":"observability/profiling/#profiling","text":"","title":"Profiling"},{"location":"observability/profiling/#overview","text":"Profiling is a form of runtime analysis that measures various components of the runtime such as, memory allocation, garbage collection, threads and locks, call stacks, or frequency and duration of specific functions. It can be used to see which functions are the most costly in your binary, allowing you to focus your effort on removing the largest inefficiencies as quickly as possible. It can help you find deadlocks, memory leaks, or inefficient memory allocation, and help inform decisions around resource allocation (ie: CPU or RAM).","title":"Overview"},{"location":"observability/profiling/#how-to-profile-your-applications","text":"Profiling is somewhat language dependent, so start off by searching for \"profile $language\" (some common tools are listed below). Additionally, Linux Perf is a good fallback, since a lot of languages have bindings in C/C++. Profiling does incur some cost, as it requires inspecting the call stack, and sometimes pausing the application all together (ie: to trigger a full GC in Java). It is recommended to continuously profile your services, say for 10s every 10 minutes. Consider the cost when deciding on tuning these parameters. Different tools visualize profiles differently. Common CPU profiles might use a directed graph or a flame graph. Unfortunately, each profiler tool typically uses its own format for storing profiles, and comes with its own visualization.","title":"How to Profile your Applications"},{"location":"observability/profiling/#specific-tools","text":"(Java, Go, Python, Ruby, eBPF) Pyroscope continuous profiling out of the box. (Java and Go) Flame - profiling containers in Kubernetes (Java, Python, Go) Datadog Continuous profiler (Go) profefe , which builds pprof to provide continuous profiling (Java) Eclipse Memory Analyzer","title":"Specific tools"},{"location":"observability/recipes-observability/","text":"Recipes Application Insights/ASP.NET GitHub Repo , Article . Application Insights/ASP.NET Core with distributed Trace Context propagation to Kafka GitHub Repo . Example: OpenTelemetry over a message oriented architecture in Java with Jaeger, Prometheus and Azure Monitor GitHub Repo Example: Setup Azure Monitor dashboards and alerts with Terraform GitHub Repo On-premises Application Insights On-premise Application Insights is a service that is compatible with Azure App Insights, but stores the data in an in-house database like PostgreSQL or object storage like Azurite . On-premises Application Insights is useful as a drop-in replacement for Azure Application Insights in scenarios where a solution must be cloud deployable but must also support on-premises disconnected deployment scenarios. On-premises Application Insights is also useful for testing telemetry integration. Issues related to telemetry can be hard to catch since often these integrations are excluded from unit-test or integration test flows due to it being non-trivial to use a live Azure Application Insights resource for testing, e.g. managing the lifetime of the resource, having to ignore old telemetry for assertions, if a new resource is used it can take a while for the telemetry to show up, etc. The On-premise Application Insights service can be used to make it easier to integrate with an Azure Application Insights compatible API endpoint during local development or continuous integration without having to spin up a resource in Azure. Additionally, the service simplifies integration testing of asynchronous workflows such as web workers since integration tests can now be written to assert against telemetry logged to the service, e.g. assert that no exceptions were logged, assert that some number of events of a specific type were logged within a certain time-frame, etc. Azure DevOps Pipelines Reporting with Power BI The Azure DevOps Pipelines Report contains a Power BI template for monitoring project, pipeline, and pipeline run data from an Azure DevOps (AzDO) organization. This dashboard recipe provides observability for AzDO pipelines by displaying various metrics (i.e. average runtime, run outcome statistics, etc.) in a table. Additionally, the second page of the template visualizes pipeline success and failure trends using Power BI charts. Documentation and setup information can be found in the project README. Python Logger class for Application Insights using OpenCensus This repository contains \"AppLogger\" class which is a python logger class for Application Insights using Opencensus. It also contains sample code that shows the usage of \"AppLogger\". GitHub Repo Java OpenTelemetry Examples This GitHub Repo contains a set of fully-functional, working examples of using the OpenTelemetry Java APIs and SDK.","title":"Recipes"},{"location":"observability/recipes-observability/#recipes","text":"","title":"Recipes"},{"location":"observability/recipes-observability/#application-insightsaspnet","text":"GitHub Repo , Article .","title":"Application Insights/ASP.NET"},{"location":"observability/recipes-observability/#application-insightsaspnet-core-with-distributed-trace-context-propagation-to-kafka","text":"GitHub Repo .","title":"Application Insights/ASP.NET Core with distributed Trace Context propagation to Kafka"},{"location":"observability/recipes-observability/#example-opentelemetry-over-a-message-oriented-architecture-in-java-with-jaeger-prometheus-and-azure-monitor","text":"GitHub Repo","title":"Example: OpenTelemetry over a message oriented architecture in Java with Jaeger, Prometheus and Azure Monitor"},{"location":"observability/recipes-observability/#example-setup-azure-monitor-dashboards-and-alerts-with-terraform","text":"GitHub Repo","title":"Example: Setup Azure Monitor dashboards and alerts with Terraform"},{"location":"observability/recipes-observability/#on-premises-application-insights","text":"On-premise Application Insights is a service that is compatible with Azure App Insights, but stores the data in an in-house database like PostgreSQL or object storage like Azurite . On-premises Application Insights is useful as a drop-in replacement for Azure Application Insights in scenarios where a solution must be cloud deployable but must also support on-premises disconnected deployment scenarios. On-premises Application Insights is also useful for testing telemetry integration. Issues related to telemetry can be hard to catch since often these integrations are excluded from unit-test or integration test flows due to it being non-trivial to use a live Azure Application Insights resource for testing, e.g. managing the lifetime of the resource, having to ignore old telemetry for assertions, if a new resource is used it can take a while for the telemetry to show up, etc. The On-premise Application Insights service can be used to make it easier to integrate with an Azure Application Insights compatible API endpoint during local development or continuous integration without having to spin up a resource in Azure. Additionally, the service simplifies integration testing of asynchronous workflows such as web workers since integration tests can now be written to assert against telemetry logged to the service, e.g. assert that no exceptions were logged, assert that some number of events of a specific type were logged within a certain time-frame, etc.","title":"On-premises Application Insights"},{"location":"observability/recipes-observability/#azure-devops-pipelines-reporting-with-power-bi","text":"The Azure DevOps Pipelines Report contains a Power BI template for monitoring project, pipeline, and pipeline run data from an Azure DevOps (AzDO) organization. This dashboard recipe provides observability for AzDO pipelines by displaying various metrics (i.e. average runtime, run outcome statistics, etc.) in a table. Additionally, the second page of the template visualizes pipeline success and failure trends using Power BI charts. Documentation and setup information can be found in the project README.","title":"Azure DevOps Pipelines Reporting with Power BI"},{"location":"observability/recipes-observability/#python-logger-class-for-application-insights-using-opencensus","text":"This repository contains \"AppLogger\" class which is a python logger class for Application Insights using Opencensus. It also contains sample code that shows the usage of \"AppLogger\". GitHub Repo","title":"Python Logger class for Application Insights using OpenCensus"},{"location":"observability/recipes-observability/#java-opentelemetry-examples","text":"This GitHub Repo contains a set of fully-functional, working examples of using the OpenTelemetry Java APIs and SDK.","title":"Java OpenTelemetry Examples"},{"location":"observability/pillars/dashboard/","text":"Dashboard Overview Dashboard is a form of data visualization that provides \"at a glance\" view of Key Performance Indicators(KPIs) of observable system. Dashboard connects multiple data sources allowing creation of visual representation of data insights which otherwise are difficult to understand. Dashboard can be used to: show trends identify patterns(user, usage, search etc) measure efficiency easily identify data outliers and correlations view health state or performance of the system give an outlook of the KPI that is important to a business/process Best Practices Common questions to ask yourself when building dashboard would be: Where did my user spend most of their time at? What is my user searching? How do I better help my team with alerts and troubleshooting? Is my system healthy for the past one day/week/month/quarter? Here are principles to consider when building dashboards: Separate a dashboard in multiple sections for simplicity. Adding page jump or anchor(#section) is also a plus if applicable. Add multiple and simple charts. Build simple chart, have more of them rather than a complicated all in one chart. Identify goals or KPI measurement. Identifying goals or KPI helps in defining what needs to be achieved. Here are some examples - server downtime, mean time to address error, service level agreement. Ask questions that can help reach the defined goal or KPI. This may sound counter-intuitive, the more questions asked while constructing dashboard the better the outcome will be. Questions like location, internet service provider, time of day the users make requests to server would be a good start. Validate the questions. This is often done with stakeholders, sponsors, leads or project managers. Observe the dashboard that is built. Is the data reflecting what the stakeholders set out to answer? Always remember this process takes time. Building dashboard is easy, building an observable dashboard to show pattern is hard. Recommended Tools Azure Monitor Workbooks - Supporting markdown, Azure Workbooks is tightly integrated with Azure services making this highly customizable without extra tool. Create dashboard using log query - Dashboard can be created using log query on Log Analytics data. Building dashboards using Application Insights - Dashboards can be created using Application Insights as well. Power Bi - Power Bi is one of the easier tools to create dashboards from data sources and reports. Grafana - Getting started with Grafana. Grafana is a popular open source tool for dashboarding and visualization. Azure Monitor as Grafana data source - This provides a step by step integration of Azure Monitor to Grafana. Brief comparison of various tools Dashboard Samples and Recipes Azure Workbooks Performance analysis - A measurement on how the system performs. Workbook template available in gallery. Failure analysis - A report about system failure with details. Workbook template available in gallery. Application Performance Index( Apdex ) - This is a way to measure user satisfaction. It classifies performance into three zones based on a baseline performance threshold T. The template for Appdex is available in Azure Workbooks gallery as well. Application Insights User retention analysis User navigation patterns analysis User session analysis For other tools, these can be used as a reference to recreate if a template is not readily available. Grafana with Azure Monitor as Data Source Azure Kubernetes Service - Cluster & Namespace Metrics - Container Insights metrics for Kubernetes clusters. Cluster utilization, namespace utilization, Node cpu & memory, Node disk usage & disk io, node network & kubelet docker operation metrics Azure Kubernetes Service - Container Level & Pod Metrics - This contains Container level and Pod Metrics like CPU and Memory which are missing in the above dashboard. Summary In order to build an observable dashboard, the goal is to make use of collected metrics, logs, traces to give an insight on how the system performs, user behaves and identify patterns. There are a lot of tools and templates out there. Whichever the choice is, a good dashboard is always a dashboard that can help you answer questions about the system and user, keep track of the KPI and goal while also allowing informed business decisions to be made.","title":"Dashboard"},{"location":"observability/pillars/dashboard/#dashboard","text":"","title":"Dashboard"},{"location":"observability/pillars/dashboard/#overview","text":"Dashboard is a form of data visualization that provides \"at a glance\" view of Key Performance Indicators(KPIs) of observable system. Dashboard connects multiple data sources allowing creation of visual representation of data insights which otherwise are difficult to understand. Dashboard can be used to: show trends identify patterns(user, usage, search etc) measure efficiency easily identify data outliers and correlations view health state or performance of the system give an outlook of the KPI that is important to a business/process","title":"Overview"},{"location":"observability/pillars/dashboard/#best-practices","text":"Common questions to ask yourself when building dashboard would be: Where did my user spend most of their time at? What is my user searching? How do I better help my team with alerts and troubleshooting? Is my system healthy for the past one day/week/month/quarter? Here are principles to consider when building dashboards: Separate a dashboard in multiple sections for simplicity. Adding page jump or anchor(#section) is also a plus if applicable. Add multiple and simple charts. Build simple chart, have more of them rather than a complicated all in one chart. Identify goals or KPI measurement. Identifying goals or KPI helps in defining what needs to be achieved. Here are some examples - server downtime, mean time to address error, service level agreement. Ask questions that can help reach the defined goal or KPI. This may sound counter-intuitive, the more questions asked while constructing dashboard the better the outcome will be. Questions like location, internet service provider, time of day the users make requests to server would be a good start. Validate the questions. This is often done with stakeholders, sponsors, leads or project managers. Observe the dashboard that is built. Is the data reflecting what the stakeholders set out to answer? Always remember this process takes time. Building dashboard is easy, building an observable dashboard to show pattern is hard.","title":"Best Practices"},{"location":"observability/pillars/dashboard/#recommended-tools","text":"Azure Monitor Workbooks - Supporting markdown, Azure Workbooks is tightly integrated with Azure services making this highly customizable without extra tool. Create dashboard using log query - Dashboard can be created using log query on Log Analytics data. Building dashboards using Application Insights - Dashboards can be created using Application Insights as well. Power Bi - Power Bi is one of the easier tools to create dashboards from data sources and reports. Grafana - Getting started with Grafana. Grafana is a popular open source tool for dashboarding and visualization. Azure Monitor as Grafana data source - This provides a step by step integration of Azure Monitor to Grafana. Brief comparison of various tools","title":"Recommended Tools"},{"location":"observability/pillars/dashboard/#dashboard-samples-and-recipes","text":"","title":"Dashboard Samples and Recipes"},{"location":"observability/pillars/dashboard/#azure-workbooks","text":"Performance analysis - A measurement on how the system performs. Workbook template available in gallery. Failure analysis - A report about system failure with details. Workbook template available in gallery. Application Performance Index( Apdex ) - This is a way to measure user satisfaction. It classifies performance into three zones based on a baseline performance threshold T. The template for Appdex is available in Azure Workbooks gallery as well.","title":"Azure Workbooks"},{"location":"observability/pillars/dashboard/#application-insights","text":"User retention analysis User navigation patterns analysis User session analysis For other tools, these can be used as a reference to recreate if a template is not readily available.","title":"Application Insights"},{"location":"observability/pillars/dashboard/#grafana-with-azure-monitor-as-data-source","text":"Azure Kubernetes Service - Cluster & Namespace Metrics - Container Insights metrics for Kubernetes clusters. Cluster utilization, namespace utilization, Node cpu & memory, Node disk usage & disk io, node network & kubelet docker operation metrics Azure Kubernetes Service - Container Level & Pod Metrics - This contains Container level and Pod Metrics like CPU and Memory which are missing in the above dashboard.","title":"Grafana with Azure Monitor as Data Source"},{"location":"observability/pillars/dashboard/#summary","text":"In order to build an observable dashboard, the goal is to make use of collected metrics, logs, traces to give an insight on how the system performs, user behaves and identify patterns. There are a lot of tools and templates out there. Whichever the choice is, a good dashboard is always a dashboard that can help you answer questions about the system and user, keep track of the KPI and goal while also allowing informed business decisions to be made.","title":"Summary"},{"location":"observability/pillars/logging/","text":"Logging Overview Logs are discrete events with the goal of helping engineers identify problem area(s) during failures. Collection Methods When it comes to log collection methods, two of the standard techniques are a direct-write, or an agent-based approach. Directly written log events are handled in-process of the particular component, usually utilizing a provided library. Azure Monitor has direct send capabilities, but it's not recommended for serious/production use. This approach has some advantages: There is no external process to configure or monitor No log file management (rolling, expiring) to prevent out of disk space issues. The potential trade-offs of this approach: Potentially higher memory usage if the particular library is using a memory backed buffer. In the event of an extended service outage, log data may get dropped or truncated due to buffer constraints. Multiple component process logging will manage & emit logs individually, which can be more complex to manage for the outbound load. Agent-based log collection relies on an external process running on the host machine, with the particular component emitting log data stdout or file. Writing log data to stdout is the preferred practice when running applications within a container environment like Kubernetes. The container runtime redirects the output to files, which can then be processed by an agent. Azure Monitor , Grafana Loki Elastic's Logstash and Fluent Bit are examples of log shipping agents. There are several advantages when using an agent to collect & ship log files: Centralized configuration. Collecting multiple sources of data with a single process. Local pre-processing & filtering of log data before sending it to a central service. Utilizing disk space as a data buffer during a service disruption. This approach isn't without trade-offs: Required exclusive CPU & memory resources for the processing of log data. Persistent disk space for buffering. Best Practices Pay attention to logging levels. Logging too much will increase costs and decrease application throughput. Ensure logging configuration can be modified without code changes. Ideally, make it changeable without application restarts. If available, take advantage of logging levels per category allowing granular logging configuration. Check for log levels before logging, thus avoiding allocations and string manipulation costs. Ensure service versions are included in logs to be able to identify problematic releases. Log a raised exception only once. In your handlers, only catch expected exceptions that you can handle gracefully (even with a specific return code). If you want to log and rethrow, leave it to the top level exception handler. Do the minimal amount of cleanup work needed then throw to maintain the original stack trace. Don\u2019t log a warning or stack trace for expected exceptions (eg: properly expected 404, 403 HTTP statuses). Fine tune logging levels in production (>= warning for instance). During a new release the verbosity can be increased to facilitate bug identification. If using sampling, implement this at the service level rather than defining it in the logging system. This way we have control over what gets logged. An additional benefit is reduced number of roundtrips. Only include failures from health checks and non-business driven requests. Ensure a downstream system malfunction won't cause repetitive logs being stored. Don't reinvent the wheel, use existing tools to collect and analyze the data. Ensure personal identifiable information policies and restrictions are followed. Ensure errors and exceptions in dependent services are captured and logged. For example, if an application uses Redis cache, Service Bus or any other service, any errors/exceptions raised while accessing these services should be captured and logged. If there's sufficient log data, is there a need for instrumenting metrics? Logs vs Metrics vs Traces covers some high level guidance on when to utilize metric data and when to use log data. Both have a valuable part to play in creating observable systems. Having problems identifying what to log? At application startup : Unrecoverable errors from startup. Warnings if application still runnable, but not as expected (i.e. not providing blob connection string, thus resorting to local files. Another example is if there's a need to fail back to a secondary service or a known good state, because it didn\u2019t get an answer from a primary dependency.) Information about the service\u2019s state at startup (build #, configs loaded, etc.) Per incoming request : Basic information for each incoming request: the url (scrubbed of any personally identifying data, a.k.a. PII), any user/tenant/request dimensions, response code returned, request-to-response latency, payload size, record counts, etc. (whatever you need to learn something from the aggregate data) Warning for any unexpected exceptions, caught only at the top controller/interceptor and logged with or alongside the request info, with stack trace. Return a 500. This code doesn\u2019t know what happened. Per outgoing request : Basic information for each outgoing request: the url (scrubbed of any personally identifying data, a.k.a. PII), any user/tenant/request dimensions, response code returned, request-to-response latency, payload sizes, record counts returned, etc. Report perceived availability and latency of dependencies and including slicing/clustering data that could help with later analysis. Recommended Tools Azure Monitor - Umbrella of services including system metrics, log analytics and more. Grafana Loki - An open source log aggregation platform, built on the learnings from the Prometheus Community for highly efficient collection & storage of log data at scale. The Elastic Stack - An open source log analytics tech stack utilizing Logstash, Beats, Elastic search and Kibana. Grafana - Open source dashboard & visualization tool. Supports Log, Metrics and Distributed tracing data sources.","title":"Logging"},{"location":"observability/pillars/logging/#logging","text":"","title":"Logging"},{"location":"observability/pillars/logging/#overview","text":"Logs are discrete events with the goal of helping engineers identify problem area(s) during failures.","title":"Overview"},{"location":"observability/pillars/logging/#collection-methods","text":"When it comes to log collection methods, two of the standard techniques are a direct-write, or an agent-based approach. Directly written log events are handled in-process of the particular component, usually utilizing a provided library. Azure Monitor has direct send capabilities, but it's not recommended for serious/production use. This approach has some advantages: There is no external process to configure or monitor No log file management (rolling, expiring) to prevent out of disk space issues. The potential trade-offs of this approach: Potentially higher memory usage if the particular library is using a memory backed buffer. In the event of an extended service outage, log data may get dropped or truncated due to buffer constraints. Multiple component process logging will manage & emit logs individually, which can be more complex to manage for the outbound load. Agent-based log collection relies on an external process running on the host machine, with the particular component emitting log data stdout or file. Writing log data to stdout is the preferred practice when running applications within a container environment like Kubernetes. The container runtime redirects the output to files, which can then be processed by an agent. Azure Monitor , Grafana Loki Elastic's Logstash and Fluent Bit are examples of log shipping agents. There are several advantages when using an agent to collect & ship log files: Centralized configuration. Collecting multiple sources of data with a single process. Local pre-processing & filtering of log data before sending it to a central service. Utilizing disk space as a data buffer during a service disruption. This approach isn't without trade-offs: Required exclusive CPU & memory resources for the processing of log data. Persistent disk space for buffering.","title":"Collection Methods"},{"location":"observability/pillars/logging/#best-practices","text":"Pay attention to logging levels. Logging too much will increase costs and decrease application throughput. Ensure logging configuration can be modified without code changes. Ideally, make it changeable without application restarts. If available, take advantage of logging levels per category allowing granular logging configuration. Check for log levels before logging, thus avoiding allocations and string manipulation costs. Ensure service versions are included in logs to be able to identify problematic releases. Log a raised exception only once. In your handlers, only catch expected exceptions that you can handle gracefully (even with a specific return code). If you want to log and rethrow, leave it to the top level exception handler. Do the minimal amount of cleanup work needed then throw to maintain the original stack trace. Don\u2019t log a warning or stack trace for expected exceptions (eg: properly expected 404, 403 HTTP statuses). Fine tune logging levels in production (>= warning for instance). During a new release the verbosity can be increased to facilitate bug identification. If using sampling, implement this at the service level rather than defining it in the logging system. This way we have control over what gets logged. An additional benefit is reduced number of roundtrips. Only include failures from health checks and non-business driven requests. Ensure a downstream system malfunction won't cause repetitive logs being stored. Don't reinvent the wheel, use existing tools to collect and analyze the data. Ensure personal identifiable information policies and restrictions are followed. Ensure errors and exceptions in dependent services are captured and logged. For example, if an application uses Redis cache, Service Bus or any other service, any errors/exceptions raised while accessing these services should be captured and logged.","title":"Best Practices"},{"location":"observability/pillars/logging/#if-theres-sufficient-log-data-is-there-a-need-for-instrumenting-metrics","text":"Logs vs Metrics vs Traces covers some high level guidance on when to utilize metric data and when to use log data. Both have a valuable part to play in creating observable systems.","title":"If there's sufficient log data, is there a need for instrumenting metrics?"},{"location":"observability/pillars/logging/#having-problems-identifying-what-to-log","text":"At application startup : Unrecoverable errors from startup. Warnings if application still runnable, but not as expected (i.e. not providing blob connection string, thus resorting to local files. Another example is if there's a need to fail back to a secondary service or a known good state, because it didn\u2019t get an answer from a primary dependency.) Information about the service\u2019s state at startup (build #, configs loaded, etc.) Per incoming request : Basic information for each incoming request: the url (scrubbed of any personally identifying data, a.k.a. PII), any user/tenant/request dimensions, response code returned, request-to-response latency, payload size, record counts, etc. (whatever you need to learn something from the aggregate data) Warning for any unexpected exceptions, caught only at the top controller/interceptor and logged with or alongside the request info, with stack trace. Return a 500. This code doesn\u2019t know what happened. Per outgoing request : Basic information for each outgoing request: the url (scrubbed of any personally identifying data, a.k.a. PII), any user/tenant/request dimensions, response code returned, request-to-response latency, payload sizes, record counts returned, etc. Report perceived availability and latency of dependencies and including slicing/clustering data that could help with later analysis.","title":"Having problems identifying what to log?"},{"location":"observability/pillars/logging/#recommended-tools","text":"Azure Monitor - Umbrella of services including system metrics, log analytics and more. Grafana Loki - An open source log aggregation platform, built on the learnings from the Prometheus Community for highly efficient collection & storage of log data at scale. The Elastic Stack - An open source log analytics tech stack utilizing Logstash, Beats, Elastic search and Kibana. Grafana - Open source dashboard & visualization tool. Supports Log, Metrics and Distributed tracing data sources.","title":"Recommended Tools"},{"location":"observability/pillars/metrics/","text":"Metrics Overview Metrics provide a near real-time stream of data, informing operators and stakeholders about the functions the system is performing as well as its health. Unlike logging and tracing, metric data tends to be more efficient to transmit and store. Collection Methods Metric collection approaches fall into two broad categories: push metrics & pull metrics. Push metrics means that the originating component sends the data to a remote service or agent. Azure Monitor and Etsy's statsd are examples of push metrics. Some strengths with push metrics include: Only require network egress to the remote target. Originating component controls the frequency of measurement. Simplified configuration as the component only needs to know the destination of where to send data. Some trade-offs with this approach: At scale, it is much more difficult to control data transmission rates, which can cause service throttling or dropping of values. Determining if every component, particularly in a dynamic scale environment, is healthy and sending data is difficult. In the case of pull metrics, each originating component publishes an endpoint for the metric agent to connect to and gather measurements. Prometheus and its ecosystem of tools are an example of pull style metrics. Benefits experienced using a pull metrics setup may involve: Singular configuration for determining what is measured and the frequency of measurement for the local environment. Every measurement target has a meta metric related to if the collection is successful or not, which can be used as a general health check. Support for routing, filtering and processing of metrics before sending them onto a globally central metrics store. Items of concern to some may include: Configuring & managing data sources can lead to a complex configuration. Prometheus has tooling to auto-discover and configure data sources in some environments, such as Kubernetes, but there are always exceptions to this, which lead to configuration complexity. Network configuration may add further complexity if firewalls and other ACLs need to be managed to allow connectivity. Best Practices When should I use metrics instead of logs? Logs vs Metrics vs Traces covers some high level guidance on when to utilize metric data and when to use log data. Both have a valuable part to play in creating observable systems. What should be tracked? System critical measurements that relate to the application/machine health, which are usually excellent alert candidates. Work with your engineering and devops peers to identify the metrics, but they may include: CPU and memory utilization. Request rate. Queue length. Unexpected exception count. Dependent service metrics like response time for Redis cache, Sql server or Service bus. Important business-related measurements, which drive reporting to stakeholders. Consult with the various stakeholders of the component, but some examples may include: Jobs performed. User Session length. Games played. Site visits. Dimension Labels Modern metric systems today usually define a single time series metric as the combination of the name of the metric and its dictionary of dimension labels. Labels are an excellent way to distinguish one instance of a metric, from another while still allowing for aggregation and other operations to be performed on the set for analysis. Some common labels used in metrics may include: Container Name Host name Code Version Kubernetes cluster name Azure Region Note : Since dimension labels are used for aggregations and grouping operations, do not use unique strings or those with high cardinality as the value of a label. The value of the label is significantly diminished for reporting and in many cases has a negative performance hit on the metric system used to track it. Recommended Tools Azure Monitor - Umbrella of services including system metrics, log analytics and more. Prometheus - A real-time monitoring & alerting application. It's exposition format for exposing time-series is the basis for OpenMetrics's standard format. Thanos - Open source, highly available Prometheus setup with long term storage capabilities. Cortex - Horizontally scalable, highly available, multi-tenant, long term Prometheus. Grafana - Open source dashboard & visualization tool. Supports Log, Metrics and Distributed tracing data sources.","title":"Metrics"},{"location":"observability/pillars/metrics/#metrics","text":"","title":"Metrics"},{"location":"observability/pillars/metrics/#overview","text":"Metrics provide a near real-time stream of data, informing operators and stakeholders about the functions the system is performing as well as its health. Unlike logging and tracing, metric data tends to be more efficient to transmit and store.","title":"Overview"},{"location":"observability/pillars/metrics/#collection-methods","text":"Metric collection approaches fall into two broad categories: push metrics & pull metrics. Push metrics means that the originating component sends the data to a remote service or agent. Azure Monitor and Etsy's statsd are examples of push metrics. Some strengths with push metrics include: Only require network egress to the remote target. Originating component controls the frequency of measurement. Simplified configuration as the component only needs to know the destination of where to send data. Some trade-offs with this approach: At scale, it is much more difficult to control data transmission rates, which can cause service throttling or dropping of values. Determining if every component, particularly in a dynamic scale environment, is healthy and sending data is difficult. In the case of pull metrics, each originating component publishes an endpoint for the metric agent to connect to and gather measurements. Prometheus and its ecosystem of tools are an example of pull style metrics. Benefits experienced using a pull metrics setup may involve: Singular configuration for determining what is measured and the frequency of measurement for the local environment. Every measurement target has a meta metric related to if the collection is successful or not, which can be used as a general health check. Support for routing, filtering and processing of metrics before sending them onto a globally central metrics store. Items of concern to some may include: Configuring & managing data sources can lead to a complex configuration. Prometheus has tooling to auto-discover and configure data sources in some environments, such as Kubernetes, but there are always exceptions to this, which lead to configuration complexity. Network configuration may add further complexity if firewalls and other ACLs need to be managed to allow connectivity.","title":"Collection Methods"},{"location":"observability/pillars/metrics/#best-practices","text":"","title":"Best Practices"},{"location":"observability/pillars/metrics/#when-should-i-use-metrics-instead-of-logs","text":"Logs vs Metrics vs Traces covers some high level guidance on when to utilize metric data and when to use log data. Both have a valuable part to play in creating observable systems.","title":"When should I use metrics instead of logs?"},{"location":"observability/pillars/metrics/#what-should-be-tracked","text":"System critical measurements that relate to the application/machine health, which are usually excellent alert candidates. Work with your engineering and devops peers to identify the metrics, but they may include: CPU and memory utilization. Request rate. Queue length. Unexpected exception count. Dependent service metrics like response time for Redis cache, Sql server or Service bus. Important business-related measurements, which drive reporting to stakeholders. Consult with the various stakeholders of the component, but some examples may include: Jobs performed. User Session length. Games played. Site visits.","title":"What should be tracked?"},{"location":"observability/pillars/metrics/#dimension-labels","text":"Modern metric systems today usually define a single time series metric as the combination of the name of the metric and its dictionary of dimension labels. Labels are an excellent way to distinguish one instance of a metric, from another while still allowing for aggregation and other operations to be performed on the set for analysis. Some common labels used in metrics may include: Container Name Host name Code Version Kubernetes cluster name Azure Region Note : Since dimension labels are used for aggregations and grouping operations, do not use unique strings or those with high cardinality as the value of a label. The value of the label is significantly diminished for reporting and in many cases has a negative performance hit on the metric system used to track it.","title":"Dimension Labels"},{"location":"observability/pillars/metrics/#recommended-tools","text":"Azure Monitor - Umbrella of services including system metrics, log analytics and more. Prometheus - A real-time monitoring & alerting application. It's exposition format for exposing time-series is the basis for OpenMetrics's standard format. Thanos - Open source, highly available Prometheus setup with long term storage capabilities. Cortex - Horizontally scalable, highly available, multi-tenant, long term Prometheus. Grafana - Open source dashboard & visualization tool. Supports Log, Metrics and Distributed tracing data sources.","title":"Recommended Tools"},{"location":"observability/pillars/tracing/","text":"Tracing Overview Produces the information required to observe series of correlated operations in a distributed system. Once collected they show the path, measurements and faults in an end-to-end transaction. Best Practices Ensure that at least key business transactions are traced. Include in each trace necessary information to identify software releases (i.e. service name, version). This is important to correlate deployments and system degradation. Ensure dependencies are included in trace (databases, I/O). If costs are a concern use sampling, avoiding throwing away errors, unexpected behavior and critical information. Don't reinvent the wheel, use existing tools to collect and analyze the data. Ensure personal identifiable information policies and restrictions are followed. Recommended Tools Azure Monitor - Umbrella of services including system metrics, log analytics and more. Jaeger Tracing - Open source, end-to-end distributed tracing. Grafana - Open source dashboard & visualization tool. Supports Log, Metrics and Distributed tracing data sources. Consider using OpenTelemetry as it implements open-source cross-platform context propagation for end-to-end distributed transactions over heterogeneous components out-of-the-box. It takes care of automatically creating and managing the Trace Context object among a full stack of microservices implemented across different technical stacks.","title":"Tracing"},{"location":"observability/pillars/tracing/#tracing","text":"","title":"Tracing"},{"location":"observability/pillars/tracing/#overview","text":"Produces the information required to observe series of correlated operations in a distributed system. Once collected they show the path, measurements and faults in an end-to-end transaction.","title":"Overview"},{"location":"observability/pillars/tracing/#best-practices","text":"Ensure that at least key business transactions are traced. Include in each trace necessary information to identify software releases (i.e. service name, version). This is important to correlate deployments and system degradation. Ensure dependencies are included in trace (databases, I/O). If costs are a concern use sampling, avoiding throwing away errors, unexpected behavior and critical information. Don't reinvent the wheel, use existing tools to collect and analyze the data. Ensure personal identifiable information policies and restrictions are followed.","title":"Best Practices"},{"location":"observability/pillars/tracing/#recommended-tools","text":"Azure Monitor - Umbrella of services including system metrics, log analytics and more. Jaeger Tracing - Open source, end-to-end distributed tracing. Grafana - Open source dashboard & visualization tool. Supports Log, Metrics and Distributed tracing data sources. Consider using OpenTelemetry as it implements open-source cross-platform context propagation for end-to-end distributed transactions over heterogeneous components out-of-the-box. It takes care of automatically creating and managing the Trace Context object among a full stack of microservices implemented across different technical stacks.","title":"Recommended Tools"},{"location":"observability/tools/","text":"Tools and Patterns There are a number of modern tools to make systems observable. While identifying and/or creating tools that work for your system, here are a few things to consider to help guide the choices. Must be simple to integrate and easy to use. It must be possible to aggregate and visualize data. Tools must provide real-time data. Must be able to guide users to the problem area with suitable, adequate end-to-end context. Choices Loki OpenTelemetry Kubernetes Dashboards Prometheus Service Mesh Leveraging a Service Mesh that follows the Sidecar Pattern quickly sets up a go-to set of metrics, and traces (although traces need to be propagated from incoming requests to outgoing requests manually). A sidecar works by intercepting all incoming and outgoing traffic to your image. It then adds trace headers to each request and emits a standard set of logs and metrics. These metrics are extremely powerful for observability, allowing every service, whether client-side or server-side, to leverage a unified set of metrics, including: Latency Bytes Request Rate Error Rate In a microservice architecture, pinpointing the root cause of a spike in 500's can be non-trivial, but with the added observability from a sidecar you can quickly determine which service in your service mesh resulted in the spike in errors. Service Mesh's have a large surface area for configuration, and can seem like a daunting undertaking to deploy. However, most services (including Linkerd) offer a sane set of defaults, and can be deployed via the happy path to quickly land these observability wins.","title":"Tools and Patterns"},{"location":"observability/tools/#tools-and-patterns","text":"There are a number of modern tools to make systems observable. While identifying and/or creating tools that work for your system, here are a few things to consider to help guide the choices. Must be simple to integrate and easy to use. It must be possible to aggregate and visualize data. Tools must provide real-time data. Must be able to guide users to the problem area with suitable, adequate end-to-end context.","title":"Tools and Patterns"},{"location":"observability/tools/#choices","text":"Loki OpenTelemetry Kubernetes Dashboards Prometheus","title":"Choices"},{"location":"observability/tools/#service-mesh","text":"Leveraging a Service Mesh that follows the Sidecar Pattern quickly sets up a go-to set of metrics, and traces (although traces need to be propagated from incoming requests to outgoing requests manually). A sidecar works by intercepting all incoming and outgoing traffic to your image. It then adds trace headers to each request and emits a standard set of logs and metrics. These metrics are extremely powerful for observability, allowing every service, whether client-side or server-side, to leverage a unified set of metrics, including: Latency Bytes Request Rate Error Rate In a microservice architecture, pinpointing the root cause of a spike in 500's can be non-trivial, but with the added observability from a sidecar you can quickly determine which service in your service mesh resulted in the spike in errors. Service Mesh's have a large surface area for configuration, and can seem like a daunting undertaking to deploy. However, most services (including Linkerd) offer a sane set of defaults, and can be deployed via the happy path to quickly land these observability wins.","title":"Service Mesh"},{"location":"observability/tools/KubernetesDashboards/","text":"Kubernetes UI Dashboards This document covers the options and benefits of various Kubernetes UI Dashboards which are useful tools for monitoring and debugging your application on Kubernetes Clusters. It allows the management of applications running in the cluster, debug them and manage the cluster all through these dashboards. Overview and Background There are times when not all solutions can be run locally. This limitation could be due to a cloud service which does not offer a robust or efficient way to locally debug the environment. In these cases, it is necessary to use other tools which provide the capabilities to monitor your application with Kubernetes. Advantages and Use Cases Allows the ability to view, manage and monitor the operational aspects of the Kubernetes Cluster. Benefits of using a UI dashboard includes the following: see an overview of the cluster deploy applications onto the cluster troubleshoot applications running on the cluster view, create, modify, and delete Kubernetes resources view basic resource metrics including resource usage for Kubernetes objects view and access logs live view of the pods state (e.g. started, terminating, etc) Different dashboards may provide different functionalities, and the use case to choose a particular dashboard will depend on the requirements. For example, many dashboards provide a way to only monitor your applications on Kubernetes but do not provide a way to manage them. Open Source Dashboards There are currently several UI dashboards available to monitor your applications or manage them with Kubernetes. For example: Octant Prometheus and Grafana Kube Prometheus Stack Chart : provides an easy way to operate end-to-end Kubernetes cluster monitoring with Prometheus using the Prometheus Operator. K8Dash kube-ops-view : a tool to visualize node occupancy & utilization Lens : Client side desktop tool Thanos and Cortex : Multi-cluster implementations References Alternatives to Kubernetes Dashboard Prometheus and Grafana with Kubernetes","title":"Kubernetes UI Dashboards"},{"location":"observability/tools/KubernetesDashboards/#kubernetes-ui-dashboards","text":"This document covers the options and benefits of various Kubernetes UI Dashboards which are useful tools for monitoring and debugging your application on Kubernetes Clusters. It allows the management of applications running in the cluster, debug them and manage the cluster all through these dashboards.","title":"Kubernetes UI Dashboards"},{"location":"observability/tools/KubernetesDashboards/#overview-and-background","text":"There are times when not all solutions can be run locally. This limitation could be due to a cloud service which does not offer a robust or efficient way to locally debug the environment. In these cases, it is necessary to use other tools which provide the capabilities to monitor your application with Kubernetes.","title":"Overview and Background"},{"location":"observability/tools/KubernetesDashboards/#advantages-and-use-cases","text":"Allows the ability to view, manage and monitor the operational aspects of the Kubernetes Cluster. Benefits of using a UI dashboard includes the following: see an overview of the cluster deploy applications onto the cluster troubleshoot applications running on the cluster view, create, modify, and delete Kubernetes resources view basic resource metrics including resource usage for Kubernetes objects view and access logs live view of the pods state (e.g. started, terminating, etc) Different dashboards may provide different functionalities, and the use case to choose a particular dashboard will depend on the requirements. For example, many dashboards provide a way to only monitor your applications on Kubernetes but do not provide a way to manage them.","title":"Advantages and Use Cases"},{"location":"observability/tools/KubernetesDashboards/#open-source-dashboards","text":"There are currently several UI dashboards available to monitor your applications or manage them with Kubernetes. For example: Octant Prometheus and Grafana Kube Prometheus Stack Chart : provides an easy way to operate end-to-end Kubernetes cluster monitoring with Prometheus using the Prometheus Operator. K8Dash kube-ops-view : a tool to visualize node occupancy & utilization Lens : Client side desktop tool Thanos and Cortex : Multi-cluster implementations","title":"Open Source Dashboards"},{"location":"observability/tools/KubernetesDashboards/#references","text":"Alternatives to Kubernetes Dashboard Prometheus and Grafana with Kubernetes","title":"References"},{"location":"observability/tools/OpenTelemetry/","text":"Open Telemetry Building observable systems enable one to measure how well or bad the application is behaving and WHY it is behaving either way. Adopting open-source standards related to implementing telemetry and tracing features built on top of the OpenTelemetry framework helps decouple vendor-specific implementations while maintaining an extensible, standard, and portable open-source solution. OpenTelemetry is an open-source observability standard that defines how to generate, collect and describe telemetry in distributed systems. OpenTelemetry also provides a single-point distribution of a set of APIs, SDKs, and instrumentation libraries that implements the open-source standard, which can collect, process, and orchestrate telemetry data (signals) like traces, metrics, and logs. It supports multiple popular languages (Java, .NET, Python, JavaScript, Golang, Erlang, etc.). Open telemetry follows a vendor-agnostic and standards-based approach for collecting and managing telemetry data. An important point to note is that OpenTelemetry does not have its own backend; all telemetry collected by OpenTelemetry Collector must be sent to a backend like Prometheus, Jaeger, Zipkin, Azure Monitor, etc. Open telemetry is also the 2nd most active CNCF project only after Kubernetes. The main two Problems OpenTelemetry solves are: First, vendor neutrality for tracing, monitoring, and logging APIs and second, out-of-the-box cross-platform context propagation implementation for end-to-end distributed tracing over heterogeneous components. Open Telemetry Core Concepts Open Telemetry Implementation Patterns A detailed explanation of OpenTelemetry concepts is out of the scope of this repo. There is plenty of available information about how the SDK and the automatic instrumentation are configured and how the Exporters, Tracers, Context, and Span's hierarchy work. See the Reference section for valuable OpenTelemetry resources. However, understanding the core implementation patterns will help you know what approach better fits the scenario you are trying to solve. These are three main patterns as follows: Automatic telemetry: Support for automatic instrumentation is available for some languages. OpenTelemetry automatic instrumentation (100% codeless) is typically done through library hooks or monkey-patching library code. Automatic instrumentation will intercept all interactions and dependencies and automatically send the telemetry to the configured exporters. More information about this concept can be found in the OpenTelemetry instrumentation doc . Manual tracing: This must be done by coding using the OpenTelemetry SDK, managing the tracer objects to obtain Spans, and forming instrumented OpenTelemetry Scopes to identify the code segments to be manually traced. Also, by using the @WithSpan annotations (method decorations in C# and Java ) to mark whole methods that will be automatically traced. Hybrid approach: Most Production-ready scenarios will require a mix of both techniques, using the automatic instrumentation to collect automatic telemetry and the OpenTelemetry SDK to identify code segments that are important to instrument manually. When considering production-ready scenarios, the hybrid approach is the way to go as it allows for a throughout cover over the whole solution. It provides automatic context propagation and events correlation out of the box. Collector The collector is a separate process that is designed to be a \u2018sink\u2019 for telemetry data emitted by many processes, which can then export that data to backend systems. The collector has two different deployment strategies \u2013 either running as an agent alongside a service or as a gateway which is a remote application. In general, using both is recommended: the agent would be deployed with your service and run as a separate process or in a sidecar; meanwhile, the collector would be deployed separately, as its own application running in a container or virtual machine. Each agent would forward telemetry data to the collector, which could then export it to a variety of backend systems such as Lightstep, Jaeger, or Prometheus. The agent can be also replaced with the automatic instrumentation if supported. The automatic instrumentation provides the collector capabilities of retrieving, processing and exporting the telemetry. Regardless of how you choose to instrument or deploy OpenTelemetry, exporters provide powerful options for reporting telemetry data. You can directly export from your service, you can proxy through the collector, or you can aggregate into standalone collectors \u2013 or even a mix of these. Instrumentation Libraries A library that enables observability for another library is called an instrumentation library. OpenTelemetry libraries are language specific, currently there is good support for Java, Python, Javascript, dotnet and golang. Support for automatic instrumentation is available for some libraries which make using OpenTelemetry easy and trivial. In case automatic instrumentation is not available, manual instrumentation can be configured by using the OpenTelemetry SDK. Integration of OpenTelemetry OpenTelemetry can be used to collect, process and export data into multiple backends, some popular integrations supported with OpenTelemetry are: Zipkin Prometheus Jaeger New Relic Azure Monitor AWS X-Ray Datadog Kafka Lightstep Splunk GCP Monitor Why use OpenTelemetry The main reason to use OpenTelemetry is that it offers an open-source standard for implementing distributed telemetry (context propagation) over heterogeneous systems. There is no need to reinvent the wheel to implement end-to-end business flow transactions monitoring when using OpenTelemetry. It enables tracing, metrics, and logging telemetry through a set of single-distribution multi-language libraries and tools that allow for a plug-and-play telemetry architecture that includes the concept of agents and collectors. Moreover, avoiding any proprietary lock down and achieving vendor-agnostic neutrality for tracing, monitoring, and logging APIs AND backends allow maximum portability and extensibility patterns. Another good reason to use OpenTelemetry would be whether the stack uses OpenCensus or OpenTracing. As OpenCensus and OpenTracing have carved the way for OpenTelemetry, it makes sense to introduce OpenTelemetry where OpenCensus or OpenTracing is used as it still has backward compatibility. Apart from adding custom attributes, sampling, collecting data for metrics and traces, OpenTelemetry is governed by specifications and backed up by big players in the Observability landscape like Microsoft, Splunk, AppDynamics, etc. OpenTelemetry will likely become a de-facto open-source standard for enabling metrics and tracing when all features become GA. Current Status of OpenTelemetry Project OpenTelemetry is a project which emerged from merging of OpenCensus and OpenTracing in 2019. Although OpenCensus and OpenTracing are frozen and no new features are being developed for them, OpenTelemetry has backward compatibility with OpenCensus and OpenTracing. Some features of OpenTelemetry are still in beta, feature support for different languages is being tracked here: Feature Status of OpenTelemetry . Status of OpenTelemetry project can be tracked here . From the website: Our goal is to provide a generally available, production quality release for the tracing data source across most OpenTelemetry components in the first half of 2021. Several components have already reached this milestone! We expect metrics to reach the same status in the second half of 2021 and are targeting logs in 2022. What to watch out for As OpenTelemetry is a very recent project (first GA version of some features released in 2020), many features are still in beta hence due diligence needs to be done before using such features in production. Also, OpenTelemetry supports many popular languages but features in all languages are not at par. Some languages offer more features as compared to other languages. It also needs to be called out as some features are not in GA, there may be some incompatibility issues with the tooling. That being said, OpenTelemetry is one of the most active projects of CNCF , so it is expected that many more features would reach GA soon. January 2022 UPDATE Apart from the logging specification and implementation that are still marked as draft or beta, all other specifications and implementations regarding tracing and metrics are marked as stable or feature-freeze. Many libraries are still on active development whatsoever, so thorough analysis has to be made depending on the language on a feature basis. Integration Options with Azure Monitor Using the Azure Monitor OpenTelemetry Exporter Library This scenario uses the OpenTelemetry SDK as the core instrumentation library. Basically this means you will instrument your application using the OpenTelemetry libraries, but you will additionally use the Azure Monitor OpenTelemetry Exporter and then added it as an additional exporter with the OpenTelemetry SDK. In this way, the OpenTelemetry traces your application creates will be pushed to your Azure Monitor Instance. Using the Application Insights Agent Jar file - Java only Java OpenTelemetry instrumentation provides another way to integrate with Azure Monitor, by using Applications Insights Java Agent jar . When configuring this option, the Applications Insights Agent file is added when executing the application. The applicationinsights.json configuration file must be also be added as part of the applications artifacts. Pay close attention to the preview section, where the \"openTelemetryApiSupport\": true, property is set to true, enabling the agent to intercept OpenTelemetry telemetry created in the application code pushing it to Azure Monitor. OpenTelemetry Java Agent instrumentation supports many libraries and frameworks and application servers . Application Insights Java Agent enhances this list. Therefore, the main difference between running the OpenTelemetry Java Agent vs. the Application Insights Java Agent is demonstrated in the amount of traces getting logged in Azure Monitor. When running with Application Insights Java agent there's more telemetry getting pushed to Azure Monitor. On the other hand, when running the solution using the Application Insights agent mode, it is essential to highlight that nothing gets logged on Jaeger (or any other OpenTelemetry exporter). All traces will be pushed exclusively to Azure Monitor. However, both manual instrumentation done via the OpenTelemetry SDK and all automatic traces, dependencies, performance counters, and metrics being instrumented by the Application Insights agent are sent to Azure Monitor. Although there is a rich amount of additional data automatically instrumented by the Application Insights agent, it can be deduced that it is not necessarily OpenTelemetry compliant. Only the traces logged by the manual instrumentation using the OpenTelemetry SDK are. OpenTelemetry vs Application Insights agents compared Highlight OpenTelemetry Agent App Insights Agent Automatic Telemetry Y Y Manual OpenTelemetry Y Y Plug and Play Exports Y N Multiple Exports Y N Full Open Telemetry layout (decoupling agents, collectors and exporters) Y N Enriched out of the box telemetry N Y Unified telemetry backend N Y Summary As you may have guessed, there is no \"one size fits all\" approach when implementing OpenTelemetry with Azure Monitor as a backend. At the time of this writing, if you want to have the flexibility of having different OpenTelemetry backends, you should definitively go with the OpenTelemetry Agent, even though you'd sacrifice all automating tracing flowing to Azure Monitor. On the other hand, if you want to get the best of Azure Monitor and still want to instrument your code with the OpenTelemetry SDK, you should use the Application Insights Agent and manually instrument your code with the OpenTelemetry SDK to get the best of both worlds. Either way, instrumenting your code with OpenTelemetry seems the right approach as the ecosystem will only get bigger, better, and more robust. Advanced topics Use the Azure OpenTelemetry Tracing plugin library for Java to enable distributed tracing across Azure components through OpenTelemetry. Manual trace context propagation The trace context is stored in Thread-local storage. When the application flow involves multiple threads (eg. multithreaded work-queue, asynchronous processing) then the traces won't get combined into one end-to-end trace chain with automatic context propagation . To achieve that you need to manually propagate the trace context ( example in Java ) by storing the trace headers along with the work-queue item. Telemetry testing Mission critical telemetry data should be covered by testing. You can cover telemetry by tests by mocking the telemetry collector web server. In automated testing environment the telemetry instrumentation can be configured to use OTLP exporter and point the OTLP exporter endpoint to the collector web server. Using mocking servers libraries (eg. MockServer or WireMock) can help verify the telemetry data pushed to the collector. References OpenTelemetry Official Site Getting Started with dotnet and OpenTelemetry Using OpenTelemetry Collector OpenTelemetry Java SDK Manual Instrumentation OpenTelemetry Instrumentation Agent for Java Application Insights Java Agent Azure Monitor OpenTelemetry Exporter client library for Java Azure OpenTelemetry Tracing plugin library for Java Application Insights Agent's OpenTelemetry configuration","title":"Open Telemetry"},{"location":"observability/tools/OpenTelemetry/#open-telemetry","text":"Building observable systems enable one to measure how well or bad the application is behaving and WHY it is behaving either way. Adopting open-source standards related to implementing telemetry and tracing features built on top of the OpenTelemetry framework helps decouple vendor-specific implementations while maintaining an extensible, standard, and portable open-source solution. OpenTelemetry is an open-source observability standard that defines how to generate, collect and describe telemetry in distributed systems. OpenTelemetry also provides a single-point distribution of a set of APIs, SDKs, and instrumentation libraries that implements the open-source standard, which can collect, process, and orchestrate telemetry data (signals) like traces, metrics, and logs. It supports multiple popular languages (Java, .NET, Python, JavaScript, Golang, Erlang, etc.). Open telemetry follows a vendor-agnostic and standards-based approach for collecting and managing telemetry data. An important point to note is that OpenTelemetry does not have its own backend; all telemetry collected by OpenTelemetry Collector must be sent to a backend like Prometheus, Jaeger, Zipkin, Azure Monitor, etc. Open telemetry is also the 2nd most active CNCF project only after Kubernetes. The main two Problems OpenTelemetry solves are: First, vendor neutrality for tracing, monitoring, and logging APIs and second, out-of-the-box cross-platform context propagation implementation for end-to-end distributed tracing over heterogeneous components.","title":"Open Telemetry"},{"location":"observability/tools/OpenTelemetry/#open-telemetry-core-concepts","text":"","title":"Open Telemetry Core Concepts"},{"location":"observability/tools/OpenTelemetry/#open-telemetry-implementation-patterns","text":"A detailed explanation of OpenTelemetry concepts is out of the scope of this repo. There is plenty of available information about how the SDK and the automatic instrumentation are configured and how the Exporters, Tracers, Context, and Span's hierarchy work. See the Reference section for valuable OpenTelemetry resources. However, understanding the core implementation patterns will help you know what approach better fits the scenario you are trying to solve. These are three main patterns as follows: Automatic telemetry: Support for automatic instrumentation is available for some languages. OpenTelemetry automatic instrumentation (100% codeless) is typically done through library hooks or monkey-patching library code. Automatic instrumentation will intercept all interactions and dependencies and automatically send the telemetry to the configured exporters. More information about this concept can be found in the OpenTelemetry instrumentation doc . Manual tracing: This must be done by coding using the OpenTelemetry SDK, managing the tracer objects to obtain Spans, and forming instrumented OpenTelemetry Scopes to identify the code segments to be manually traced. Also, by using the @WithSpan annotations (method decorations in C# and Java ) to mark whole methods that will be automatically traced. Hybrid approach: Most Production-ready scenarios will require a mix of both techniques, using the automatic instrumentation to collect automatic telemetry and the OpenTelemetry SDK to identify code segments that are important to instrument manually. When considering production-ready scenarios, the hybrid approach is the way to go as it allows for a throughout cover over the whole solution. It provides automatic context propagation and events correlation out of the box.","title":"Open Telemetry Implementation Patterns"},{"location":"observability/tools/OpenTelemetry/#collector","text":"The collector is a separate process that is designed to be a \u2018sink\u2019 for telemetry data emitted by many processes, which can then export that data to backend systems. The collector has two different deployment strategies \u2013 either running as an agent alongside a service or as a gateway which is a remote application. In general, using both is recommended: the agent would be deployed with your service and run as a separate process or in a sidecar; meanwhile, the collector would be deployed separately, as its own application running in a container or virtual machine. Each agent would forward telemetry data to the collector, which could then export it to a variety of backend systems such as Lightstep, Jaeger, or Prometheus. The agent can be also replaced with the automatic instrumentation if supported. The automatic instrumentation provides the collector capabilities of retrieving, processing and exporting the telemetry. Regardless of how you choose to instrument or deploy OpenTelemetry, exporters provide powerful options for reporting telemetry data. You can directly export from your service, you can proxy through the collector, or you can aggregate into standalone collectors \u2013 or even a mix of these.","title":"Collector"},{"location":"observability/tools/OpenTelemetry/#instrumentation-libraries","text":"A library that enables observability for another library is called an instrumentation library. OpenTelemetry libraries are language specific, currently there is good support for Java, Python, Javascript, dotnet and golang. Support for automatic instrumentation is available for some libraries which make using OpenTelemetry easy and trivial. In case automatic instrumentation is not available, manual instrumentation can be configured by using the OpenTelemetry SDK.","title":"Instrumentation Libraries"},{"location":"observability/tools/OpenTelemetry/#integration-of-opentelemetry","text":"OpenTelemetry can be used to collect, process and export data into multiple backends, some popular integrations supported with OpenTelemetry are: Zipkin Prometheus Jaeger New Relic Azure Monitor AWS X-Ray Datadog Kafka Lightstep Splunk GCP Monitor","title":"Integration of OpenTelemetry"},{"location":"observability/tools/OpenTelemetry/#why-use-opentelemetry","text":"The main reason to use OpenTelemetry is that it offers an open-source standard for implementing distributed telemetry (context propagation) over heterogeneous systems. There is no need to reinvent the wheel to implement end-to-end business flow transactions monitoring when using OpenTelemetry. It enables tracing, metrics, and logging telemetry through a set of single-distribution multi-language libraries and tools that allow for a plug-and-play telemetry architecture that includes the concept of agents and collectors. Moreover, avoiding any proprietary lock down and achieving vendor-agnostic neutrality for tracing, monitoring, and logging APIs AND backends allow maximum portability and extensibility patterns. Another good reason to use OpenTelemetry would be whether the stack uses OpenCensus or OpenTracing. As OpenCensus and OpenTracing have carved the way for OpenTelemetry, it makes sense to introduce OpenTelemetry where OpenCensus or OpenTracing is used as it still has backward compatibility. Apart from adding custom attributes, sampling, collecting data for metrics and traces, OpenTelemetry is governed by specifications and backed up by big players in the Observability landscape like Microsoft, Splunk, AppDynamics, etc. OpenTelemetry will likely become a de-facto open-source standard for enabling metrics and tracing when all features become GA.","title":"Why use OpenTelemetry"},{"location":"observability/tools/OpenTelemetry/#current-status-of-opentelemetry-project","text":"OpenTelemetry is a project which emerged from merging of OpenCensus and OpenTracing in 2019. Although OpenCensus and OpenTracing are frozen and no new features are being developed for them, OpenTelemetry has backward compatibility with OpenCensus and OpenTracing. Some features of OpenTelemetry are still in beta, feature support for different languages is being tracked here: Feature Status of OpenTelemetry . Status of OpenTelemetry project can be tracked here . From the website: Our goal is to provide a generally available, production quality release for the tracing data source across most OpenTelemetry components in the first half of 2021. Several components have already reached this milestone! We expect metrics to reach the same status in the second half of 2021 and are targeting logs in 2022.","title":"Current Status of OpenTelemetry Project"},{"location":"observability/tools/OpenTelemetry/#what-to-watch-out-for","text":"As OpenTelemetry is a very recent project (first GA version of some features released in 2020), many features are still in beta hence due diligence needs to be done before using such features in production. Also, OpenTelemetry supports many popular languages but features in all languages are not at par. Some languages offer more features as compared to other languages. It also needs to be called out as some features are not in GA, there may be some incompatibility issues with the tooling. That being said, OpenTelemetry is one of the most active projects of CNCF , so it is expected that many more features would reach GA soon.","title":"What to watch out for"},{"location":"observability/tools/OpenTelemetry/#january-2022-update","text":"Apart from the logging specification and implementation that are still marked as draft or beta, all other specifications and implementations regarding tracing and metrics are marked as stable or feature-freeze. Many libraries are still on active development whatsoever, so thorough analysis has to be made depending on the language on a feature basis.","title":"January 2022 UPDATE"},{"location":"observability/tools/OpenTelemetry/#integration-options-with-azure-monitor","text":"","title":"Integration Options with Azure Monitor"},{"location":"observability/tools/OpenTelemetry/#using-the-azure-monitor-opentelemetry-exporter-library","text":"This scenario uses the OpenTelemetry SDK as the core instrumentation library. Basically this means you will instrument your application using the OpenTelemetry libraries, but you will additionally use the Azure Monitor OpenTelemetry Exporter and then added it as an additional exporter with the OpenTelemetry SDK. In this way, the OpenTelemetry traces your application creates will be pushed to your Azure Monitor Instance.","title":"Using the Azure Monitor OpenTelemetry Exporter Library"},{"location":"observability/tools/OpenTelemetry/#using-the-application-insights-agent-jar-file-java-only","text":"Java OpenTelemetry instrumentation provides another way to integrate with Azure Monitor, by using Applications Insights Java Agent jar . When configuring this option, the Applications Insights Agent file is added when executing the application. The applicationinsights.json configuration file must be also be added as part of the applications artifacts. Pay close attention to the preview section, where the \"openTelemetryApiSupport\": true, property is set to true, enabling the agent to intercept OpenTelemetry telemetry created in the application code pushing it to Azure Monitor. OpenTelemetry Java Agent instrumentation supports many libraries and frameworks and application servers . Application Insights Java Agent enhances this list. Therefore, the main difference between running the OpenTelemetry Java Agent vs. the Application Insights Java Agent is demonstrated in the amount of traces getting logged in Azure Monitor. When running with Application Insights Java agent there's more telemetry getting pushed to Azure Monitor. On the other hand, when running the solution using the Application Insights agent mode, it is essential to highlight that nothing gets logged on Jaeger (or any other OpenTelemetry exporter). All traces will be pushed exclusively to Azure Monitor. However, both manual instrumentation done via the OpenTelemetry SDK and all automatic traces, dependencies, performance counters, and metrics being instrumented by the Application Insights agent are sent to Azure Monitor. Although there is a rich amount of additional data automatically instrumented by the Application Insights agent, it can be deduced that it is not necessarily OpenTelemetry compliant. Only the traces logged by the manual instrumentation using the OpenTelemetry SDK are.","title":"Using the Application Insights Agent Jar file - Java only"},{"location":"observability/tools/OpenTelemetry/#opentelemetry-vs-application-insights-agents-compared","text":"Highlight OpenTelemetry Agent App Insights Agent Automatic Telemetry Y Y Manual OpenTelemetry Y Y Plug and Play Exports Y N Multiple Exports Y N Full Open Telemetry layout (decoupling agents, collectors and exporters) Y N Enriched out of the box telemetry N Y Unified telemetry backend N Y","title":"OpenTelemetry vs Application Insights agents compared"},{"location":"observability/tools/OpenTelemetry/#summary","text":"As you may have guessed, there is no \"one size fits all\" approach when implementing OpenTelemetry with Azure Monitor as a backend. At the time of this writing, if you want to have the flexibility of having different OpenTelemetry backends, you should definitively go with the OpenTelemetry Agent, even though you'd sacrifice all automating tracing flowing to Azure Monitor. On the other hand, if you want to get the best of Azure Monitor and still want to instrument your code with the OpenTelemetry SDK, you should use the Application Insights Agent and manually instrument your code with the OpenTelemetry SDK to get the best of both worlds. Either way, instrumenting your code with OpenTelemetry seems the right approach as the ecosystem will only get bigger, better, and more robust.","title":"Summary"},{"location":"observability/tools/OpenTelemetry/#advanced-topics","text":"Use the Azure OpenTelemetry Tracing plugin library for Java to enable distributed tracing across Azure components through OpenTelemetry.","title":"Advanced topics"},{"location":"observability/tools/OpenTelemetry/#manual-trace-context-propagation","text":"The trace context is stored in Thread-local storage. When the application flow involves multiple threads (eg. multithreaded work-queue, asynchronous processing) then the traces won't get combined into one end-to-end trace chain with automatic context propagation . To achieve that you need to manually propagate the trace context ( example in Java ) by storing the trace headers along with the work-queue item.","title":"Manual trace context propagation"},{"location":"observability/tools/OpenTelemetry/#telemetry-testing","text":"Mission critical telemetry data should be covered by testing. You can cover telemetry by tests by mocking the telemetry collector web server. In automated testing environment the telemetry instrumentation can be configured to use OTLP exporter and point the OTLP exporter endpoint to the collector web server. Using mocking servers libraries (eg. MockServer or WireMock) can help verify the telemetry data pushed to the collector.","title":"Telemetry testing"},{"location":"observability/tools/OpenTelemetry/#references","text":"OpenTelemetry Official Site Getting Started with dotnet and OpenTelemetry Using OpenTelemetry Collector OpenTelemetry Java SDK Manual Instrumentation OpenTelemetry Instrumentation Agent for Java Application Insights Java Agent Azure Monitor OpenTelemetry Exporter client library for Java Azure OpenTelemetry Tracing plugin library for Java Application Insights Agent's OpenTelemetry configuration","title":"References"},{"location":"observability/tools/Prometheus/","text":"Prometheus Overview Originally built at SoundCloud, Prometheus is an open-source monitoring and alerting toolkit based on time series metrics data. It has become a de facto standard metrics solution in the Cloud Native world and widely used with Kubernetes. The core of Prometheus is a server that scrapes and stores metrics. There are other numerous optional features and components like an Alert-manager and client libraries for programming languages to extend the functionalities of Prometheus beyond the basics. The client libraries offer four metric types : Counter , Gauge , Histogram , and Summary . Why Prometheus? Prometheus is a time series database and allow for events or measurements to be tracked, monitored, and aggregated over time. Prometheus is a pull-based tool. One of the biggest advantages of Prometheus over other monitoring tools is that Prometheus actively scrapes targets in order to retrieve metrics from them. Prometheus also supports the push model for pushing metrics. Prometheus allows for control over how to scrape, and how often to scrape them. Through the Prometheus server, there can be multiple scrape configurations, allowing for multiple rates for different targets. Similar to Grafana , visualization for the time series can be directly done through the Prometheus Web UI. The Web UI provides the ability to easily filter and have an overview of what is taking place with your different targets. Prometheus provides a powerful functional query language called PromQL (Prometheus Query Language) that lets the user aggregate time series data in real time. Integration with Other Tools The Prometheus client libraries allow you to add instrumentation to your code and expose internal metrics via an HTTP endpoint. The official Prometheus client libraries currently are Go , Java or Scala , Python and Ruby . Unofficial third-party libraries include: .NET/C# , Node.js , and C++ . Prometheus' metrics format is supported by a wide array of tools and services including: Azure Monitor Stackdriver Datadog CloudWatch New Relic Flagger Grafana GitLab etc... There are numerous exporters which are used in exporting existing metrics from third-party databases, hardware, CI/CD tools, messaging systems, APIs and other monitoring systems. In addition to client libraries and exporters, there is a significant number of integration points for service discovery, remote storage, alerts and management. References Prometheus Docs Prometheus Best Practices Grafana with Prometheus","title":"Prometheus"},{"location":"observability/tools/Prometheus/#prometheus","text":"","title":"Prometheus"},{"location":"observability/tools/Prometheus/#overview","text":"Originally built at SoundCloud, Prometheus is an open-source monitoring and alerting toolkit based on time series metrics data. It has become a de facto standard metrics solution in the Cloud Native world and widely used with Kubernetes. The core of Prometheus is a server that scrapes and stores metrics. There are other numerous optional features and components like an Alert-manager and client libraries for programming languages to extend the functionalities of Prometheus beyond the basics. The client libraries offer four metric types : Counter , Gauge , Histogram , and Summary .","title":"Overview"},{"location":"observability/tools/Prometheus/#why-prometheus","text":"Prometheus is a time series database and allow for events or measurements to be tracked, monitored, and aggregated over time. Prometheus is a pull-based tool. One of the biggest advantages of Prometheus over other monitoring tools is that Prometheus actively scrapes targets in order to retrieve metrics from them. Prometheus also supports the push model for pushing metrics. Prometheus allows for control over how to scrape, and how often to scrape them. Through the Prometheus server, there can be multiple scrape configurations, allowing for multiple rates for different targets. Similar to Grafana , visualization for the time series can be directly done through the Prometheus Web UI. The Web UI provides the ability to easily filter and have an overview of what is taking place with your different targets. Prometheus provides a powerful functional query language called PromQL (Prometheus Query Language) that lets the user aggregate time series data in real time.","title":"Why Prometheus?"},{"location":"observability/tools/Prometheus/#integration-with-other-tools","text":"The Prometheus client libraries allow you to add instrumentation to your code and expose internal metrics via an HTTP endpoint. The official Prometheus client libraries currently are Go , Java or Scala , Python and Ruby . Unofficial third-party libraries include: .NET/C# , Node.js , and C++ . Prometheus' metrics format is supported by a wide array of tools and services including: Azure Monitor Stackdriver Datadog CloudWatch New Relic Flagger Grafana GitLab etc... There are numerous exporters which are used in exporting existing metrics from third-party databases, hardware, CI/CD tools, messaging systems, APIs and other monitoring systems. In addition to client libraries and exporters, there is a significant number of integration points for service discovery, remote storage, alerts and management.","title":"Integration with Other Tools"},{"location":"observability/tools/Prometheus/#references","text":"Prometheus Docs Prometheus Best Practices Grafana with Prometheus","title":"References"},{"location":"observability/tools/loki/","text":"Loki Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system, created by Grafana Labs inspired by the learnings from Prometheus. Loki is commonly referred as 'Prometheus, but for logs', which makes total sense. Both tools follow the same architecture, which is an agent collecting metrics in each of the components of the software system, a server which stores the logs and also the Grafana dashboard, which access the loki server to build its visualizations and queries. That being said, Loki has three main components: Promtail It is the agent portion of Loki. It can be used to grab logs from several places, like var/log/ for example. The configuration of the Promtail is a yaml file called config-promtail.yml . In this file, its described all the paths and log sources that will be aggregated on Loki Server. Loki Server Loki Server is responsible for receiving and storing all the logs received from all the different systems. The Loki Server is also responsible for the queries done on Grafana, for example. Grafana Dashboards Grafana Dashboards are responsible for creating the visualizations and performing queries. After all, it will be a web page that people with the right access can log into to see, query and create alerts for the aggregated logs. Why use Loki The main reason to use Loki instead of other log aggregation tools, is that Loki optimizes the necessary storage. It does that by following the same pattern as prometheus, which index the labels and make chunks of the log itself, using less space than just storing the raw logs. References Loki Official Site Inserting logs into Loki Adding Loki Source to Grafana Loki Best Practices","title":"Loki"},{"location":"observability/tools/loki/#loki","text":"Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system, created by Grafana Labs inspired by the learnings from Prometheus. Loki is commonly referred as 'Prometheus, but for logs', which makes total sense. Both tools follow the same architecture, which is an agent collecting metrics in each of the components of the software system, a server which stores the logs and also the Grafana dashboard, which access the loki server to build its visualizations and queries. That being said, Loki has three main components:","title":"Loki"},{"location":"observability/tools/loki/#promtail","text":"It is the agent portion of Loki. It can be used to grab logs from several places, like var/log/ for example. The configuration of the Promtail is a yaml file called config-promtail.yml . In this file, its described all the paths and log sources that will be aggregated on Loki Server.","title":"Promtail"},{"location":"observability/tools/loki/#loki-server","text":"Loki Server is responsible for receiving and storing all the logs received from all the different systems. The Loki Server is also responsible for the queries done on Grafana, for example.","title":"Loki Server"},{"location":"observability/tools/loki/#grafana-dashboards","text":"Grafana Dashboards are responsible for creating the visualizations and performing queries. After all, it will be a web page that people with the right access can log into to see, query and create alerts for the aggregated logs.","title":"Grafana Dashboards"},{"location":"observability/tools/loki/#why-use-loki","text":"The main reason to use Loki instead of other log aggregation tools, is that Loki optimizes the necessary storage. It does that by following the same pattern as prometheus, which index the labels and make chunks of the log itself, using less space than just storing the raw logs.","title":"Why use Loki"},{"location":"observability/tools/loki/#references","text":"Loki Official Site Inserting logs into Loki Adding Loki Source to Grafana Loki Best Practices","title":"References"},{"location":"privacy/","text":"Privacy fundamentals This part of the engineering playbook focuses on privacy design guidelines and principles. Private data handling and protection requires both the proper design of software, systems and databases, as well as the implementation of organizational processes and procedures. In general, developers working on ISE projects should adhere to Microsoft's recommended standard practices and regulations on Privacy and Data Handling. The playbook currently contains two main parts: Privacy and Data : Best practices for properly handling sensitive and private data. Privacy frameworks : A list of frameworks which could be applied in private data scenarios.","title":"Privacy fundamentals"},{"location":"privacy/#privacy-fundamentals","text":"This part of the engineering playbook focuses on privacy design guidelines and principles. Private data handling and protection requires both the proper design of software, systems and databases, as well as the implementation of organizational processes and procedures. In general, developers working on ISE projects should adhere to Microsoft's recommended standard practices and regulations on Privacy and Data Handling. The playbook currently contains two main parts: Privacy and Data : Best practices for properly handling sensitive and private data. Privacy frameworks : A list of frameworks which could be applied in private data scenarios.","title":"Privacy fundamentals"},{"location":"privacy/data-handling/","text":"Privacy and Data Goal The goal of this section is to briefly describe best practices in privacy fundamentals for data heavy projects or portions of a project that may contain data. What it is not : This document is not a checklist for how customers or readers should handle data in their environment, and does not override Microsoft's or the customers' policies for data handling, data protection and information security. Introduction Microsoft runs on trust. Our customers trust ISE to adhere to the highest standards when handling their data. Protecting our customers' data is a joint responsibility between Microsoft and the customers; both have the responsibility to help projects follow the guidelines outlined on this page. Developers working on ISE projects should implement best practices and guidance on handling data throughout the project phases. This page is not meant to suggest how customers should handle data in their environment. It does not override : Microsoft's Information Security Policy Limited Data Protection Addendum Professional Services Data Protection Addendum 5 W's of data handling When working on an engagement it is important to address the following 5 W 's: Who \u2013 gets access to and with whom will we share the data and/or models developed with the data? What \u2013 data is shared with us and under what expectations and understanding. Customers need to be explicit about how the data they share applies to the overarching effort. The understanding shouldn't be vague and we shouldn't have access to broad set of data if not necessary. Where \u2013 will the data be stored and what legal jurisdiction will preside over that data. This is particularly important in countries like Germany, where different privacy laws apply but also important when it comes to responding to legal subpoenas for the data. When \u2013 will the access to data be provided and for how long? It is important to not leave straggling access to data once the engagement is completed, and define a priori the data retention policies. Why \u2013 have you given access to the data? This is particularly important to clarify the purpose and any restrictions on usage beyond the intended purpose. Please use the above guidelines to ensure the data is used only for intended purposes and thereby gain trust. It is important to be aware of data handling best practices and ensure the required clarity is provided to adhere to the above 5Ws. Handling data in ISE engagements Data should never leave customer-controlled environments and contractors and/or other members in the engagement should never have access to complete customer data sets but use limited customer data sets using the following prioritized approaches: Contractors or engagement partners do not work directly with production data, data will be copied before processing per the guidelines below. Always apply data minimization principles to minimize the blast radius of errors, only work with the minimal data set required to achieve the goals. Generate synthetic data to support engagement work. If synthetic data is not possible to achieve project goals, request anonymized data in which the likelihood that unique individuals can be re-identified is minimal. Select a suitably diverse, limited data set, again, follow the Principles of Data Minimization and attempt to work with the fewest rows possible to achieve the goals. Before work begins on data, ensure OS patches are up to date and permissions are properly set with no open internet access. Developers working on ISE projects will work with our customers to define the data needed for each engagement. If there is a need to access production data, ISE needs to review the need with their lead and work with the customer to put audits in place verifying what data was accessed. Production data must only be shared with approved members of the engagement team and must not be processed/transferred outside of the customer controlled environment. Customers should provide ISE with a copy of the requested data in a location managed by the customer. The customer should consider turning any logging capabilities on so they can clearly identify who has access and what they do with that access. ISE should notify the customer when they are done with the data and suggest the customer destroy copies of the data if they are no longer needed. Our guiding principles when handling data in an engagement Never directly access production data. Explicitly state the intended purpose of data that can be used for engagement. Only share copies of the production data with the approved members of the engagement team. The entire team should work together to ensure that there are no dead copies of data. When the data is no longer needed, the team should promptly work to clean up engagement copies of data. Do not send any copies of the production data outside the customer-controlled environment. Only use the minimal subset of the data needed for the purpose of the engagement. Questions to consider when working with data What data do we need? What is the legal basis for processing this data? If we are the processor based on contract obligation what is our responsibility listed in the contract? Does the contract need to be amended? How can we contain data proliferation? What security controls are in place to protect this data? What is the data breech protocol? How does this data benefit the data subject? What is the lifespan of this data? Do we need to keep this data linked to a data subject? Can we turn this data into Not in a Position to Identify (NPI) data to be used later on? How is the system architected so data subject rights can be fulfilled? (ex manually, automated) If personal data is involved have engaged privacy and legal teams for this project? Summary It is important to only pull in data that is needed for the problem at hand, when this is put in practice we find that we only maintain data that is adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed. This is particularly important for personal data. Once you have personal data there are many rules and regulations that apply, some examples of these might be HIPPA, GDPR, CCPA. The customer should be aware of and surface any applicable regulations that apply to their data. Furthermore the seven principles of privacy by design should be reviewed and considered when handling any type of sensitive data. Resources Microsoft Trust Center Tools for responsible AI - Protect Data Protection Resources FAQ and White Papers Microsoft Compliance Offerings Accountability Readiness Checklists Privacy by Design The 7 Foundational Principles","title":"Privacy and Data"},{"location":"privacy/data-handling/#privacy-and-data","text":"","title":"Privacy and Data"},{"location":"privacy/data-handling/#goal","text":"The goal of this section is to briefly describe best practices in privacy fundamentals for data heavy projects or portions of a project that may contain data. What it is not : This document is not a checklist for how customers or readers should handle data in their environment, and does not override Microsoft's or the customers' policies for data handling, data protection and information security.","title":"Goal"},{"location":"privacy/data-handling/#introduction","text":"Microsoft runs on trust. Our customers trust ISE to adhere to the highest standards when handling their data. Protecting our customers' data is a joint responsibility between Microsoft and the customers; both have the responsibility to help projects follow the guidelines outlined on this page. Developers working on ISE projects should implement best practices and guidance on handling data throughout the project phases. This page is not meant to suggest how customers should handle data in their environment. It does not override : Microsoft's Information Security Policy Limited Data Protection Addendum Professional Services Data Protection Addendum","title":"Introduction"},{"location":"privacy/data-handling/#5-ws-of-data-handling","text":"When working on an engagement it is important to address the following 5 W 's: Who \u2013 gets access to and with whom will we share the data and/or models developed with the data? What \u2013 data is shared with us and under what expectations and understanding. Customers need to be explicit about how the data they share applies to the overarching effort. The understanding shouldn't be vague and we shouldn't have access to broad set of data if not necessary. Where \u2013 will the data be stored and what legal jurisdiction will preside over that data. This is particularly important in countries like Germany, where different privacy laws apply but also important when it comes to responding to legal subpoenas for the data. When \u2013 will the access to data be provided and for how long? It is important to not leave straggling access to data once the engagement is completed, and define a priori the data retention policies. Why \u2013 have you given access to the data? This is particularly important to clarify the purpose and any restrictions on usage beyond the intended purpose. Please use the above guidelines to ensure the data is used only for intended purposes and thereby gain trust. It is important to be aware of data handling best practices and ensure the required clarity is provided to adhere to the above 5Ws.","title":"5 W's of data handling"},{"location":"privacy/data-handling/#handling-data-in-ise-engagements","text":"Data should never leave customer-controlled environments and contractors and/or other members in the engagement should never have access to complete customer data sets but use limited customer data sets using the following prioritized approaches: Contractors or engagement partners do not work directly with production data, data will be copied before processing per the guidelines below. Always apply data minimization principles to minimize the blast radius of errors, only work with the minimal data set required to achieve the goals. Generate synthetic data to support engagement work. If synthetic data is not possible to achieve project goals, request anonymized data in which the likelihood that unique individuals can be re-identified is minimal. Select a suitably diverse, limited data set, again, follow the Principles of Data Minimization and attempt to work with the fewest rows possible to achieve the goals. Before work begins on data, ensure OS patches are up to date and permissions are properly set with no open internet access. Developers working on ISE projects will work with our customers to define the data needed for each engagement. If there is a need to access production data, ISE needs to review the need with their lead and work with the customer to put audits in place verifying what data was accessed. Production data must only be shared with approved members of the engagement team and must not be processed/transferred outside of the customer controlled environment. Customers should provide ISE with a copy of the requested data in a location managed by the customer. The customer should consider turning any logging capabilities on so they can clearly identify who has access and what they do with that access. ISE should notify the customer when they are done with the data and suggest the customer destroy copies of the data if they are no longer needed.","title":"Handling data in ISE engagements"},{"location":"privacy/data-handling/#our-guiding-principles-when-handling-data-in-an-engagement","text":"Never directly access production data. Explicitly state the intended purpose of data that can be used for engagement. Only share copies of the production data with the approved members of the engagement team. The entire team should work together to ensure that there are no dead copies of data. When the data is no longer needed, the team should promptly work to clean up engagement copies of data. Do not send any copies of the production data outside the customer-controlled environment. Only use the minimal subset of the data needed for the purpose of the engagement.","title":"Our guiding principles when handling data in an engagement"},{"location":"privacy/data-handling/#questions-to-consider-when-working-with-data","text":"What data do we need? What is the legal basis for processing this data? If we are the processor based on contract obligation what is our responsibility listed in the contract? Does the contract need to be amended? How can we contain data proliferation? What security controls are in place to protect this data? What is the data breech protocol? How does this data benefit the data subject? What is the lifespan of this data? Do we need to keep this data linked to a data subject? Can we turn this data into Not in a Position to Identify (NPI) data to be used later on? How is the system architected so data subject rights can be fulfilled? (ex manually, automated) If personal data is involved have engaged privacy and legal teams for this project?","title":"Questions to consider when working with data"},{"location":"privacy/data-handling/#summary","text":"It is important to only pull in data that is needed for the problem at hand, when this is put in practice we find that we only maintain data that is adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed. This is particularly important for personal data. Once you have personal data there are many rules and regulations that apply, some examples of these might be HIPPA, GDPR, CCPA. The customer should be aware of and surface any applicable regulations that apply to their data. Furthermore the seven principles of privacy by design should be reviewed and considered when handling any type of sensitive data.","title":"Summary"},{"location":"privacy/data-handling/#resources","text":"Microsoft Trust Center Tools for responsible AI - Protect Data Protection Resources FAQ and White Papers Microsoft Compliance Offerings Accountability Readiness Checklists Privacy by Design The 7 Foundational Principles","title":"Resources"},{"location":"privacy/privacy-frameworks/","text":"Privacy related frameworks The following tools/frameworks could be leveraged when data analysis or model development needs to take place on private data. Note that the use of such frameworks still requires the solution to adhere to privacy regulations and others, and additional safeguards should be applied. Typical scenarios for leveraging a Privacy framework Sharing data or results while preserving data subjects' privacy Performing analysis or statistical modeling on private data Developing privacy preserving ML models and data pipelines Privacy frameworks Protecting private data involves the entire data lifecycle, from acquisition, through storage, processing, analysis, modeling and usage in reports or machine learning models. Proper safeguards and restrictions should be applied in each of these phases. In this section we provide a non-exhaustive list of privacy frameworks which can be leveraged for protecting and preserving privacy. We focus on four main use cases in the data lifecycle: Obtaining non-sensitive data Establishing trusted research and modeling environments Creating privacy preserving data and ML pipelines Data loss prevention Obtaining non-sensitive data In many scenarios, analysts, researchers and data scientists require access to a non-sensitive version or sample of the private data. In this section we focus on two approaches for obtaining non-sensitive data. Note: These two approaches do not guarantee that the outcome would not include private data, and additional measures should be applied. Data de-identification De-identification is the process of applying a set of transformations to a dataset, in order to lower the risk of unintended disclosure of personal data. De-identification involves the removal or substitution of both direct identifiers (such as name, or social security number) or quasi-identifiers, which can be used for re-identification using additional external information. De-identification can be applied to different types of data, such as structured data, images and text. However, de-identification of non-structured data often involves statistical approaches which might result in undetected PII (Personal Identifiable Information) or non-private information being redacted or replaced. Here we outline several de-identification solutions available as open source: Solution Notes Presidio Presidio helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more in unstructured text and images. It's useful when high customization is required, for example to detect custom PII entities or languages. Link to repo , link to docs , link to demo . FHIR tools for anonymization FHIR Tools for Anonymization is an open-source project that helps anonymize healthcare FHIR data (FHIR=Fast Healthcare Interoperability Resources, a standard for exchanging Electric Health Records), on-premises or in the cloud, for secondary usage such as research, public health, and more. Link . Works with FHIR format (Stu3 and R4), allows different strategies for anonymization (date shift, crypto-hash, encrypt, substitute, perturb, generalize) ARX Anonymization using statistical models, specifically k-anonymity, \u2113-diversity, t-closeness and \u03b4-presence. Useful for validating the anonymization of aggregated data. Links: Repo , Website . Written in Java. k-Anonymity GitHub repo with examples on how to produce k-anonymous datasets. k-anonymity protects the privacy of individual persons by pooling their attributes into groups of at least k people. repo Synthetic data generation A synthetic dataset is a repository of data generated from actual data and has the same statistical properties as the real data. The degree to which a synthetic dataset is an accurate proxy for real data is a measure of utility. The potential benefit of such synthetic datasets is for sensitive applications \u2013 medical classifications or financial modelling, where getting hands on a high-quality labelled dataset is often prohibitive. When determining the best method for creating synthetic data, it is essential first to consider what type of synthetic data you aim to have. There are two broad categories to choose from, each with different benefits and drawbacks: Fully synthetic: This data does not contain any original data, which means that re-identification of any single unit is almost impossible, and all variables are still fully available. Partially synthetic: Only sensitive data is replaced with synthetic data, which requires a heavy dependency on the imputation model. This leads to decreased model dependence but does mean that some disclosure is possible due to the actual values within the dataset. Solution Notes Synthea Synthea was developed with numerous data sources collected on the internet, including US Census Bureau demographics, Centers for Disease Control and Prevention prevalence and incidence rates, and National Institutes of Health reports. The source code and disease models include annotations and citations for all data, statistics, and treatments. These models of diseases and treatments interact appropriately with the health record. PII dataset generator A synthetic data generator developed on top of Fake Name Generator which takes a text file with templates (e.g. my name is PERSON ) and creates a list of Input Samples which contain fake PII entities instead of placeholders. CheckList CheckList provides a framework for perturbation techniques to evaluate specific behavioral capabilities of NLP models systematically Mimesis Mimesis a high-performance fake data generator for Python, which provides data for a variety of purposes in a variety of languages. Faker Faker is a Python package that generates fake data for you. Whether you need to bootstrap your database, create good-looking XML documents, fill-in your persistence to stress test it, or anonymize data taken from a production service, Faker is for you. Plaitpy The idea behind plait.py is that it should be easy to model fake data that has an interesting shape. Currently, many fake data generators model their data as a collection of IID variables; with plait.py we can stitch together those variables into a more coherent model. Trusted research and modeling environments Trusted research environments Trusted Research Environments (TREs) enable organizations to create secure workspaces for analysts, data scientists and researchers who require access to sensitive data. TREs enforce a secure boundary around distinct workspaces to enable information governance controls. Each workspace is accessible by a set of authorized users, prevents the exfiltration of sensitive data, and has access to one or more datasets provided by the data platform. We highlight several alternatives for Trusted Research Environments: Solution Notes Azure Trusted Research Environment An Open Source TRE for Azure. Aridhia DRE Eyes-off machine learning In certain situations, Data Scientists may need to train models on data they are not allowed to see. In these cases, an \"eyes-off\" approach is recommended. An eyes-off approach provides a data scientist with an environment in which scripts can be run on the data but direct access to samples is not allowed. When using Azure ML, tools such as the Identity Based Data Access can enable this scenario, alongside proper role assignment for users. During the processing within the eyes-off environment, only certain outputs (e.g. logs) are allowed to be extracted back to the user. For example, a user would be able to submit a script which trains a model and inspect the model's performance, but would not be able to see on which samples the model predicted the wrong output. In addition to the eyes-off environment, this approach usually entails providing access to an \"eyes-on\" dataset, which is a representative, cleansed, sample set of data for model design purposes. The Eyes-on dataset is often a de-identified subset of the private dataset, or a synthetic dataset generated based on the characteristics of the private dataset. Private data sharing platforms Various tools and systems allow different parties to share data with 3rd parties while protecting private entities, and securely process data while reducing the likelihood of data exfiltration. These tools include Secure Multi Party Computation (SMPC) systems, Homomorphic Encryption systems, Confidential Computing , private data analysis frameworks such as PySift among others. Privacy preserving data pipelines and ML Even when our data is secure, private entities can still be extracted when the data is consumed. Privacy preserving data pipelines and ML models focus on minimizing the risk of private data exfiltration during data querying or model predictions. Differential Privacy Differential privacy (DP) is a system that enables one to extract meaningful insights from datasets about subgroups of people, while also providing strong guarantees with regards to protecting any given individual's privacy. This is typically achieved by adding a small statistical noise to every individual's information, thereby introducing uncertainty in the data. However, the insights gleaned still accurately represent what we intend to learn about the population in the aggregate. This approach is known to be robust to re-identification attacks and data reconstruction by adversaries who possess auxiliary information. For a more comprehensive overview, check out Differential privacy: A primer for a non-technical audience . DP has been widely adopted in various scenarios such as learning from census data, user telemetry data analysis, audience engagement to advertisements, and health data insights where PII protection is of paramount importance. However, DP is less suitable for small datasets. Tools that implement DP include SmartNoise , Tensorflow Privacy among some others. Homomorphic Encryption Homomorphic Encryption (HE) is a form of encryption allowing one to perform calculations on encrypted data without decrypting it first. The result of the computation F is in an encrypted form, which on decrypting gives us the same result if computation F was done on raw unencrypted data. ( source ) Homomorphic Encryption frameworks: Solution Notes Microsoft SEAL Secure Cloud Storage and Computation, ML Modeling. A widely used open-source library from Microsoft that supports the BFV and the CKKS schemes. Palisade A widely used open-source library from a consortium of DARPA-funded defense contractors that supports multiple homomorphic encryption schemes such as BGV, BFV, CKKS, TFHE and FHEW, among others, with multiparty support. Link to repo PySift Private deep learning. PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow. A list of additional OSS tools can be found here . Federated learning Federated learning is a Machine Learning technique which allows the training of ML models in a decentralized way without having to share the actual data. Instead of sending data to the processing engine of the model, the approach is to distribute the model to the different data owners and perform training in a distributed fashion. Federated learning frameworks: Solution Notes TensorFlow Federated Learning OSS federated learning system built on top of TensorFlow FATE An OSS federated learning system with different options for deployment and different algorithms adapted for federated learning IBM Federated Learning A Python based federated learning framework focused on enterprise environments. Data loss prevention Organizations have sensitive information under their control such as financial data, proprietary data, credit card numbers, health records, or social security numbers. To help protect this sensitive data and reduce risk, they need a way to prevent their users from inappropriately sharing it with people who shouldn't have it. This practice is called data loss prevention (DLP) . Below we focus on two aspects of DLP: Sensitive data classification and Access management. Sensitive data classification Sensitive data classification is an important aspect of DLP, as it allows organizations to track, monitor, secure and identify sensitive and private data. Furthermore, different sensitivity levels can be applied to different data items, facilitating proper governance and cataloging. There are typically four levels data classification levels: Public Internal Confidential Restricted / Highly confidential Tools for data classification on Azure: Solution Notes Microsoft Information Protection (MIP) A suite for DLP, sensitive data classification, cataloging and more. Azure Purview A unified data governance service, which includes the classification and cataloging of sensitive data. Azure Purview leverages the MIP technology for data classification and more. Data Discovery & Classification for Azure SQL Database, Azure SQL Managed Instance, and Azure Synapse Basic capabilities for discovering, classifying, labeling, and reporting the sensitive data in Azure SQL and Synapse databases. Data Discovery & Classification for SQL Server Capabilities for discovering, classifying, labeling & reporting the sensitive data in SQL Server databases. Often, tools used for de-identification can also serve as sensitive data classifiers. Refer to de-identification tools for such tools. Additional resources: Example guidelines for data classification Learn about sensitivity levels Access management Access control is an important component of privacy by design and falls into overall data lifecycle protection. Successful access control will restrict access only to authorized individuals that should have access to data. Once data is secure in an environment, it is important to review who should access this data and for what purpose. Access control may be audited with a comprehensive logging strategy which may include the integration of activity logs that can provide insight into operations performed on resources in a subscription. OWASP Access Control Cheat Sheet","title":"Privacy related frameworks"},{"location":"privacy/privacy-frameworks/#privacy-related-frameworks","text":"The following tools/frameworks could be leveraged when data analysis or model development needs to take place on private data. Note that the use of such frameworks still requires the solution to adhere to privacy regulations and others, and additional safeguards should be applied.","title":"Privacy related frameworks"},{"location":"privacy/privacy-frameworks/#typical-scenarios-for-leveraging-a-privacy-framework","text":"Sharing data or results while preserving data subjects' privacy Performing analysis or statistical modeling on private data Developing privacy preserving ML models and data pipelines","title":"Typical scenarios for leveraging a Privacy framework"},{"location":"privacy/privacy-frameworks/#privacy-frameworks","text":"Protecting private data involves the entire data lifecycle, from acquisition, through storage, processing, analysis, modeling and usage in reports or machine learning models. Proper safeguards and restrictions should be applied in each of these phases. In this section we provide a non-exhaustive list of privacy frameworks which can be leveraged for protecting and preserving privacy. We focus on four main use cases in the data lifecycle: Obtaining non-sensitive data Establishing trusted research and modeling environments Creating privacy preserving data and ML pipelines Data loss prevention","title":"Privacy frameworks"},{"location":"privacy/privacy-frameworks/#obtaining-non-sensitive-data","text":"In many scenarios, analysts, researchers and data scientists require access to a non-sensitive version or sample of the private data. In this section we focus on two approaches for obtaining non-sensitive data. Note: These two approaches do not guarantee that the outcome would not include private data, and additional measures should be applied.","title":"Obtaining non-sensitive data"},{"location":"privacy/privacy-frameworks/#data-de-identification","text":"De-identification is the process of applying a set of transformations to a dataset, in order to lower the risk of unintended disclosure of personal data. De-identification involves the removal or substitution of both direct identifiers (such as name, or social security number) or quasi-identifiers, which can be used for re-identification using additional external information. De-identification can be applied to different types of data, such as structured data, images and text. However, de-identification of non-structured data often involves statistical approaches which might result in undetected PII (Personal Identifiable Information) or non-private information being redacted or replaced. Here we outline several de-identification solutions available as open source: Solution Notes Presidio Presidio helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more in unstructured text and images. It's useful when high customization is required, for example to detect custom PII entities or languages. Link to repo , link to docs , link to demo . FHIR tools for anonymization FHIR Tools for Anonymization is an open-source project that helps anonymize healthcare FHIR data (FHIR=Fast Healthcare Interoperability Resources, a standard for exchanging Electric Health Records), on-premises or in the cloud, for secondary usage such as research, public health, and more. Link . Works with FHIR format (Stu3 and R4), allows different strategies for anonymization (date shift, crypto-hash, encrypt, substitute, perturb, generalize) ARX Anonymization using statistical models, specifically k-anonymity, \u2113-diversity, t-closeness and \u03b4-presence. Useful for validating the anonymization of aggregated data. Links: Repo , Website . Written in Java. k-Anonymity GitHub repo with examples on how to produce k-anonymous datasets. k-anonymity protects the privacy of individual persons by pooling their attributes into groups of at least k people. repo","title":"Data de-identification"},{"location":"privacy/privacy-frameworks/#synthetic-data-generation","text":"A synthetic dataset is a repository of data generated from actual data and has the same statistical properties as the real data. The degree to which a synthetic dataset is an accurate proxy for real data is a measure of utility. The potential benefit of such synthetic datasets is for sensitive applications \u2013 medical classifications or financial modelling, where getting hands on a high-quality labelled dataset is often prohibitive. When determining the best method for creating synthetic data, it is essential first to consider what type of synthetic data you aim to have. There are two broad categories to choose from, each with different benefits and drawbacks: Fully synthetic: This data does not contain any original data, which means that re-identification of any single unit is almost impossible, and all variables are still fully available. Partially synthetic: Only sensitive data is replaced with synthetic data, which requires a heavy dependency on the imputation model. This leads to decreased model dependence but does mean that some disclosure is possible due to the actual values within the dataset. Solution Notes Synthea Synthea was developed with numerous data sources collected on the internet, including US Census Bureau demographics, Centers for Disease Control and Prevention prevalence and incidence rates, and National Institutes of Health reports. The source code and disease models include annotations and citations for all data, statistics, and treatments. These models of diseases and treatments interact appropriately with the health record. PII dataset generator A synthetic data generator developed on top of Fake Name Generator which takes a text file with templates (e.g. my name is PERSON ) and creates a list of Input Samples which contain fake PII entities instead of placeholders. CheckList CheckList provides a framework for perturbation techniques to evaluate specific behavioral capabilities of NLP models systematically Mimesis Mimesis a high-performance fake data generator for Python, which provides data for a variety of purposes in a variety of languages. Faker Faker is a Python package that generates fake data for you. Whether you need to bootstrap your database, create good-looking XML documents, fill-in your persistence to stress test it, or anonymize data taken from a production service, Faker is for you. Plaitpy The idea behind plait.py is that it should be easy to model fake data that has an interesting shape. Currently, many fake data generators model their data as a collection of IID variables; with plait.py we can stitch together those variables into a more coherent model.","title":"Synthetic data generation"},{"location":"privacy/privacy-frameworks/#trusted-research-and-modeling-environments","text":"","title":"Trusted research and modeling environments"},{"location":"privacy/privacy-frameworks/#trusted-research-environments","text":"Trusted Research Environments (TREs) enable organizations to create secure workspaces for analysts, data scientists and researchers who require access to sensitive data. TREs enforce a secure boundary around distinct workspaces to enable information governance controls. Each workspace is accessible by a set of authorized users, prevents the exfiltration of sensitive data, and has access to one or more datasets provided by the data platform. We highlight several alternatives for Trusted Research Environments: Solution Notes Azure Trusted Research Environment An Open Source TRE for Azure. Aridhia DRE","title":"Trusted research environments"},{"location":"privacy/privacy-frameworks/#eyes-off-machine-learning","text":"In certain situations, Data Scientists may need to train models on data they are not allowed to see. In these cases, an \"eyes-off\" approach is recommended. An eyes-off approach provides a data scientist with an environment in which scripts can be run on the data but direct access to samples is not allowed. When using Azure ML, tools such as the Identity Based Data Access can enable this scenario, alongside proper role assignment for users. During the processing within the eyes-off environment, only certain outputs (e.g. logs) are allowed to be extracted back to the user. For example, a user would be able to submit a script which trains a model and inspect the model's performance, but would not be able to see on which samples the model predicted the wrong output. In addition to the eyes-off environment, this approach usually entails providing access to an \"eyes-on\" dataset, which is a representative, cleansed, sample set of data for model design purposes. The Eyes-on dataset is often a de-identified subset of the private dataset, or a synthetic dataset generated based on the characteristics of the private dataset.","title":"Eyes-off machine learning"},{"location":"privacy/privacy-frameworks/#private-data-sharing-platforms","text":"Various tools and systems allow different parties to share data with 3rd parties while protecting private entities, and securely process data while reducing the likelihood of data exfiltration. These tools include Secure Multi Party Computation (SMPC) systems, Homomorphic Encryption systems, Confidential Computing , private data analysis frameworks such as PySift among others.","title":"Private data sharing platforms"},{"location":"privacy/privacy-frameworks/#privacy-preserving-data-pipelines-and-ml","text":"Even when our data is secure, private entities can still be extracted when the data is consumed. Privacy preserving data pipelines and ML models focus on minimizing the risk of private data exfiltration during data querying or model predictions.","title":"Privacy preserving data pipelines and ML"},{"location":"privacy/privacy-frameworks/#differential-privacy","text":"Differential privacy (DP) is a system that enables one to extract meaningful insights from datasets about subgroups of people, while also providing strong guarantees with regards to protecting any given individual's privacy. This is typically achieved by adding a small statistical noise to every individual's information, thereby introducing uncertainty in the data. However, the insights gleaned still accurately represent what we intend to learn about the population in the aggregate. This approach is known to be robust to re-identification attacks and data reconstruction by adversaries who possess auxiliary information. For a more comprehensive overview, check out Differential privacy: A primer for a non-technical audience . DP has been widely adopted in various scenarios such as learning from census data, user telemetry data analysis, audience engagement to advertisements, and health data insights where PII protection is of paramount importance. However, DP is less suitable for small datasets. Tools that implement DP include SmartNoise , Tensorflow Privacy among some others.","title":"Differential Privacy"},{"location":"privacy/privacy-frameworks/#homomorphic-encryption","text":"Homomorphic Encryption (HE) is a form of encryption allowing one to perform calculations on encrypted data without decrypting it first. The result of the computation F is in an encrypted form, which on decrypting gives us the same result if computation F was done on raw unencrypted data. ( source ) Homomorphic Encryption frameworks: Solution Notes Microsoft SEAL Secure Cloud Storage and Computation, ML Modeling. A widely used open-source library from Microsoft that supports the BFV and the CKKS schemes. Palisade A widely used open-source library from a consortium of DARPA-funded defense contractors that supports multiple homomorphic encryption schemes such as BGV, BFV, CKKS, TFHE and FHEW, among others, with multiparty support. Link to repo PySift Private deep learning. PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow. A list of additional OSS tools can be found here .","title":"Homomorphic Encryption"},{"location":"privacy/privacy-frameworks/#federated-learning","text":"Federated learning is a Machine Learning technique which allows the training of ML models in a decentralized way without having to share the actual data. Instead of sending data to the processing engine of the model, the approach is to distribute the model to the different data owners and perform training in a distributed fashion. Federated learning frameworks: Solution Notes TensorFlow Federated Learning OSS federated learning system built on top of TensorFlow FATE An OSS federated learning system with different options for deployment and different algorithms adapted for federated learning IBM Federated Learning A Python based federated learning framework focused on enterprise environments.","title":"Federated learning"},{"location":"privacy/privacy-frameworks/#data-loss-prevention","text":"Organizations have sensitive information under their control such as financial data, proprietary data, credit card numbers, health records, or social security numbers. To help protect this sensitive data and reduce risk, they need a way to prevent their users from inappropriately sharing it with people who shouldn't have it. This practice is called data loss prevention (DLP) . Below we focus on two aspects of DLP: Sensitive data classification and Access management.","title":"Data loss prevention"},{"location":"privacy/privacy-frameworks/#sensitive-data-classification","text":"Sensitive data classification is an important aspect of DLP, as it allows organizations to track, monitor, secure and identify sensitive and private data. Furthermore, different sensitivity levels can be applied to different data items, facilitating proper governance and cataloging. There are typically four levels data classification levels: Public Internal Confidential Restricted / Highly confidential Tools for data classification on Azure: Solution Notes Microsoft Information Protection (MIP) A suite for DLP, sensitive data classification, cataloging and more. Azure Purview A unified data governance service, which includes the classification and cataloging of sensitive data. Azure Purview leverages the MIP technology for data classification and more. Data Discovery & Classification for Azure SQL Database, Azure SQL Managed Instance, and Azure Synapse Basic capabilities for discovering, classifying, labeling, and reporting the sensitive data in Azure SQL and Synapse databases. Data Discovery & Classification for SQL Server Capabilities for discovering, classifying, labeling & reporting the sensitive data in SQL Server databases. Often, tools used for de-identification can also serve as sensitive data classifiers. Refer to de-identification tools for such tools. Additional resources: Example guidelines for data classification Learn about sensitivity levels","title":"Sensitive data classification"},{"location":"privacy/privacy-frameworks/#access-management","text":"Access control is an important component of privacy by design and falls into overall data lifecycle protection. Successful access control will restrict access only to authorized individuals that should have access to data. Once data is secure in an environment, it is important to review who should access this data and for what purpose. Access control may be audited with a comprehensive logging strategy which may include the integration of activity logs that can provide insight into operations performed on resources in a subscription. OWASP Access Control Cheat Sheet","title":"Access management"},{"location":"reliability/","text":"Reliability All the other ISE Engineering Fundamentals work towards a more reliable infrastructure. Automated integration and deployment ensures code is properly tested, and helps remove human error, while slow releases build confidence in the code. Observability helps more quickly pinpoint errors when they arise to get back to a stable state, and so on. However, there are some additional steps we can take, that don't neatly fit into the previous categories, to help ensure a more reliable solution. We'll explore these below. Remove \"Foot-Guns\" Prevent your dev team from shooting themselves in the foot. People make mistakes; any mistake made in production is not the fault of that person, it's the collective fault of the system to not prevent that mistake from happening. Check out the below list for some common tooling to remove these foot guns: In Kubernetes, leverage Admission Controllers to prevent \"bad things\" from happening. You can create custom controllers using the Webhook Admission controller. Gatekeeper is a pre-built Webhook Admission controller, leveraging OPA underneath the hood, with support for some out-of-the-box protections If a user ever makes a mistake, don't ask: \"how could somebody possibly do that?\", do ask: \"how can we prevent this from happening in the future?\" Autoscaling Whenever possible, leverage autoscaling for your deployments. Vertical autoscaling can scale your VMs by tuning parameters like CPU, disk, and RAM, while horizontal autoscaling can tune the number of running images backing your deployments. Autoscaling can help your system respond to inorganic growth in traffic, and prevent failing requests due to resource starvation. Note: In environments like K8s, both horizontal and vertical autoscaling are offered as a native solution. The VMs backing each Pod however, may also need autoscaling to handle an increase in the number of Pods. It should also be noted that the parameters that affect autoscaling can be difficult to tune. Typical metrics like CPU or RAM utilization, or request rate may not be enough. Sometimes you might want to consider custom metrics, like cache eviction rate. Load shedding & DOS Protection Often we think of Denial of Service [DOS] attacks as an act from a malicious actor, so we place some load shedding at the gates to our system and call it a day. In reality, many DOS attacks are unintentional, and self-inflicted. A bad deployment that takes down a Cache results in hammering downstream services. Polling from a distributed system synchronizes and results in a thundering herd . A misconfiguration results in an error which triggers clients to retry uncontrollably. Requests append to a stored object until it is so big that future reads crash the server. The list goes on. Follow these steps to protect yourself: Add a jitter (random) to any action that occurs from a non-user triggered flow (ie: add a random duration to the sleep in a cron, or job that continuously polls a downstream service). Implement exponential backoff retry policies in your client code Add load shedding to your servers (yes, your internal microservices too). This can be configured easily when leveraging a sidecar like envoy. Be careful when deserializing user requests, and use buffer limits. ie: HTTP/gRPC Servers can set limits on how much data will get read from the socket. Set alerts for utilization, servers restarting, or going offline to detect when your system may be failing. These types of errors can result in Cascading Failures, where a non-critical portion of your system takes down the entire service. Plan accordingly, and make sure to put extra thought into how your system might degrade during failures. Backup Data Data gets lost, corrupted, or accidentally deleted. It happens. Take data backups to help get your system back up online as soon as possible. It can happen in the application stack, with code deleting or corrupting data, or at the storage layer by losing the volumes, or losing encryption keys. Consider things like: How long will it take to restore data. How much data loss can you tolerate. How long will it take you to notice there is data loss. Look into the difference between snapshot and incremental backups. A good policy might be to take incremental backups on a period of N, and a snapshot backup on a period of M (where N < M). Target Uptime & Failing Gracefully It's a known fact that systems cannot target 100% uptime. There are too many factors in today's software systems to achieve this, many outside of our control. Even a service that never gets updated and is 100% bug free will fail. Upstream DNS servers have issues all the time. Hardware breaks. Power outages, backup generators fail. The world is chaotic. Good services target some number of \"9's\" of uptime. ie: 99.99% uptime means that the system has a \"budget\" of 4 minutes and 22 seconds of uptime each month. Some months might achieve 100% uptime, which means that budget gets rolled over to the next month. What uptime means is different for everybody, and up to the service to define. A good practice is to use any leftover budget at the end of the period (ie: year, quarter), to intentionally take that service down, and ensure that the rest of your systems fail as expected. Often times other engineers and services come to rely on that additional achieved availability, and it can be healthy to ensure that systems fail gracefully. We can build graceful failure (or graceful degradation) into our software stack by anticipating failures. Some tactics include: Failover to healthy services Leader Election can be used to keep healthy services on standby in case the leader experiences issues. Entire cluster failover can redirect traffic to another region or availability zone. Propagate downstream failures of dependent services up the stack via health checks, so that your ingress points can re-route to healthy services. Circuit breakers can bail early on requests vs. propagating errors throughout the system. Consider using a well-known, tested library such as Polly (.NET) that enables configurable implementations of this and other common resilience and transient fault-handling patterns. Practice None of the above recommendations will work if they are not tested . Your backups are meaningless if you don't know how to mount them. Your cluster failover and other mitigations will regress over time if they are not tested. Here are some tips to test the above: Maintain Playbooks No software service is complete without playbooks to navigate the developers through unfamiliar territory. Playbooks should be thorough and cover all known failure scenarios and mitigations. Run maintenance exercises Take the time to fabricate scenarios, and run a D&D style campaign to solve your issues. This can be as elaborate as spinning up a new environment and injecting errors, or as simple as asking the \"players\" to navigate to a dashboard and describing would they would see in the fabricated scenario (small amounts of imagination required). The playbooks should easily navigate the user to the correct solution/mitigation. If not, update your playbooks. Chaos Testing Leverage automated chaos testing to see how things break. You can read this playbook's article on fault injection testing for more information on developing a hypothesis-driven suite of automated chaos test. The following list of chaos testing tools as well as this section in the article linked above have more details on available platforms and tooling for this purpose: Azure Chaos Studio - An in-preview tool for orchestrating controlled fault injection experiments on Azure resources. Chaos toolkit - A declarative, modular chaos platform with many extensions, including the Azure actions and probes kit . Kraken - An Openshift-specific chaos tool, maintained by Redhat. Chaos Monkey - The Netflix platform which popularized chaos engineering (doesn't support Azure OOTB). Many services meshes, like Linkerd , offer fault injection tooling through the use of their sidecars. Chaos Mesh Simmy - A .NET library for chaos testing and fault injection integrated with the Polly library for resilience engineering. This ISE dev blog post provides code snippets as an example of how to use Polly and Simmy to implement a hypothesis-driven approach to resilience and chaos testing. Analyze all Failures Writing up a post-mortem is a great way to document the root causes, and action items for your failures. They're also a great way to track recurring issues, and create a strong case for prioritizing fixes. This can even be tied into your regular Agile restrospectives .","title":"Reliability"},{"location":"reliability/#reliability","text":"All the other ISE Engineering Fundamentals work towards a more reliable infrastructure. Automated integration and deployment ensures code is properly tested, and helps remove human error, while slow releases build confidence in the code. Observability helps more quickly pinpoint errors when they arise to get back to a stable state, and so on. However, there are some additional steps we can take, that don't neatly fit into the previous categories, to help ensure a more reliable solution. We'll explore these below.","title":"Reliability"},{"location":"reliability/#remove-foot-guns","text":"Prevent your dev team from shooting themselves in the foot. People make mistakes; any mistake made in production is not the fault of that person, it's the collective fault of the system to not prevent that mistake from happening. Check out the below list for some common tooling to remove these foot guns: In Kubernetes, leverage Admission Controllers to prevent \"bad things\" from happening. You can create custom controllers using the Webhook Admission controller. Gatekeeper is a pre-built Webhook Admission controller, leveraging OPA underneath the hood, with support for some out-of-the-box protections If a user ever makes a mistake, don't ask: \"how could somebody possibly do that?\", do ask: \"how can we prevent this from happening in the future?\"","title":"Remove \"Foot-Guns\""},{"location":"reliability/#autoscaling","text":"Whenever possible, leverage autoscaling for your deployments. Vertical autoscaling can scale your VMs by tuning parameters like CPU, disk, and RAM, while horizontal autoscaling can tune the number of running images backing your deployments. Autoscaling can help your system respond to inorganic growth in traffic, and prevent failing requests due to resource starvation. Note: In environments like K8s, both horizontal and vertical autoscaling are offered as a native solution. The VMs backing each Pod however, may also need autoscaling to handle an increase in the number of Pods. It should also be noted that the parameters that affect autoscaling can be difficult to tune. Typical metrics like CPU or RAM utilization, or request rate may not be enough. Sometimes you might want to consider custom metrics, like cache eviction rate.","title":"Autoscaling"},{"location":"reliability/#load-shedding-dos-protection","text":"Often we think of Denial of Service [DOS] attacks as an act from a malicious actor, so we place some load shedding at the gates to our system and call it a day. In reality, many DOS attacks are unintentional, and self-inflicted. A bad deployment that takes down a Cache results in hammering downstream services. Polling from a distributed system synchronizes and results in a thundering herd . A misconfiguration results in an error which triggers clients to retry uncontrollably. Requests append to a stored object until it is so big that future reads crash the server. The list goes on. Follow these steps to protect yourself: Add a jitter (random) to any action that occurs from a non-user triggered flow (ie: add a random duration to the sleep in a cron, or job that continuously polls a downstream service). Implement exponential backoff retry policies in your client code Add load shedding to your servers (yes, your internal microservices too). This can be configured easily when leveraging a sidecar like envoy. Be careful when deserializing user requests, and use buffer limits. ie: HTTP/gRPC Servers can set limits on how much data will get read from the socket. Set alerts for utilization, servers restarting, or going offline to detect when your system may be failing. These types of errors can result in Cascading Failures, where a non-critical portion of your system takes down the entire service. Plan accordingly, and make sure to put extra thought into how your system might degrade during failures.","title":"Load shedding &amp; DOS Protection"},{"location":"reliability/#backup-data","text":"Data gets lost, corrupted, or accidentally deleted. It happens. Take data backups to help get your system back up online as soon as possible. It can happen in the application stack, with code deleting or corrupting data, or at the storage layer by losing the volumes, or losing encryption keys. Consider things like: How long will it take to restore data. How much data loss can you tolerate. How long will it take you to notice there is data loss. Look into the difference between snapshot and incremental backups. A good policy might be to take incremental backups on a period of N, and a snapshot backup on a period of M (where N < M).","title":"Backup Data"},{"location":"reliability/#target-uptime-failing-gracefully","text":"It's a known fact that systems cannot target 100% uptime. There are too many factors in today's software systems to achieve this, many outside of our control. Even a service that never gets updated and is 100% bug free will fail. Upstream DNS servers have issues all the time. Hardware breaks. Power outages, backup generators fail. The world is chaotic. Good services target some number of \"9's\" of uptime. ie: 99.99% uptime means that the system has a \"budget\" of 4 minutes and 22 seconds of uptime each month. Some months might achieve 100% uptime, which means that budget gets rolled over to the next month. What uptime means is different for everybody, and up to the service to define. A good practice is to use any leftover budget at the end of the period (ie: year, quarter), to intentionally take that service down, and ensure that the rest of your systems fail as expected. Often times other engineers and services come to rely on that additional achieved availability, and it can be healthy to ensure that systems fail gracefully. We can build graceful failure (or graceful degradation) into our software stack by anticipating failures. Some tactics include: Failover to healthy services Leader Election can be used to keep healthy services on standby in case the leader experiences issues. Entire cluster failover can redirect traffic to another region or availability zone. Propagate downstream failures of dependent services up the stack via health checks, so that your ingress points can re-route to healthy services. Circuit breakers can bail early on requests vs. propagating errors throughout the system. Consider using a well-known, tested library such as Polly (.NET) that enables configurable implementations of this and other common resilience and transient fault-handling patterns.","title":"Target Uptime &amp; Failing Gracefully"},{"location":"reliability/#practice","text":"None of the above recommendations will work if they are not tested . Your backups are meaningless if you don't know how to mount them. Your cluster failover and other mitigations will regress over time if they are not tested. Here are some tips to test the above:","title":"Practice"},{"location":"reliability/#maintain-playbooks","text":"No software service is complete without playbooks to navigate the developers through unfamiliar territory. Playbooks should be thorough and cover all known failure scenarios and mitigations.","title":"Maintain Playbooks"},{"location":"reliability/#run-maintenance-exercises","text":"Take the time to fabricate scenarios, and run a D&D style campaign to solve your issues. This can be as elaborate as spinning up a new environment and injecting errors, or as simple as asking the \"players\" to navigate to a dashboard and describing would they would see in the fabricated scenario (small amounts of imagination required). The playbooks should easily navigate the user to the correct solution/mitigation. If not, update your playbooks.","title":"Run maintenance exercises"},{"location":"reliability/#chaos-testing","text":"Leverage automated chaos testing to see how things break. You can read this playbook's article on fault injection testing for more information on developing a hypothesis-driven suite of automated chaos test. The following list of chaos testing tools as well as this section in the article linked above have more details on available platforms and tooling for this purpose: Azure Chaos Studio - An in-preview tool for orchestrating controlled fault injection experiments on Azure resources. Chaos toolkit - A declarative, modular chaos platform with many extensions, including the Azure actions and probes kit . Kraken - An Openshift-specific chaos tool, maintained by Redhat. Chaos Monkey - The Netflix platform which popularized chaos engineering (doesn't support Azure OOTB). Many services meshes, like Linkerd , offer fault injection tooling through the use of their sidecars. Chaos Mesh Simmy - A .NET library for chaos testing and fault injection integrated with the Polly library for resilience engineering. This ISE dev blog post provides code snippets as an example of how to use Polly and Simmy to implement a hypothesis-driven approach to resilience and chaos testing.","title":"Chaos Testing"},{"location":"reliability/#analyze-all-failures","text":"Writing up a post-mortem is a great way to document the root causes, and action items for your failures. They're also a great way to track recurring issues, and create a strong case for prioritizing fixes. This can even be tied into your regular Agile restrospectives .","title":"Analyze all Failures"},{"location":"resources/templates/","text":"project-xyz Description of the project Deploying to Azure Getting started Dependencies Run it locally Code of conduct By participating in this project, you agree to abide by the Microsoft Open Source Code of Conduct","title":"project-xyz"},{"location":"resources/templates/#project-xyz","text":"Description of the project","title":"project-xyz"},{"location":"resources/templates/#deploying-to-azure","text":"","title":"Deploying to Azure"},{"location":"resources/templates/#getting-started","text":"","title":"Getting started"},{"location":"resources/templates/#dependencies","text":"","title":"Dependencies"},{"location":"resources/templates/#run-it-locally","text":"","title":"Run it locally"},{"location":"resources/templates/#code-of-conduct","text":"By participating in this project, you agree to abide by the Microsoft Open Source Code of Conduct","title":"Code of conduct"},{"location":"resources/templates/CONTRIBUTING/","text":"Contributing We love pull requests from everyone. By participating in this project, you agree to abide by the Microsoft Open Source Code of Conduct Fork, then clone the repo Make sure the tests pass Make your change. Add tests for your change. Make the tests pass Push to your fork and submit a pull request . At this point you're waiting on us. We like to at least comment on pull requests within three business days (and, typically, one business day). We may suggest some changes or improvements or alternatives. Some things that will increase the chance that your pull request is accepted: Write tests. Follow our engineering playbook and the style guide for this project. Write a good commit message .","title":"Contributing"},{"location":"resources/templates/CONTRIBUTING/#contributing","text":"We love pull requests from everyone. By participating in this project, you agree to abide by the Microsoft Open Source Code of Conduct Fork, then clone the repo Make sure the tests pass Make your change. Add tests for your change. Make the tests pass Push to your fork and submit a pull request . At this point you're waiting on us. We like to at least comment on pull requests within three business days (and, typically, one business day). We may suggest some changes or improvements or alternatives. Some things that will increase the chance that your pull request is accepted: Write tests. Follow our engineering playbook and the style guide for this project. Write a good commit message .","title":"Contributing"},{"location":"security/","text":"Security Developers working on projects should adhere to industry-recommended standard practices for secure design and implementation of code. For the purposes of our customers, this means our engineers should understand the OWASP Top 10 Web Application Security Risks , as well as how to mitigate as many of them as possible, using the resources below. If you are looking for a fast way to get started evaluating your application or design, check out the \"Secure Coding Practices Quick Reference\" document below, which contains an itemized checklist of high-level concepts you can validate are being done properly. This checklist covers many common errors associated with the OWASP Top 10 list linked above, and should be the minimum amount of effort being put into security. Requesting Security Reviews When requesting a security review for your application, please make sure you have familiarized yourself with the Rules of Engagement . This will help you to prepare the application for testing, as well as understand the scope limits of the test. Quick References Secure Coding Practices Quick Reference Web Application Security Quick Reference Security Mindset/Creating a Security Program Quick Start Credential Scanning / Secret Detection Threat Modelling Azure DevOps Security Security Engineering DevSecOps Practices Azure DevOps Data Protection Overview Security and Identity in Azure DevOps Security Code Analysis DevSecOps Introduce security to your project at early stages. The DevSecOps section covers security practices, automation, tools and frameworks as part of the application CI. OWASP Cheat Sheets Note: OWASP is considered to be the gold-standard in computer security information. OWASP maintains an extensive series of cheat sheets which cover all the OWASP Top 10 and more. Below, many of the more relevant cheat sheets have been summarized. To view all the cheat sheets, check out their Cheat Sheet Index . Access Control Basics Attack Surface Analysis Content Security Policy (CSP) Cross-Site Request Forgery (CSRF) Prevention Cross-Site Scripting (XSS) Prevention Cryptographic Storage Deserialization Docker/Kubernetes (k8s) Security Input Validation Key Management OS Command Injection Defense Query Parameterization Examples Server-Side Request Forgery Prevention SQL Injection Prevention Unvalidated Redirects and Forwards Web Service Security XML Security Recommended Tools Check out the list of tools to help enable security in your projects. Note: Although some tools are agnostic, the below list is geared towards Cloud Native security, with a focus on Kubernetes. Vulnerability Scanning SonarCloud Integrates with Azure Devops with the click of a button. Snyk Trivy Cloudsploit Anchore Other tools from OWASP See why you should check for vulnerabilities at all layers of the stack , as well as a couple of other useful tips to reduce surface area for attacks. Runtime Security Falco Tracee Kubelinter May not fully qualify as runtime security, but helps ensure you're enabling best practices. Binary Authorization Binary authorization can happen both at the docker registry layer, and runtime (ie: via a K8s admission controller). The authorization check ensures that the image is signed by a trusted authority. This can occur for both (pre-approved) 3rd party images, and internal images. Taking this a step further the signing should occur only on images where all code has been reviewed and approved. Binary authorization can both reduce the impact of damage from a compromised hosting environment, and the damage from malicious insiders. Harbor Operator available Portieris Notary Note harbor leverages notary internally. TUF Other K8s Security OPA , Gatekeeper , and the Gatekeeper Library cert-manager for easy certificate provisioning and automatic rotation. Quickly enable mTLS between your microservices with Linkerd . Useful links Non-Functional Requirements Guidance","title":"Security"},{"location":"security/#security","text":"Developers working on projects should adhere to industry-recommended standard practices for secure design and implementation of code. For the purposes of our customers, this means our engineers should understand the OWASP Top 10 Web Application Security Risks , as well as how to mitigate as many of them as possible, using the resources below. If you are looking for a fast way to get started evaluating your application or design, check out the \"Secure Coding Practices Quick Reference\" document below, which contains an itemized checklist of high-level concepts you can validate are being done properly. This checklist covers many common errors associated with the OWASP Top 10 list linked above, and should be the minimum amount of effort being put into security.","title":"Security"},{"location":"security/#requesting-security-reviews","text":"When requesting a security review for your application, please make sure you have familiarized yourself with the Rules of Engagement . This will help you to prepare the application for testing, as well as understand the scope limits of the test.","title":"Requesting Security Reviews"},{"location":"security/#quick-references","text":"Secure Coding Practices Quick Reference Web Application Security Quick Reference Security Mindset/Creating a Security Program Quick Start Credential Scanning / Secret Detection Threat Modelling","title":"Quick References"},{"location":"security/#azure-devops-security","text":"Security Engineering DevSecOps Practices Azure DevOps Data Protection Overview Security and Identity in Azure DevOps Security Code Analysis","title":"Azure DevOps Security"},{"location":"security/#devsecops","text":"Introduce security to your project at early stages. The DevSecOps section covers security practices, automation, tools and frameworks as part of the application CI.","title":"DevSecOps"},{"location":"security/#owasp-cheat-sheets","text":"Note: OWASP is considered to be the gold-standard in computer security information. OWASP maintains an extensive series of cheat sheets which cover all the OWASP Top 10 and more. Below, many of the more relevant cheat sheets have been summarized. To view all the cheat sheets, check out their Cheat Sheet Index . Access Control Basics Attack Surface Analysis Content Security Policy (CSP) Cross-Site Request Forgery (CSRF) Prevention Cross-Site Scripting (XSS) Prevention Cryptographic Storage Deserialization Docker/Kubernetes (k8s) Security Input Validation Key Management OS Command Injection Defense Query Parameterization Examples Server-Side Request Forgery Prevention SQL Injection Prevention Unvalidated Redirects and Forwards Web Service Security XML Security","title":"OWASP Cheat Sheets"},{"location":"security/#recommended-tools","text":"Check out the list of tools to help enable security in your projects. Note: Although some tools are agnostic, the below list is geared towards Cloud Native security, with a focus on Kubernetes. Vulnerability Scanning SonarCloud Integrates with Azure Devops with the click of a button. Snyk Trivy Cloudsploit Anchore Other tools from OWASP See why you should check for vulnerabilities at all layers of the stack , as well as a couple of other useful tips to reduce surface area for attacks. Runtime Security Falco Tracee Kubelinter May not fully qualify as runtime security, but helps ensure you're enabling best practices. Binary Authorization Binary authorization can happen both at the docker registry layer, and runtime (ie: via a K8s admission controller). The authorization check ensures that the image is signed by a trusted authority. This can occur for both (pre-approved) 3rd party images, and internal images. Taking this a step further the signing should occur only on images where all code has been reviewed and approved. Binary authorization can both reduce the impact of damage from a compromised hosting environment, and the damage from malicious insiders. Harbor Operator available Portieris Notary Note harbor leverages notary internally. TUF Other K8s Security OPA , Gatekeeper , and the Gatekeeper Library cert-manager for easy certificate provisioning and automatic rotation. Quickly enable mTLS between your microservices with Linkerd .","title":"Recommended Tools"},{"location":"security/#useful-links","text":"Non-Functional Requirements Guidance","title":"Useful links"},{"location":"security/rules-of-engagement/","text":"Rules of Engagement When performing application security analysis, it is expected that the tester follow the Rules of Engagement as laid out below. This is to standardize the scope of application testing and provide a concrete awareness of what is considered \"out of scope\" for security analysis. Rules of Engagement - For those requesting review Web Application Firewalls can be up and configured, but do not enable any automatic blocking. This can greatly slow down the person performing the test. Similarly, if a service is running on a virtual machine, ensure services such as fail2ban are disabled. You cannot make changes to the running application until the test is complete. This is to prevent accidentally breaking an otherwise valid attack in progress. Any review results are not considered as \"final\". A security review should always be performed by a security team orchestrated by the customer prior to moving an application into production. If a customer requires further assistance, they can engage Premier Support. Rules of Engagement - For those performing tests Do not attempt to perform Denial-of-Service attacks or otherwise crash services. Heavy active scanning is tolerated (and is assumed to be somewhat of a load test) but deliberate takedowns are not permitted. Do not interact with human beings. Phishing credentials or other such client-side attacks are off-limits. Detailing XSS and similar attacks is encouraged as a part of the test, but do not leverage these against internal users or customers. Attack from a single point. Especially if the application is currently in the customer's hands, provide the IP address or hostname of the attacking host to avoid setting off alarms.","title":"Rules of Engagement"},{"location":"security/rules-of-engagement/#rules-of-engagement","text":"When performing application security analysis, it is expected that the tester follow the Rules of Engagement as laid out below. This is to standardize the scope of application testing and provide a concrete awareness of what is considered \"out of scope\" for security analysis.","title":"Rules of Engagement"},{"location":"security/rules-of-engagement/#rules-of-engagement-for-those-requesting-review","text":"Web Application Firewalls can be up and configured, but do not enable any automatic blocking. This can greatly slow down the person performing the test. Similarly, if a service is running on a virtual machine, ensure services such as fail2ban are disabled. You cannot make changes to the running application until the test is complete. This is to prevent accidentally breaking an otherwise valid attack in progress. Any review results are not considered as \"final\". A security review should always be performed by a security team orchestrated by the customer prior to moving an application into production. If a customer requires further assistance, they can engage Premier Support.","title":"Rules of Engagement - For those requesting review"},{"location":"security/rules-of-engagement/#rules-of-engagement-for-those-performing-tests","text":"Do not attempt to perform Denial-of-Service attacks or otherwise crash services. Heavy active scanning is tolerated (and is assumed to be somewhat of a load test) but deliberate takedowns are not permitted. Do not interact with human beings. Phishing credentials or other such client-side attacks are off-limits. Detailing XSS and similar attacks is encouraged as a part of the test, but do not leverage these against internal users or customers. Attack from a single point. Especially if the application is currently in the customer's hands, provide the IP address or hostname of the attacking host to avoid setting off alarms.","title":"Rules of Engagement - For those performing tests"},{"location":"security/threat-modelling-example/","text":"Overview This document covers the threat models for a sample project which takes video frames from video camera and process these frames on IoTEdge device and send them to Azure Cognitive Service to get the audio output. These models can be considered as reference template to show how we can construct threat modeling document. Each of the labeled entities in the figures below are accompanied by meta-information which describe the threats, recommended mitigations, and the associated security principle or goal . Architecture Diagram Assets Asset Entry Point Trust Level Azure Blob Storage Http End point Connection String Azure Monitor Http End Point Connection String Azure Cognitive Service Http End Point Connection String IoTEdge Module: M1 Http End Point Public Access (Local Area Network) IoTEdge Module: M2 Http End Point Public Access (Local Area Network) IoTEdge Module: M3 Http End Point Public Access (Local Area Network) IoTEdge Module: IoTEdgeMetricsCollector Http EndPoint Public Access (Local Area Network) Application Insights Http End Point Connection String Data Flow Diagram Client Browser makes requests to the M1 IoTEdge module. Browser and IoTEdge device are on same network, so browser directly hits the webapp URL. M1 IoTEdge module interacts with other two IoTEdge modules to render live stream from video device and display order scanning results via WebSockets. IoTEdge modules interact with Azure Cognitive service to get the translated text via OCR and audio stream via Text to Speech Service. IoTEdge modules send telemetry information to application insights. IoTEdge device is deployed with IoTEdge runtime which interacts with IoTEdge hub for deployments. IoTEdge module also sends some data to Azure storage which is required for debugging purpose. Cognitive service, application insights and Azure Storage are authenticated using connection strings which are stored in GitHub secrets and deployed using CI/CD pipelines. Threat List Assumptions Secrets like ACR credentials are stored in GitHub secrets store which are deployed to IoTEdge Device by CI/CD pipelines. However, CI/CD pipelines are out of scope. Threats Vector Threat Mitigation (1) Sniff Unencrypted data can be intercepted in transit Not Mitigated (2) Access to M1 IoT Edge Module Unauthorized Access to M1 IoT Edge Module Not Mitigated (3) Access to M2 IoT Edge Module Unauthorized Access to M2 IoT Edge Module Not Mitigated (4) Access to M3 IoT Edge Module Unauthorized Access to M3 IoT Edge Module Not Mitigated (5) Steal Storage Credentials Unauthorized Access to M2 IoTEdge Module where database secrets are used Not Mitigated (6) Denial Of Service Dos attack on all IoTEdge Modules since there is no Authentication Not Mitigated (7) Tampering with Log data Application Insights is connected via Connection String which is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker can tamper the log data. Not Mitigated (8) Tampering with video camera device. Video camera path is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker can tamper the video feed or use another video source or fake video stream. Not Mitigated (9) Spoofing Tampering Azure IoT Hub connection string is stored in .env file on IoTEdge Device. Once user gains access to the device, .env file can be read and attacker cause Dos attacks on IoTHub Not Mitigated (10) Denial of Service DDOS attack Azure Cognitive Service connection string is stored in .env file on IoTEdge Device. Once user gains access to the device, .env file can be read and attacker cause DoS attacks on Azure Cognitive Service Not Mitigated (11) Tampering with Storage Storage connection string is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker can tamper data on storage or read from the storage. Not Mitigated (12) Tampering with Storage Cognitive Service connection string is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker use cognitive service API's for his own purpose causing increase cost to use. Not Mitigated Threat Model Threat Properties Notable Threats # Principle Threat Mitigation 1 Authenticity Since channel from browser to IoTEdge Module is not authenticated, anyone can spoof it once gains access to WiFi network. Add authentication in all IoTEdge modules. 2 Confidentiality and Integrity As a result of the vulnerability of not encrypting data, plaintext data could be intercepted during transit via a man-in-the-middle (MitM) attack. Sensitive data could be exposed or tampered with to allow further exploits. All products and services must encrypt data in transit using approved cryptographic protocols and algorithms. Use TLS to encrypt all HTTP-based network traffic. Use other mechanisms, such as IPSec, to encrypt non-HTTP network traffic that contains customer or confidential data. Applies to data flow from browser to IoTEdge modules. 3 Confidentiality Data is a valuable target for most threat actors and attacking the data store directly, as opposed to stealing it during transit, allows data exfiltration at a much larger scale. In our scenario we are storing some data in Azure Blob containers. All customer or confidential data must be encrypted before being written to non-volatile storage media (encrypted at-rest) per the following requirements. Use approved algorithms. This includes AES-256, AES-192, or AES-128. Encryption must be enabled before writing data to storage. Applies to all data stores on the diagram. Azure Storage encrypt data at rest by default (AES-256). 4 Confidentiality Broken or non-existent authentication mechanisms may allow attackers to gain access to confidential information. All services within the Azure Trust Boundary must authenticate all incoming requests, including requests coming from the same network. Proper authorizations should also be applied to prevent unnecessary privileges. Whenever available, use Azure Managed Identities to authenticate services. Service Principals may be used if Managed Identities are not supported. External users or services may use UserName + Passwords, Tokens, Certificates or Connection Strings to authenticate, provided these are stored on Key Vault or any other vaulting solution. For authorization, use Azure RBAC to segregate duties and grant only the least amount of access to perform an action at a particular scope. Applies to Azure services like Azure IoTHub, Azure Cognitive Service, Azure Application Insights are authenticated using connection strings. 5 Confidentiality and Integrity A large attack surface, particularly those that are exposed on the internet, will increase the probability of a compromise Minimize the application attack surface by limiting publicly exposed services. Use strong network controls by using virtual networks, subnets and network security groups to protect against unsolicited traffic. Use Azure Private Endpoint for Azure Storage. Applies to Azure storage. 6 Confidentiality and Integrity Browser and IoTEdge device are connected over in store WIFI network Minimize the attack on WIFI network by using secure algorithm like WPA2. Applies to connection between browser and IoTEdge devices. 7 Integrity Exploitation of insufficient logging and monitoring is the bedrock of nearly every major incident. Attackers rely on the lack of monitoring and timely response to achieve their goals without being detected. Logging of critical application events must be performed to ensure that, should a security incident occur, incident response and root-cause analysis may be done. Steps must also be taken to ensure that logs are available and cannot be overwritten or destroyed through malicious or accidental occurrences. At a minimum, the following events should be logged. Login/logout events Privilege delegation events Security validation failures (e.g. input validation or authorization check failures) Application errors and system events Application and system start-ups and shut-downs, as well as logging initialization 6 Availability Exploitation of the public endpoint by malicious actors who aim to render the service unavailable to its intended users by interrupting the service normal activity, for instance by flooding the target service with requests until normal traffic is unable to be processed (Denial of Service) Application is accessed via web app deployed as one of the IoTEdge modules on the IoTEdge device. This app can be accessed by anyone in the local area network. Hence DDoS attacks are possible if the attacker gained access to local area network. All services deployed as IoTEdge modules must use authentication. Applies to services deployed on IoTEdge device 7 Integrity Tampering with data Data at rest, in Azure Storage must be encrypted on disk. Data at rest, in Azure can be protected further by Azure Advanced Threat Protection. Data at rest, in Azure Storage and Azure monitor workspace will use Azure RBAC to segregate duties and grant only the least amount of access to perform an action at a particular scope. Data in motion between services can be encrypted in TLS 1.2 Applies to data flow between IoTEdge modules and Azure Services. Security Principles Confidentiality refers to the objective of keeping data private or secret. In practice, it\u2019s about controlling access to data to prevent unauthorized disclosure. Integrity is about ensuring that data has not been tampered with and, therefore, can be trusted. It is correct, authentic, and reliable. Availability means that networks, systems, and applications are up and running. It ensures that authorized users have timely, reliable access to resources when they are needed.","title":"Overview"},{"location":"security/threat-modelling-example/#overview","text":"This document covers the threat models for a sample project which takes video frames from video camera and process these frames on IoTEdge device and send them to Azure Cognitive Service to get the audio output. These models can be considered as reference template to show how we can construct threat modeling document. Each of the labeled entities in the figures below are accompanied by meta-information which describe the threats, recommended mitigations, and the associated security principle or goal .","title":"Overview"},{"location":"security/threat-modelling-example/#architecture-diagram","text":"","title":"Architecture Diagram"},{"location":"security/threat-modelling-example/#assets","text":"Asset Entry Point Trust Level Azure Blob Storage Http End point Connection String Azure Monitor Http End Point Connection String Azure Cognitive Service Http End Point Connection String IoTEdge Module: M1 Http End Point Public Access (Local Area Network) IoTEdge Module: M2 Http End Point Public Access (Local Area Network) IoTEdge Module: M3 Http End Point Public Access (Local Area Network) IoTEdge Module: IoTEdgeMetricsCollector Http EndPoint Public Access (Local Area Network) Application Insights Http End Point Connection String","title":"Assets"},{"location":"security/threat-modelling-example/#data-flow-diagram","text":"Client Browser makes requests to the M1 IoTEdge module. Browser and IoTEdge device are on same network, so browser directly hits the webapp URL. M1 IoTEdge module interacts with other two IoTEdge modules to render live stream from video device and display order scanning results via WebSockets. IoTEdge modules interact with Azure Cognitive service to get the translated text via OCR and audio stream via Text to Speech Service. IoTEdge modules send telemetry information to application insights. IoTEdge device is deployed with IoTEdge runtime which interacts with IoTEdge hub for deployments. IoTEdge module also sends some data to Azure storage which is required for debugging purpose. Cognitive service, application insights and Azure Storage are authenticated using connection strings which are stored in GitHub secrets and deployed using CI/CD pipelines.","title":"Data Flow Diagram"},{"location":"security/threat-modelling-example/#threat-list","text":"","title":"Threat List"},{"location":"security/threat-modelling-example/#assumptions","text":"Secrets like ACR credentials are stored in GitHub secrets store which are deployed to IoTEdge Device by CI/CD pipelines. However, CI/CD pipelines are out of scope.","title":"Assumptions"},{"location":"security/threat-modelling-example/#threats","text":"Vector Threat Mitigation (1) Sniff Unencrypted data can be intercepted in transit Not Mitigated (2) Access to M1 IoT Edge Module Unauthorized Access to M1 IoT Edge Module Not Mitigated (3) Access to M2 IoT Edge Module Unauthorized Access to M2 IoT Edge Module Not Mitigated (4) Access to M3 IoT Edge Module Unauthorized Access to M3 IoT Edge Module Not Mitigated (5) Steal Storage Credentials Unauthorized Access to M2 IoTEdge Module where database secrets are used Not Mitigated (6) Denial Of Service Dos attack on all IoTEdge Modules since there is no Authentication Not Mitigated (7) Tampering with Log data Application Insights is connected via Connection String which is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker can tamper the log data. Not Mitigated (8) Tampering with video camera device. Video camera path is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker can tamper the video feed or use another video source or fake video stream. Not Mitigated (9) Spoofing Tampering Azure IoT Hub connection string is stored in .env file on IoTEdge Device. Once user gains access to the device, .env file can be read and attacker cause Dos attacks on IoTHub Not Mitigated (10) Denial of Service DDOS attack Azure Cognitive Service connection string is stored in .env file on IoTEdge Device. Once user gains access to the device, .env file can be read and attacker cause DoS attacks on Azure Cognitive Service Not Mitigated (11) Tampering with Storage Storage connection string is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker can tamper data on storage or read from the storage. Not Mitigated (12) Tampering with Storage Cognitive Service connection string is stored in .env file on the IoTEdge device. Once user gains access to the device, .env file can be read and attacker use cognitive service API's for his own purpose causing increase cost to use. Not Mitigated","title":"Threats"},{"location":"security/threat-modelling-example/#threat-model","text":"","title":"Threat Model"},{"location":"security/threat-modelling-example/#threat-properties","text":"Notable Threats # Principle Threat Mitigation 1 Authenticity Since channel from browser to IoTEdge Module is not authenticated, anyone can spoof it once gains access to WiFi network. Add authentication in all IoTEdge modules. 2 Confidentiality and Integrity As a result of the vulnerability of not encrypting data, plaintext data could be intercepted during transit via a man-in-the-middle (MitM) attack. Sensitive data could be exposed or tampered with to allow further exploits. All products and services must encrypt data in transit using approved cryptographic protocols and algorithms. Use TLS to encrypt all HTTP-based network traffic. Use other mechanisms, such as IPSec, to encrypt non-HTTP network traffic that contains customer or confidential data. Applies to data flow from browser to IoTEdge modules. 3 Confidentiality Data is a valuable target for most threat actors and attacking the data store directly, as opposed to stealing it during transit, allows data exfiltration at a much larger scale. In our scenario we are storing some data in Azure Blob containers. All customer or confidential data must be encrypted before being written to non-volatile storage media (encrypted at-rest) per the following requirements. Use approved algorithms. This includes AES-256, AES-192, or AES-128. Encryption must be enabled before writing data to storage. Applies to all data stores on the diagram. Azure Storage encrypt data at rest by default (AES-256). 4 Confidentiality Broken or non-existent authentication mechanisms may allow attackers to gain access to confidential information. All services within the Azure Trust Boundary must authenticate all incoming requests, including requests coming from the same network. Proper authorizations should also be applied to prevent unnecessary privileges. Whenever available, use Azure Managed Identities to authenticate services. Service Principals may be used if Managed Identities are not supported. External users or services may use UserName + Passwords, Tokens, Certificates or Connection Strings to authenticate, provided these are stored on Key Vault or any other vaulting solution. For authorization, use Azure RBAC to segregate duties and grant only the least amount of access to perform an action at a particular scope. Applies to Azure services like Azure IoTHub, Azure Cognitive Service, Azure Application Insights are authenticated using connection strings. 5 Confidentiality and Integrity A large attack surface, particularly those that are exposed on the internet, will increase the probability of a compromise Minimize the application attack surface by limiting publicly exposed services. Use strong network controls by using virtual networks, subnets and network security groups to protect against unsolicited traffic. Use Azure Private Endpoint for Azure Storage. Applies to Azure storage. 6 Confidentiality and Integrity Browser and IoTEdge device are connected over in store WIFI network Minimize the attack on WIFI network by using secure algorithm like WPA2. Applies to connection between browser and IoTEdge devices. 7 Integrity Exploitation of insufficient logging and monitoring is the bedrock of nearly every major incident. Attackers rely on the lack of monitoring and timely response to achieve their goals without being detected. Logging of critical application events must be performed to ensure that, should a security incident occur, incident response and root-cause analysis may be done. Steps must also be taken to ensure that logs are available and cannot be overwritten or destroyed through malicious or accidental occurrences. At a minimum, the following events should be logged. Login/logout events Privilege delegation events Security validation failures (e.g. input validation or authorization check failures) Application errors and system events Application and system start-ups and shut-downs, as well as logging initialization 6 Availability Exploitation of the public endpoint by malicious actors who aim to render the service unavailable to its intended users by interrupting the service normal activity, for instance by flooding the target service with requests until normal traffic is unable to be processed (Denial of Service) Application is accessed via web app deployed as one of the IoTEdge modules on the IoTEdge device. This app can be accessed by anyone in the local area network. Hence DDoS attacks are possible if the attacker gained access to local area network. All services deployed as IoTEdge modules must use authentication. Applies to services deployed on IoTEdge device 7 Integrity Tampering with data Data at rest, in Azure Storage must be encrypted on disk. Data at rest, in Azure can be protected further by Azure Advanced Threat Protection. Data at rest, in Azure Storage and Azure monitor workspace will use Azure RBAC to segregate duties and grant only the least amount of access to perform an action at a particular scope. Data in motion between services can be encrypted in TLS 1.2 Applies to data flow between IoTEdge modules and Azure Services.","title":"Threat Properties"},{"location":"security/threat-modelling-example/#security-principles","text":"Confidentiality refers to the objective of keeping data private or secret. In practice, it\u2019s about controlling access to data to prevent unauthorized disclosure. Integrity is about ensuring that data has not been tampered with and, therefore, can be trusted. It is correct, authentic, and reliable. Availability means that networks, systems, and applications are up and running. It ensures that authorized users have timely, reliable access to resources when they are needed.","title":"Security Principles"},{"location":"security/threat-modelling/","text":"Threat Modeling Threat modeling is an effective way to help secure your systems, applications, networks, and services. It's a systematic approach that identifies potential threats and recommendations to help reduce risk and meet security objectives earlier in the development lifecycle. Threat Modeling Phases Diagram Capture all requirements for your system and create a data-flow diagram Identify Apply a threat-modeling framework to the data-flow diagram and find potential security issues. Here we can use STRIDE framework to identify the threats. Mitigate Decide how to approach each issue with the appropriate combination of security controls. Validate Verify requirements are met, issues are found, and security controls are implemented. Example of these phases is covered in the threat modelling example. More details about these phases can be found at Threat Modeling Security Fundamentals. Threat Modeling Example Here is an example of a threat modeling document which talks about the architecture and different phases involved in the threat modeling. This document can be used as reference template for creating threat modeling documents. References Threat Modeling Microsoft Threat Modeling Tool STRIDE (Threat modeling framework)","title":"Threat Modeling"},{"location":"security/threat-modelling/#threat-modeling","text":"Threat modeling is an effective way to help secure your systems, applications, networks, and services. It's a systematic approach that identifies potential threats and recommendations to help reduce risk and meet security objectives earlier in the development lifecycle.","title":"Threat Modeling"},{"location":"security/threat-modelling/#threat-modeling-phases","text":"Diagram Capture all requirements for your system and create a data-flow diagram Identify Apply a threat-modeling framework to the data-flow diagram and find potential security issues. Here we can use STRIDE framework to identify the threats. Mitigate Decide how to approach each issue with the appropriate combination of security controls. Validate Verify requirements are met, issues are found, and security controls are implemented. Example of these phases is covered in the threat modelling example. More details about these phases can be found at Threat Modeling Security Fundamentals.","title":"Threat Modeling Phases"},{"location":"security/threat-modelling/#threat-modeling-example","text":"Here is an example of a threat modeling document which talks about the architecture and different phases involved in the threat modeling. This document can be used as reference template for creating threat modeling documents.","title":"Threat Modeling Example"},{"location":"security/threat-modelling/#references","text":"Threat Modeling Microsoft Threat Modeling Tool STRIDE (Threat modeling framework)","title":"References"},{"location":"source-control/","text":"Source Control There are many options when working with Source Control. In ISE we use AzureDevOps for private repositories and GitHub for public repositories. Sections within Source Control Merge Strategies Branch Naming Versioning Working with Secrets Git Guidance Goal Following industry best practice to work in geo-distributed teams which encourage contributions from all across ISE as well as the broader OSS community Improve code quality by enforcing reviews before merging into main branches Improve traceability of features and fixes through a clean commit history General Guidance Consistency is important, so agree to the approach as a team before starting to code. Treat this as a design decision, so include a design proposal and review, in the same way as you would document all design decisions (see Working Agreements and Design Reviews ). Creating a new repository When creating a new repository, the team should at least do the following Agree on the branch , release and merge strategy Define the merge strategy ( linear or non-linear ) Lock the default branch and merge using pull requests (PRs) Agree on branch naming (e.g. user/your_alias/feature_name ) Establish branch/PR policies For public repositories the default branch should contain the following files: LICENSE README.md CONTRIBUTING.md Contributing to an existing repository When working on an existing project, git clone the repository and ensure you understand the team's branch, merge and release strategy (e.g. through the projects CONTRIBUTING.md file ). Mixed DevOps Environments For most engagements having a single hosted DevOps environment (i.e. Azure DevOps) is the preferred path but there are times when a mixed DevOps environment (i.e. Azure DevOps for Agile/Work item tracking & GitHub for Source Control) is needed due to customer requirements. When working in a mixed environment: Manually tag PR's in work items Ensure that the scope of work items / tasks align with PR's Resources Git --local-branching-on-the-cheap Azure DevOps ISE Git details details on how to use Git as part of a ISE project. GitHub - Removing sensitive data from a repository How Git Works Pluralsight course Mastering Git Pluralsight course","title":"Source Control"},{"location":"source-control/#source-control","text":"There are many options when working with Source Control. In ISE we use AzureDevOps for private repositories and GitHub for public repositories.","title":"Source Control"},{"location":"source-control/#sections-within-source-control","text":"Merge Strategies Branch Naming Versioning Working with Secrets Git Guidance","title":"Sections within Source Control"},{"location":"source-control/#goal","text":"Following industry best practice to work in geo-distributed teams which encourage contributions from all across ISE as well as the broader OSS community Improve code quality by enforcing reviews before merging into main branches Improve traceability of features and fixes through a clean commit history","title":"Goal"},{"location":"source-control/#general-guidance","text":"Consistency is important, so agree to the approach as a team before starting to code. Treat this as a design decision, so include a design proposal and review, in the same way as you would document all design decisions (see Working Agreements and Design Reviews ).","title":"General Guidance"},{"location":"source-control/#creating-a-new-repository","text":"When creating a new repository, the team should at least do the following Agree on the branch , release and merge strategy Define the merge strategy ( linear or non-linear ) Lock the default branch and merge using pull requests (PRs) Agree on branch naming (e.g. user/your_alias/feature_name ) Establish branch/PR policies For public repositories the default branch should contain the following files: LICENSE README.md CONTRIBUTING.md","title":"Creating a new repository"},{"location":"source-control/#contributing-to-an-existing-repository","text":"When working on an existing project, git clone the repository and ensure you understand the team's branch, merge and release strategy (e.g. through the projects CONTRIBUTING.md file ).","title":"Contributing to an existing repository"},{"location":"source-control/#mixed-devops-environments","text":"For most engagements having a single hosted DevOps environment (i.e. Azure DevOps) is the preferred path but there are times when a mixed DevOps environment (i.e. Azure DevOps for Agile/Work item tracking & GitHub for Source Control) is needed due to customer requirements. When working in a mixed environment: Manually tag PR's in work items Ensure that the scope of work items / tasks align with PR's","title":"Mixed DevOps Environments"},{"location":"source-control/#resources","text":"Git --local-branching-on-the-cheap Azure DevOps ISE Git details details on how to use Git as part of a ISE project. GitHub - Removing sensitive data from a repository How Git Works Pluralsight course Mastering Git Pluralsight course","title":"Resources"},{"location":"source-control/component-versioning/","text":"Component Versioning Goal Larger applications consist of multiple components that reference each other and rely on compatibility of the interfaces/contracts of the components. To achieve the goal of loosely coupled applications, each component should be versioned independently hence allowing developers to detect breaking changes or seamless updates just by looking at the version number. Version Numbers and Versioning schemes For developers or other components to detect breaking changes the version number of a component is important. There is different versioning number schemes, e.g. major.minor[.build[.revision]] or major.minor[.maintenance[.build]] . Upon build / CI these version numbers are being generated. During CD / release components are pushed to a component repository such as Nuget, NPM, Docker Hub where a history of different versions is being kept. Each build the version number is incremented at the last digit. Updating the major / minor version indicates changes of the API / interfaces / contracts: Major Version: A breaking change Minor Version: A backwards-compatible minor change Build / Revision: No API change, just a different build. Semantic Versioning Semantic Versioning is a versioning scheme specifying how to interpret the different version numbers. The most common format is major.minor.patch . The version number is incremented based on the following rules: Major version when you make incompatible API changes, Minor version when you add functionality in a backwards-compatible manner, and Patch version when you make backwards-compatible bug fixes. Examples of semver version numbers: 1.0.0-alpha.1 : +1 commit after the alpha release of 1.0.0 2.1.0-beta : 2.1.0 in beta branch 2.4.2 : 2.4.2 release A common practice is to determine the version number during the build process. For this the source control repository is utilized to determine the version number automatically based the source code repository. The GitVersion tool uses the git history to generate repeatable and unique version number based on number of commits since last major or minor release commit messages tags branch names Version updates happen through: Commit messages or tags for Major / Minor / Revision updates. When using commit messages a convention such as Conventional Commits is recommended (see Git Guidance - Commit Message Structure ) Branch names (e.g. develop, release/..) for Alpha / Beta / RC Otherwise: Number of commits (+12, ...) Resources GitVersion Semantic Versioning Versioning in C#","title":"Component Versioning"},{"location":"source-control/component-versioning/#component-versioning","text":"","title":"Component Versioning"},{"location":"source-control/component-versioning/#goal","text":"Larger applications consist of multiple components that reference each other and rely on compatibility of the interfaces/contracts of the components. To achieve the goal of loosely coupled applications, each component should be versioned independently hence allowing developers to detect breaking changes or seamless updates just by looking at the version number.","title":"Goal"},{"location":"source-control/component-versioning/#version-numbers-and-versioning-schemes","text":"For developers or other components to detect breaking changes the version number of a component is important. There is different versioning number schemes, e.g. major.minor[.build[.revision]] or major.minor[.maintenance[.build]] . Upon build / CI these version numbers are being generated. During CD / release components are pushed to a component repository such as Nuget, NPM, Docker Hub where a history of different versions is being kept. Each build the version number is incremented at the last digit. Updating the major / minor version indicates changes of the API / interfaces / contracts: Major Version: A breaking change Minor Version: A backwards-compatible minor change Build / Revision: No API change, just a different build.","title":"Version Numbers and Versioning schemes"},{"location":"source-control/component-versioning/#semantic-versioning","text":"Semantic Versioning is a versioning scheme specifying how to interpret the different version numbers. The most common format is major.minor.patch . The version number is incremented based on the following rules: Major version when you make incompatible API changes, Minor version when you add functionality in a backwards-compatible manner, and Patch version when you make backwards-compatible bug fixes. Examples of semver version numbers: 1.0.0-alpha.1 : +1 commit after the alpha release of 1.0.0 2.1.0-beta : 2.1.0 in beta branch 2.4.2 : 2.4.2 release A common practice is to determine the version number during the build process. For this the source control repository is utilized to determine the version number automatically based the source code repository. The GitVersion tool uses the git history to generate repeatable and unique version number based on number of commits since last major or minor release commit messages tags branch names Version updates happen through: Commit messages or tags for Major / Minor / Revision updates. When using commit messages a convention such as Conventional Commits is recommended (see Git Guidance - Commit Message Structure ) Branch names (e.g. develop, release/..) for Alpha / Beta / RC Otherwise: Number of commits (+12, ...)","title":"Semantic Versioning"},{"location":"source-control/component-versioning/#resources","text":"GitVersion Semantic Versioning Versioning in C#","title":"Resources"},{"location":"source-control/merge-strategies/","text":"Merge strategies Agree if you want a linear or non-linear commit history. There are pros and cons to both approaches: Pro linear: Avoid messy git history, use linear history Con linear: Why you should stop using Git rebase Approach for non-linear commit history Merging topic into main A---B---C topic / \\ D---E---F---G---H main git fetch origin git checkout main git merge topic Two approaches to achieve a linear commit history Rebase topic branch before merging into main Before merging topic into main , we rebase topic with the main branch: A---B---C topic / \\ D---E---F-----------G---H main git checkout main git pull git checkout topic git rebase origin/main Create a PR topic --> main in Azure DevOps and approve using the squash merge option Rebase topic branch before squash merge into main Squash merging is a merge option that allows you to condense the Git history of topic branches when you complete a pull request. Instead of adding each commit on topic to the history of main , a squash merge takes all the file changes and adds them to a single new commit on main . A---B---C topic / D---E---F-----------G---H main Create a PR topic --> main in Azure DevOps and approve using the squash merge option","title":"Merge strategies"},{"location":"source-control/merge-strategies/#merge-strategies","text":"Agree if you want a linear or non-linear commit history. There are pros and cons to both approaches: Pro linear: Avoid messy git history, use linear history Con linear: Why you should stop using Git rebase","title":"Merge strategies"},{"location":"source-control/merge-strategies/#approach-for-non-linear-commit-history","text":"Merging topic into main A---B---C topic / \\ D---E---F---G---H main git fetch origin git checkout main git merge topic","title":"Approach for non-linear commit history"},{"location":"source-control/merge-strategies/#two-approaches-to-achieve-a-linear-commit-history","text":"","title":"Two approaches to achieve a linear commit history"},{"location":"source-control/merge-strategies/#rebase-topic-branch-before-merging-into-main","text":"Before merging topic into main , we rebase topic with the main branch: A---B---C topic / \\ D---E---F-----------G---H main git checkout main git pull git checkout topic git rebase origin/main Create a PR topic --> main in Azure DevOps and approve using the squash merge option","title":"Rebase topic branch before merging into main"},{"location":"source-control/merge-strategies/#rebase-topic-branch-before-squash-merge-into-main","text":"Squash merging is a merge option that allows you to condense the Git history of topic branches when you complete a pull request. Instead of adding each commit on topic to the history of main , a squash merge takes all the file changes and adds them to a single new commit on main . A---B---C topic / D---E---F-----------G---H main Create a PR topic --> main in Azure DevOps and approve using the squash merge option","title":"Rebase topic branch before squash merge into main"},{"location":"source-control/naming-branches/","text":"Naming branches When contributing to existing projects, look for and stick with the agreed branch naming convention. In open source projects this information is typically found in the contributing instructions, often in a file named CONTRIBUTING.md . In the beginning of a new project the team agrees on the project conventions including the branch naming strategy. Here's an example of a branch naming convention: <user alias>/[feature/bug/hotfix]/<work item ID>_<title> Which could translate to something as follows: dickinson/feature/271_add_more_cowbell The example above is just that - an example. The team can choose to omit or add parts. Choosing a branch convention can depend on the development model (e.g. trunk-based development ), versioning model, tools used in managing source control, matter of taste etc. Focus on simplicity and reducing ambiguity; a good branch naming strategy allows the team to understand the purpose and ownership of each branch in the repository.","title":"Naming branches"},{"location":"source-control/naming-branches/#naming-branches","text":"When contributing to existing projects, look for and stick with the agreed branch naming convention. In open source projects this information is typically found in the contributing instructions, often in a file named CONTRIBUTING.md . In the beginning of a new project the team agrees on the project conventions including the branch naming strategy. Here's an example of a branch naming convention: <user alias>/[feature/bug/hotfix]/<work item ID>_<title> Which could translate to something as follows: dickinson/feature/271_add_more_cowbell The example above is just that - an example. The team can choose to omit or add parts. Choosing a branch convention can depend on the development model (e.g. trunk-based development ), versioning model, tools used in managing source control, matter of taste etc. Focus on simplicity and reducing ambiguity; a good branch naming strategy allows the team to understand the purpose and ownership of each branch in the repository.","title":"Naming branches"},{"location":"source-control/secrets-management/","text":"Working with Secrets in Source Control The best way to avoid leaking secrets is to store them in local/private files and exclude these from git tracking with a .gitignore file. E.g. the following pattern will exclude all files with the extension .private.config : # remove private configuration *.private.config For more details on proper management of credentials and secrets in source control, and handling an accidental commit of secrets to source control, please refer to the Secrets Management document which has further information, split by language as well. As an extra security measure, apply credential scanning in your CI/CD pipeline.","title":"Working with Secrets in Source Control"},{"location":"source-control/secrets-management/#working-with-secrets-in-source-control","text":"The best way to avoid leaking secrets is to store them in local/private files and exclude these from git tracking with a .gitignore file. E.g. the following pattern will exclude all files with the extension .private.config : # remove private configuration *.private.config For more details on proper management of credentials and secrets in source control, and handling an accidental commit of secrets to source control, please refer to the Secrets Management document which has further information, split by language as well. As an extra security measure, apply credential scanning in your CI/CD pipeline.","title":"Working with Secrets in Source Control"},{"location":"source-control/git-guidance/","text":"Git Guidance What is Git? Git is a distributed version control system. This means that - unlike SVN or CVS - it doesn't use a central server to synchronize. Instead, every participant has a local copy of the source-code, and the attached history that is kept in sync by comparing commit hashes (SHA hashes of changes between each git commit command) making up the latest version (called HEAD ). For example: repo 1: A -> B -> C -> D -> HEAD repo 2: A -> B -> HEAD repo 3: X -> Y -> Z -> HEAD repo 4: A -> J -> HEAD Since they share a common history, repo 1 and repo 2 can be synchronized fairly easily, repo 4 may be able to synchronize as well, but it's going to have to add a commit (J, and maybe a merge commit) to repo 1. Repo 3 cannot be easily synchronized with the others. Everything related to these commits is stored in a local .git directory in the root of the repository. In other words, by using Git you are simply creating immutable file histories that uniquely identify the current state and therefore allow sharing whatever comes after. It's a Merkle tree . Be sure to run git help after Git installation to find really in-depth explanations of everything. Installation Git is a tool set that must be installed. Install Git and follow the First-Time Git Setup . A recommended installation is the Git Lens extension for Visual Studio Code . Visualize code authorship at a glance via Git blame annotations and code lens, seamlessly navigate and explore Git repositories, gain valuable insights via powerful comparison commands, and so much more. You can use these commands as well to configure your Git for Visual Studio Code as an editor for merge conflicts and diff tool. git config --global user.name [YOUR FIRST AND LAST NAME] git config --global user.email [YOUR E-MAIL ADDRESS] git config --global merge.tool vscode git config --global mergetool.vscode.cmd \"code --wait $MERGED\" git config --global diff.tool vscode git config --global difftool.vscode.cmd \"code --wait --diff $LOCAL $REMOTE\" Basic workflow A basic Git workflow is as follows; you can find more information on the specific steps below. # pull the latest changes git pull # start a new feature branch based on the develop branch git checkout -b feature/123-add-git-instructions develop # edit some files # add and commit the files git add <file> git commit -m \"add basic instructions\" # edit some files # add and commit the files git add <file> git commit -m \"add more advanced instructions\" # check your changes git status # push the branch to the remote repository git push --set-upstream origin feature/123-add-git-instructions Cloning Whenever you want to make a change to a repository, you need to first clone it. Cloning a repository pulls down a full copy of all the repository data, so that you can work on it locally. This copy includes all versions of every file and folder for the project. git clone https://github.com/username/repo-name You only need to clone the repository the first time. Before any subsequent branches you can sync any changes from the remote repository using git pull . Branching To avoid adding code that has not been peer reviewed to the main branch (ex. develop ) we typically work in feature branches, and merge these back to the main trunk with a Pull Request. It's even the case that often the main or develop branch of a repository are locked so that you can't make changes without a Pull Request. Therefore, it is useful to create a separate branch for your local/feature work, so that you can work and track your changes in this branch. Pull the latest changes and create a new branch for your work based on the trunk (in this case develop ). git pull git checkout -b feature/feature-name develop At any point, you can move between the branches with git checkout <branch> as long as you have committed or stashed your work. If you forget the name of your branch use git branch --all to list all branches. Committing To avoid losing work, it is good to commit often in small chunks. This allows you to revert only the last changes if you discover a problem and also neatly explains exactly what changes were made and why. Make changes to your branch Check what files were changed > git status On branch feature/271-basic-commit-info Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git restore <file>...\" to discard changes in working directory) modified: source-control/git-guidance/README.md Track the files you wish to include in the commit. To track all modified files: git add --all Or to track only specific files: git add source-control/git-guidance/README.md Commit the changes to your local branch with a descriptive commit message git commit -m \"add basic git instructions\" Pushing When you are done working, push your changes to a branch in the remote repository using: git push The first time you push, you first need to set an upstream branch as follows. After the first push, the --set-upstream parameter and branch name are not needed anymore. git push --set-upstream origin feature/feature-name Once the feature branch is pushed to the remote repository, it is visible to anyone with access to the code. Merging We encourage the use of Pull Request to merge code to the main repository to make sure that all code in the final product is code reviewed The Pull Request (PR) process in Azure DevOps , GitHub and other similar tools make it easy both to start a PR, review a PR and merge a PR. Merge Conflicts If multiple people make changes to the same files, you may need to resolve any conflicts that have occurred before you can merge. # check out the develop branch and get the latest changes git checkout develop git pull # check out your branch git checkout <your branch> # merge the develop branch into your branch git merge develop # if merge conflicts occur, above command will fail with a message telling you that there are conflicts to be solved # find which files need to be resolved git status You can start an interactive process that will show which files have conflicts. Sometimes you removed a file, where it was changed in dev. Or you made changes to some lines in a file where another developer made changes as well. If you went through the installation steps mentioned before, Visual Studio Code is set up as merge tool. You can also use a merge tool like kdiff3 . When editing conflicts occur, the process will automatically open Visual Studio Code where the conflicting parts are highlighted in green and blue, and you have make a choice: Accept your changes (current) Accept the changes from dev branch (incoming) Accept them both and fix the code (probably needed) Here are lines that are either unchanged from the common ancestor, or cleanly resolved because only one side changed. <<<<<<< yours:sample.txt Conflict resolution is hard; let's go shopping. ======= Git makes conflict resolution easy. >>>>>>> theirs:sample.txt And here is another line that is cleanly resolved or unmodified When this process is completed, make sure you test the result by executing build, checks, test to validate this merged result. # conclude the merge git merge --continue # verify that everything went ok git log # push the changes to the remote branch git push If no other conflicts appear, the PR can now be merged, and your branch deleted. Use squash to reduce your changes into a single commit, so the commit history can be within an acceptable size. Stashing changes git stash is super handy if you have un-committed changes in your working directory, but you want to work on a different branch. You can run git stash , save the un-committed work, and revert to the HEAD commit. You can retrieve the saved changes by running git stash pop : git stash \u2026 git stash pop Or you can move the current state into a new branch: git stash branch <new_branch_to_save_changes> Recovering lost commits If you \"lost\" a commit that you want to return to, for example to revert a git rebase where your commits got squashed, you can use git reflog to find the commit: git reflog Then you can use the reflog reference ( HEAD@{} ) to reset to a specific commit before the rebase: git reset HEAD@{2} Commit Best Practices A commit combines changes into a logical unit. Adding a descriptive commit message can aid in comprehending the code changes and understanding the rationale behind the modifications. Consider the following when making your commits: Make small commits. This makes changes easier to review, and if we need to revert a commit, we lose less work. Consider splitting the commit into separate commits with git add -p if it includes more than one logical change or bug fix. Don't mix whitespace changes with functional code changes. It is hard to determine if the line has a functional change or only removes a whitespace, so functional changes may go unnoticed. Commit complete and well tested code. Never commit incomplete code, get in the habit of testing your code before committing. Write good commit messages. Why is it necessary? It may fix a bug, add a feature, improve performance, or just be a change for the sake of correctness What effects does this change have? In addition to the obvious ones, this may include benchmarks, side effects etc. You can specify the default git editor, which allows you to write your commit messages using your favorite editor. The following command makes Visual Studio Code your default git editor: git config --global core.editor \"code --wait\" Commit Message Structure The essential parts of a commit message are: * subject line: a short description of the commit, maximum 50 characters long * body (optional): a longer description of the commit, wrapped at 72 characters, separated from the subject line by a blank line You are free to structure commit messages; however, git commands like git log utilize above structure. Therefore, it can be helpful to follow a convention within your team and to utilize git best. For example, Conventional Commits is a lightweight convention that complements SemVer , by describing the features, fixes, and breaking changes made in commit messages. See Component Versioning for more information on versioning. For more information on commit message conventions, see: A Note About Git Commit Messages Conventional Commits Git commit best practices How to Write a Git Commit Message How to Write Better Git Commit Messages Information in commit messages On commit messages Managing remotes A local git repository can have one or more backing remote repositories. You can list the remote repositories using git remote - by default, the remote repository you cloned from will be called origin > git remote -v origin https://github.com/microsoft/code-with-engineering-playbook.git (fetch) origin https://github.com/microsoft/code-with-engineering-playbook.git (push) Working with forks You can set multiple remotes. This is useful for example if you want to work with a forked version of the repository. For more info on how to set upstream remotes and syncing repositories when working with forks see GitHub's Working with forks documentation . Updating the remote if a repository changes names If the repository is changed in some way, for example a name change, or if you want to switch between HTTPS and SSH you need to update the remote # list the existing remotes > git remote -v origin https://hostname/username/repository-name.git (fetch) origin https://hostname/username/repository-name.git (push) # change the remote url git remote set-url origin https://hostname/username/new-repository-name.git # verify that the remote URL has changed > git remote -v origin https://hostname/username/new-repository-name.git (fetch) origin https://hostname/username/new-repository-name.git (push) Rolling back changes Reverting and deleting commits To \"undo\" a commit, run the following two commands: git revert and git reset . git revert creates a new commit that undoes commits while git reset allows deleting commits entirely from the commit history. If you have committed secrets/keys, git reset will remove them from the commit history! To delete the latest commit use HEAD~ : git reset --hard HEAD~1 To delete commits back to a specific commit, use the respective commit id: git reset --hard <sha1-commit-id> after you deleted the unwanted commits, push using force : git push origin HEAD --force Interactive rebase for undoing commits: git rebase -i HEAD~N The above command will open an interactive session in an editor (for example vim) with the last N commits sorted from oldest to newest. To undo a commit, delete the corresponding line of the commit and save the file. Git will rewrite the commits in the order listed in the file and because one (or many) commits were deleted, the commit will no longer be part of the history. Running rebase will locally modify the history, after this one can use force to push the changes to remote without the deleted commit. Using submodules Submodules can be useful in more complex deployment and/or development scenarios Adding a submodule to your repo git submodule add -b master <your_submodule> Initialize and pull a repo with submodules: git submodule init git submodule update --init --remote git submodule foreach git checkout master git submodule foreach git pull origin Working with images, video and other binary content Avoid committing frequently changed binary files, such as large images, video or compiled code to your git repository. Binary content is not diffed like text content, so cloning or pulling from the repository may pull each revision of the binary file. One solution to this problem is Git LFS (Git Large File Storage) - an open source Git extension for versioning large files. You can find more information on Git LFS in the Git LFS and VFS document . Working with large repositories When working with a very large repository of which you don't require all the files, you can use VFS for Git - an open source Git extension that virtualize the file system beneath your Git repository, so that you seem to work in a regular working directory but while VFS for Git only downloads objects as they are needed. You can find more information on VFS for Git in the Git LFS and VFS document . Tools Visual Studio Code is a cross-platform powerful source code editor with built in git commands. Within Visual Studio Code editor you can review diffs, stage changes, make commits, pull and push to your git repositories. You can refer to Visual Studio Code Git Support for documentation. Use a shell/terminal to work with Git commands instead of relying on GUI clients . If you're working on Windows, posh-git is a great PowerShell environment for Git. Another option is to use Git bash for Windows . On Linux/Mac, install git and use your favorite shell/terminal.","title":"Git Guidance"},{"location":"source-control/git-guidance/#git-guidance","text":"","title":"Git Guidance"},{"location":"source-control/git-guidance/#what-is-git","text":"Git is a distributed version control system. This means that - unlike SVN or CVS - it doesn't use a central server to synchronize. Instead, every participant has a local copy of the source-code, and the attached history that is kept in sync by comparing commit hashes (SHA hashes of changes between each git commit command) making up the latest version (called HEAD ). For example: repo 1: A -> B -> C -> D -> HEAD repo 2: A -> B -> HEAD repo 3: X -> Y -> Z -> HEAD repo 4: A -> J -> HEAD Since they share a common history, repo 1 and repo 2 can be synchronized fairly easily, repo 4 may be able to synchronize as well, but it's going to have to add a commit (J, and maybe a merge commit) to repo 1. Repo 3 cannot be easily synchronized with the others. Everything related to these commits is stored in a local .git directory in the root of the repository. In other words, by using Git you are simply creating immutable file histories that uniquely identify the current state and therefore allow sharing whatever comes after. It's a Merkle tree . Be sure to run git help after Git installation to find really in-depth explanations of everything.","title":"What is Git?"},{"location":"source-control/git-guidance/#installation","text":"Git is a tool set that must be installed. Install Git and follow the First-Time Git Setup . A recommended installation is the Git Lens extension for Visual Studio Code . Visualize code authorship at a glance via Git blame annotations and code lens, seamlessly navigate and explore Git repositories, gain valuable insights via powerful comparison commands, and so much more. You can use these commands as well to configure your Git for Visual Studio Code as an editor for merge conflicts and diff tool. git config --global user.name [YOUR FIRST AND LAST NAME] git config --global user.email [YOUR E-MAIL ADDRESS] git config --global merge.tool vscode git config --global mergetool.vscode.cmd \"code --wait $MERGED\" git config --global diff.tool vscode git config --global difftool.vscode.cmd \"code --wait --diff $LOCAL $REMOTE\"","title":"Installation"},{"location":"source-control/git-guidance/#basic-workflow","text":"A basic Git workflow is as follows; you can find more information on the specific steps below. # pull the latest changes git pull # start a new feature branch based on the develop branch git checkout -b feature/123-add-git-instructions develop # edit some files # add and commit the files git add <file> git commit -m \"add basic instructions\" # edit some files # add and commit the files git add <file> git commit -m \"add more advanced instructions\" # check your changes git status # push the branch to the remote repository git push --set-upstream origin feature/123-add-git-instructions","title":"Basic workflow"},{"location":"source-control/git-guidance/#cloning","text":"Whenever you want to make a change to a repository, you need to first clone it. Cloning a repository pulls down a full copy of all the repository data, so that you can work on it locally. This copy includes all versions of every file and folder for the project. git clone https://github.com/username/repo-name You only need to clone the repository the first time. Before any subsequent branches you can sync any changes from the remote repository using git pull .","title":"Cloning"},{"location":"source-control/git-guidance/#branching","text":"To avoid adding code that has not been peer reviewed to the main branch (ex. develop ) we typically work in feature branches, and merge these back to the main trunk with a Pull Request. It's even the case that often the main or develop branch of a repository are locked so that you can't make changes without a Pull Request. Therefore, it is useful to create a separate branch for your local/feature work, so that you can work and track your changes in this branch. Pull the latest changes and create a new branch for your work based on the trunk (in this case develop ). git pull git checkout -b feature/feature-name develop At any point, you can move between the branches with git checkout <branch> as long as you have committed or stashed your work. If you forget the name of your branch use git branch --all to list all branches.","title":"Branching"},{"location":"source-control/git-guidance/#committing","text":"To avoid losing work, it is good to commit often in small chunks. This allows you to revert only the last changes if you discover a problem and also neatly explains exactly what changes were made and why. Make changes to your branch Check what files were changed > git status On branch feature/271-basic-commit-info Changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git restore <file>...\" to discard changes in working directory) modified: source-control/git-guidance/README.md Track the files you wish to include in the commit. To track all modified files: git add --all Or to track only specific files: git add source-control/git-guidance/README.md Commit the changes to your local branch with a descriptive commit message git commit -m \"add basic git instructions\"","title":"Committing"},{"location":"source-control/git-guidance/#pushing","text":"When you are done working, push your changes to a branch in the remote repository using: git push The first time you push, you first need to set an upstream branch as follows. After the first push, the --set-upstream parameter and branch name are not needed anymore. git push --set-upstream origin feature/feature-name Once the feature branch is pushed to the remote repository, it is visible to anyone with access to the code.","title":"Pushing"},{"location":"source-control/git-guidance/#merging","text":"We encourage the use of Pull Request to merge code to the main repository to make sure that all code in the final product is code reviewed The Pull Request (PR) process in Azure DevOps , GitHub and other similar tools make it easy both to start a PR, review a PR and merge a PR.","title":"Merging"},{"location":"source-control/git-guidance/#merge-conflicts","text":"If multiple people make changes to the same files, you may need to resolve any conflicts that have occurred before you can merge. # check out the develop branch and get the latest changes git checkout develop git pull # check out your branch git checkout <your branch> # merge the develop branch into your branch git merge develop # if merge conflicts occur, above command will fail with a message telling you that there are conflicts to be solved # find which files need to be resolved git status You can start an interactive process that will show which files have conflicts. Sometimes you removed a file, where it was changed in dev. Or you made changes to some lines in a file where another developer made changes as well. If you went through the installation steps mentioned before, Visual Studio Code is set up as merge tool. You can also use a merge tool like kdiff3 . When editing conflicts occur, the process will automatically open Visual Studio Code where the conflicting parts are highlighted in green and blue, and you have make a choice: Accept your changes (current) Accept the changes from dev branch (incoming) Accept them both and fix the code (probably needed) Here are lines that are either unchanged from the common ancestor, or cleanly resolved because only one side changed. <<<<<<< yours:sample.txt Conflict resolution is hard; let's go shopping. ======= Git makes conflict resolution easy. >>>>>>> theirs:sample.txt And here is another line that is cleanly resolved or unmodified When this process is completed, make sure you test the result by executing build, checks, test to validate this merged result. # conclude the merge git merge --continue # verify that everything went ok git log # push the changes to the remote branch git push If no other conflicts appear, the PR can now be merged, and your branch deleted. Use squash to reduce your changes into a single commit, so the commit history can be within an acceptable size.","title":"Merge Conflicts"},{"location":"source-control/git-guidance/#stashing-changes","text":"git stash is super handy if you have un-committed changes in your working directory, but you want to work on a different branch. You can run git stash , save the un-committed work, and revert to the HEAD commit. You can retrieve the saved changes by running git stash pop : git stash \u2026 git stash pop Or you can move the current state into a new branch: git stash branch <new_branch_to_save_changes>","title":"Stashing changes"},{"location":"source-control/git-guidance/#recovering-lost-commits","text":"If you \"lost\" a commit that you want to return to, for example to revert a git rebase where your commits got squashed, you can use git reflog to find the commit: git reflog Then you can use the reflog reference ( HEAD@{} ) to reset to a specific commit before the rebase: git reset HEAD@{2}","title":"Recovering lost commits"},{"location":"source-control/git-guidance/#commit-best-practices","text":"A commit combines changes into a logical unit. Adding a descriptive commit message can aid in comprehending the code changes and understanding the rationale behind the modifications. Consider the following when making your commits: Make small commits. This makes changes easier to review, and if we need to revert a commit, we lose less work. Consider splitting the commit into separate commits with git add -p if it includes more than one logical change or bug fix. Don't mix whitespace changes with functional code changes. It is hard to determine if the line has a functional change or only removes a whitespace, so functional changes may go unnoticed. Commit complete and well tested code. Never commit incomplete code, get in the habit of testing your code before committing. Write good commit messages. Why is it necessary? It may fix a bug, add a feature, improve performance, or just be a change for the sake of correctness What effects does this change have? In addition to the obvious ones, this may include benchmarks, side effects etc. You can specify the default git editor, which allows you to write your commit messages using your favorite editor. The following command makes Visual Studio Code your default git editor: git config --global core.editor \"code --wait\"","title":"Commit Best Practices"},{"location":"source-control/git-guidance/#commit-message-structure","text":"The essential parts of a commit message are: * subject line: a short description of the commit, maximum 50 characters long * body (optional): a longer description of the commit, wrapped at 72 characters, separated from the subject line by a blank line You are free to structure commit messages; however, git commands like git log utilize above structure. Therefore, it can be helpful to follow a convention within your team and to utilize git best. For example, Conventional Commits is a lightweight convention that complements SemVer , by describing the features, fixes, and breaking changes made in commit messages. See Component Versioning for more information on versioning. For more information on commit message conventions, see: A Note About Git Commit Messages Conventional Commits Git commit best practices How to Write a Git Commit Message How to Write Better Git Commit Messages Information in commit messages On commit messages","title":"Commit Message Structure"},{"location":"source-control/git-guidance/#managing-remotes","text":"A local git repository can have one or more backing remote repositories. You can list the remote repositories using git remote - by default, the remote repository you cloned from will be called origin > git remote -v origin https://github.com/microsoft/code-with-engineering-playbook.git (fetch) origin https://github.com/microsoft/code-with-engineering-playbook.git (push)","title":"Managing remotes"},{"location":"source-control/git-guidance/#working-with-forks","text":"You can set multiple remotes. This is useful for example if you want to work with a forked version of the repository. For more info on how to set upstream remotes and syncing repositories when working with forks see GitHub's Working with forks documentation .","title":"Working with forks"},{"location":"source-control/git-guidance/#updating-the-remote-if-a-repository-changes-names","text":"If the repository is changed in some way, for example a name change, or if you want to switch between HTTPS and SSH you need to update the remote # list the existing remotes > git remote -v origin https://hostname/username/repository-name.git (fetch) origin https://hostname/username/repository-name.git (push) # change the remote url git remote set-url origin https://hostname/username/new-repository-name.git # verify that the remote URL has changed > git remote -v origin https://hostname/username/new-repository-name.git (fetch) origin https://hostname/username/new-repository-name.git (push)","title":"Updating the remote if a repository changes names"},{"location":"source-control/git-guidance/#rolling-back-changes","text":"","title":"Rolling back changes"},{"location":"source-control/git-guidance/#reverting-and-deleting-commits","text":"To \"undo\" a commit, run the following two commands: git revert and git reset . git revert creates a new commit that undoes commits while git reset allows deleting commits entirely from the commit history. If you have committed secrets/keys, git reset will remove them from the commit history! To delete the latest commit use HEAD~ : git reset --hard HEAD~1 To delete commits back to a specific commit, use the respective commit id: git reset --hard <sha1-commit-id> after you deleted the unwanted commits, push using force : git push origin HEAD --force Interactive rebase for undoing commits: git rebase -i HEAD~N The above command will open an interactive session in an editor (for example vim) with the last N commits sorted from oldest to newest. To undo a commit, delete the corresponding line of the commit and save the file. Git will rewrite the commits in the order listed in the file and because one (or many) commits were deleted, the commit will no longer be part of the history. Running rebase will locally modify the history, after this one can use force to push the changes to remote without the deleted commit.","title":"Reverting and deleting commits"},{"location":"source-control/git-guidance/#using-submodules","text":"Submodules can be useful in more complex deployment and/or development scenarios Adding a submodule to your repo git submodule add -b master <your_submodule> Initialize and pull a repo with submodules: git submodule init git submodule update --init --remote git submodule foreach git checkout master git submodule foreach git pull origin","title":"Using submodules"},{"location":"source-control/git-guidance/#working-with-images-video-and-other-binary-content","text":"Avoid committing frequently changed binary files, such as large images, video or compiled code to your git repository. Binary content is not diffed like text content, so cloning or pulling from the repository may pull each revision of the binary file. One solution to this problem is Git LFS (Git Large File Storage) - an open source Git extension for versioning large files. You can find more information on Git LFS in the Git LFS and VFS document .","title":"Working with images, video and other binary content"},{"location":"source-control/git-guidance/#working-with-large-repositories","text":"When working with a very large repository of which you don't require all the files, you can use VFS for Git - an open source Git extension that virtualize the file system beneath your Git repository, so that you seem to work in a regular working directory but while VFS for Git only downloads objects as they are needed. You can find more information on VFS for Git in the Git LFS and VFS document .","title":"Working with large repositories"},{"location":"source-control/git-guidance/#tools","text":"Visual Studio Code is a cross-platform powerful source code editor with built in git commands. Within Visual Studio Code editor you can review diffs, stage changes, make commits, pull and push to your git repositories. You can refer to Visual Studio Code Git Support for documentation. Use a shell/terminal to work with Git commands instead of relying on GUI clients . If you're working on Windows, posh-git is a great PowerShell environment for Git. Another option is to use Git bash for Windows . On Linux/Mac, install git and use your favorite shell/terminal.","title":"Tools"},{"location":"source-control/git-guidance/git-lfs-and-vfs/","text":"Using Git LFS and VFS for Git introduction Git LFS and VFS for Git are solutions for using Git with (large) binary files and large source trees. Git LFS Git is very good and keeping track of changes in text-based files like code, but it is not that good at tracking binary files. For instance, if you store a Photoshop image file (PSD) in a repository, with every change, the complete file is stored again in the history. This can make the history of the Git repo very large, which makes a clone of the repository more and more time-consuming. A solution to work with binary files is using Git LFS (or Git Large File System). This is an extension to Git and must be installed separately, and it can only be used with a repository platform that supports LFS. GitHub.com and Azure DevOps for instance are platforms that have support for LFS. The way it works in short, is that a placeholder file is stored in the repo with information for the LFS system. It looks something like this: version https://git-lfs.github.com/spec/v1 oid a747cfbbef63fc0a3f5ffca332ae486ee7bf77c1d1b9b2de02e261ef97d085fe size 4923023 The actual file is stored in a separate storage. This way Git will track changes in this placeholder file, not the large file. The combination of using Git and Git LFS will hide this from the developer though. You will just work with the repository and files as before. When working with these large files yourself, you'll still see the Git history grown on your own machine, as Git will still start tracking these large files locally, but when you clone the repo, the history is actually pretty small. So it's beneficial for others not working directly on the large files. Pros of Git LFS Uses the end to end Git workflow for all files Git LFS supports file locking to avoid conflicts for undiffable assets Git LFS is fully supported in Azure DevOps Services Cons of Git LFS Everyone who contributes to the repository needs to install Git LFS If not set up properly: Binary files committed through Git LFS are not visible as Git will only download the data describing the large file Committing large binaries will push the full binary to the repository Git cannot merge the changes from two different versions of a binary file; file locking mitigates this Azure Repos do not support using SSH for repositories with Git LFS tracked files - for more information see the Git LFS authentication documentation Installation and use of Git LFS Go to https://git-lfs.github.com and download and install the setup from there. For every repository you want to use LFS, you have to go through these steps: Setup LFS for the repo: git lfs install Indicate which files have to be considered as large files (or binary files). As an example, to consider all Photoshop files to be large: git lfs track \"*.psd\" There are more fine-grained ways to indicate files in a folder and more. See the Git LFS Documentation . With these commands a .gitattribute file is created which contains these settings and must be part of the repository. From here on you just use the standard Git commands to work in the repository. The rest will be handled by Git and Git LFS. Common LFS commands Install Git LFS git lfs install # windows sudo apt-get git-lfs # linux See the Git LFS installation instructions for installation on other systems Track .mp4 files with Git LFS git lfs track '*.mp4' Update the .gitattributes file listing the files and patterns to track *.mp4 filter = lfs diff = lfs merge = lfs -text docs/images/* filter = lfs diff = lfs merge = lfs -text List all patterns tracked git lfs track List all files tracked git lfs ls-files Download files to your working directory git lfs pull git lfs pull --include = \"path/to/file\" VFS for Git Imagine a large repository containing multiple projects, ex. one per feature. As a developer you may only be working on some features, and thus you don't want to download all the projects in the repo. By default, with Git however, cloning the repository means you will download all files/projects. VFS for Git (or Virtual File System for Git) solves this problem, as it will only download what you need to your local machine, but if you look in the file system, e.g. with Windows Explorer, it will show all the folders and files including the correct file sizes. The Git platform must support GVFS to make this work. GitHub.com and Azure DevOps both support this out of the box. Installation and use of VFS for Git Microsoft create VFS for Git and made it open source. It can be found at https://github.com/microsoft/VFSForGit . It's only available for Windows. The necessary installers can be found at https://github.com/Microsoft/VFSForGit/releases On the releases page you'll find two important downloads: Git 2.28.0.0 installer, which is a requirement for running VFS for Git. This is not the same as the standard Git for Windows install! SetupGVFS installer. Download those files and install them on your machine. To be able to use VFS for Git for a repository, a .gitattributes file needs to be added to the repo with this line in it: * -text To clone a repository to your machine using VFS for Git you use gvfs instead of git like so: gvfs clone [ URL ] [ dir ] Once this is done, you have a folder which contains a src folder which contains the contents of the repository. This is done because of a practice to put all outputs of build systems outside this tree. This makes it easier to manage .gitignore files and to keep Git performant with lots of files. For working with the repository you just use Git commands as before. To remove a VFS for Git repository from your machine, make sure the VFS process is stopped and execute this command from the main folder: gvfs unmount This will stop the process and unregister it, after that you can safely remove the folder. References Git LFS getting started Git LFS manual Git LFS on Azure Repos","title":"Using Git LFS and VFS for Git introduction"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#using-git-lfs-and-vfs-for-git-introduction","text":"Git LFS and VFS for Git are solutions for using Git with (large) binary files and large source trees.","title":"Using Git LFS and VFS for Git introduction"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#git-lfs","text":"Git is very good and keeping track of changes in text-based files like code, but it is not that good at tracking binary files. For instance, if you store a Photoshop image file (PSD) in a repository, with every change, the complete file is stored again in the history. This can make the history of the Git repo very large, which makes a clone of the repository more and more time-consuming. A solution to work with binary files is using Git LFS (or Git Large File System). This is an extension to Git and must be installed separately, and it can only be used with a repository platform that supports LFS. GitHub.com and Azure DevOps for instance are platforms that have support for LFS. The way it works in short, is that a placeholder file is stored in the repo with information for the LFS system. It looks something like this: version https://git-lfs.github.com/spec/v1 oid a747cfbbef63fc0a3f5ffca332ae486ee7bf77c1d1b9b2de02e261ef97d085fe size 4923023 The actual file is stored in a separate storage. This way Git will track changes in this placeholder file, not the large file. The combination of using Git and Git LFS will hide this from the developer though. You will just work with the repository and files as before. When working with these large files yourself, you'll still see the Git history grown on your own machine, as Git will still start tracking these large files locally, but when you clone the repo, the history is actually pretty small. So it's beneficial for others not working directly on the large files.","title":"Git LFS"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#pros-of-git-lfs","text":"Uses the end to end Git workflow for all files Git LFS supports file locking to avoid conflicts for undiffable assets Git LFS is fully supported in Azure DevOps Services","title":"Pros of Git LFS"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#cons-of-git-lfs","text":"Everyone who contributes to the repository needs to install Git LFS If not set up properly: Binary files committed through Git LFS are not visible as Git will only download the data describing the large file Committing large binaries will push the full binary to the repository Git cannot merge the changes from two different versions of a binary file; file locking mitigates this Azure Repos do not support using SSH for repositories with Git LFS tracked files - for more information see the Git LFS authentication documentation","title":"Cons of Git LFS"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#installation-and-use-of-git-lfs","text":"Go to https://git-lfs.github.com and download and install the setup from there. For every repository you want to use LFS, you have to go through these steps: Setup LFS for the repo: git lfs install Indicate which files have to be considered as large files (or binary files). As an example, to consider all Photoshop files to be large: git lfs track \"*.psd\" There are more fine-grained ways to indicate files in a folder and more. See the Git LFS Documentation . With these commands a .gitattribute file is created which contains these settings and must be part of the repository. From here on you just use the standard Git commands to work in the repository. The rest will be handled by Git and Git LFS.","title":"Installation and use of Git LFS"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#common-lfs-commands","text":"Install Git LFS git lfs install # windows sudo apt-get git-lfs # linux See the Git LFS installation instructions for installation on other systems Track .mp4 files with Git LFS git lfs track '*.mp4' Update the .gitattributes file listing the files and patterns to track *.mp4 filter = lfs diff = lfs merge = lfs -text docs/images/* filter = lfs diff = lfs merge = lfs -text List all patterns tracked git lfs track List all files tracked git lfs ls-files Download files to your working directory git lfs pull git lfs pull --include = \"path/to/file\"","title":"Common LFS commands"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#vfs-for-git","text":"Imagine a large repository containing multiple projects, ex. one per feature. As a developer you may only be working on some features, and thus you don't want to download all the projects in the repo. By default, with Git however, cloning the repository means you will download all files/projects. VFS for Git (or Virtual File System for Git) solves this problem, as it will only download what you need to your local machine, but if you look in the file system, e.g. with Windows Explorer, it will show all the folders and files including the correct file sizes. The Git platform must support GVFS to make this work. GitHub.com and Azure DevOps both support this out of the box.","title":"VFS for Git"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#installation-and-use-of-vfs-for-git","text":"Microsoft create VFS for Git and made it open source. It can be found at https://github.com/microsoft/VFSForGit . It's only available for Windows. The necessary installers can be found at https://github.com/Microsoft/VFSForGit/releases On the releases page you'll find two important downloads: Git 2.28.0.0 installer, which is a requirement for running VFS for Git. This is not the same as the standard Git for Windows install! SetupGVFS installer. Download those files and install them on your machine. To be able to use VFS for Git for a repository, a .gitattributes file needs to be added to the repo with this line in it: * -text To clone a repository to your machine using VFS for Git you use gvfs instead of git like so: gvfs clone [ URL ] [ dir ] Once this is done, you have a folder which contains a src folder which contains the contents of the repository. This is done because of a practice to put all outputs of build systems outside this tree. This makes it easier to manage .gitignore files and to keep Git performant with lots of files. For working with the repository you just use Git commands as before. To remove a VFS for Git repository from your machine, make sure the VFS process is stopped and execute this command from the main folder: gvfs unmount This will stop the process and unregister it, after that you can safely remove the folder.","title":"Installation and use of VFS for Git"},{"location":"source-control/git-guidance/git-lfs-and-vfs/#references","text":"Git LFS getting started Git LFS manual Git LFS on Azure Repos","title":"References"},{"location":"user-interface-engineering/","text":"User Interface and User Experience Engineering Also known as UI/UX , Front End Development , or Web Development , user interface and user experience engineering is a broad topic and encompasses many different aspects of modern application development. When a user interface is required, ISE primarily develops a web application . Web apps can be built in a variety of ways with many different tools. Goal The goal of the User Interface section is to provide guidance on developing web applications. Everyone should begin by reading the General Guidance for a quick introduction to the four main aspects of every web application project. From there, readers are encouraged to dive deeper into each topic, or begin reviewing technical guidance that pertains to their engagement. All UI/UX projects should begin with a detailed design document. Review the Design Process section for more details, and a template to get started. Keep in mind that like all software, there is no \"right way\" to build a user interface application. Leverage and trust your team's or your customer's experience and expertise for the best development experience. General Guidance The state of web platform engineering is fast moving. There is no one-size-fits-all solution. For any team to be successful in building a UI, they need to have an understanding of the higher-level aspects of all UI project. Accessibility - ensuring your application is usable and enjoyed by as many people as possible is at the heart of accessibility and inclusive design. Usability - how effortless should it be for any given user to use the application? Do they need special training or a document to understand how to use it, or will it be intuitive? Maintainability - is the application just a proof of concept to showcase an idea for future work, or will it be an MVP and act as the starting point for a larger, production-ready application? Sometimes you don't need React or any other framework. Sometimes you need React, but not all the bells and whistles from create-react-app. Understanding project maintainability requirements can simplify an engagement\u2019s tooling needs significantly and let folks iterate without headaches. Stability - what is the cost of adding a dependency? Is it actively stable/updated/maintained? If not, can you afford the tech debt (sometimes the answer can be yes!)? Could you get 90% of the way there without adding another dependency? More information is available for each general guidance section in the corresponding pages. Design Process All user interface applications begin with the design process. The true definition for \"the design process\" is ever changing and highly opinion based as well. This sections aims to deliver a general overview of a design process any engineering team could conduct when starting an UI application engagement. When committing to a UI/UX project, be certain to not over-promise on the web application requirements. Delivering a production-ready application involves a large number of engineering complexities resulting in a very long timeline. Always start with a proof-of-concept or minimum-viable-product first. These projects can easily be achieved within a couple month timeline (and sometimes even less). The first step in the design process is to understand the problem at hand and outline what the solution should achieve. Commonly referred to as Desired Outcomes , the output of this first step should be a generalized list of outcomes that the solution will accomplish. Consider the following example: A public library has a set of data containing information about its collection. The data stores text, images, and the status of a book (borrowed, available, reserved). The library librarian wants to share this data with its users. As the librarian, I want to notify users before they receive late penalties for overdue books As the librarian, I want to notify users when a book they have reserved becomes available With the desired outcomes in mind, the next step in the design process is to define user personas. Regardless of the solution for a given problem, understanding the user needs leads to a better understanding of feature development and technological choices. Personas are written as prose-like paragraphs that describe different types of users. Considering the previous example, the various user personas could be: An individual with no disabilities, but is unfamiliar with using software interfaces An individual with no disabilities, and is familiar with using software interfaces An individual with disabilities, and is unfamiliar with using software interfaces (with or without the use of accessibility tooling) An individual with disabilities, but familiar with using software interfaces through the use of accessibility tooling After defining these personas it is clear that whatever the solution is, it requires a lot of accessibility and user experience design work. Sometimes personas can be simpler than this, but always include disabled users . Even when a user set is predefined as a group of individuals without disabilities, there is no guarantee that the user set will remain that way. After defining the desired outcomes as well as the personas , the next step in the design process is to begin conducting Trade Studies for potential solutions. The first trade study should be high-level and solution oriented. It will utilize the results of previous steps and propose multiple solutions for achieving the desired outcomes with the listed personas in mind. Continuing with the library example, this first trade study may compare various application solutions such as automated emails or text messages, an RSS feed, or an user interface application. There are pros and cons for each solution both from an user experience and a developer experience perspective, but at this stage it is important to focus on the users. After arriving on the best solution, the next trade study can dive into different implementation methods. It is in this subsequent trade studies that developer experience becomes more important. The benefit of building software applications is that there are truly infinite ways to build something. A team can use the latest shiny tools, or they can utilize the tried-and-tested ones. It is for this reason that focussing completely on the user until a solution is defined is better than obsessing over technology choices. Within ISE, we often reach for tools such as the React framework. React is a great tool when wielded by an experienced team. Otherwise, it can create more hurdles than it is worth. Keep in mind that even if you feel capable with React, the rest of your team and your customer's dev team needs to as well. Some other great options to consider when building a proof-of-concept or minimum-viable-product are: HTML/CSS/JavaScript Back to the basics! Start with a single index.html , include a popular CSS framework such as Bootstrap using their CDN link, and start prototyping! Rarely will you have to support legacy browsers; thus, you can rely on modern JavaScript language features! No need for build tools or even TypeScript (did you know you can type check JavaScript ). Web Component frameworks Web Components are now standardized in all modern browsers Microsoft has their own, stable & actively-maintained framework, Fast For more information of choosing the right implementation tool, read the Recommended Technologies document. Continue reading the Trade Study section of this site for more information on completing this step in the design process. After iterating through multiple trade study documents, this design process can be considered complete! With an agreed upon solution and implementation in mind, it is now time to begin development. A natural continuation of the design process is to get users (or stakeholders) involved as early as possible. Constantly look for design and usability feedback, and utilize this to improve the application as it is being developed. Example Coming soon!","title":"User Interface and User Experience Engineering"},{"location":"user-interface-engineering/#user-interface-and-user-experience-engineering","text":"Also known as UI/UX , Front End Development , or Web Development , user interface and user experience engineering is a broad topic and encompasses many different aspects of modern application development. When a user interface is required, ISE primarily develops a web application . Web apps can be built in a variety of ways with many different tools.","title":"User Interface and User Experience Engineering"},{"location":"user-interface-engineering/#goal","text":"The goal of the User Interface section is to provide guidance on developing web applications. Everyone should begin by reading the General Guidance for a quick introduction to the four main aspects of every web application project. From there, readers are encouraged to dive deeper into each topic, or begin reviewing technical guidance that pertains to their engagement. All UI/UX projects should begin with a detailed design document. Review the Design Process section for more details, and a template to get started. Keep in mind that like all software, there is no \"right way\" to build a user interface application. Leverage and trust your team's or your customer's experience and expertise for the best development experience.","title":"Goal"},{"location":"user-interface-engineering/#general-guidance","text":"The state of web platform engineering is fast moving. There is no one-size-fits-all solution. For any team to be successful in building a UI, they need to have an understanding of the higher-level aspects of all UI project. Accessibility - ensuring your application is usable and enjoyed by as many people as possible is at the heart of accessibility and inclusive design. Usability - how effortless should it be for any given user to use the application? Do they need special training or a document to understand how to use it, or will it be intuitive? Maintainability - is the application just a proof of concept to showcase an idea for future work, or will it be an MVP and act as the starting point for a larger, production-ready application? Sometimes you don't need React or any other framework. Sometimes you need React, but not all the bells and whistles from create-react-app. Understanding project maintainability requirements can simplify an engagement\u2019s tooling needs significantly and let folks iterate without headaches. Stability - what is the cost of adding a dependency? Is it actively stable/updated/maintained? If not, can you afford the tech debt (sometimes the answer can be yes!)? Could you get 90% of the way there without adding another dependency? More information is available for each general guidance section in the corresponding pages.","title":"General Guidance"},{"location":"user-interface-engineering/#design-process","text":"All user interface applications begin with the design process. The true definition for \"the design process\" is ever changing and highly opinion based as well. This sections aims to deliver a general overview of a design process any engineering team could conduct when starting an UI application engagement. When committing to a UI/UX project, be certain to not over-promise on the web application requirements. Delivering a production-ready application involves a large number of engineering complexities resulting in a very long timeline. Always start with a proof-of-concept or minimum-viable-product first. These projects can easily be achieved within a couple month timeline (and sometimes even less). The first step in the design process is to understand the problem at hand and outline what the solution should achieve. Commonly referred to as Desired Outcomes , the output of this first step should be a generalized list of outcomes that the solution will accomplish. Consider the following example: A public library has a set of data containing information about its collection. The data stores text, images, and the status of a book (borrowed, available, reserved). The library librarian wants to share this data with its users. As the librarian, I want to notify users before they receive late penalties for overdue books As the librarian, I want to notify users when a book they have reserved becomes available With the desired outcomes in mind, the next step in the design process is to define user personas. Regardless of the solution for a given problem, understanding the user needs leads to a better understanding of feature development and technological choices. Personas are written as prose-like paragraphs that describe different types of users. Considering the previous example, the various user personas could be: An individual with no disabilities, but is unfamiliar with using software interfaces An individual with no disabilities, and is familiar with using software interfaces An individual with disabilities, and is unfamiliar with using software interfaces (with or without the use of accessibility tooling) An individual with disabilities, but familiar with using software interfaces through the use of accessibility tooling After defining these personas it is clear that whatever the solution is, it requires a lot of accessibility and user experience design work. Sometimes personas can be simpler than this, but always include disabled users . Even when a user set is predefined as a group of individuals without disabilities, there is no guarantee that the user set will remain that way. After defining the desired outcomes as well as the personas , the next step in the design process is to begin conducting Trade Studies for potential solutions. The first trade study should be high-level and solution oriented. It will utilize the results of previous steps and propose multiple solutions for achieving the desired outcomes with the listed personas in mind. Continuing with the library example, this first trade study may compare various application solutions such as automated emails or text messages, an RSS feed, or an user interface application. There are pros and cons for each solution both from an user experience and a developer experience perspective, but at this stage it is important to focus on the users. After arriving on the best solution, the next trade study can dive into different implementation methods. It is in this subsequent trade studies that developer experience becomes more important. The benefit of building software applications is that there are truly infinite ways to build something. A team can use the latest shiny tools, or they can utilize the tried-and-tested ones. It is for this reason that focussing completely on the user until a solution is defined is better than obsessing over technology choices. Within ISE, we often reach for tools such as the React framework. React is a great tool when wielded by an experienced team. Otherwise, it can create more hurdles than it is worth. Keep in mind that even if you feel capable with React, the rest of your team and your customer's dev team needs to as well. Some other great options to consider when building a proof-of-concept or minimum-viable-product are: HTML/CSS/JavaScript Back to the basics! Start with a single index.html , include a popular CSS framework such as Bootstrap using their CDN link, and start prototyping! Rarely will you have to support legacy browsers; thus, you can rely on modern JavaScript language features! No need for build tools or even TypeScript (did you know you can type check JavaScript ). Web Component frameworks Web Components are now standardized in all modern browsers Microsoft has their own, stable & actively-maintained framework, Fast For more information of choosing the right implementation tool, read the Recommended Technologies document. Continue reading the Trade Study section of this site for more information on completing this step in the design process. After iterating through multiple trade study documents, this design process can be considered complete! With an agreed upon solution and implementation in mind, it is now time to begin development. A natural continuation of the design process is to get users (or stakeholders) involved as early as possible. Constantly look for design and usability feedback, and utilize this to improve the application as it is being developed.","title":"Design Process"},{"location":"user-interface-engineering/#example","text":"Coming soon!","title":"Example"},{"location":"user-interface-engineering/maintainability/","text":"Maintainability Coming soon!","title":"Maintainability"},{"location":"user-interface-engineering/maintainability/#maintainability","text":"Coming soon!","title":"Maintainability"},{"location":"user-interface-engineering/recommended-technologies/","text":"Recommended Technologies The purpose of this page is to review the commonly selected technology options when developing user interface applications. To reiterate from the general guidance section: Keep in mind that like all software, there is no \"right way\" to build a user interface application. Leverage and trust your team's or your customer's experience and expertise for the best development experience. Additionally, while some of these technologies are presented as alternate options, many can be combined together. For example, you can use React in a basic HTML/CSS/JS workflow by inline-importing React along with Babel. See the Add React to a Website for more details. Similarly, any Fast web component can be integrated into any existing React application . And of course, every JavaScript technology can also be used with TypeScript! TypeScript TypeScript is JavaScript with syntax for types. TypeScript is a strongly typed programming language that builds on JavaScript, giving you better tooling at any scale. typescriptlang.org TypeScript is highly recommended for all new web application projects. The stability it provides for teams is unmatched, and can make it easier for folks with C# backgrounds to work with web technologies. There are many ways to integrate TypeScript into a web application. The easiest way to get started is by reviewing the TypeScript Tooling in 5 Minutes guide from the official TypeScript docs. The other sections on this page contain information regarding integration with TypeScript. React React is a framework developed and maintained by Facebook. React is used throughout Microsoft and has a vast open source community. Documentation & Recommended Resources One can expect to find a multitude of guides, answers, and posts on how to work with React; don't take everything at face value. The best place to review React concepts is the React documentation. From there, you can review articles from various sources such as React Community Articles , Kent C Dodd's Blog , CSS Tricks Articles , and Awesome React . The React API has changed dramatically over time. Older resources may contain solutions or patterns that have since been changed and improved upon. Modern React development uses the React Hooks pattern. Rarely will you have to implement something using React Class pattern. If you're reading an article/answer/docs that instruct you to use the class pattern you may be looking at an out-of-date resource. Bootstrapping There are many different ways to bootstrap a React application. Two great tool sets to use are create-react-app and vite . create-react-app From Adding TypeScript npx create-react-app my-app --template typescript Vite From Scaffolding your First Vite Project # npm 6.x npm init vite@latest my-app --template react-ts # npm 7.x npm init vite@latest my-app -- --template react-ts HTML/CSS/JS Coming soon! Web Components Coming soon!","title":"Recommended Technologies"},{"location":"user-interface-engineering/recommended-technologies/#recommended-technologies","text":"The purpose of this page is to review the commonly selected technology options when developing user interface applications. To reiterate from the general guidance section: Keep in mind that like all software, there is no \"right way\" to build a user interface application. Leverage and trust your team's or your customer's experience and expertise for the best development experience. Additionally, while some of these technologies are presented as alternate options, many can be combined together. For example, you can use React in a basic HTML/CSS/JS workflow by inline-importing React along with Babel. See the Add React to a Website for more details. Similarly, any Fast web component can be integrated into any existing React application . And of course, every JavaScript technology can also be used with TypeScript!","title":"Recommended Technologies"},{"location":"user-interface-engineering/recommended-technologies/#typescript","text":"TypeScript is JavaScript with syntax for types. TypeScript is a strongly typed programming language that builds on JavaScript, giving you better tooling at any scale. typescriptlang.org TypeScript is highly recommended for all new web application projects. The stability it provides for teams is unmatched, and can make it easier for folks with C# backgrounds to work with web technologies. There are many ways to integrate TypeScript into a web application. The easiest way to get started is by reviewing the TypeScript Tooling in 5 Minutes guide from the official TypeScript docs. The other sections on this page contain information regarding integration with TypeScript.","title":"TypeScript"},{"location":"user-interface-engineering/recommended-technologies/#react","text":"React is a framework developed and maintained by Facebook. React is used throughout Microsoft and has a vast open source community.","title":"React"},{"location":"user-interface-engineering/recommended-technologies/#documentation-recommended-resources","text":"One can expect to find a multitude of guides, answers, and posts on how to work with React; don't take everything at face value. The best place to review React concepts is the React documentation. From there, you can review articles from various sources such as React Community Articles , Kent C Dodd's Blog , CSS Tricks Articles , and Awesome React . The React API has changed dramatically over time. Older resources may contain solutions or patterns that have since been changed and improved upon. Modern React development uses the React Hooks pattern. Rarely will you have to implement something using React Class pattern. If you're reading an article/answer/docs that instruct you to use the class pattern you may be looking at an out-of-date resource.","title":"Documentation &amp; Recommended Resources"},{"location":"user-interface-engineering/recommended-technologies/#bootstrapping","text":"There are many different ways to bootstrap a React application. Two great tool sets to use are create-react-app and vite .","title":"Bootstrapping"},{"location":"user-interface-engineering/recommended-technologies/#create-react-app","text":"From Adding TypeScript npx create-react-app my-app --template typescript","title":"create-react-app"},{"location":"user-interface-engineering/recommended-technologies/#vite","text":"From Scaffolding your First Vite Project # npm 6.x npm init vite@latest my-app --template react-ts # npm 7.x npm init vite@latest my-app -- --template react-ts","title":"Vite"},{"location":"user-interface-engineering/recommended-technologies/#htmlcssjs","text":"Coming soon!","title":"HTML/CSS/JS"},{"location":"user-interface-engineering/recommended-technologies/#web-components","text":"Coming soon!","title":"Web Components"},{"location":"user-interface-engineering/stability/","text":"Stability Coming soon!","title":"Stability"},{"location":"user-interface-engineering/stability/#stability","text":"Coming soon!","title":"Stability"},{"location":"user-interface-engineering/usability/","text":"Usability Coming soon!","title":"Usability"},{"location":"user-interface-engineering/usability/#usability","text":"Coming soon!","title":"Usability"}]}